{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb0dc71-79d7-4fee-ba31-4881d6e9e398",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0958c46-a9ed-46ae-aab8-f2b65bccff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1426/2258311576.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = pd.concat([df, df_raw.iloc[:, 63:65].fillna(method='ffill').diff(1)], axis=1)\n",
      "/tmp/ipykernel_1426/2258311576.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = pd.concat([df, df_raw.iloc[:, 65:].fillna(method='ffill').diff(1)], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIBOR_2Y-FR007_2Y 前端缺失，已删除。\n",
      "TL当季价格 前端缺失，已删除。\n",
      "TL下季价格 前端缺失，已删除。\n",
      "TL成交量 前端缺失，已删除。\n",
      "TL持仓量 前端缺失，已删除。\n",
      "TL跨期价差 前端缺失，已删除。\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1783 entries, 2019-01-03 to 2025-08-28\n",
      "Columns: 189 entries, 同业存单_1Y-FR007_1Y to 永续债_7Y-二级资本债_7Y\n",
      "dtypes: float64(189)\n",
      "memory usage: 2.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_excel('全因子.xlsx')\n",
    "df_raw.set_index('date', inplace=True)\n",
    "#df_raw = df_raw.loc[df_raw.index > '2021-08-13']#永续回测需要\n",
    "\n",
    "df = pd.DataFrame(index=df_raw.index)\n",
    "\n",
    "# 0:63 直接差分（保持原逻辑）\n",
    "df = pd.concat([df, df_raw.iloc[:, 0:63].diff(1)], axis=1)\n",
    "\n",
    "# 63:65 先前向填充再差分（保持原逻辑）\n",
    "df = pd.concat([df, df_raw.iloc[:, 63:65].fillna(method='ffill').diff(1)], axis=1)\n",
    "\n",
    "# 65: 之后 —— 改为先前向填充再差分（这是唯一改动）\n",
    "df = pd.concat([df, df_raw.iloc[:, 65:].fillna(method='ffill').diff(1)], axis=1)\n",
    "\n",
    "# 行/列缺失清理\n",
    "df = df.dropna(thresh=df.shape[1] / 2)  # 删除一行超过一半 NaN（周末等）\n",
    "for col in df.columns:  # 删除 NaN 过多的列\n",
    "    if df[col].isnull().sum() > df.shape[0] / 2:\n",
    "        print(col, '前端缺失，已删除。')\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "\n",
    "# 转数值 + 异常值置 NaN + 线性插补\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "    # z-score 绝对值大于 5 判定为异常\n",
    "    df[col] = df[col].apply(lambda x: np.nan if abs((x - df[col].mean()) / df[col].std()) > 5 else x)\n",
    "    df[col] = df[col].interpolate(method='linear', axis=0)\n",
    "    \n",
    "df.fillna(0, inplace=True)\n",
    "df_clean = df.dropna()\n",
    "print(df_clean.info())\n",
    "\n",
    "# 标签：下一期 Δ(二级5yYTM) 是否 > 0\n",
    "df_clean['value_sort'] = df_clean['二级5yYTM'].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "df_clean = df_clean.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97087b2-cc5f-41e1-95d1-9036b9814abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIBOR_2Y-FR007_2Y 前端缺失，已删除。\n",
      "TL当季价格 前端缺失，已删除。\n",
      "TL下季价格 前端缺失，已删除。\n",
      "TL成交量 前端缺失，已删除。\n",
      "TL持仓量 前端缺失，已删除。\n",
      "TL跨期价差 前端缺失，已删除。\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1662 entries, 2019-01-03 to 2025-08-28\n",
      "Columns: 189 entries, 同业存单_1Y-FR007_1Y to value_sort\n",
      "dtypes: float64(188), int64(1)\n",
      "memory usage: 2.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_excel('全因子.xlsx')\n",
    "df_raw.set_index('date', inplace=True)\n",
    "\n",
    "# === 1) 先从原始数据抽出 ytm，并据此生成标签（不做任何插值/差分） ===\n",
    "ytm = df_raw['二级5yYTM'].copy()\n",
    "ytm = ytm.dropna()  # 去掉原始缺失的样本\n",
    "labels = (ytm.shift(-5) - ytm > 0).astype(int)  # 周一→下周一（5个交易日）\n",
    "labels = labels.dropna()  # 去掉尾部 5 行\n",
    "\n",
    "# === 2) 特征：把 ytm 剔除后再做你原来的分段差分与清洗 ===\n",
    "feat_raw = df_raw.drop(columns=['二级5yYTM'])\n",
    "\n",
    "df = pd.DataFrame(index=feat_raw.index)\n",
    "df = pd.concat([df, feat_raw.iloc[:, 0:63].diff(1)], axis=1)\n",
    "df = pd.concat([df, feat_raw.iloc[:, 63:65].ffill().diff(1)], axis=1)\n",
    "df = pd.concat([df, feat_raw.iloc[:, 65:].ffill().diff(1)], axis=1)\n",
    "\n",
    "# 行/列缺失清理\n",
    "df = df.dropna(thresh=df.shape[1] / 2)\n",
    "for col in list(df.columns):\n",
    "    if df[col].isna().sum() > df.shape[0] / 2:\n",
    "        print(col, '前端缺失，已删除。')\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# 数值化 + 异常值→NaN + 线性插补（仅对特征做）\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    mu, sd = df[col].mean(), df[col].std()\n",
    "    z = (df[col] - mu) / (sd if sd not in (0, np.nan) else 1)\n",
    "    df[col] = df[col].mask(z.abs() > 5)\n",
    "    df[col] = df[col].interpolate(method='linear', axis=0)\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "# === 3) 与标签按时间对齐，得到最终 df_clean ===\n",
    "common_idx = df.index.intersection(labels.index)\n",
    "df_clean = df.loc[common_idx].copy()\n",
    "df_clean['value_sort'] = labels.loc[common_idx].astype(int)\n",
    "\n",
    "print(df_clean.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66d699-727a-4609-8e05-41b8e24a76d2",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd8851ef-4147-4bd8-b1a8-303696da7957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from hypernets.utils import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from hypergbm import make_experiment\n",
    "from hypernets.tabular.datasets import dsutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09211def-46d1-49d6-b95d-516bd945fc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Input Data"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_train.shape</th>\n",
       "      <th>y_train.shape</th>\n",
       "      <th>X_eval.shape</th>\n",
       "      <th>y_eval.shape</th>\n",
       "      <th>X_test.shape</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1163, 188)</td>\n",
       "      <td>(1163,)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>binary(2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  X_train.shape y_train.shape X_eval.shape y_eval.shape X_test.shape  \\\n",
       "0   (1163, 188)       (1163,)         None         None         None   \n",
       "\n",
       "        Task  \n",
       "0  binary(2)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/backend_bases.py:2204\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2201\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2204\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2207\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2208\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2052\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2053\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2054\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:496\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:444\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    446\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    447\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:387\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    386\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/figure.py:3161\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3158\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3162\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3163\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[1;32m   3165\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/patches.py:632\u001b[0m, in \u001b[0;36mPatch.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    630\u001b[0m tpath \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform_path_non_affine(path)\n\u001b[1;32m    631\u001b[0m affine \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[0;32m--> 632\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_paths_with_artist_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Work around a bug in the PDF and SVG renderers, which\u001b[39;49;00m\n\u001b[1;32m    636\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# do not draw the hatches if the facecolor is fully\u001b[39;49;00m\n\u001b[1;32m    637\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# transparent, but do if it is None.\u001b[39;49;00m\n\u001b[1;32m    638\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/patches.py:617\u001b[0m, in \u001b[0;36mPatch._draw_paths_with_artist_properties\u001b[0;34m(self, renderer, draw_path_args_list)\u001b[0m\n\u001b[1;32m    614\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m PathEffectRenderer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path_effects(), renderer)\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m draw_path_args \u001b[38;5;129;01min\u001b[39;00m draw_path_args_list:\n\u001b[0;32m--> 617\u001b[0m     \u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdraw_path_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m gc\u001b[38;5;241m.\u001b[39mrestore()\n\u001b[1;32m    620\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hypergbm/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:131\u001b[0m, in \u001b[0;36mRendererAgg.draw_path\u001b[0;34m(self, gc, path, transform, rgbFace)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgbFace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m         cant_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Data Adaption"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Initliazed parameters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>memory_limit</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min_cols</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "      <td>data_adaption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key          value\n",
       "0  memory_limit           0.05\n",
       "1      min_cols            0.3\n",
       "2          name  data_adaption\n",
       "3        target           None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Fitted parameters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_features</td>\n",
       "      <td>[同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>selected_features</td>\n",
       "      <td>[同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unselected_features</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   key                                              value\n",
       "0       input_features  [同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...\n",
       "1    selected_features  [同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...\n",
       "2  unselected_features                                                 []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Elapsed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "* 0.007 seconds"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Data Clean"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Initliazed parameters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_cleaner_args</td>\n",
       "      <td>{'nan_chars': None, 'correct_object_dtype': Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "      <td>data_clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_test_split_strategy</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         key  \\\n",
       "0                         cv   \n",
       "1          data_cleaner_args   \n",
       "2                       name   \n",
       "3  train_test_split_strategy   \n",
       "\n",
       "                                               value  \n",
       "0                                               True  \n",
       "1  {'nan_chars': None, 'correct_object_dtype': Tr...  \n",
       "2                                         data_clean  \n",
       "3                                               None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Fitted parameters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_features</td>\n",
       "      <td>[同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>selected_features</td>\n",
       "      <td>[同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unselected_features</td>\n",
       "      <td>[OMO007, SLF007]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train.shape</td>\n",
       "      <td>(1163, 186)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y_train.shape</td>\n",
       "      <td>(1163,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X_eval.shape</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>y_eval.shape</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X_test.shape</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unselected_reason</td>\n",
       "      <td>{'OMO007': 'constant', 'SLF007': 'constant'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kept/dropped feature count</td>\n",
       "      <td>186/2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          key  \\\n",
       "0              input_features   \n",
       "1           selected_features   \n",
       "2         unselected_features   \n",
       "3               X_train.shape   \n",
       "4               y_train.shape   \n",
       "5                X_eval.shape   \n",
       "6                y_eval.shape   \n",
       "7                X_test.shape   \n",
       "8           unselected_reason   \n",
       "9  kept/dropped feature count   \n",
       "\n",
       "                                               value  \n",
       "0  [同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...  \n",
       "1  [同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...  \n",
       "2                                   [OMO007, SLF007]  \n",
       "3                                        (1163, 186)  \n",
       "4                                            (1163,)  \n",
       "5                                               None  \n",
       "6                                               None  \n",
       "7                                               None  \n",
       "8       {'OMO007': 'constant', 'SLF007': 'constant'}  \n",
       "9                                              186/2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Elapsed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "* 0.034 seconds"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Space Searching"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Initliazed parameters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>space_searching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_folds</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         key            value\n",
       "0         cv             True\n",
       "1       name  space_searching\n",
       "2  num_folds                3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Experiment Settings:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HyperGBM(searcher=EvolutionSearcher(space_fn=GeneralSearchSpaceGenerator(kwargs=None, n_estimators=200), population_size=30, sample_size=10, regularized=True, optimize_direction='max', random_state=RandomState(MT19937) at 0x7FDEA0E12E40), callbacks=[EarlyStoppingCallback(max_no_improvement_trials=10, mode='max', time_limit=3599.95792555809), NotebookCallback(), ProgressiveCallback(), FitCrossValidationCallback()], task='binary', discriminator=OncePercentileDiscriminator(percentile=50, history=TrialHistory(direction='max'), optimize_direction='max'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>X_eval</th>\n",
       "      <th>y_eval</th>\n",
       "      <th>cv</th>\n",
       "      <th>num_folds</th>\n",
       "      <th>max_trials</th>\n",
       "      <th>fit_kwargs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1163, 186)</td>\n",
       "      <td>(1163,)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X        y X_eval y_eval    cv  num_folds  max_trials fit_kwargs\n",
       "0  (1163, 186)  (1163,)   None   None  True          3          10         ()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Trials Summary:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial No.</th>\n",
       "      <th>Previous reward</th>\n",
       "      <th>Best trial</th>\n",
       "      <th>Best reward</th>\n",
       "      <th>Total elapsed</th>\n",
       "      <th>Valid trials</th>\n",
       "      <th>Max trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>ERR</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.6672398968185727]</td>\n",
       "      <td>5.112949</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trial No. Previous reward  Best trial           Best reward  Total elapsed  \\\n",
       "0         10             ERR           2  [0.6672398968185727]       5.112949   \n",
       "\n",
       "   Valid trials  Max trials  \n",
       "0             2          10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Best Trial:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "<thead>\n",
       "<tr style=\"text-align: right;\">\n",
       "  <th>key</th>\n",
       "  <th>value</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody><tr>\n",
       "  <td>signature</td>\n",
       "  <td>07eb114c3cebfac1fa1af984886326ec</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>vectors</td>\n",
       "  <td>[2, 3, 0, 2, 0, 2]</td>\n",
       "</tr><tr>\n",
       "  <td>0-estimator_options.hp_or</td>\n",
       "  <td>2</td>\n",
       "</tr>\n",
       "<tr><tr>\n",
       "  <td>1-numeric_imputer_0.strategy</td>\n",
       "  <td>most_frequent</td>\n",
       "</tr>\n",
       "<tr><tr>\n",
       "  <td>2-numeric_or_scaler_0.hp_or</td>\n",
       "  <td>0</td>\n",
       "</tr>\n",
       "<tr><tr>\n",
       "  <td>3-Module_CatBoostEstimator_1.learning_rate</td>\n",
       "  <td>0.5</td>\n",
       "</tr>\n",
       "<tr><tr>\n",
       "  <td>4-Module_CatBoostEstimator_1.depth</td>\n",
       "  <td>3</td>\n",
       "</tr>\n",
       "<tr><tr>\n",
       "  <td>5-Module_CatBoostEstimator_1.l2_leaf_reg</td>\n",
       "  <td>10</td>\n",
       "</tr>\n",
       "<tr>  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "DAG_HyperSpace_1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Top trials:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial No.</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Elapsed</th>\n",
       "      <th>Space Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.6672398968185727]</td>\n",
       "      <td>1.155156</td>\n",
       "      <td>[2, 3, 0, 2, 0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>[0.650042992261393]</td>\n",
       "      <td>1.030864</td>\n",
       "      <td>[2, 1, 1, 3, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trial No.                Reward   Elapsed        Space Vector\n",
       "0          2  [0.6672398968185727]  1.155156  [2, 3, 0, 2, 0, 2]\n",
       "1          7   [0.650042992261393]  1.030864  [2, 1, 1, 3, 0, 1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbfc404ded94ad794ba45562ce30a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "search:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8bb0ff5fa14767aa6249d6c7a34be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fit_cross_validation:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09-16 22:31:02 E hypernets.m.hyper_model.py 104 - run_trail failed! trail_no=1\n",
      "09-16 22:31:02 E hypernets.m.hyper_model.py 106 - Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypernets/model/hyper_model.py\", line 95, in _run_trial\n",
      "    ret_data = estimator.fit_cross_validation(X, y, stratified=True, num_folds=num_folds, shuffle=False,\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/hyper_gbm.py\", line 338, in fit_cross_validation\n",
      "    fold_est.fit(x_train_fold, y_train_fold, **fit_kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 517, in fit\n",
      "    return self.fit_with_encoder(super().fit, X, y, kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 198, in fit_with_encoder\n",
      "    return fn_fit(X, y, **kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "TypeError: fit() got an unexpected keyword argument 'callbacks'\n",
      "\n",
      "09-16 22:31:04 E hypernets.m.hyper_model.py 104 - run_trail failed! trail_no=3\n",
      "09-16 22:31:04 E hypernets.m.hyper_model.py 106 - Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypernets/model/hyper_model.py\", line 95, in _run_trial\n",
      "    ret_data = estimator.fit_cross_validation(X, y, stratified=True, num_folds=num_folds, shuffle=False,\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/hyper_gbm.py\", line 338, in fit_cross_validation\n",
      "    fold_est.fit(x_train_fold, y_train_fold, **fit_kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 346, in fit\n",
      "    kwargs = self.prepare_fit_kwargs(X, y, kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 334, in prepare_fit_kwargs\n",
      "    self.feature_names_in_ = X.columns.tolist()\n",
      "AttributeError: can't set attribute\n",
      "\n",
      "09-16 22:31:04 E hypernets.m.hyper_model.py 104 - run_trail failed! trail_no=4\n",
      "09-16 22:31:04 E hypernets.m.hyper_model.py 106 - Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypernets/model/hyper_model.py\", line 95, in _run_trial\n",
      "    ret_data = estimator.fit_cross_validation(X, y, stratified=True, num_folds=num_folds, shuffle=False,\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/hyper_gbm.py\", line 338, in fit_cross_validation\n",
      "    fold_est.fit(x_train_fold, y_train_fold, **fit_kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 346, in fit\n",
      "    kwargs = self.prepare_fit_kwargs(X, y, kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 334, in prepare_fit_kwargs\n",
      "    self.feature_names_in_ = X.columns.tolist()\n",
      "AttributeError: can't set attribute\n",
      "\n",
      "09-16 22:31:05 E hypernets.m.hyper_model.py 104 - run_trail failed! trail_no=5\n",
      "09-16 22:31:05 E hypernets.m.hyper_model.py 106 - Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypernets/model/hyper_model.py\", line 95, in _run_trial\n",
      "    ret_data = estimator.fit_cross_validation(X, y, stratified=True, num_folds=num_folds, shuffle=False,\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/hyper_gbm.py\", line 338, in fit_cross_validation\n",
      "    fold_est.fit(x_train_fold, y_train_fold, **fit_kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 517, in fit\n",
      "    return self.fit_with_encoder(super().fit, X, y, kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 198, in fit_with_encoder\n",
      "    return fn_fit(X, y, **kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "TypeError: fit() got an unexpected keyword argument 'callbacks'\n",
      "\n",
      "09-16 22:31:05 E hypernets.m.hyper_model.py 104 - run_trail failed! trail_no=6\n",
      "09-16 22:31:05 E hypernets.m.hyper_model.py 106 - Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypernets/model/hyper_model.py\", line 95, in _run_trial\n",
      "    ret_data = estimator.fit_cross_validation(X, y, stratified=True, num_folds=num_folds, shuffle=False,\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/hyper_gbm.py\", line 338, in fit_cross_validation\n",
      "    fold_est.fit(x_train_fold, y_train_fold, **fit_kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 517, in fit\n",
      "    return self.fit_with_encoder(super().fit, X, y, kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 198, in fit_with_encoder\n",
      "    return fn_fit(X, y, **kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "TypeError: fit() got an unexpected keyword argument 'callbacks'\n",
      "\n",
      "09-16 22:31:07 E hypernets.m.hyper_model.py 104 - run_trail failed! trail_no=8\n",
      "09-16 22:31:07 E hypernets.m.hyper_model.py 106 - Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypernets/model/hyper_model.py\", line 95, in _run_trial\n",
      "    ret_data = estimator.fit_cross_validation(X, y, stratified=True, num_folds=num_folds, shuffle=False,\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/hyper_gbm.py\", line 338, in fit_cross_validation\n",
      "    fold_est.fit(x_train_fold, y_train_fold, **fit_kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 517, in fit\n",
      "    return self.fit_with_encoder(super().fit, X, y, kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 198, in fit_with_encoder\n",
      "    return fn_fit(X, y, **kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "TypeError: fit() got an unexpected keyword argument 'callbacks'\n",
      "\n",
      "09-16 22:31:07 E hypernets.m.hyper_model.py 104 - run_trail failed! trail_no=9\n",
      "09-16 22:31:07 E hypernets.m.hyper_model.py 106 - Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypernets/model/hyper_model.py\", line 95, in _run_trial\n",
      "    ret_data = estimator.fit_cross_validation(X, y, stratified=True, num_folds=num_folds, shuffle=False,\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/hyper_gbm.py\", line 338, in fit_cross_validation\n",
      "    fold_est.fit(x_train_fold, y_train_fold, **fit_kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 517, in fit\n",
      "    return self.fit_with_encoder(super().fit, X, y, kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 198, in fit_with_encoder\n",
      "    return fn_fit(X, y, **kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "TypeError: fit() got an unexpected keyword argument 'callbacks'\n",
      "\n",
      "09-16 22:31:07 E hypernets.m.hyper_model.py 104 - run_trail failed! trail_no=10\n",
      "09-16 22:31:07 E hypernets.m.hyper_model.py 106 - Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypernets/model/hyper_model.py\", line 95, in _run_trial\n",
      "    ret_data = estimator.fit_cross_validation(X, y, stratified=True, num_folds=num_folds, shuffle=False,\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/hyper_gbm.py\", line 338, in fit_cross_validation\n",
      "    fold_est.fit(x_train_fold, y_train_fold, **fit_kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 346, in fit\n",
      "    kwargs = self.prepare_fit_kwargs(X, y, kwargs)\n",
      "  File \"/root/miniconda3/envs/hypergbm/lib/python3.9/site-packages/hypergbm/estimators.py\", line 334, in prepare_fit_kwargs\n",
      "    self.feature_names_in_ = X.columns.tolist()\n",
      "AttributeError: can't set attribute\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Fitted parameters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_features</td>\n",
       "      <td>[同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best_reward</td>\n",
       "      <td>[0.6672398968185727]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>history</td>\n",
       "      <td>TrialHistory(direction='max', size=10, succeed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              key                                              value\n",
       "0  input_features  [同业存单_1Y-FR007_1Y, 国债_1Y-FR007_1Y, 国债_2Y-FR007...\n",
       "1     best_reward                               [0.6672398968185727]\n",
       "2         history  TrialHistory(direction='max', size=10, succeed..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Elapsed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "* 5.146 seconds"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Final Ensemble"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Initliazed parameters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensemble_size</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>final_ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scorer</td>\n",
       "      <td>make_scorer(accuracy_score, response_method='p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key                                              value\n",
       "0  ensemble_size                                                 20\n",
       "1           name                                     final_ensemble\n",
       "2         scorer  make_scorer(accuracy_score, response_method='p..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Fitted parameters"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weights</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scores</td>\n",
       "      <td>[0.6672398968185727, 0.6672398968185727, 0.667...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best_stack</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hits</td>\n",
       "      <td>{0: 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensemble_size</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "GreedyEnsemble(weight=[1.0, 0.0], scores=[0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727, 0.6672398968185727])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Elapsed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "* 4.770 seconds"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 假设 df_clean 已经准备好，索引为时间或顺序\n",
    "label_col = \"value_sort\"\n",
    "split_point = int(len(df_clean) * 0.7)\n",
    "\n",
    "# 按顺序切分\n",
    "df_train = df_clean.iloc[:split_point]\n",
    "df_test  = df_clean.iloc[split_point:]\n",
    "\n",
    "# 拆分特征和标签\n",
    "X_train, y_train = df_train.drop(columns=[label_col]), df_train[label_col]\n",
    "X_test,  y_test  = df_test.drop(columns=[label_col]),  df_test[label_col]\n",
    "\n",
    "train_data = pd.concat([X_train,y_train],axis=1)\n",
    "experiment = make_experiment(train_data, target='value_sort')\n",
    "estimator = experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ad1b9a-3d41-4594-a125-fbf7cc82bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pkl','wb') as f:\n",
    "  pickle.dump(estimator, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1165d43f-ebe0-48b3-9a41-09cd78974859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.66324   0.80124   0.72574       322\n",
      "           1    0.41818   0.25989   0.32056       177\n",
      "\n",
      "    accuracy                        0.60922       499\n",
      "   macro avg    0.54071   0.53056   0.52315       499\n",
      "weighted avg    0.57631   0.60922   0.58202       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred=estimator.predict(df_test)\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9056a0-97a1-4fb1-acb6-668e3acf5239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5608134189563814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 假设 estimator 是你训练好的模型\n",
    "y_prob = estimator.predict_proba(X_test)[:, 1]   # 取正类概率\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3001ba78-70d0-496e-bc2c-7db2a431398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.2.2\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: /root/miniconda3/envs/hypergbm/lib/python3.9/site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: hypergbm, hypernets, imbalanced-learn\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f306a5c-a787-4492-bc7b-46ad4ec6e91b",
   "metadata": {},
   "source": [
    "# AUTOGLUON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e11bc4-c458-4367-b0de-18caea08cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a08a5-e868-48ab-899e-ddcada64b639",
   "metadata": {},
   "source": [
    "## 处理二级债"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd7ee7c-baa1-4a5f-9e28-ef01311b42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_excel('全因子.xlsx')\n",
    "df_raw.set_index('date', inplace=True)\n",
    "\n",
    "\n",
    "ytm = df_raw[['二级5yYTM']].copy()\n",
    "\n",
    "labels = (ytm['二级5yYTM'].shift(-1) - ytm['二级5yYTM'] > 0).astype(int)\n",
    "\n",
    "df_clean = df_raw.copy()\n",
    "df_clean['value_sort'] = labels\n",
    "\n",
    "# 删除最后一行（因为没有未来数据做标签）\n",
    "df_clean = df_clean.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0057a8e0-161a-4e2c-bcce-fd2281395cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取数据\n",
    "df_1 = pd.read_excel('全因子.xlsx')\n",
    "#df_2 = pd.read_csv('all_data_5.csv')\n",
    "df_2 = pd.read_excel('FR007_PRED.xlsx',sheet_name = 1)\n",
    "# 将 'date' 列设置为索引\n",
    "df_1.set_index('date', inplace=True)\n",
    "df_2.set_index('date', inplace=True)\n",
    "\n",
    "# 删除 df_2 中的 'Y1' 列\n",
    "df_2 = df_2.drop('Y1', axis=1)\n",
    "\n",
    "# 确保索引是 datetime 类型\n",
    "df_1.index = pd.to_datetime(df_1.index, errors='coerce')\n",
    "df_2.index = pd.to_datetime(df_2.index, errors='coerce')\n",
    "\n",
    "# 合并两个 DataFrame，基于索引进行合并\n",
    "df_clean = pd.merge(df_1, df_2, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "df_3 = pd.read_excel('FR007.xlsx')\n",
    "df_3.set_index('date', inplace=True)\n",
    "df_clean = pd.merge(df_clean, df_3, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb47691-9d28-43ed-83e2-709e9c2dad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1: 行数=3183, 日期范围=[2017-01-01 00:00:00 ~ 2025-09-18 00:00:00]\n",
      "df2: 行数=571, 日期范围=[2023-06-01 00:00:00 ~ 2025-09-16 00:00:00]\n",
      "df3: 行数=2273, 日期范围=[2017-01-02 00:00:00 ~ 2025-09-17 00:00:00]\n",
      "共同日期个数=560, 共同日期范围=[2023-06-01 00:00:00 ~ 2025-09-16 00:00:00]\n",
      "df_clean: 行数=559, 日期范围=[2023-06-02 00:00:00 ~ 2025-09-16 00:00:00]\n",
      "标签基于列: Y1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ====== 配置 ======\n",
    "path1, sheet1 = \"merged.xlsx\", 0\n",
    "path2, sheet2 = \"FR007_PRED.xlsx\", 1   # 确认这个 sheet 索引是否正确！\n",
    "path3, sheet3 = \"FR007.xlsx\", 0\n",
    "target_col = \"Y1\"                       # 你要差分的列名（如 \"Y1\" 或 \"Y2\"）\n",
    "\n",
    "# ====== 工具函数 ======\n",
    "def ensure_date_index(df, date_col=None):\n",
    "    \"\"\"\n",
    "    将 df 的日期列设为索引，自动处理常见格式：\n",
    "    - 指定了 date_col 就用该列，否则用第一列\n",
    "    - 先常规 pd.to_datetime 解析；若大量 NaT，尝试按 Excel 序列号解析\n",
    "    - 归一化到日期、丢 NaT、去重、排序\n",
    "    \"\"\"\n",
    "    # 选索引列\n",
    "    if date_col is not None:\n",
    "        if date_col not in df.columns:\n",
    "            raise ValueError(f\"指定的日期列 '{date_col}' 不存在；可用列: {df.columns.tolist()[:10]} ...\")\n",
    "        idx = df[date_col]\n",
    "        df = df.drop(columns=[date_col])\n",
    "    else:\n",
    "        idx = df.iloc[:, 0]\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "    # 常规解析\n",
    "    dt = pd.to_datetime(idx, errors=\"coerce\")\n",
    "\n",
    "    # 若解析失败较多，尝试 Excel 序列号（天数，自 1899-12-30 起）\n",
    "    if dt.isna().mean() > 0.5:\n",
    "        s = pd.to_numeric(idx, errors=\"coerce\")\n",
    "        if s.notna().mean() > 0.5 and s.between(40000, 90000).mean() > 0.5:\n",
    "            dt = pd.to_datetime(s, unit=\"d\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "\n",
    "    dt = dt.dt.normalize()\n",
    "    mask = dt.notna()\n",
    "    df = df.loc[mask].copy()\n",
    "    df.index = dt[mask]\n",
    "    df = df[~df.index.duplicated(keep=\"first\")].sort_index()\n",
    "    return df\n",
    "\n",
    "def describe(name, df):\n",
    "    mn = df.index.min()\n",
    "    mx = df.index.max()\n",
    "    print(f\"{name}: 行数={len(df)}, 日期范围=[{mn} ~ {mx}]\")\n",
    "\n",
    "# ====== 读取与预处理 ======\n",
    "df1 = pd.read_excel(path1, sheet_name=sheet1)\n",
    "df2 = pd.read_excel(path2, sheet_name=sheet2)\n",
    "df3 = pd.read_excel(path3, sheet_name=sheet3)\n",
    "\n",
    "# 优先用名为 'date' 的列；没有则默认第一列\n",
    "df1 = ensure_date_index(df1, 'date' if 'date' in df1.columns else None)\n",
    "df2 = ensure_date_index(df2, 'date' if 'date' in df2.columns else None)\n",
    "df3 = ensure_date_index(df3, 'date' if 'date' in df3.columns else None)\n",
    "\n",
    "describe(\"df1\", df1)\n",
    "describe(\"df2\", df2)\n",
    "describe(\"df3\", df3)\n",
    "\n",
    "# ====== 求三表的日期交集并合并 ======\n",
    "common_idx = df1.index.intersection(df2.index).intersection(df3.index)\n",
    "print(f\"共同日期个数={len(common_idx)}, 共同日期范围=[{common_idx.min()} ~ {common_idx.max()}]\")\n",
    "\n",
    "df_clean = pd.concat([df1, df2, df3], axis=1).loc[common_idx].sort_index()\n",
    "\n",
    "# ====== 差分与标签（统一使用你提供的 target_col）======\n",
    "if target_col not in df_clean.columns:\n",
    "    raise ValueError(f\"目标列 '{target_col}' 不在合并后的数据中。可用列示例: {df_clean.columns.tolist()[:20]}\")\n",
    "\n",
    "df_clean[\"diff\"]  = df_clean[target_col].diff()\n",
    "df_clean[\"label\"] = (df_clean[\"diff\"].shift(-1) > 0).astype(\"float\")\n",
    "df_clean = df_clean.dropna(subset=[\"diff\"])\n",
    "if df_clean[\"label\"].isna().any():\n",
    "    df_clean = df_clean.iloc[:-1, :]\n",
    "df_clean[\"label\"] = df_clean[\"label\"].astype(int)\n",
    "\n",
    "describe(\"df_clean\", df_clean)\n",
    "print(f\"标签基于列: {target_col}\")\n",
    "# df_clean.to_excel(\"df_clean.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b8fac1-ffcb-49c1-966b-e435cb8bfd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1: 行数=3183, 日期范围=[2017-01-01 00:00:00 ~ 2025-09-18 00:00:00]\n",
      "df3 (清理后): 行数=2115, 日期范围=[2017-01-03 00:00:00 ~ 2025-09-11 00:00:00]\n",
      "共同日期个数=2115, 范围=[2017-01-03 00:00:00 ~ 2025-09-11 00:00:00]\n",
      "df_clean: 行数=2113, 日期范围=[2017-01-04 00:00:00 ~ 2025-09-10 00:00:00]\n",
      "标签基于列: 国债_10Y\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ====== 配置 ======\n",
    "path1, sheet1 = \"merged.xlsx\", 0\n",
    "path3, sheet3 = \"国债.xlsx\", 0\n",
    "target_col = \"国债_10Y\"   # 作为标签基准的列（来自 FR007.xlsx）\n",
    "\n",
    "# ====== 工具函数 ======\n",
    "def ensure_date_index(df, date_col=None):\n",
    "    \"\"\"将 df 的日期列设为索引，并做日期规范化、去重、排序。\"\"\"\n",
    "    if date_col is not None and date_col in df.columns:\n",
    "        idx = df[date_col]\n",
    "        df = df.drop(columns=[date_col])\n",
    "    else:\n",
    "        idx = df.iloc[:, 0]\n",
    "        df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "    # 常规解析\n",
    "    dt = pd.to_datetime(idx, errors=\"coerce\")\n",
    "\n",
    "    # 若解析失败较多，尝试 Excel 序列号（以 1899-12-30 为起点的天数）\n",
    "    if dt.isna().mean() > 0.5:\n",
    "        s = pd.to_numeric(idx, errors=\"coerce\")\n",
    "        if s.notna().mean() > 0.5 and s.between(40000, 90000).mean() > 0.5:\n",
    "            dt = pd.to_datetime(s, unit=\"d\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "\n",
    "    dt = dt.dt.normalize()\n",
    "    mask = dt.notna()\n",
    "    df = df.loc[mask].copy()\n",
    "    df.index = dt[mask]\n",
    "    df = df[~df.index.duplicated(keep=\"first\")].sort_index()\n",
    "    return df\n",
    "\n",
    "def describe(name, df):\n",
    "    mn, mx = df.index.min(), df.index.max()\n",
    "    print(f\"{name}: 行数={len(df)}, 日期范围=[{mn} ~ {mx}]\")\n",
    "\n",
    "# ====== 读取与预处理 ======\n",
    "df1 = pd.read_excel(path1, sheet_name=sheet1)\n",
    "df3 = pd.read_excel(path3, sheet_name=sheet3)\n",
    "\n",
    "# 优先使用名为 'date' 的列作为索引；没有则默认第一列\n",
    "df1 = ensure_date_index(df1, 'date' if 'date' in df1.columns else None)\n",
    "df3 = ensure_date_index(df3, 'date' if 'date' in df3.columns else None)\n",
    "\n",
    "# 删除 FR007_5Y 为空的行（在 FR007.xlsx 侧先清理）\n",
    "if target_col not in df3.columns:\n",
    "    raise ValueError(f\"FR007.xlsx 中未找到列 {target_col}，可用列有：{list(df3.columns)}\")\n",
    "df3 = df3.dropna(subset=[target_col])\n",
    "\n",
    "describe(\"df1\", df1)\n",
    "describe(\"df3 (清理后)\", df3)\n",
    "\n",
    "# ====== 求交集并合并 ======\n",
    "common_idx = df1.index.intersection(df3.index)\n",
    "print(f\"共同日期个数={len(common_idx)}, 范围=[{common_idx.min()} ~ {common_idx.max()}]\")\n",
    "\n",
    "df_clean = pd.concat([df1, df3], axis=1).loc[common_idx].sort_index()\n",
    "\n",
    "# ====== 差分与标签（基于 FR007_5Y）=====\n",
    "df_clean[\"diff\"] = df_clean[target_col].diff()\n",
    "\n",
    "# 用“下一期”的涨跌作为当前样本标签：>0 -> -1，<0 -> 1，=0 -> 0\n",
    "df_clean[\"label\"] = df_clean[\"diff\"].shift(-1).apply(\n",
    "    lambda x: (-1 if x > 0 else (1 if x < 0 else 0)) if pd.notna(x) else pd.NA\n",
    ")\n",
    "\n",
    "# 去掉首行(diff 为 NaN) 与末行(label 为 NA)\n",
    "df_clean = df_clean.dropna(subset=[\"diff\", \"label\"])\n",
    "df_clean[\"label\"] = df_clean[\"label\"].astype(int)\n",
    "\n",
    "# 如果不想保留“持平=0”的样本，取消下一行注释：\n",
    "# df_clean = df_clean[df_clean[\"label\"] != 0]\n",
    "\n",
    "describe(\"df_clean\", df_clean)\n",
    "print(f\"标签基于列: {target_col}\")\n",
    "\n",
    "# 可选：保存结果\n",
    "df_clean.to_excel(\"df_clean.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783b3a2-24b1-4889-bd74-763eba637176",
   "metadata": {},
   "source": [
    "## 处理FR007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e10c6341-4d67-49b3-8205-09727ad6cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_clean = pd.read_csv('all_data_5.csv')\n",
    "df_clean.set_index('date', inplace=True)\n",
    "df_clean = df_clean.drop('Y1',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fcff986-d7c9-41b8-9712-5ecfafcf1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 df_clean 已经准备好，索引为时间或顺序\n",
    "\n",
    "label_col = \"label\"\n",
    "split_point = int(len(df_clean) * 0.8)\n",
    "\n",
    "# 按顺序切分\n",
    "df_train = df_clean.iloc[:split_point]\n",
    "df_test  = df_clean.iloc[split_point:]\n",
    "\n",
    "# 拆分特征和标签\n",
    "X_train, y_train = df_train.drop(columns=[label_col]), df_train[label_col]\n",
    "X_test,  y_test  = df_test.drop(columns=[label_col]),  df_test[label_col]\n",
    "\n",
    "train_data = pd.concat([X_train,y_train],axis=1)\n",
    "test_data = pd.concat([X_test, y_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb7e2136-bb39-49be-89e4-a0f376f2d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250919_035048\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.3\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #25-Ubuntu SMP Wed Mar 30 15:54:22 UTC 2022\n",
      "CPU Count:          20\n",
      "Memory Avail:       974.53 GB / 1007.51 GB (96.7%)\n",
      "Disk Space Avail:   14.19 GB / 30.00 GB (47.3%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/root/AutogluonModels/ag-20250919_035048\"\n",
      "Train Data Rows:    1690\n",
      "Train Data Columns: 517\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(-1), np.int64(1), np.int64(0)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 3 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9988165680473373\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    997911.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.66 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 94): ['国债_10Y-国开债_10Y', '国债_10Y-企业债AAA+_10Y', '国债_10Y-中短期票据AAA+_10Y', '国债_10Y-国债_1Y', '国债_10Y-国债_3Y', '国债_10Y-国债_5Y', '国债_10Y-国债_7Y', '国债_30Y-国债_10Y', '国开债_10Y-国债_10Y', '国开债_5Y-国债_5Y', '国开债_1Y-国债_1Y', '中短期票据AAA+_1Y-国开债1Y', '中短期票据AAA+_3Y-国开债3Y', '中短期票据AAA+_5Y-国开债5Y', '中短期票据AAA+_7Y-国开债7Y', '中短期票据AAA+_10Y-国开债10Y', '中短期票据AAA+_30Y-国开债30Y', '国债_10Y-同业存单AAA_1Y', '国开债_10Y-国开债_5Y', '国开债_10Y-国开债_1Y', '活跃券_10Y-国债_10Y', '国债_5Y-FR007_IRS_5Y', '国债_1Y_收益率变动_5D', '国债_1Y_收益率变动_30D', '国债_1Y_收益率变动_90D', '国债_5Y_收益率变动_5D', '国债_5Y_收益率变动_30D', '国债_5Y_收益率变动_90D', '国债_7Y_收益率变动_5D', '国债_7Y_收益率变动_30D', '国债_7Y_收益率变动_90D', '国债_10Y_收益率变动_5D', '国债_10Y_收益率变动_30D', '国债_10Y_收益率变动_90D', '国债_30Y_收益率变动_5D', '国债_30Y_收益率变动_30D', '国债_30Y_收益率变动_90D', '国债_1Y_动量', '国债_5Y_动量', '国债_7Y_动量', '国债_10Y_动量', '国债_30Y_动量', '国债_1Y_macd', '国债_5Y_macd', '国债_7Y_macd', '国债_10Y_macd', '国债_30Y_macd', '利率利差国债_10Y-国开债_10Y', '利率利差国债_10Y-企业债AAA+_10Y', '利率利差国债_10Y-中短期票据AAA+_10Y', '利率利差国债_10Y-国债_1Y', '利率利差国债_10Y-国债_3Y', '利率利差国债_10Y-国债_5Y', '利率利差国债_10Y-国债_7Y', '利率利差国债_30Y-国债_10Y', '利率利差国开债_10Y-国债_10Y', '利率利差国开债_5Y-国债_5Y', '利率利差国开债_1Y-国债_1Y', '利率利差中短期票据AAA+_1Y-国开债1Y', '利率利差中短期票据AAA+_3Y-国开债3Y', '利率利差中短期票据AAA+_5Y-国开债5Y', '利率利差中短期票据AAA+_7Y-国开债7Y', '利率利差中短期票据AAA+_10Y-国开债10Y', '利率利差中短期票据AAA+_30Y-国开债30Y', '利率利差国债_10Y-同业存单AAA_1Y', '利率利差国开债_10Y-国开债_5Y', '利率利差国开债_10Y-国开债_1Y', '利率利差活跃券_10Y-国债_10Y', '利率利差国债_5Y-FR007_IRS_5Y', '国债技术指标国债_1Y_收益率变动_5D', '国债技术指标国债_1Y_收益率变动_30D', '国债技术指标国债_1Y_收益率变动_90D', '国债技术指标国债_5Y_收益率变动_5D', '国债技术指标国债_5Y_收益率变动_30D', '国债技术指标国债_5Y_收益率变动_90D', '国债技术指标国债_7Y_收益率变动_5D', '国债技术指标国债_7Y_收益率变动_30D', '国债技术指标国债_7Y_收益率变动_90D', '国债技术指标国债_10Y_收益率变动_5D', '国债技术指标国债_10Y_收益率变动_30D', '国债技术指标国债_10Y_收益率变动_90D', '国债技术指标国债_30Y_收益率变动_5D', '国债技术指标国债_30Y_收益率变动_30D', '国债技术指标国债_30Y_收益率变动_90D', '国债技术指标国债_1Y_动量', '国债技术指标国债_5Y_动量', '国债技术指标国债_7Y_动量', '国债技术指标国债_10Y_动量', '国债技术指标国债_30Y_动量', '国债技术指标国债_1Y_macd', '国债技术指标国债_5Y_macd', '国债技术指标国债_7Y_macd', '国债技术指标国债_10Y_macd', '国债技术指标国债_30Y_macd']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 207): ['交易日期是否交易日', '交易日期月', '交易日期日', '交易日期是否15号', '交易日期是否20号', '交易日期星期', '利率利差R007-R001', '利率利差活跃券_10Y-活跃券_3Y', '利率利差活跃券_10Y-活跃券_5Y', '利率利差活跃券_10Y-活跃券_7Y', '利率利差FR007_IRS_5Y-FR007_IRS_1Y', '利率利差FR007_IRS_1Y-FR007_IRS_9M', '利率利差SHIBOR_1Y-FR007_IRS_1Y', '国债期货价差国债期货_活跃_2Y_均价-国债期货_次活跃_2Y_均价', '国债期货价差国债期货_活跃_5Y_均价-国债期货_次活跃_5Y_均价', '国债期货价差国债期货_活跃_10Y_均价-国债期货_次活跃_10Y_均价', '国债期货价差国债期货_活跃_30Y_均价-国债期货_次活跃_30Y_均价', '国债期货技术指标国债期货_2Y_open', '国债期货技术指标国债期货_2Y_close', '国债期货技术指标国债期货_2Y_high', '国债期货技术指标国债期货_2Y_low', '国债期货技术指标国债期货_2Y_volume', '国债期货技术指标国债期货_2Y_sma_5', '国债期货技术指标国债期货_2Y_trima_5', '国债期货技术指标国债期货_2Y_roc_5', '国债期货技术指标国债期货_2Y_cmo_5', '国债期货技术指标国债期货_2Y_wr_5', '国债期货技术指标国债期货_2Y_kdj_5', '国债期货技术指标国债期货_2Y_sma_10', '国债期货技术指标国债期货_2Y_trima_10', '国债期货技术指标国债期货_2Y_roc_10', '国债期货技术指标国债期货_2Y_cmo_10', '国债期货技术指标国债期货_2Y_wr_10', '国债期货技术指标国债期货_2Y_kdj_10', '国债期货技术指标国债期货_2Y_sma_20', '国债期货技术指标国债期货_2Y_trima_20', '国债期货技术指标国债期货_2Y_roc_20', '国债期货技术指标国债期货_2Y_cmo_20', '国债期货技术指标国债期货_2Y_wr_20', '国债期货技术指标国债期货_2Y_kdj_20', '国债期货技术指标国债期货_2Y_momentum', '国债期货技术指标国债期货_2Y_obv', '国债期货技术指标国债期货_2Y_adi', '国债期货技术指标国债期货_2Y_atr', '国债期货技术指标国债期货_2Y_vwap', '国债期货技术指标国债期货_2Y_low2high', '国债期货技术指标国债期货_2Y_vwap2close', '国债期货技术指标国债期货_2Y_kmid', '国债期货技术指标国债期货_2Y_klen', '国债期货技术指标国债期货_2Y_kmid2', '国债期货技术指标国债期货_2Y_kup2', '国债期货技术指标国债期货_2Y_klow2', '国债期货技术指标国债期货_2Y_ksft2', '国债期货技术指标国债期货_5Y_open', '国债期货技术指标国债期货_5Y_close', '国债期货技术指标国债期货_5Y_high', '国债期货技术指标国债期货_5Y_low', '国债期货技术指标国债期货_5Y_volume', '国债期货技术指标国债期货_5Y_sma_5', '国债期货技术指标国债期货_5Y_trima_5', '国债期货技术指标国债期货_5Y_roc_5', '国债期货技术指标国债期货_5Y_cmo_5', '国债期货技术指标国债期货_5Y_wr_5', '国债期货技术指标国债期货_5Y_kdj_5', '国债期货技术指标国债期货_5Y_sma_10', '国债期货技术指标国债期货_5Y_trima_10', '国债期货技术指标国债期货_5Y_roc_10', '国债期货技术指标国债期货_5Y_cmo_10', '国债期货技术指标国债期货_5Y_wr_10', '国债期货技术指标国债期货_5Y_kdj_10', '国债期货技术指标国债期货_5Y_sma_20', '国债期货技术指标国债期货_5Y_trima_20', '国债期货技术指标国债期货_5Y_roc_20', '国债期货技术指标国债期货_5Y_cmo_20', '国债期货技术指标国债期货_5Y_wr_20', '国债期货技术指标国债期货_5Y_kdj_20', '国债期货技术指标国债期货_5Y_momentum', '国债期货技术指标国债期货_5Y_obv', '国债期货技术指标国债期货_5Y_adi', '国债期货技术指标国债期货_5Y_atr', '国债期货技术指标国债期货_5Y_vwap', '国债期货技术指标国债期货_5Y_low2high', '国债期货技术指标国债期货_5Y_vwap2close', '国债期货技术指标国债期货_5Y_kmid', '国债期货技术指标国债期货_5Y_klen', '国债期货技术指标国债期货_5Y_kmid2', '国债期货技术指标国债期货_5Y_kup2', '国债期货技术指标国债期货_5Y_klow2', '国债期货技术指标国债期货_5Y_ksft2', '国债期货技术指标国债期货_10Y_open', '国债期货技术指标国债期货_10Y_close', '国债期货技术指标国债期货_10Y_high', '国债期货技术指标国债期货_10Y_low', '国债期货技术指标国债期货_10Y_volume', '国债期货技术指标国债期货_10Y_sma_5', '国债期货技术指标国债期货_10Y_trima_5', '国债期货技术指标国债期货_10Y_roc_5', '国债期货技术指标国债期货_10Y_cmo_5', '国债期货技术指标国债期货_10Y_wr_5', '国债期货技术指标国债期货_10Y_kdj_5', '国债期货技术指标国债期货_10Y_sma_10', '国债期货技术指标国债期货_10Y_trima_10', '国债期货技术指标国债期货_10Y_roc_10', '国债期货技术指标国债期货_10Y_cmo_10', '国债期货技术指标国债期货_10Y_wr_10', '国债期货技术指标国债期货_10Y_kdj_10', '国债期货技术指标国债期货_10Y_sma_20', '国债期货技术指标国债期货_10Y_trima_20', '国债期货技术指标国债期货_10Y_roc_20', '国债期货技术指标国债期货_10Y_cmo_20', '国债期货技术指标国债期货_10Y_wr_20', '国债期货技术指标国债期货_10Y_kdj_20', '国债期货技术指标国债期货_10Y_momentum', '国债期货技术指标国债期货_10Y_obv', '国债期货技术指标国债期货_10Y_adi', '国债期货技术指标国债期货_10Y_atr', '国债期货技术指标国债期货_10Y_vwap', '国债期货技术指标国债期货_10Y_low2high', '国债期货技术指标国债期货_10Y_vwap2close', '国债期货技术指标国债期货_10Y_kmid', '国债期货技术指标国债期货_10Y_klen', '国债期货技术指标国债期货_10Y_kmid2', '国债期货技术指标国债期货_10Y_kup2', '国债期货技术指标国债期货_10Y_klow2', '国债期货技术指标国债期货_10Y_ksft2', '国债期货技术指标国债期货_30Y_open', '国债期货技术指标国债期货_30Y_close', '国债期货技术指标国债期货_30Y_high', '国债期货技术指标国债期货_30Y_low', '国债期货技术指标国债期货_30Y_volume', '国债期货技术指标国债期货_30Y_sma_5', '国债期货技术指标国债期货_30Y_trima_5', '国债期货技术指标国债期货_30Y_roc_5', '国债期货技术指标国债期货_30Y_cmo_5', '国债期货技术指标国债期货_30Y_wr_5', '国债期货技术指标国债期货_30Y_kdj_5', '国债期货技术指标国债期货_30Y_sma_10', '国债期货技术指标国债期货_30Y_trima_10', '国债期货技术指标国债期货_30Y_roc_10', '国债期货技术指标国债期货_30Y_cmo_10', '国债期货技术指标国债期货_30Y_wr_10', '国债期货技术指标国债期货_30Y_kdj_10', '国债期货技术指标国债期货_30Y_sma_20', '国债期货技术指标国债期货_30Y_trima_20', '国债期货技术指标国债期货_30Y_roc_20', '国债期货技术指标国债期货_30Y_cmo_20', '国债期货技术指标国债期货_30Y_wr_20', '国债期货技术指标国债期货_30Y_kdj_20', '国债期货技术指标国债期货_30Y_momentum', '国债期货技术指标国债期货_30Y_obv', '国债期货技术指标国债期货_30Y_adi', '国债期货技术指标国债期货_30Y_atr', '国债期货技术指标国债期货_30Y_vwap', '国债期货技术指标国债期货_30Y_low2high', '国债期货技术指标国债期货_30Y_vwap2close', '国债期货技术指标国债期货_30Y_kmid', '国债期货技术指标国债期货_30Y_klen', '国债期货技术指标国债期货_30Y_kmid2', '国债期货技术指标国债期货_30Y_kup2', '国债期货技术指标国债期货_30Y_klow2', '国债期货技术指标国债期货_30Y_ksft2', '宏观GDP不变价同比', '宏观GDP不变价当季值', '宏观美元指数', '宏观美元兑人民币即期汇率', '宏观MLF1Y', '宏观OMO007数量', '股市万得全A_收盘价_1D涨幅', '股市上证50_收盘价_1D涨幅', '股市中证500_收盘价_1D涨幅', '股市中证1000_收盘价_1D涨幅', '股市万得全A_收盘价_1M涨幅', '股市上证50_收盘价_1M涨幅', '股市中证500_收盘价_1M涨幅', '股市中证1000_收盘价_1M涨幅', '资金面R007_5日移动平均', '资金面R001_5日移动平均', '资金面DR007_5日移动平均', '资金面DR001_5日移动平均', '资金面FR007_5日移动平均', '资金面FR001_5日移动平均', '资金面SHIROR_3M_5日移动平均', '资金面SHIBOR_1Y_5日移动平均', '资金面R007_5日移动平均_近1Y历史分位数', '资金面R001_5日移动平均_近1Y历史分位数', '资金面DR007_5日移动平均_近1Y历史分位数', '资金面DR001_5日移动平均_近1Y历史分位数', '资金面FR007_5日移动平均_近1Y历史分位数', '资金面FR001_5日移动平均_近1Y历史分位数', '资金面SHIROR_3M_5日移动平均_近1Y历史分位数', '资金面SHIBOR_1Y_5日移动平均_近1Y历史分位数', '资金面R007_5日标准差', '资金面R001_5日标准差', '资金面DR007_5日标准差', '资金面DR001_5日标准差', '资金面FR007_5日标准差', '资金面FR001_5日标准差', '资金面SHIROR_3M_5日标准差', '资金面SHIBOR_1Y_5日标准差', '资金面R007_5日标准差_近1Y历史分位数', '资金面R001_5日标准差_近1Y历史分位数', '资金面DR007_5日标准差_近1Y历史分位数', '资金面DR001_5日标准差_近1Y历史分位数', '资金面FR007_5日标准差_近1Y历史分位数', '资金面FR001_5日标准差_近1Y历史分位数', '资金面SHIROR_3M_5日标准差_近1Y历史分位数', '资金面SHIBOR_1Y_5日标准差_近1Y历史分位数']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 201 | ['利率利差R007-R001', '利率利差活跃券_10Y-活跃券_3Y', '利率利差活跃券_10Y-活跃券_5Y', '利率利差活跃券_10Y-活跃券_7Y', '利率利差FR007_IRS_5Y-FR007_IRS_1Y', ...]\n",
      "\t\t('int', [])   :   6 | ['交易日期是否交易日', '交易日期月', '交易日期日', '交易日期是否15号', '交易日期是否20号', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 210 | ['R007-R001', '活跃券_10Y-活跃券_3Y', '活跃券_10Y-活跃券_5Y', '活跃券_10Y-活跃券_7Y', 'FR007_IRS_5Y-FR007_IRS_1Y', ...]\n",
      "\t\t('int', [])   :   6 | ['是否交易日', '月', '日', '是否15号', '是否20号', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 210 | ['R007-R001', '活跃券_10Y-活跃券_3Y', '活跃券_10Y-活跃券_5Y', '活跃券_10Y-活跃券_7Y', 'FR007_IRS_5Y-FR007_IRS_1Y', ...]\n",
      "\t\t('int', [])       :   3 | ['月', '日', '星期']\n",
      "\t\t('int', ['bool']) :   3 | ['是否交易日', '是否15号', '是否20号']\n",
      "\t15.6s = Fit runtime\n",
      "\t216 features in original data used to generate 216 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.75 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 15.63s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1350, Val Rows: 338\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=20, gpus=0, mem=0.1/974.4 GB\n",
      "\t0.6006\t = Validation score   (accuracy)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=20, gpus=0, mem=0.1/974.4 GB\n",
      "\t0.5828\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=20, gpus=0\n",
      "\tWarning: Exception caused RandomForestGini to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2171, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 219, in _fit\n",
      "    model = model.fit(X, y, sample_weight=sample_weight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 374, in fit\n",
      "    estimator._compute_missing_values_in_feature_mask(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
      "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=20, gpus=0\n",
      "\tWarning: Exception caused RandomForestEntr to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2171, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 219, in _fit\n",
      "    model = model.fit(X, y, sample_weight=sample_weight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 374, in fit\n",
      "    estimator._compute_missing_values_in_feature_mask(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
      "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=20, gpus=0\n",
      "\t0.5947\t = Validation score   (accuracy)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=20, gpus=0\n",
      "\tWarning: Exception caused ExtraTreesGini to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2171, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 219, in _fit\n",
      "    model = model.fit(X, y, sample_weight=sample_weight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 374, in fit\n",
      "    estimator._compute_missing_values_in_feature_mask(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
      "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=20, gpus=0\n",
      "\tWarning: Exception caused ExtraTreesEntr to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float32').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2171, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/rf/rf_model.py\", line 219, in _fit\n",
      "    model = model.fit(X, y, sample_weight=sample_weight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 374, in fit\n",
      "    estimator._compute_missing_values_in_feature_mask(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py\", line 222, in _compute_missing_values_in_feature_mask\n",
      "    _assert_all_finite_element_wise(X, xp=np, allow_nan=True, **common_kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float32').\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=20, gpus=0, mem=0.0/974.4 GB\n",
      "/root/miniconda3/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:199: RuntimeWarning: invalid value encountered in subtract\n",
      "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
      "/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:199: RuntimeWarning: invalid value encountered in subtract\n",
      "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
      "No improvement since epoch 0: early stopping\n",
      "/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py:199: RuntimeWarning: invalid value encountered in subtract\n",
      "  (X[self.cont_columns].values - cont_mean) / cont_std,\n",
      "\t0.4911\t = Validation score   (accuracy)\n",
      "\t2.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=20, gpus=0\n",
      "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
      "\t\t[11:51:10] /workspace/src/data/gradient_index.h:100: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
      "Stack trace:\n",
      "  [bt] (0) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6e7c) [0x7f217cea6e7c]\n",
      "  [bt] (1) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5e9e74) [0x7f217d1e9e74]\n",
      "  [bt] (2) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5ea8f9) [0x7f217d1ea8f9]\n",
      "  [bt] (3) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57b4f1) [0x7f217d17b4f1]\n",
      "  [bt] (4) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x178) [0x7f217cdb9378]\n",
      "  [bt] (5) /root/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7f22f9374052]\n",
      "  [bt] (6) /root/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7f22f9372925]\n",
      "  [bt] (7) /root/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f22f937306e]\n",
      "  [bt] (8) /root/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x97b7) [0x7f22f9f087b7]\n",
      "\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2171, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 191, in _fit\n",
      "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1664, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/xgboost/sklearn.py\", line 628, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1137, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/xgboost/core.py\", line 1614, in __init__\n",
      "    self._init(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/xgboost/core.py\", line 1680, in _init\n",
      "    _check_call(ret)\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/xgboost/core.py\", line 310, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:51:10] /workspace/src/data/gradient_index.h:100: Check failed: valid: Input data contains `inf` or a value too large, while `missing` is not set to `inf`\n",
      "Stack trace:\n",
      "  [bt] (0) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x2a6e7c) [0x7f217cea6e7c]\n",
      "  [bt] (1) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5e9e74) [0x7f217d1e9e74]\n",
      "  [bt] (2) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5ea8f9) [0x7f217d1ea8f9]\n",
      "  [bt] (3) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57b4f1) [0x7f217d17b4f1]\n",
      "  [bt] (4) /root/miniconda3/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGQuantileDMatrixCreateFromCallback+0x178) [0x7f217cdb9378]\n",
      "  [bt] (5) /root/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0xa052) [0x7f22f9374052]\n",
      "  [bt] (6) /root/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(+0x8925) [0x7f22f9372925]\n",
      "  [bt] (7) /root/miniconda3/lib/python3.12/lib-dynload/../../libffi.so.8(ffi_call+0xde) [0x7f22f937306e]\n",
      "  [bt] (8) /root/miniconda3/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x97b7) [0x7f22f9f087b7]\n",
      "\n",
      "\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=20, gpus=0, mem=0.0/974.2 GB\n",
      "/root/miniconda3/lib/python3.12/site-packages/pandas/core/nanops.py:1256: RuntimeWarning: invalid value encountered in subtract\n",
      "  adjusted = values - mean\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tInput X contains infinity or a value too large for dtype('float64').\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2171, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1068, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 214, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 692, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 764, in _process_train_data\n",
      "    df = self.processor.fit_transform(df)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 996, in fit_transform\n",
      "    result = self._call_func_on_transformers(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py\", line 897, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 82, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 1986, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 147, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 719, in fit_transform\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 589, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 894, in fit_transform\n",
      "    return self.fit(X, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/impute/_base.py\", line 436, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/impute/_base.py\", line 363, in _validate_input\n",
      "    raise ve\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/impute/_base.py\", line 344, in _validate_input\n",
      "    X = validate_data(\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 2954, in validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1105, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains infinity or a value too large for dtype('float64').\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=20, gpus=0, mem=0.2/974.2 GB\n",
      "\t0.5917\t = Validation score   (accuracy)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBMXT': 1.0}\n",
      "\t0.6006\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 24.49s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 164025.8 rows/s (338 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/root/AutogluonModels/ag-20250919_035048\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "predictor = TabularPredictor(label=label_col).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d65844-6ffa-45ba-8784-8d372564187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5224586288416075,\n",
       " 'balanced_accuracy': np.float64(0.36499226436807924),\n",
       " 'mcc': 0.10013290053350657}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d138e00e-f6dd-4b05-aa04-4fb60065e964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.026210</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.429002</td>\n",
       "      <td>0.026210</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.429002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.031925</td>\n",
       "      <td>0.025985</td>\n",
       "      <td>0.959421</td>\n",
       "      <td>0.031925</td>\n",
       "      <td>0.025985</td>\n",
       "      <td>0.959421</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.025678</td>\n",
       "      <td>0.023011</td>\n",
       "      <td>0.822087</td>\n",
       "      <td>0.025678</td>\n",
       "      <td>0.023011</td>\n",
       "      <td>0.822087</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.056777</td>\n",
       "      <td>0.091613</td>\n",
       "      <td>1.028770</td>\n",
       "      <td>0.056777</td>\n",
       "      <td>0.091613</td>\n",
       "      <td>1.028770</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.367625</td>\n",
       "      <td>0.238382</td>\n",
       "      <td>21.063900</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.040376</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.057842</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>1.021810</td>\n",
       "      <td>0.057842</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>1.021810</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.045053</td>\n",
       "      <td>0.034264</td>\n",
       "      <td>2.587463</td>\n",
       "      <td>0.045053</td>\n",
       "      <td>0.034264</td>\n",
       "      <td>2.587463</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.059717</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>0.899581</td>\n",
       "      <td>0.059717</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>0.899581</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.057804</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>1.038618</td>\n",
       "      <td>0.057804</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>1.038618</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.491071</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.052368</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>4.194760</td>\n",
       "      <td>0.052368</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>4.194760</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.038842</td>\n",
       "      <td>0.038475</td>\n",
       "      <td>12.024074</td>\n",
       "      <td>0.038842</td>\n",
       "      <td>0.038475</td>\n",
       "      <td>12.024074</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.172564</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>1.188456</td>\n",
       "      <td>0.172564</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>1.188456</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0              LightGBM    0.607143   0.688889    accuracy        0.026210   \n",
       "1               XGBoost    0.607143   0.655556    accuracy        0.031925   \n",
       "2            LightGBMXT    0.562500   0.677778    accuracy        0.025678   \n",
       "3        ExtraTreesGini    0.562500   0.700000    accuracy        0.056777   \n",
       "4   WeightedEnsemble_L2    0.535714   0.755556    accuracy        0.367625   \n",
       "5        ExtraTreesEntr    0.526786   0.666667    accuracy        0.057842   \n",
       "6       NeuralNetFastAI    0.517857   0.733333    accuracy        0.045053   \n",
       "7      RandomForestEntr    0.508929   0.700000    accuracy        0.059717   \n",
       "8      RandomForestGini    0.500000   0.700000    accuracy        0.057804   \n",
       "9        NeuralNetTorch    0.491071   0.644444    accuracy        0.052368   \n",
       "10             CatBoost    0.482143   0.711111    accuracy        0.038842   \n",
       "11        LightGBMLarge    0.482143   0.733333    accuracy        0.172564   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.025625   0.429002                 0.026210                0.025625   \n",
       "1        0.025985   0.959421                 0.031925                0.025985   \n",
       "2        0.023011   0.822087                 0.025678                0.023011   \n",
       "3        0.091613   1.028770                 0.056777                0.091613   \n",
       "4        0.238382  21.063900                 0.002021                0.000618   \n",
       "5        0.090468   1.021810                 0.057842                0.090468   \n",
       "6        0.034264   2.587463                 0.045053                0.034264   \n",
       "7        0.102804   0.899581                 0.059717                0.102804   \n",
       "8        0.087081   1.038618                 0.057804                0.087081   \n",
       "9        0.049133   4.194760                 0.052368                0.049133   \n",
       "10       0.038475  12.024074                 0.038842                0.038475   \n",
       "11       0.024278   1.188456                 0.172564                0.024278   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.429002            1       True          2  \n",
       "1            0.959421            1       True          9  \n",
       "2            0.822087            1       True          1  \n",
       "3            1.028770            1       True          6  \n",
       "4            0.040376            2       True         12  \n",
       "5            1.021810            1       True          7  \n",
       "6            2.587463            1       True          8  \n",
       "7            0.899581            1       True          4  \n",
       "8            1.038618            1       True          3  \n",
       "9            4.194760            1       True         10  \n",
       "10          12.024074            1       True          5  \n",
       "11           1.188456            1       True         11  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e326bf6-18e2-4585-916a-899e6d994487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  国债_10Y  label  predictions\n",
      "0 2023-12-15  2.5612      1            1\n",
      "1 2023-12-18  2.5546     -1           -1\n",
      "2 2023-12-19  2.5666     -1           -1\n",
      "3 2023-12-20  2.5760      1           -1\n",
      "4 2023-12-21  2.5353      1            1\n",
      "预测结果已保存到 prediction_results_国债_2025.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 1. 确保 'test_data' 是正确的，并且返回的预测结果是 Series 类型\n",
    "predictions = predictor.predict(test_data)\n",
    "\n",
    "# 2. 将预测结果的索引对齐到 'test_data' 的索引\n",
    "df_result = test_data.reset_index()[['date', '国债_10Y', 'label']].copy()\n",
    "\n",
    "# 3. 将预测结果添加到 DataFrame\n",
    "df_result['predictions'] = predictions.values  # 使用 .values 确保是一个可插入的值\n",
    "\n",
    "# 4. 输出查看\n",
    "print(df_result.head())\n",
    "\n",
    "# 5. 保存到 Excel 文件\n",
    "output_file = 'prediction_results_国债_2025.xlsx'\n",
    "df_result.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"预测结果已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2642f58-14b4-4777-91e7-96ac49595b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-03-21   -1\n",
       "2025-03-24    1\n",
       "2025-03-25   -1\n",
       "2025-03-26    1\n",
       "2025-03-27   -1\n",
       "             ..\n",
       "2025-08-22    1\n",
       "2025-08-25    1\n",
       "2025-08-26    1\n",
       "2025-08-27   -1\n",
       "2025-08-28   -1\n",
       "Name: label, Length: 110, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictor.predict(test_data)\n",
    "predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dc2614e-da71-4b75-8ced-455f965257e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051e3c8d-80f2-4cd6-83d1-0df02076820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['国债_10Y-国开债_10Y', '国债_10Y-企业债AAA+_10Y', '国债_10Y-中短期票据AAA+_10Y', '国债_10Y-国债_1Y', '国债_10Y-国债_3Y', '国债_10Y-国债_5Y', '国债_10Y-国债_7Y', '国债_30Y-国债_10Y', '国开债_10Y-国债_10Y', '国开债_5Y-国债_5Y', '国开债_1Y-国债_1Y', '中短期票据AAA+_1Y-国开债1Y', '中短期票据AAA+_3Y-国开债3Y', '中短期票据AAA+_5Y-国开债5Y', '中短期票据AAA+_7Y-国开债7Y', '中短期票据AAA+_10Y-国开债10Y', '中短期票据AAA+_30Y-国开债30Y', '国债_10Y-同业存单AAA_1Y', '国开债_10Y-国开债_5Y', '国开债_10Y-国开债_1Y', '活跃券_10Y-国债_10Y', '国债_5Y-FR007_IRS_5Y', '国债_1Y_收益率变动_5D', '国债_1Y_收益率变动_30D', '国债_1Y_收益率变动_90D', '国债_5Y_收益率变动_5D', '国债_5Y_收益率变动_30D', '国债_5Y_收益率变动_90D', '国债_7Y_收益率变动_5D', '国债_7Y_收益率变动_30D', '国债_7Y_收益率变动_90D', '国债_10Y_收益率变动_5D', '国债_10Y_收益率变动_30D', '国债_10Y_收益率变动_90D', '国债_30Y_收益率变动_5D', '国债_30Y_收益率变动_30D', '国债_30Y_收益率变动_90D', '国债_1Y_动量', '国债_5Y_动量', '国债_7Y_动量', '国债_10Y_动量', '国债_30Y_动量', '国债_1Y_macd', '国债_5Y_macd', '国债_7Y_macd', '国债_10Y_macd', '国债_30Y_macd', '交易日期是否交易日', '交易日期月', '交易日期日', '交易日期是否15号', '交易日期是否20号', '交易日期星期', '利率利差国债_10Y-国开债_10Y', '利率利差国债_10Y-企业债AAA+_10Y', '利率利差国债_10Y-中短期票据AAA+_10Y', '利率利差国债_10Y-国债_1Y', '利率利差国债_10Y-国债_3Y', '利率利差国债_10Y-国债_5Y', '利率利差国债_10Y-国债_7Y', '利率利差国债_30Y-国债_10Y', '利率利差国开债_10Y-国债_10Y', '利率利差国开债_5Y-国债_5Y', '利率利差国开债_1Y-国债_1Y', '利率利差中短期票据AAA+_1Y-国开债1Y', '利率利差中短期票据AAA+_3Y-国开债3Y', '利率利差中短期票据AAA+_5Y-国开债5Y', '利率利差中短期票据AAA+_7Y-国开债7Y', '利率利差中短期票据AAA+_10Y-国开债10Y', '利率利差中短期票据AAA+_30Y-国开债30Y', '利率利差国债_10Y-同业存单AAA_1Y', '利率利差国开债_10Y-国开债_5Y', '利率利差国开债_10Y-国开债_1Y', '利率利差R007-R001', '利率利差活跃券_10Y-活跃券_3Y', '利率利差活跃券_10Y-活跃券_5Y', '利率利差活跃券_10Y-活跃券_7Y', '利率利差活跃券_10Y-国债_10Y', '利率利差FR007_IRS_5Y-FR007_IRS_1Y', '利率利差FR007_IRS_1Y-FR007_IRS_9M', '利率利差国债_5Y-FR007_IRS_5Y', '利率利差SHIBOR_1Y-FR007_IRS_1Y', '国债技术指标国债_1Y_收益率变动_5D', '国债技术指标国债_1Y_收益率变动_30D', '国债技术指标国债_1Y_收益率变动_90D', '国债技术指标国债_5Y_收益率变动_5D', '国债技术指标国债_5Y_收益率变动_30D', '国债技术指标国债_5Y_收益率变动_90D', '国债技术指标国债_7Y_收益率变动_5D', '国债技术指标国债_7Y_收益率变动_30D', '国债技术指标国债_7Y_收益率变动_90D', '国债技术指标国债_10Y_收益率变动_5D', '国债技术指标国债_10Y_收益率变动_30D', '国债技术指标国债_10Y_收益率变动_90D', '国债技术指标国债_30Y_收益率变动_5D', '国债技术指标国债_30Y_收益率变动_30D', '国债技术指标国债_30Y_收益率变动_90D', '国债技术指标国债_1Y_动量', '国债技术指标国债_5Y_动量', '国债技术指标国债_7Y_动量', '国债技术指标国债_10Y_动量', '国债技术指标国债_30Y_动量', '国债技术指标国债_1Y_macd', '国债技术指标国债_5Y_macd', '国债技术指标国债_7Y_macd', '国债技术指标国债_10Y_macd', '国债技术指标国债_30Y_macd', '国债期货价差国债期货_活跃_2Y_均价-国债期货_次活跃_2Y_均价', '国债期货价差国债期货_活跃_5Y_均价-国债期货_次活跃_5Y_均价', '国债期货价差国债期货_活跃_10Y_均价-国债期货_次活跃_10Y_均价', '国债期货价差国债期货_活跃_30Y_均价-国债期货_次活跃_30Y_均价', '国债期货技术指标国债期货_2Y_open', '国债期货技术指标国债期货_2Y_close', '国债期货技术指标国债期货_2Y_high', '国债期货技术指标国债期货_2Y_low', '国债期货技术指标国债期货_2Y_volume', '国债期货技术指标国债期货_2Y_sma_5', '国债期货技术指标国债期货_2Y_trima_5', '国债期货技术指标国债期货_2Y_roc_5', '国债期货技术指标国债期货_2Y_cmo_5', '国债期货技术指标国债期货_2Y_wr_5', '国债期货技术指标国债期货_2Y_kdj_5', '国债期货技术指标国债期货_2Y_sma_10', '国债期货技术指标国债期货_2Y_trima_10', '国债期货技术指标国债期货_2Y_roc_10', '国债期货技术指标国债期货_2Y_cmo_10', '国债期货技术指标国债期货_2Y_wr_10', '国债期货技术指标国债期货_2Y_kdj_10', '国债期货技术指标国债期货_2Y_sma_20', '国债期货技术指标国债期货_2Y_trima_20', '国债期货技术指标国债期货_2Y_roc_20', '国债期货技术指标国债期货_2Y_cmo_20', '国债期货技术指标国债期货_2Y_wr_20', '国债期货技术指标国债期货_2Y_kdj_20', '国债期货技术指标国债期货_2Y_momentum', '国债期货技术指标国债期货_2Y_obv', '国债期货技术指标国债期货_2Y_adi', '国债期货技术指标国债期货_2Y_atr', '国债期货技术指标国债期货_2Y_vwap', '国债期货技术指标国债期货_2Y_low2high', '国债期货技术指标国债期货_2Y_vwap2close', '国债期货技术指标国债期货_2Y_kmid', '国债期货技术指标国债期货_2Y_klen', '国债期货技术指标国债期货_2Y_kmid2', '国债期货技术指标国债期货_2Y_kup2', '国债期货技术指标国债期货_2Y_klow2', '国债期货技术指标国债期货_2Y_ksft2', '国债期货技术指标国债期货_5Y_open', '国债期货技术指标国债期货_5Y_close', '国债期货技术指标国债期货_5Y_high', '国债期货技术指标国债期货_5Y_low', '国债期货技术指标国债期货_5Y_volume', '国债期货技术指标国债期货_5Y_sma_5', '国债期货技术指标国债期货_5Y_trima_5', '国债期货技术指标国债期货_5Y_roc_5', '国债期货技术指标国债期货_5Y_cmo_5', '国债期货技术指标国债期货_5Y_wr_5', '国债期货技术指标国债期货_5Y_kdj_5', '国债期货技术指标国债期货_5Y_sma_10', '国债期货技术指标国债期货_5Y_trima_10', '国债期货技术指标国债期货_5Y_roc_10', '国债期货技术指标国债期货_5Y_cmo_10', '国债期货技术指标国债期货_5Y_wr_10', '国债期货技术指标国债期货_5Y_kdj_10', '国债期货技术指标国债期货_5Y_sma_20', '国债期货技术指标国债期货_5Y_trima_20', '国债期货技术指标国债期货_5Y_roc_20', '国债期货技术指标国债期货_5Y_cmo_20', '国债期货技术指标国债期货_5Y_wr_20', '国债期货技术指标国债期货_5Y_kdj_20', '国债期货技术指标国债期货_5Y_momentum', '国债期货技术指标国债期货_5Y_obv', '国债期货技术指标国债期货_5Y_adi', '国债期货技术指标国债期货_5Y_atr', '国债期货技术指标国债期货_5Y_vwap', '国债期货技术指标国债期货_5Y_low2high', '国债期货技术指标国债期货_5Y_vwap2close', '国债期货技术指标国债期货_5Y_kmid', '国债期货技术指标国债期货_5Y_klen', '国债期货技术指标国债期货_5Y_kmid2', '国债期货技术指标国债期货_5Y_kup2', '国债期货技术指标国债期货_5Y_klow2', '国债期货技术指标国债期货_5Y_ksft2', '国债期货技术指标国债期货_10Y_open', '国债期货技术指标国债期货_10Y_close', '国债期货技术指标国债期货_10Y_high', '国债期货技术指标国债期货_10Y_low', '国债期货技术指标国债期货_10Y_volume', '国债期货技术指标国债期货_10Y_sma_5', '国债期货技术指标国债期货_10Y_trima_5', '国债期货技术指标国债期货_10Y_roc_5', '国债期货技术指标国债期货_10Y_cmo_5', '国债期货技术指标国债期货_10Y_wr_5', '国债期货技术指标国债期货_10Y_kdj_5', '国债期货技术指标国债期货_10Y_sma_10', '国债期货技术指标国债期货_10Y_trima_10', '国债期货技术指标国债期货_10Y_roc_10', '国债期货技术指标国债期货_10Y_cmo_10', '国债期货技术指标国债期货_10Y_wr_10', '国债期货技术指标国债期货_10Y_kdj_10', '国债期货技术指标国债期货_10Y_sma_20', '国债期货技术指标国债期货_10Y_trima_20', '国债期货技术指标国债期货_10Y_roc_20', '国债期货技术指标国债期货_10Y_cmo_20', '国债期货技术指标国债期货_10Y_wr_20', '国债期货技术指标国债期货_10Y_kdj_20', '国债期货技术指标国债期货_10Y_momentum', '国债期货技术指标国债期货_10Y_obv', '国债期货技术指标国债期货_10Y_adi', '国债期货技术指标国债期货_10Y_atr', '国债期货技术指标国债期货_10Y_vwap', '国债期货技术指标国债期货_10Y_low2high', '国债期货技术指标国债期货_10Y_vwap2close', '国债期货技术指标国债期货_10Y_kmid', '国债期货技术指标国债期货_10Y_klen', '国债期货技术指标国债期货_10Y_kmid2', '国债期货技术指标国债期货_10Y_kup2', '国债期货技术指标国债期货_10Y_klow2', '国债期货技术指标国债期货_10Y_ksft2', '国债期货技术指标国债期货_30Y_open', '国债期货技术指标国债期货_30Y_close', '国债期货技术指标国债期货_30Y_high', '国债期货技术指标国债期货_30Y_low', '国债期货技术指标国债期货_30Y_volume', '国债期货技术指标国债期货_30Y_sma_5', '国债期货技术指标国债期货_30Y_trima_5', '国债期货技术指标国债期货_30Y_roc_5', '国债期货技术指标国债期货_30Y_cmo_5', '国债期货技术指标国债期货_30Y_wr_5', '国债期货技术指标国债期货_30Y_kdj_5', '国债期货技术指标国债期货_30Y_sma_10', '国债期货技术指标国债期货_30Y_trima_10', '国债期货技术指标国债期货_30Y_roc_10', '国债期货技术指标国债期货_30Y_cmo_10', '国债期货技术指标国债期货_30Y_wr_10', '国债期货技术指标国债期货_30Y_kdj_10', '国债期货技术指标国债期货_30Y_sma_20', '国债期货技术指标国债期货_30Y_trima_20', '国债期货技术指标国债期货_30Y_roc_20', '国债期货技术指标国债期货_30Y_cmo_20', '国债期货技术指标国债期货_30Y_wr_20', '国债期货技术指标国债期货_30Y_kdj_20', '国债期货技术指标国债期货_30Y_momentum', '国债期货技术指标国债期货_30Y_obv', '国债期货技术指标国债期货_30Y_adi', '国债期货技术指标国债期货_30Y_atr', '国债期货技术指标国债期货_30Y_vwap', '国债期货技术指标国债期货_30Y_low2high', '国债期货技术指标国债期货_30Y_vwap2close', '国债期货技术指标国债期货_30Y_kmid', '国债期货技术指标国债期货_30Y_klen', '国债期货技术指标国债期货_30Y_kmid2', '国债期货技术指标国债期货_30Y_kup2', '国债期货技术指标国债期货_30Y_klow2', '国债期货技术指标国债期货_30Y_ksft2', '宏观GDP不变价同比', '宏观GDP不变价当季值', '宏观美元指数', '宏观美元兑人民币即期汇率', '宏观MLF1Y', '宏观OMO007数量', '股市万得全A_收盘价_1D涨幅', '股市上证50_收盘价_1D涨幅', '股市中证500_收盘价_1D涨幅', '股市中证1000_收盘价_1D涨幅', '股市万得全A_收盘价_1M涨幅', '股市上证50_收盘价_1M涨幅', '股市中证500_收盘价_1M涨幅', '股市中证1000_收盘价_1M涨幅', '资金面R007_5日移动平均', '资金面R001_5日移动平均', '资金面DR007_5日移动平均', '资金面DR001_5日移动平均', '资金面FR007_5日移动平均', '资金面FR001_5日移动平均', '资金面SHIROR_3M_5日移动平均', '资金面SHIBOR_1Y_5日移动平均', '资金面R007_5日移动平均_近1Y历史分位数', '资金面R001_5日移动平均_近1Y历史分位数', '资金面DR007_5日移动平均_近1Y历史分位数', '资金面DR001_5日移动平均_近1Y历史分位数', '资金面FR007_5日移动平均_近1Y历史分位数', '资金面FR001_5日移动平均_近1Y历史分位数', '资金面SHIROR_3M_5日移动平均_近1Y历史分位数', '资金面SHIBOR_1Y_5日移动平均_近1Y历史分位数', '资金面R007_5日标准差', '资金面R001_5日标准差', '资金面DR007_5日标准差', '资金面DR001_5日标准差', '资金面FR007_5日标准差', '资金面FR001_5日标准差', '资金面SHIROR_3M_5日标准差', '资金面SHIBOR_1Y_5日标准差', '资金面R007_5日标准差_近1Y历史分位数', '资金面R001_5日标准差_近1Y历史分位数', '资金面DR007_5日标准差_近1Y历史分位数', '资金面DR001_5日标准差_近1Y历史分位数', '资金面FR007_5日标准差_近1Y历史分位数', '资金面FR001_5日标准差_近1Y历史分位数', '资金面SHIROR_3M_5日标准差_近1Y历史分位数', '资金面SHIBOR_1Y_5日标准差_近1Y历史分位数']\n",
      "Computing feature importance via permutation shuffling for 216 features using 422 rows with 5 shuffle sets...\n",
      "\t14.93s\t= Expected runtime (2.99s per shuffle set)\n",
      "\t2.92s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 22269 (\\N{CJK UNIFIED IDEOGRAPH-56FD}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 20538 (\\N{CJK UNIFIED IDEOGRAPH-503A}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 26399 (\\N{CJK UNIFIED IDEOGRAPH-671F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 36135 (\\N{CJK UNIFIED IDEOGRAPH-8D27}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 26085 (\\N{CJK UNIFIED IDEOGRAPH-65E5}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 26631 (\\N{CJK UNIFIED IDEOGRAPH-6807}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 24046 (\\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 27963 (\\N{CJK UNIFIED IDEOGRAPH-6D3B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 36291 (\\N{CJK UNIFIED IDEOGRAPH-8DC3}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 20215 (\\N{CJK UNIFIED IDEOGRAPH-4EF7}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:19: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 22269 (\\N{CJK UNIFIED IDEOGRAPH-56FD}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 20538 (\\N{CJK UNIFIED IDEOGRAPH-503A}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 26399 (\\N{CJK UNIFIED IDEOGRAPH-671F}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 36135 (\\N{CJK UNIFIED IDEOGRAPH-8D27}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 26085 (\\N{CJK UNIFIED IDEOGRAPH-65E5}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 26631 (\\N{CJK UNIFIED IDEOGRAPH-6807}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 24046 (\\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 27963 (\\N{CJK UNIFIED IDEOGRAPH-6D3B}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 36291 (\\N{CJK UNIFIED IDEOGRAPH-8DC3}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 22343 (\\N{CJK UNIFIED IDEOGRAPH-5747}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 20215 (\\N{CJK UNIFIED IDEOGRAPH-4EF7}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n",
      "/tmp/ipykernel_1385/2431260117.py:20: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig('feature_importance_top30.png', dpi=150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成：feature_importance.xlsx / feature_importance.csv / feature_importance_top30.png\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 用验证集/测试集计算特征重要性（需要包含label列，AutoGluon会用它评估）\n",
    "imp = predictor.feature_importance(test_data, subsample_size=None)  # 或 train_data\n",
    "\n",
    "# 1) 保存到 Excel/CSV\n",
    "imp.to_excel('feature_importance.xlsx')\n",
    "imp.to_csv('feature_importance.csv', index=True)\n",
    "\n",
    "# 2) 画前30个特征的重要性条形图并保存\n",
    "topk = 30\n",
    "plot_df = imp.head(topk).sort_values('importance')  # importance越大越重要\n",
    "ax = plot_df['importance'].plot(kind='barh', figsize=(8, 10))\n",
    "ax.set_xlabel('Permutation Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_title(f'AutoGluon Feature Importance (Top {topk})')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_top30.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print('已生成：feature_importance.xlsx / feature_importance.csv / feature_importance_top30.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
