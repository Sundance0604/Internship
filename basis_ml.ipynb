{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e7554b3",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4331f9d",
   "metadata": {},
   "source": [
    "## 提取基差数据并进行差分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c96c5489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to use Wind Quant API for Python (WindPy)!\n",
      "\n",
      "COPYRIGHT (C) 2024 WIND INFORMATION CO., LTD. ALL RIGHTS RESERVED.\n",
      "IN NO CIRCUMSTANCE SHALL WIND BE RESPONSIBLE FOR ANY DAMAGES OR LOSSES CAUSED BY USING WIND QUANT API FOR Python.\n"
     ]
    }
   ],
   "source": [
    "import new_factor as nf\n",
    "\n",
    "myfactor = nf.NewFactor()\n",
    "df_basis = myfactor.get_data('basis')\n",
    "df_basis['T_diff'] = df_basis['T'].diff()\n",
    "df_basis['TF_diff'] = df_basis['TF'].diff()\n",
    "df_basis['TS_diff'] = df_basis['TS'].diff() \n",
    "df_basis['TL_diff'] = df_basis['TL'].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb961c2",
   "metadata": {},
   "source": [
    "## 读取因子数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tech_factor as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad39c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_excel('gold.xlsx')\n",
    "df_raw.set_index('date', inplace=True)\n",
    "\n",
    "# 计算差分（可选）\n",
    "df_raw['diff'] = df_raw['收盘价'].diff()\n",
    "\n",
    "# ============ 技术指标 ============\n",
    "\n",
    "# 移动均线（MA5, MA20, MA60）\n",
    "df_raw['ma5'] = df_raw['收盘价'].rolling(window=5).mean()\n",
    "df_raw['ma20'] = df_raw['收盘价'].rolling(window=20).mean()\n",
    "df_raw['ma60'] = df_raw['收盘价'].rolling(window=60).mean()\n",
    "\n",
    "# 也可以加一些常见的技术指标：\n",
    "# 波动率（5日、20日标准差）\n",
    "df_raw['volatility5'] = df_raw['收盘价'].rolling(window=5).std()\n",
    "df_raw['volatility20'] = df_raw['收盘价'].rolling(window=20).std()\n",
    "\n",
    "# 均线差值（趋势信号）\n",
    "df_raw['ma5_ma20_diff'] = df_raw['ma5'] - df_raw['ma20']\n",
    "\n",
    "# ============ 标签 ============\n",
    "\n",
    "# 涨跌标签：下一期比当前期涨为 1，跌为 -1，不变为 0\n",
    "df_raw['label'] = (df_raw['收盘价'].shift(-1) - df_raw['收盘价']).apply(\n",
    "    lambda x: 1 if x > 0 else -1 if x < 0 else 0\n",
    ")\n",
    "\n",
    "# 删除最后一行（因为没有未来数据做标签）\n",
    "df_clean = df_raw.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5732c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 df_clean 已经准备好，索引为时间或顺序\n",
    "\n",
    "label_col = \"label\"\n",
    "split_point = int(len(df_clean) * 0.8)\n",
    "\n",
    "# 按顺序切分\n",
    "df_train = df_clean.iloc[:split_point]\n",
    "df_test  = df_clean.iloc[split_point:]\n",
    "\n",
    "# 拆分特征和标签\n",
    "X_train, y_train = df_train.drop(columns=[label_col]), df_train[label_col]\n",
    "X_test,  y_test  = df_test.drop(columns=[label_col]),  df_test[label_col]\n",
    "\n",
    "train_data = pd.concat([X_train,y_train],axis=1)\n",
    "test_data = pd.concat([X_test, y_test],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa290496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\pavane\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250924_062624\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       5.57 GB / 15.73 GB (35.4%)\n",
      "Disk Space Avail:   46.70 GB / 274.71 GB (17.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"d:\\mycodelife\\workshop\\yinhe\\AutogluonModels\\ag-20250924_062624\"\n",
      "Train Data Rows:    2087\n",
      "Train Data Columns: 19\n",
      "Label Column:       label\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(-1), np.int64(0)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5639.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.30 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 18 | ['开盘价', '最高价', '最低价', '收盘价', '涨跌幅', ...]\n",
      "\t\t('int', [])   :  1 | ['周成交量\\n[单位]股(张)']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 18 | ['开盘价', '最高价', '最低价', '收盘价', '涨跌幅', ...]\n",
      "\t\t('int', [])   :  1 | ['周成交量\\n[单位]股(张)']\n",
      "\t0.0s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.30 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1669, Val Rows: 418\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.0/5.3 GB\n",
      "\t0.6411\t = Validation score   (accuracy)\n",
      "\t8.87s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.0/5.3 GB\n",
      "\t0.6172\t = Validation score   (accuracy)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.0/5.3 GB\n",
      "\t0.622\t = Validation score   (accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=16, gpus=0\n",
      "\t0.5622\t = Validation score   (accuracy)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=16, gpus=0\n",
      "\t0.5694\t = Validation score   (accuracy)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t0.6196\t = Validation score   (accuracy)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=16, gpus=0\n",
      "\t0.5431\t = Validation score   (accuracy)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=16, gpus=0\n",
      "\t0.5287\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t0.622\t = Validation score   (accuracy)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.0/5.3 GB\n",
      "d:\\conda\\envs\\pavane\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.6364\t = Validation score   (accuracy)\n",
      "\t5.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.1/5.5 GB\n",
      "\t0.6053\t = Validation score   (accuracy)\n",
      "\t2.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.667, 'NeuralNetFastAI': 0.333}\n",
      "\t0.6579\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 24.91s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13410.9 rows/s (418 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"d:\\mycodelife\\workshop\\yinhe\\AutogluonModels\\ag-20250924_062624\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "predictor = TabularPredictor(label=label_col).fit(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pavane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
