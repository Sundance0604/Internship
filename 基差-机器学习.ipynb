{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a178ae41",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab521d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('基差.xls')\n",
    "df.set_index('日期', inplace=True)\n",
    "\n",
    "df = df.diff(1)  # 全部先差分，后续再细化\n",
    "df_clean = df.dropna().copy()\n",
    "# 标签：下一期 Δ(基差) 是否 > 0\n",
    "df_clean['value_sort'] = df_clean['基差'].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "df_clean = df_clean.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4336e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_sort\n",
      "1    1324\n",
      "0    1219\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['value_sort'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f988a495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>收益率(%)</th>\n",
       "      <th>净价</th>\n",
       "      <th>全价</th>\n",
       "      <th>期货价格</th>\n",
       "      <th>发票价格</th>\n",
       "      <th>转换因子</th>\n",
       "      <th>基差</th>\n",
       "      <th>期现价差</th>\n",
       "      <th>IRR(%)</th>\n",
       "      <th>十债主连成交量</th>\n",
       "      <th>十债主连持仓量</th>\n",
       "      <th>置信区间上限</th>\n",
       "      <th>置信区间下限</th>\n",
       "      <th>value_sort</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>日期</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-09-04</th>\n",
       "      <td>-0.0350</td>\n",
       "      <td>-0.3109</td>\n",
       "      <td>-0.4428</td>\n",
       "      <td>0.382</td>\n",
       "      <td>-0.3802</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>-0.0688</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>-8599.0</td>\n",
       "      <td>-523.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-03</th>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>-0.1271</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>-4154.0</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-02</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>-0.1384</td>\n",
       "      <td>-0.1457</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>-0.1472</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>-0.0156</td>\n",
       "      <td>-26100.0</td>\n",
       "      <td>-7855.0</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-01</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>-0.6229</td>\n",
       "      <td>-0.7545</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.7364</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>-0.0241</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>23432.0</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>-0.0086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-29</th>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.6501</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.6530</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>-0.0318</td>\n",
       "      <td>-10472.0</td>\n",
       "      <td>-7482.0</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            收益率(%)      净价      全价   期货价格    发票价格    转换因子      基差    期现价差  \\\n",
       "日期                                                                          \n",
       "2025-09-04 -0.0350 -0.3109 -0.4428  0.382 -0.3802 -0.0057 -0.0688  0.0630   \n",
       "2025-09-03  0.0142  0.4564  0.5737 -0.218  0.5411  0.0057  0.0530 -0.0326   \n",
       "2025-09-02  0.0208 -0.1384 -0.1457 -0.150 -0.1472  0.0000  0.0091 -0.0018   \n",
       "2025-09-01  0.0109 -0.6229 -0.7545  0.017 -0.7364 -0.0057 -0.0241  0.0179   \n",
       "2025-08-29  0.0016  0.5478  0.6501 -0.102  0.6530  0.0057  0.0324  0.0031   \n",
       "\n",
       "            IRR(%)  十债主连成交量  十债主连持仓量  置信区间上限  置信区间下限  value_sort  \n",
       "日期                                                                \n",
       "2025-09-04  0.2044  -8599.0   -523.0  0.0010 -0.0003           1  \n",
       "2025-09-03 -0.1271   2944.0  -4154.0  0.0035  0.0327           1  \n",
       "2025-09-02 -0.0156 -26100.0  -7855.0  0.0266 -0.0033           0  \n",
       "2025-09-01  0.0555  23432.0   1747.0  0.0444 -0.0086           1  \n",
       "2025-08-29 -0.0318 -10472.0  -7482.0 -0.0105  0.0332           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08079b",
   "metadata": {},
   "source": [
    "# LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a11684da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-10 09:36:05,362] A new study created in memory with name: no-name-743faec4-0e46-421f-8c45-2a4fd7098662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top Drifted Features (TrainFit vs Test) ====\n",
      "feature  is_categorical    PSI  KS/Chi2_p  KS_stat  missing_ref  missing_new  missing_diff\n",
      "   期现价差           False 0.8140     0.0000   0.1833       0.0000       0.0000        0.0000\n",
      " IRR(%)           False 0.8045     0.0000   0.1897       0.0000       0.0000        0.0000\n",
      "十债主连持仓量           False 0.7268     0.0000   0.1936       0.0000       0.0000        0.0000\n",
      "     基差           False 0.6009     0.0000   0.1884       0.0000       0.0000        0.0000\n",
      "     净价           False 0.4835     0.0000   0.1542       0.0000       0.0000        0.0000\n",
      " 置信区间上限           False 0.4779     0.0000   0.1436       0.0000       0.0000        0.0000\n",
      " 置信区间下限           False 0.4329     0.0000   0.1532       0.0000       0.0000        0.0000\n",
      "   发票价格           False 0.4185     0.0000   0.1547       0.0000       0.0000        0.0000\n",
      "十债主连成交量           False 0.3992     0.0000   0.1549       0.0000       0.0000        0.0000\n",
      "     全价           False 0.3792     0.0000   0.1548       0.0000       0.0000        0.0000\n",
      "   期货价格           False 0.3068     0.0000   0.1275       0.0000       0.0000        0.0000\n",
      " 收益率(%)           False 0.1684     0.0014   0.0964       0.0000       0.0000        0.0000\n",
      "   转换因子           False 0.1355     0.0000   0.1209       0.0000       0.0000        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-10 09:36:05,794] Trial 0 finished with value: 0.7140600315955766 and parameters: {'n_estimators': 1424, 'learning_rate': 0.00184456687425243, 'num_leaves': 110, 'min_child_samples': 75, 'subsample': 0.8412014500110103, 'colsample_bytree': 0.5488239470061993, 'reg_alpha': 3.8804425708981016, 'reg_lambda': 0.0005604986873053644}. Best is trial 0 with value: 0.7140600315955766.\n",
      "[I 2025-09-10 09:36:06,455] Trial 1 finished with value: 0.7664670658682635 and parameters: {'n_estimators': 1785, 'learning_rate': 0.003982908557807532, 'num_leaves': 71, 'min_child_samples': 17, 'subsample': 0.6397661809047013, 'colsample_bytree': 0.7175662567583736, 'reg_alpha': 0.09630601503340519, 'reg_lambda': 0.0005380596544962404}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:06,934] Trial 2 finished with value: 0.7652495378927912 and parameters: {'n_estimators': 1628, 'learning_rate': 0.025271766588726815, 'num_leaves': 74, 'min_child_samples': 39, 'subsample': 0.7835627726235415, 'colsample_bytree': 0.9132630511876862, 'reg_alpha': 0.11250242748183727, 'reg_lambda': 4.438008033501167e-07}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:07,366] Trial 3 finished with value: 0.7560521415270018 and parameters: {'n_estimators': 801, 'learning_rate': 0.007384887900225752, 'num_leaves': 105, 'min_child_samples': 153, 'subsample': 0.697050071765497, 'colsample_bytree': 0.8946663291863479, 'reg_alpha': 5.096835194093152e-06, 'reg_lambda': 0.038306804832724625}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:07,828] Trial 4 finished with value: 0.7577413479052824 and parameters: {'n_estimators': 1931, 'learning_rate': 0.005062632460495786, 'num_leaves': 72, 'min_child_samples': 195, 'subsample': 0.6845378332514432, 'colsample_bytree': 0.8587182212573117, 'reg_alpha': 0.04949806232815368, 'reg_lambda': 3.616363467866201e-08}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:08,239] Trial 5 finished with value: 0.7140600315955766 and parameters: {'n_estimators': 683, 'learning_rate': 0.0013303198526370306, 'num_leaves': 192, 'min_child_samples': 46, 'subsample': 0.7872540850421754, 'colsample_bytree': 0.91958179850068, 'reg_alpha': 0.0002800928053339203, 'reg_lambda': 0.006642940391316645}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:08,969] Trial 6 finished with value: 0.7586206896551724 and parameters: {'n_estimators': 389, 'learning_rate': 0.0017325992851647241, 'num_leaves': 363, 'min_child_samples': 26, 'subsample': 0.9743530295475966, 'colsample_bytree': 0.5864511922676563, 'reg_alpha': 0.11267116522116802, 'reg_lambda': 0.0023730475505409584}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:09,377] Trial 7 finished with value: 0.7545787545787546 and parameters: {'n_estimators': 528, 'learning_rate': 0.016937237208860943, 'num_leaves': 108, 'min_child_samples': 124, 'subsample': 0.8350593908093296, 'colsample_bytree': 0.7850132373859522, 'reg_alpha': 5.49462113789658e-07, 'reg_lambda': 0.0025043808031965896}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:09,776] Trial 8 finished with value: 0.7547169811320755 and parameters: {'n_estimators': 1517, 'learning_rate': 0.030699659978242647, 'num_leaves': 30, 'min_child_samples': 56, 'subsample': 0.9324335396304526, 'colsample_bytree': 0.576175005817289, 'reg_alpha': 1.0167331812105841e-07, 'reg_lambda': 0.07433353961292676}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:10,241] Trial 9 finished with value: 0.7540394973070018 and parameters: {'n_estimators': 1466, 'learning_rate': 0.005911921618233507, 'num_leaves': 31, 'min_child_samples': 194, 'subsample': 0.8886792428086316, 'colsample_bytree': 0.7878872404532122, 'reg_alpha': 2.748622591695701, 'reg_lambda': 4.234664790917381e-08}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:10,648] Trial 10 finished with value: 0.754325259515571 and parameters: {'n_estimators': 1027, 'learning_rate': 0.12960015620382645, 'num_leaves': 16, 'min_child_samples': 105, 'subsample': 0.5072319070329934, 'colsample_bytree': 0.6879394877472695, 'reg_alpha': 0.0004621794093700289, 'reg_lambda': 2.225437441310861}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:11,174] Trial 11 finished with value: 0.7654320987654321 and parameters: {'n_estimators': 1954, 'learning_rate': 0.05230035519555752, 'num_leaves': 52, 'min_child_samples': 10, 'subsample': 0.5906983392184217, 'colsample_bytree': 0.6899174261470061, 'reg_alpha': 0.01988101616304775, 'reg_lambda': 1.5372924092808026e-06}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:11,680] Trial 12 finished with value: 0.7474048442906575 and parameters: {'n_estimators': 1853, 'learning_rate': 0.06921486641877503, 'num_leaves': 44, 'min_child_samples': 5, 'subsample': 0.5677693665116472, 'colsample_bytree': 0.6847853308740328, 'reg_alpha': 0.0019230170393107913, 'reg_lambda': 8.535205494341677e-06}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:12,339] Trial 13 finished with value: 0.7627737226277372 and parameters: {'n_estimators': 1937, 'learning_rate': 0.055729775591184326, 'num_leaves': 193, 'min_child_samples': 10, 'subsample': 0.6161615328925045, 'colsample_bytree': 0.6785382671680392, 'reg_alpha': 0.011878730695743345, 'reg_lambda': 2.050571402027048e-05}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:12,760] Trial 14 finished with value: 0.759493670886076 and parameters: {'n_estimators': 1232, 'learning_rate': 0.18779068864219728, 'num_leaves': 43, 'min_child_samples': 69, 'subsample': 0.6313337979188547, 'colsample_bytree': 0.6428280063506182, 'reg_alpha': 2.1947906995402955e-05, 'reg_lambda': 1.769346160364413e-05}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:13,282] Trial 15 finished with value: 0.7609561752988048 and parameters: {'n_estimators': 1725, 'learning_rate': 0.010890779705247213, 'num_leaves': 16, 'min_child_samples': 81, 'subsample': 0.5412170687195886, 'colsample_bytree': 0.755499406193777, 'reg_alpha': 0.7460922999842203, 'reg_lambda': 1.1221333937615605e-06}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:13,990] Trial 16 finished with value: 0.7651515151515151 and parameters: {'n_estimators': 1212, 'learning_rate': 0.003326213878486354, 'num_leaves': 53, 'min_child_samples': 18, 'subsample': 0.688240595397378, 'colsample_bytree': 0.8221430233350602, 'reg_alpha': 0.0058498282009287845, 'reg_lambda': 0.0001214761079218292}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:14,514] Trial 17 finished with value: 0.7468581687612208 and parameters: {'n_estimators': 1762, 'learning_rate': 0.0032572120411767623, 'num_leaves': 172, 'min_child_samples': 38, 'subsample': 0.6086520524918504, 'colsample_bytree': 0.513194414250542, 'reg_alpha': 8.15389625410194e-05, 'reg_lambda': 6.194860676215818e-07}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:14,939] Trial 18 finished with value: 0.7588785046728972 and parameters: {'n_estimators': 1987, 'learning_rate': 0.059971031816782004, 'num_leaves': 27, 'min_child_samples': 102, 'subsample': 0.646454000793043, 'colsample_bytree': 0.7279123636882638, 'reg_alpha': 0.3988953962077982, 'reg_lambda': 0.00014600635981555608}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:15,374] Trial 19 finished with value: 0.7564575645756457 and parameters: {'n_estimators': 1008, 'learning_rate': 0.014877072307494197, 'num_leaves': 502, 'min_child_samples': 150, 'subsample': 0.7364268985081256, 'colsample_bytree': 0.982736911105615, 'reg_alpha': 0.016472634968739866, 'reg_lambda': 1.2208198650119448}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:15,913] Trial 20 finished with value: 0.7583774250440917 and parameters: {'n_estimators': 1294, 'learning_rate': 0.02727428855979083, 'num_leaves': 60, 'min_child_samples': 25, 'subsample': 0.5722764457976518, 'colsample_bytree': 0.6189514417809407, 'reg_alpha': 7.854764569288967, 'reg_lambda': 3.7767217799267177e-06}. Best is trial 1 with value: 0.7664670658682635.\n",
      "[I 2025-09-10 09:36:16,434] Trial 21 finished with value: 0.7706422018348624 and parameters: {'n_estimators': 1584, 'learning_rate': 0.027637922411249093, 'num_leaves': 76, 'min_child_samples': 36, 'subsample': 0.7711670033868725, 'colsample_bytree': 0.7426464836997688, 'reg_alpha': 0.1762093563515288, 'reg_lambda': 1.8236415861469961e-07}. Best is trial 21 with value: 0.7706422018348624.\n",
      "[I 2025-09-10 09:36:16,996] Trial 22 finished with value: 0.7637051039697542 and parameters: {'n_estimators': 1684, 'learning_rate': 0.0861553713268692, 'num_leaves': 135, 'min_child_samples': 52, 'subsample': 0.7590581210685764, 'colsample_bytree': 0.7273477820123964, 'reg_alpha': 0.0015444021936670347, 'reg_lambda': 2.241279212600879e-07}. Best is trial 21 with value: 0.7706422018348624.\n",
      "[I 2025-09-10 09:36:18,053] Trial 23 finished with value: 0.7632508833922261 and parameters: {'n_estimators': 1536, 'learning_rate': 0.04038246948882532, 'num_leaves': 76, 'min_child_samples': 5, 'subsample': 0.7234427851990457, 'colsample_bytree': 0.6439042094268417, 'reg_alpha': 0.6414525576447283, 'reg_lambda': 1.783257666865476e-08}. Best is trial 21 with value: 0.7706422018348624.\n",
      "[I 2025-09-10 09:36:18,597] Trial 24 finished with value: 0.7739602169981917 and parameters: {'n_estimators': 1798, 'learning_rate': 0.008667277818767917, 'num_leaves': 43, 'min_child_samples': 34, 'subsample': 0.6526140693197464, 'colsample_bytree': 0.7574020070803538, 'reg_alpha': 0.040213638012356064, 'reg_lambda': 1.2647932847540616e-07}. Best is trial 24 with value: 0.7739602169981917.\n",
      "[I 2025-09-10 09:36:19,066] Trial 25 finished with value: 0.7660377358490567 and parameters: {'n_estimators': 1763, 'learning_rate': 0.008983550877638906, 'num_leaves': 37, 'min_child_samples': 61, 'subsample': 0.6506396285677953, 'colsample_bytree': 0.8214886633756354, 'reg_alpha': 0.23442869881941872, 'reg_lambda': 1.2231967686117066e-07}. Best is trial 24 with value: 0.7739602169981917.\n",
      "[I 2025-09-10 09:36:19,827] Trial 26 finished with value: 0.7701375245579568 and parameters: {'n_estimators': 1362, 'learning_rate': 0.003848501506423826, 'num_leaves': 25, 'min_child_samples': 30, 'subsample': 0.81173053924462, 'colsample_bytree': 0.7456393716668535, 'reg_alpha': 0.0018158296858454006, 'reg_lambda': 5.4641629835144584e-05}. Best is trial 24 with value: 0.7739602169981917.\n",
      "[I 2025-09-10 09:36:20,301] Trial 27 finished with value: 0.7567567567567568 and parameters: {'n_estimators': 1351, 'learning_rate': 0.01747461817274558, 'num_leaves': 24, 'min_child_samples': 84, 'subsample': 0.835441535016386, 'colsample_bytree': 0.7731655357948495, 'reg_alpha': 0.0032952748570184136, 'reg_lambda': 1.057203492708451e-08}. Best is trial 24 with value: 0.7739602169981917.\n",
      "[I 2025-09-10 09:36:21,090] Trial 28 finished with value: 0.7767695099818511 and parameters: {'n_estimators': 1113, 'learning_rate': 0.002353708529464213, 'num_leaves': 23, 'min_child_samples': 33, 'subsample': 0.8813676651494842, 'colsample_bytree': 0.8371434219312059, 'reg_alpha': 0.00054660902955889, 'reg_lambda': 5.0190761530858195e-05}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:21,922] Trial 29 finished with value: 0.7598425196850394 and parameters: {'n_estimators': 1127, 'learning_rate': 0.001001057722459098, 'num_leaves': 23, 'min_child_samples': 92, 'subsample': 0.8932183576796532, 'colsample_bytree': 0.8341956534470476, 'reg_alpha': 4.445271191792234e-06, 'reg_lambda': 1.02689200084349e-07}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:22,517] Trial 30 finished with value: 0.7597765363128491 and parameters: {'n_estimators': 863, 'learning_rate': 0.002304509581454431, 'num_leaves': 20, 'min_child_samples': 65, 'subsample': 0.8829381944480517, 'colsample_bytree': 0.8741596876226337, 'reg_alpha': 1.486940187111748, 'reg_lambda': 4.448439146801689e-06}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:23,346] Trial 31 finished with value: 0.7756653992395437 and parameters: {'n_estimators': 1392, 'learning_rate': 0.0024047307479135483, 'num_leaves': 34, 'min_child_samples': 37, 'subsample': 0.7956553491297299, 'colsample_bytree': 0.7901190366401094, 'reg_alpha': 0.0005302319778405397, 'reg_lambda': 5.3112224034725656e-05}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:23,820] Trial 32 finished with value: 0.7140600315955766 and parameters: {'n_estimators': 1607, 'learning_rate': 0.002143940811787106, 'num_leaves': 37, 'min_child_samples': 44, 'subsample': 0.7680327326950608, 'colsample_bytree': 0.8058421470615799, 'reg_alpha': 0.00044188940517298907, 'reg_lambda': 4.83444166598696e-05}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:24,537] Trial 33 finished with value: 0.7703703703703704 and parameters: {'n_estimators': 1426, 'learning_rate': 0.0028128244791773703, 'num_leaves': 37, 'min_child_samples': 37, 'subsample': 0.8651297238319919, 'colsample_bytree': 0.8492504443639962, 'reg_alpha': 7.18637141139532e-05, 'reg_lambda': 0.0004684314736316479}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:25,228] Trial 34 finished with value: 0.7615384615384615 and parameters: {'n_estimators': 1601, 'learning_rate': 0.0052199380857181855, 'num_leaves': 94, 'min_child_samples': 22, 'subsample': 0.9321499800157176, 'colsample_bytree': 0.9453597051901828, 'reg_alpha': 0.07827557821492316, 'reg_lambda': 1.9015983929687768e-06}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:26,025] Trial 35 finished with value: 0.7651515151515151 and parameters: {'n_estimators': 938, 'learning_rate': 0.00151288932866154, 'num_leaves': 20, 'min_child_samples': 53, 'subsample': 0.7957095052722356, 'colsample_bytree': 0.7505765175828385, 'reg_alpha': 1.3407495391460862e-05, 'reg_lambda': 2.7682580268489394e-07}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:26,623] Trial 36 finished with value: 0.7624521072796935 and parameters: {'n_estimators': 1241, 'learning_rate': 0.01033344922937893, 'num_leaves': 63, 'min_child_samples': 31, 'subsample': 0.7229678533223269, 'colsample_bytree': 0.8792699765425617, 'reg_alpha': 0.0001267429065938939, 'reg_lambda': 0.03262121067140183}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:27,128] Trial 37 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 1826, 'learning_rate': 0.006800133203133678, 'num_leaves': 47, 'min_child_samples': 71, 'subsample': 0.8141125482315072, 'colsample_bytree': 0.8040297527005233, 'reg_alpha': 0.044253311351007976, 'reg_lambda': 0.0013495557780467834}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:27,615] Trial 38 finished with value: 0.7140600315955766 and parameters: {'n_estimators': 1132, 'learning_rate': 0.0010629093344492648, 'num_leaves': 34, 'min_child_samples': 42, 'subsample': 0.6694021540341578, 'colsample_bytree': 0.7766027321543916, 'reg_alpha': 0.001017281562444061, 'reg_lambda': 0.010577703787750371}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:28,108] Trial 39 finished with value: 0.7654784240150094 and parameters: {'n_estimators': 737, 'learning_rate': 0.020565873777553603, 'num_leaves': 79, 'min_child_samples': 51, 'subsample': 0.9384476458361435, 'colsample_bytree': 0.9202179736111309, 'reg_alpha': 1.1381765621941944e-08, 'reg_lambda': 4.465453152319344e-08}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:28,728] Trial 40 finished with value: 0.7440147329650092 and parameters: {'n_estimators': 1536, 'learning_rate': 0.0045809025454689395, 'num_leaves': 133, 'min_child_samples': 133, 'subsample': 0.7082226543846027, 'colsample_bytree': 0.7058198222922758, 'reg_alpha': 0.008029122978324149, 'reg_lambda': 0.5107279788872043}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:29,420] Trial 41 finished with value: 0.770949720670391 and parameters: {'n_estimators': 1480, 'learning_rate': 0.002627591147423555, 'num_leaves': 38, 'min_child_samples': 34, 'subsample': 0.8669795467549365, 'colsample_bytree': 0.8503814384336409, 'reg_alpha': 4.27187404881659e-05, 'reg_lambda': 0.00036097715704414576}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:30,056] Trial 42 finished with value: 0.775047258979206 and parameters: {'n_estimators': 1410, 'learning_rate': 0.002478630811000503, 'num_leaves': 30, 'min_child_samples': 34, 'subsample': 0.8645404204075886, 'colsample_bytree': 0.8510006082854977, 'reg_alpha': 2.652435154776523e-06, 'reg_lambda': 0.00103534733712197}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:30,712] Trial 43 finished with value: 0.7712665406427222 and parameters: {'n_estimators': 1367, 'learning_rate': 0.0025234707010756852, 'num_leaves': 30, 'min_child_samples': 17, 'subsample': 0.8651605495002719, 'colsample_bytree': 0.8538043270959379, 'reg_alpha': 5.867191134453674e-07, 'reg_lambda': 0.00021467492500272748}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:31,343] Trial 44 finished with value: 0.7725631768953068 and parameters: {'n_estimators': 1371, 'learning_rate': 0.0018391503075031732, 'num_leaves': 20, 'min_child_samples': 20, 'subsample': 0.9140910008788979, 'colsample_bytree': 0.9042625282083473, 'reg_alpha': 1.7279035729951052e-06, 'reg_lambda': 0.0008444109367261336}. Best is trial 28 with value: 0.7767695099818511.\n",
      "[I 2025-09-10 09:36:32,045] Trial 45 finished with value: 0.7803992740471869 and parameters: {'n_estimators': 1052, 'learning_rate': 0.0017238125098239, 'num_leaves': 20, 'min_child_samples': 16, 'subsample': 0.914112017948876, 'colsample_bytree': 0.9008934872435979, 'reg_alpha': 1.7381789085083636e-06, 'reg_lambda': 0.001349619929962286}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:32,636] Trial 46 finished with value: 0.7557932263814616 and parameters: {'n_estimators': 1053, 'learning_rate': 0.0015580056357937951, 'num_leaves': 18, 'min_child_samples': 183, 'subsample': 0.9723011659340314, 'colsample_bytree': 0.9450323806300739, 'reg_alpha': 8.875958851232438e-08, 'reg_lambda': 0.004294405842313291}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:33,219] Trial 47 finished with value: 0.7569573283858998 and parameters: {'n_estimators': 222, 'learning_rate': 0.0012526062351267161, 'num_leaves': 29, 'min_child_samples': 12, 'subsample': 0.9518971063251178, 'colsample_bytree': 0.8849403553011512, 'reg_alpha': 1.118282212831385e-05, 'reg_lambda': 0.10236402743735669}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:33,635] Trial 48 finished with value: 0.7140600315955766 and parameters: {'n_estimators': 902, 'learning_rate': 0.0019724538181759644, 'num_leaves': 21, 'min_child_samples': 60, 'subsample': 0.847133263342921, 'colsample_bytree': 0.7928420738120537, 'reg_alpha': 0.00018327258382182436, 'reg_lambda': 0.01000257722349027}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:34,386] Trial 49 finished with value: 0.7557117750439367 and parameters: {'n_estimators': 1165, 'learning_rate': 0.004024968991786837, 'num_leaves': 27, 'min_child_samples': 45, 'subsample': 0.9055535002301198, 'colsample_bytree': 0.9302428796056462, 'reg_alpha': 2.024071953719517e-06, 'reg_lambda': 6.18110664908605e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:35,058] Trial 50 finished with value: 0.7723132969034608 and parameters: {'n_estimators': 789, 'learning_rate': 0.001321725485414969, 'num_leaves': 18, 'min_child_samples': 26, 'subsample': 0.82192006451265, 'colsample_bytree': 0.9902854300031251, 'reg_alpha': 1.550192102285615e-07, 'reg_lambda': 1.9218730100806165e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:35,718] Trial 51 finished with value: 0.7725631768953068 and parameters: {'n_estimators': 1299, 'learning_rate': 0.0016172893084053386, 'num_leaves': 22, 'min_child_samples': 25, 'subsample': 0.9093391772744569, 'colsample_bytree': 0.895037879678233, 'reg_alpha': 5.725223927154548e-07, 'reg_lambda': 0.000994750237970263}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:36,379] Trial 52 finished with value: 0.7763401109057301 and parameters: {'n_estimators': 978, 'learning_rate': 0.00191017172209626, 'num_leaves': 18, 'min_child_samples': 17, 'subsample': 0.9099257680201488, 'colsample_bytree': 0.8990736108941022, 'reg_alpha': 3.685623007924936e-06, 'reg_lambda': 0.0009396687743389636}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:37,056] Trial 53 finished with value: 0.7676056338028169 and parameters: {'n_estimators': 622, 'learning_rate': 0.003112284919755168, 'num_leaves': 32, 'min_child_samples': 8, 'subsample': 0.9998853938294381, 'colsample_bytree': 0.9622220372257282, 'reg_alpha': 4.63103163835016e-06, 'reg_lambda': 0.018365926370876817}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:37,618] Trial 54 finished with value: 0.7727272727272727 and parameters: {'n_estimators': 1034, 'learning_rate': 0.003767246087374863, 'num_leaves': 18, 'min_child_samples': 14, 'subsample': 0.7918165318997047, 'colsample_bytree': 0.8296736662494512, 'reg_alpha': 2.886299677432663e-05, 'reg_lambda': 0.0024771582876448703}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:38,123] Trial 55 finished with value: 0.7661141804788214 and parameters: {'n_estimators': 958, 'learning_rate': 0.006208152931368154, 'num_leaves': 16, 'min_child_samples': 48, 'subsample': 0.8510269963681492, 'colsample_bytree': 0.8689374659210864, 'reg_alpha': 1.5487285421234242e-06, 'reg_lambda': 0.0047039041898009875}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:38,988] Trial 56 finished with value: 0.7630057803468208 and parameters: {'n_estimators': 1875, 'learning_rate': 0.0021417214165819513, 'num_leaves': 42, 'min_child_samples': 31, 'subsample': 0.8830949994663865, 'colsample_bytree': 0.8120915995148568, 'reg_alpha': 2.3458157074823625e-07, 'reg_lambda': 0.00014058670536238056}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:39,435] Trial 57 finished with value: 0.7140600315955766 and parameters: {'n_estimators': 816, 'learning_rate': 0.001189592725558206, 'num_leaves': 25, 'min_child_samples': 17, 'subsample': 0.9707848074094199, 'colsample_bytree': 0.8371308272637129, 'reg_alpha': 0.0007100612371172781, 'reg_lambda': 1.0782393932722845e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:39,948] Trial 58 finished with value: 0.7703703703703704 and parameters: {'n_estimators': 1173, 'learning_rate': 0.00827459135815163, 'num_leaves': 51, 'min_child_samples': 40, 'subsample': 0.9225718606205167, 'colsample_bytree': 0.7624231880530727, 'reg_alpha': 9.955732306060645e-06, 'reg_lambda': 8.136036066560992}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:40,563] Trial 59 finished with value: 0.7746478873239436 and parameters: {'n_estimators': 1079, 'learning_rate': 0.004921608103095476, 'num_leaves': 27, 'min_child_samples': 5, 'subsample': 0.9602012178930066, 'colsample_bytree': 0.9087084004870711, 'reg_alpha': 0.02856644257548844, 'reg_lambda': 0.0016348982006836401}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:41,175] Trial 60 finished with value: 0.7760141093474426 and parameters: {'n_estimators': 1067, 'learning_rate': 0.004619435223387015, 'num_leaves': 28, 'min_child_samples': 6, 'subsample': 0.9518041752524781, 'colsample_bytree': 0.9079400333901072, 'reg_alpha': 2.107761952673391e-08, 'reg_lambda': 0.001902929398452315}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:41,911] Trial 61 finished with value: 0.7781818181818182 and parameters: {'n_estimators': 1068, 'learning_rate': 0.0031225756667151196, 'num_leaves': 28, 'min_child_samples': 5, 'subsample': 0.9535175235022398, 'colsample_bytree': 0.9102014445216172, 'reg_alpha': 0.0036005052493358527, 'reg_lambda': 0.0005727414347164193}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:42,601] Trial 62 finished with value: 0.7731397459165155 and parameters: {'n_estimators': 973, 'learning_rate': 0.002992231805856237, 'num_leaves': 33, 'min_child_samples': 13, 'subsample': 0.9912831969018492, 'colsample_bytree': 0.9697892798889962, 'reg_alpha': 2.8176907940095476e-08, 'reg_lambda': 0.0006210724688163835}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:43,212] Trial 63 finished with value: 0.7675675675675676 and parameters: {'n_estimators': 1218, 'learning_rate': 0.0018863881669222322, 'num_leaves': 23, 'min_child_samples': 24, 'subsample': 0.9459117240988208, 'colsample_bytree': 0.8957688092872658, 'reg_alpha': 0.0003101371100956557, 'reg_lambda': 0.0002882190871426424}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:43,798] Trial 64 finished with value: 0.776173285198556 and parameters: {'n_estimators': 1272, 'learning_rate': 0.002407466954101643, 'num_leaves': 17, 'min_child_samples': 11, 'subsample': 0.9018824868966079, 'colsample_bytree': 0.9491750084918416, 'reg_alpha': 0.003929310883736108, 'reg_lambda': 9.38181566360655e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:44,350] Trial 65 finished with value: 0.776173285198556 and parameters: {'n_estimators': 1285, 'learning_rate': 0.003346336583467576, 'num_leaves': 16, 'min_child_samples': 10, 'subsample': 0.8949104086263355, 'colsample_bytree': 0.933771936641473, 'reg_alpha': 0.003893221269596904, 'reg_lambda': 8.513419183520706e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:44,925] Trial 66 finished with value: 0.7695167286245354 and parameters: {'n_estimators': 1090, 'learning_rate': 0.0035477966321048916, 'num_leaves': 16, 'min_child_samples': 5, 'subsample': 0.8976571104892951, 'colsample_bytree': 0.943429505598695, 'reg_alpha': 0.005371105865921778, 'reg_lambda': 9.571017365588055e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:45,630] Trial 67 finished with value: 0.7761194029850746 and parameters: {'n_estimators': 1280, 'learning_rate': 0.004531802984000134, 'num_leaves': 18, 'min_child_samples': 12, 'subsample': 0.9232489348596906, 'colsample_bytree': 0.9248294492426256, 'reg_alpha': 0.003079216364130116, 'reg_lambda': 3.0316485481059924e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:46,532] Trial 68 finished with value: 0.7783985102420856 and parameters: {'n_estimators': 1268, 'learning_rate': 0.0015627334366608806, 'num_leaves': 18, 'min_child_samples': 18, 'subsample': 0.9262040877320166, 'colsample_bytree': 0.9658488898778885, 'reg_alpha': 0.0028355197995053013, 'reg_lambda': 2.835492076587633e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:47,334] Trial 69 finished with value: 0.7746741154562383 and parameters: {'n_estimators': 1175, 'learning_rate': 0.0015808260429821118, 'num_leaves': 16, 'min_child_samples': 16, 'subsample': 0.9806461541921966, 'colsample_bytree': 0.957463061615083, 'reg_alpha': 0.011425976314415894, 'reg_lambda': 9.235969700201518e-06}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:48,377] Trial 70 finished with value: 0.7713717693836978 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0013356663057089281, 'num_leaves': 19, 'min_child_samples': 24, 'subsample': 0.8813701807602762, 'colsample_bytree': 0.9945361776248882, 'reg_alpha': 0.003853903733862972, 'reg_lambda': 4.328443762347409e-06}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:49,053] Trial 71 finished with value: 0.7803992740471869 and parameters: {'n_estimators': 998, 'learning_rate': 0.002914742197688957, 'num_leaves': 18, 'min_child_samples': 11, 'subsample': 0.9299080639502146, 'colsample_bytree': 0.9244993870098942, 'reg_alpha': 0.0020069116086363207, 'reg_lambda': 3.973498435197278e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:49,984] Trial 72 finished with value: 0.776735459662289 and parameters: {'n_estimators': 989, 'learning_rate': 0.0020743923119363288, 'num_leaves': 21, 'min_child_samples': 18, 'subsample': 0.9322613421927163, 'colsample_bytree': 0.9775576221859228, 'reg_alpha': 0.0012055892075125039, 'reg_lambda': 0.00018056565616925352}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:50,785] Trial 73 finished with value: 0.7757352941176471 and parameters: {'n_estimators': 890, 'learning_rate': 0.0020056838185963663, 'num_leaves': 21, 'min_child_samples': 19, 'subsample': 0.9322074009094707, 'colsample_bytree': 0.9751038929782802, 'reg_alpha': 0.0011181430116856048, 'reg_lambda': 0.00018757739441540924}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:51,345] Trial 74 finished with value: 0.7140600315955766 and parameters: {'n_estimators': 1021, 'learning_rate': 0.001742307724147527, 'num_leaves': 24, 'min_child_samples': 29, 'subsample': 0.9197690803916347, 'colsample_bytree': 0.9485430904427632, 'reg_alpha': 0.002010618213629967, 'reg_lambda': 3.1667835929808664e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:52,079] Trial 75 finished with value: 0.7744227353463587 and parameters: {'n_estimators': 983, 'learning_rate': 0.0028296404913013117, 'num_leaves': 22, 'min_child_samples': 21, 'subsample': 0.9369470584245863, 'colsample_bytree': 0.9803257496493228, 'reg_alpha': 0.0008479407045582046, 'reg_lambda': 0.0005087508154552286}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:55,559] Trial 76 finished with value: 0.7551724137931034 and parameters: {'n_estimators': 915, 'learning_rate': 0.0014362018269108443, 'num_leaves': 300, 'min_child_samples': 12, 'subsample': 0.962078293902404, 'colsample_bytree': 0.9979854886951727, 'reg_alpha': 0.017532669335801384, 'reg_lambda': 3.071722910179785e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:56,321] Trial 77 finished with value: 0.7620817843866171 and parameters: {'n_estimators': 1128, 'learning_rate': 0.0011494705691094914, 'num_leaves': 19, 'min_child_samples': 28, 'subsample': 0.9059861464037655, 'colsample_bytree': 0.9157496855336258, 'reg_alpha': 0.0002420613593583763, 'reg_lambda': 0.00021141990558418578}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:57,246] Trial 78 finished with value: 0.7728085867620751 and parameters: {'n_estimators': 812, 'learning_rate': 0.0022134431619282146, 'num_leaves': 25, 'min_child_samples': 19, 'subsample': 0.9415701996076806, 'colsample_bytree': 0.9647147426276317, 'reg_alpha': 0.00010569805411201777, 'reg_lambda': 1.4493687321635502e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:57,936] Trial 79 finished with value: 0.7485822306238186 and parameters: {'n_estimators': 850, 'learning_rate': 0.0017185523731043342, 'num_leaves': 17, 'min_child_samples': 114, 'subsample': 0.8739513722535429, 'colsample_bytree': 0.8651811226837841, 'reg_alpha': 0.009858944518095498, 'reg_lambda': 0.0003770079896952021}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:58,728] Trial 80 finished with value: 0.7767695099818511 and parameters: {'n_estimators': 703, 'learning_rate': 0.002582708175610565, 'num_leaves': 20, 'min_child_samples': 15, 'subsample': 0.980025938510702, 'colsample_bytree': 0.9326852609978467, 'reg_alpha': 0.0021862904486189176, 'reg_lambda': 9.07350039346248e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:36:59,544] Trial 81 finished with value: 0.7757352941176471 and parameters: {'n_estimators': 430, 'learning_rate': 0.0025656106057799356, 'num_leaves': 20, 'min_child_samples': 10, 'subsample': 0.9781674953875206, 'colsample_bytree': 0.9348529066118341, 'reg_alpha': 0.0019358478787872332, 'reg_lambda': 0.0001194764747154059}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:00,563] Trial 82 finished with value: 0.7701612903225806 and parameters: {'n_estimators': 763, 'learning_rate': 0.002278862496083209, 'num_leaves': 23, 'min_child_samples': 15, 'subsample': 0.9540936275595014, 'colsample_bytree': 0.8834741170115084, 'reg_alpha': 0.0004739837885176943, 'reg_lambda': 6.753460276437143e-06}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:01,251] Trial 83 finished with value: 0.7781818181818182 and parameters: {'n_estimators': 657, 'learning_rate': 0.002852160157212938, 'num_leaves': 17, 'min_child_samples': 21, 'subsample': 0.9903638635202261, 'colsample_bytree': 0.9566168896973521, 'reg_alpha': 0.006796799319915109, 'reg_lambda': 3.993023423976006e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:02,029] Trial 84 finished with value: 0.7783783783783784 and parameters: {'n_estimators': 1004, 'learning_rate': 0.0029689082185584783, 'num_leaves': 21, 'min_child_samples': 22, 'subsample': 0.9942936329575367, 'colsample_bytree': 0.956386325949727, 'reg_alpha': 0.0012390619474876273, 'reg_lambda': 3.760904253338834e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:03,034] Trial 85 finished with value: 0.7719928186714542 and parameters: {'n_estimators': 679, 'learning_rate': 0.0029477012365123553, 'num_leaves': 26, 'min_child_samples': 32, 'subsample': 0.9871327920712459, 'colsample_bytree': 0.9866841643723328, 'reg_alpha': 0.0014476584302684319, 'reg_lambda': 3.175405059667091e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:03,783] Trial 86 finished with value: 0.7722419928825622 and parameters: {'n_estimators': 484, 'learning_rate': 0.0037706194568200703, 'num_leaves': 21, 'min_child_samples': 22, 'subsample': 0.9996122031368114, 'colsample_bytree': 0.9571904521793569, 'reg_alpha': 0.006165397837781003, 'reg_lambda': 2.710804609239464e-06}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:04,352] Trial 87 finished with value: 0.7630522088353414 and parameters: {'n_estimators': 651, 'learning_rate': 0.004124692466705464, 'num_leaves': 19, 'min_child_samples': 40, 'subsample': 0.9666165813992429, 'colsample_bytree': 0.9245466008734498, 'reg_alpha': 0.00017926785473516442, 'reg_lambda': 6.429396862296874e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:04,876] Trial 88 finished with value: 0.761384335154827 and parameters: {'n_estimators': 548, 'learning_rate': 0.0058194735237230835, 'num_leaves': 22, 'min_child_samples': 173, 'subsample': 0.9852054016535423, 'colsample_bytree': 0.9743750456955401, 'reg_alpha': 0.07128941196738926, 'reg_lambda': 1.5861208044532644e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:05,594] Trial 89 finished with value: 0.7725631768953068 and parameters: {'n_estimators': 610, 'learning_rate': 0.0032475361748119406, 'num_leaves': 24, 'min_child_samples': 27, 'subsample': 0.9292251101250412, 'colsample_bytree': 0.9327708958680694, 'reg_alpha': 0.025339057626468646, 'reg_lambda': 4.686644520835597e-05}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:06,173] Trial 90 finished with value: 0.7796610169491526 and parameters: {'n_estimators': 1113, 'learning_rate': 0.0027834874581554787, 'num_leaves': 17, 'min_child_samples': 22, 'subsample': 0.9632061746313445, 'colsample_bytree': 0.9124323963791615, 'reg_alpha': 0.0006684963687670249, 'reg_lambda': 0.0003123671213902015}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:06,820] Trial 91 finished with value: 0.7789855072463768 and parameters: {'n_estimators': 1110, 'learning_rate': 0.0026744542930762965, 'num_leaves': 17, 'min_child_samples': 23, 'subsample': 0.9632720838030969, 'colsample_bytree': 0.9177687420919719, 'reg_alpha': 0.0006269708771233888, 'reg_lambda': 0.00026748171103123917}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:07,487] Trial 92 finished with value: 0.7757352941176471 and parameters: {'n_estimators': 1116, 'learning_rate': 0.002608134585286698, 'num_leaves': 17, 'min_child_samples': 22, 'subsample': 0.9686898476620552, 'colsample_bytree': 0.9145141626009434, 'reg_alpha': 0.0025185560388997167, 'reg_lambda': 0.0006540607676881411}. Best is trial 45 with value: 0.7803992740471869.\n",
      "[I 2025-09-10 09:37:08,031] Trial 93 finished with value: 0.781021897810219 and parameters: {'n_estimators': 725, 'learning_rate': 0.003403294193734849, 'num_leaves': 19, 'min_child_samples': 28, 'subsample': 0.9580489585456795, 'colsample_bytree': 0.8880496038248439, 'reg_alpha': 0.00034642111177091286, 'reg_lambda': 9.309572597338924e-07}. Best is trial 93 with value: 0.781021897810219.\n",
      "[I 2025-09-10 09:37:08,590] Trial 94 finished with value: 0.7712177121771218 and parameters: {'n_estimators': 1161, 'learning_rate': 0.004135057871324418, 'num_leaves': 17, 'min_child_samples': 33, 'subsample': 0.9480706136484832, 'colsample_bytree': 0.8844247906690003, 'reg_alpha': 0.0006085064801321914, 'reg_lambda': 1.2380080902264712e-06}. Best is trial 93 with value: 0.781021897810219.\n",
      "[I 2025-09-10 09:37:09,130] Trial 95 finished with value: 0.7741935483870968 and parameters: {'n_estimators': 1038, 'learning_rate': 0.005561546903184957, 'num_leaves': 19, 'min_child_samples': 36, 'subsample': 0.990687056192737, 'colsample_bytree': 0.8921940017616949, 'reg_alpha': 6.381782821367882e-05, 'reg_lambda': 0.0003010797102816951}. Best is trial 93 with value: 0.781021897810219.\n",
      "[I 2025-09-10 09:37:09,716] Trial 96 finished with value: 0.7662835249042146 and parameters: {'n_estimators': 1201, 'learning_rate': 0.0034195880787399957, 'num_leaves': 17, 'min_child_samples': 46, 'subsample': 0.9566317443687335, 'colsample_bytree': 0.8663763862875015, 'reg_alpha': 0.0003652339407123171, 'reg_lambda': 4.7441260068684756e-07}. Best is trial 93 with value: 0.781021897810219.\n",
      "[I 2025-09-10 09:37:10,605] Trial 97 finished with value: 0.7775768535262206 and parameters: {'n_estimators': 1092, 'learning_rate': 0.002858821754227366, 'num_leaves': 22, 'min_child_samples': 28, 'subsample': 0.968510831348763, 'colsample_bytree': 0.9049817250666088, 'reg_alpha': 0.0007586750280580717, 'reg_lambda': 5.87312423219961e-06}. Best is trial 93 with value: 0.781021897810219.\n",
      "[I 2025-09-10 09:37:12,096] Trial 98 finished with value: 0.7795992714025501 and parameters: {'n_estimators': 939, 'learning_rate': 0.00297871923929892, 'num_leaves': 19, 'min_child_samples': 27, 'subsample': 0.9657446718496039, 'colsample_bytree': 0.9148748935244032, 'reg_alpha': 0.00016221628373182362, 'reg_lambda': 7.40429974956378e-07}. Best is trial 93 with value: 0.781021897810219.\n",
      "[I 2025-09-10 09:37:13,267] Trial 99 finished with value: 0.7769516728624535 and parameters: {'n_estimators': 859, 'learning_rate': 0.00681768358318852, 'num_leaves': 19, 'min_child_samples': 9, 'subsample': 0.959466039684317, 'colsample_bytree': 0.9544791264342776, 'reg_alpha': 0.0002099897521469694, 'reg_lambda': 7.581380363488428e-07}. Best is trial 93 with value: 0.781021897810219.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Optuna Best (VAL by chosen metric) ====\n",
      "Optimize metric: f1\n",
      "Best score: 0.781021897810219\n",
      "Best params: {'n_estimators': 725, 'learning_rate': 0.003403294193734849, 'num_leaves': 19, 'min_child_samples': 28, 'subsample': 0.9580489585456795, 'colsample_bytree': 0.8880496038248439, 'reg_alpha': 0.00034642111177091286, 'reg_lambda': 9.309572597338924e-07}\n",
      "Best VAL thr_source: f1\n",
      "Best VAL thr: 0.4\n",
      "Best VAL precision: 0.6645962732919255\n",
      "Best VAL recall: 0.9469026548672567\n",
      "Best VAL f1: 0.781021897810219\n",
      "Best VAL pos_rate: 0.7911547911547911\n",
      "\n",
      "[Threshold] VAL selected via F1: t*=0.400, P=0.6646, R=0.9469, F1=0.7810, Acc=nan, Youden=nan\n",
      "\n",
      "==== Test Performance (held-out, with chosen threshold) ====\n",
      "AUC:           0.737195\n",
      "AveragePrecision(PR-AUC): 0.753538\n",
      "LogLoss:       0.636761\n",
      "Accuracy:      0.612205\n",
      "Precision@t*:  0.589074\n",
      "Recall@t*:     0.911765\n",
      "F1@t*:         0.715729\n",
      "(t* chosen on VAL: 0.400)\n",
      "\n",
      "Score PSI (TrainFit→Val):  0.0098\n",
      "Score PSI (TrainFit→Test): 0.2173\n",
      "\n",
      "==== Feature Importance (top 20 by LGB Gain) ====\n",
      "feature  lgb_split     lgb_gain  lgb_gain_norm  perm_importance_mean  perm_importance_std\n",
      "     基差        886 17744.461735       0.358829              0.000201             0.003032\n",
      " 置信区间下限        804 14714.457193       0.297556              0.002098             0.002097\n",
      " 置信区间上限        613  9653.302380       0.195209              0.014780             0.009101\n",
      "   期现价差        127  1480.973896       0.029948              0.000554             0.003689\n",
      "     全价        132  1296.632380       0.026221             -0.002913             0.004212\n",
      "十债主连成交量        118  1095.032688       0.022144              0.000000             0.000000\n",
      "   期货价格        160   988.577530       0.019991              0.118605             0.029233\n",
      " IRR(%)         97   913.518390       0.018473              0.003744             0.004465\n",
      "   发票价格         87   665.060281       0.013449              0.003581             0.002120\n",
      "     净价         48   367.752869       0.007437             -0.003655             0.002675\n",
      "十债主连持仓量         38   274.361890       0.005548             -0.004700             0.003592\n",
      " 收益率(%)         40   256.871141       0.005194              0.077543             0.006827\n",
      "   转换因子          0     0.000000       0.000000              0.070136             0.015337\n"
     ]
    }
   ],
   "source": [
    "# ========= 全量可运行脚本：漂移检查 + 阈值策略 + 贝叶斯超参搜索（静默日志，兼容新版LightGBM） =========\n",
    "# 依赖：\n",
    "#   pip install numpy pandas scipy scikit-learn lightgbm optuna\n",
    "\n",
    "import os\n",
    "os.environ[\"LIGHTGBM_VERBOSITY\"] = \"-1\"  # 兜底关闭底层日志\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, log_loss\n",
    ")\n",
    "from sklearn.inspection import permutation_importance  # NEW\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt  # NEW\n",
    "\n",
    "# ========= 公共工具 =========\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# ========= 1) 特征稳定性 / 漂移检查 =========\n",
    "\n",
    "def psi_for_series(train_s: pd.Series, test_s: pd.Series, bins=10):\n",
    "    train_s = pd.to_numeric(train_s, errors='coerce')\n",
    "    test_s  = pd.to_numeric(test_s,  errors='coerce')\n",
    "    tr = train_s.dropna(); te = test_s.dropna()\n",
    "    if tr.empty or te.empty:\n",
    "        return np.nan\n",
    "    quantiles = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.unique(np.nanquantile(tr, quantiles))\n",
    "    if len(cuts) <= 2:\n",
    "        return np.nan\n",
    "    tr_bins = pd.cut(train_s, bins=cuts, include_lowest=True)\n",
    "    te_bins = pd.cut(test_s,  bins=cuts, include_lowest=True)\n",
    "    tr_ratio = tr_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_ratio.reindex(tr_ratio.index).fillna(0.0)\n",
    "    tr_ratio = tr_ratio.fillna(0.0)\n",
    "    tr_ratio = tr_ratio.replace(0, 1e-8)\n",
    "    te_ratio = te_ratio.replace(0, 1e-8)\n",
    "    psi = np.sum((te_ratio - tr_ratio) * np.log(te_ratio / tr_ratio))\n",
    "    return float(psi)\n",
    "\n",
    "def cat_psi(train_s: pd.Series, test_s: pd.Series):\n",
    "    tr_p = train_s.value_counts(normalize=True)\n",
    "    te_p = test_s.value_counts(normalize=True)\n",
    "    idx = tr_p.index.union(te_p.index)\n",
    "    tr_p = tr_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    te_p = te_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    psi = np.sum((te_p - tr_p) * np.log(te_p / tr_p))\n",
    "    return float(psi)\n",
    "\n",
    "def two_sample_drift(train_s: pd.Series, test_s: pd.Series, is_categorical=False):\n",
    "    if is_categorical:\n",
    "        idx = pd.Index(pd.concat([train_s.astype(str), test_s.astype(str)], ignore_index=True).unique())\n",
    "        tr_counts = train_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        te_counts = test_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        table = np.vstack([tr_counts.values, te_counts.values])\n",
    "        try:\n",
    "            chi2, p, dof, exp = chi2_contingency(table)\n",
    "        except ValueError:\n",
    "            p = 1.0\n",
    "        return {\"stat\": None, \"pvalue\": float(p)}\n",
    "    else:\n",
    "        tr = pd.to_numeric(train_s, errors='coerce').dropna()\n",
    "        te = pd.to_numeric(test_s,  errors='coerce').dropna()\n",
    "        if len(tr) < 2 or len(te) < 2:\n",
    "            return {\"stat\": None, \"pvalue\": np.nan}\n",
    "        ks = ks_2samp(tr, te, alternative='two-sided', mode='auto')\n",
    "        return {\"stat\": float(ks.statistic), \"pvalue\": float(ks.pvalue)}\n",
    "\n",
    "def drift_report(df_ref: pd.DataFrame, df_new: pd.DataFrame,\n",
    "                 categorical_cols=None, topk=15):\n",
    "    categorical_cols = set(categorical_cols or [])\n",
    "    rows = []\n",
    "    for c in df_ref.columns:\n",
    "        is_cat = c in categorical_cols or (df_ref[c].dtype.name in [\"category\", \"object\"])\n",
    "        psi = cat_psi(df_ref[c], df_new[c]) if is_cat else psi_for_series(df_ref[c], df_new[c])\n",
    "        stat = two_sample_drift(df_ref[c], df_new[c], is_categorical=is_cat)\n",
    "        miss_ref = df_ref[c].isna().mean()\n",
    "        miss_new = df_new[c].isna().mean()\n",
    "        rows.append({\n",
    "            \"feature\": c,\n",
    "            \"is_categorical\": is_cat,\n",
    "            \"PSI\": psi,\n",
    "            \"KS/Chi2_p\": stat[\"pvalue\"],\n",
    "            \"KS_stat\": stat[\"stat\"],\n",
    "            \"missing_ref\": miss_ref,\n",
    "            \"missing_new\": miss_new,\n",
    "            \"missing_diff\": miss_new - miss_ref,\n",
    "        })\n",
    "    rep = pd.DataFrame(rows)\n",
    "    rep = rep.sort_values(by=[\"PSI\", \"KS/Chi2_p\"], ascending=[False, True]).reset_index(drop=True)\n",
    "    return rep.iloc[:topk]\n",
    "\n",
    "# ========= 2) 阈值策略 =========\n",
    "\n",
    "def choose_threshold(\n",
    "    y_true, y_prob,\n",
    "    method=\"f1\",\n",
    "    grid=None,\n",
    "    min_precision=None,\n",
    "    min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.01, 0.99, 99)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    out_rows = []\n",
    "    best_thr, best_key = 0.5, (-1e9, -1e9)\n",
    "\n",
    "    for t in grid:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        P  = precision_score(y_true, pred, zero_division=0)\n",
    "        R  = recall_score(y_true, pred, zero_division=0)\n",
    "        F1 = f1_score(y_true, pred, zero_division=0)\n",
    "        tn = np.sum((pred==0)&(y_true==0))\n",
    "        fp = np.sum((pred==1)&(y_true==0))\n",
    "        fn = np.sum((pred==0)&(y_true==1))\n",
    "        tp = np.sum((pred==1)&(y_true==1))\n",
    "        TNR = tn / max(1, (tn+fp))\n",
    "        J = R + TNR - 1\n",
    "        pos_rate = pred.mean()\n",
    "\n",
    "        out_rows.append({\"thr\": t, \"precision\": P, \"recall\": R, \"f1\": F1,\n",
    "                         \"youdenJ\": J, \"pos_rate\": pos_rate, \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn})\n",
    "\n",
    "        if method == \"f1\":\n",
    "            key = (F1, 0.0)\n",
    "        elif method == \"youden\":\n",
    "            key = (J, 0.0)\n",
    "        elif method == \"posrate\" and target_pos_rate is not None:\n",
    "            key = (-abs(pos_rate - target_pos_rate), 0.0)\n",
    "        elif method == \"constraint\":\n",
    "            if (min_precision is not None and P < min_precision) or (min_recall is not None and R < min_recall):\n",
    "                key = (-1e9, -1e9)\n",
    "            else:\n",
    "                key = (R, F1)\n",
    "        else:\n",
    "            key = (F1, 0.0)\n",
    "\n",
    "        if key > best_key:\n",
    "            best_key = key\n",
    "            best_thr = t\n",
    "\n",
    "    table = pd.DataFrame(out_rows).sort_values(\"thr\").reset_index(drop=True)\n",
    "    best_row = table.loc[table[\"thr\"].sub(best_thr).abs().idxmin()].to_dict()\n",
    "    return float(best_thr), best_row, table\n",
    "\n",
    "# ========= 3) 分数 PSI =========\n",
    "\n",
    "def score_psi(ref_scores, new_scores, bins=10):\n",
    "    ref = pd.Series(ref_scores)\n",
    "    new = pd.Series(new_scores)\n",
    "    return psi_for_series(ref, new, bins=bins)\n",
    "\n",
    "# ========= 4) 数据准备（日期阈值 / 比例切分） =========\n",
    "\n",
    "def temporal_split(df_clean: pd.DataFrame,\n",
    "                   label_col=\"value_sort\",\n",
    "                   cutoff_date=None,\n",
    "                   test_size_ratio=0.2,\n",
    "                   val_size_ratio=0.2):\n",
    "    assert label_col in df_clean.columns\n",
    "    df = df_clean.copy().sort_index()\n",
    "\n",
    "    feat_cols = df.columns.drop([label_col]).tolist()\n",
    "    X_all = df[feat_cols].values\n",
    "    y_all = df[label_col].astype(int).values\n",
    "\n",
    "    if cutoff_date is not None:\n",
    "        assert isinstance(df.index, pd.DatetimeIndex), \"需 DatetimeIndex 才能按日期切分\"\n",
    "        mask_trainval = (df.index <= pd.to_datetime(cutoff_date))\n",
    "        X_trainval, y_trainval = X_all[mask_trainval], y_all[mask_trainval]\n",
    "        X_test, y_test = X_all[~mask_trainval], y_all[~mask_trainval]\n",
    "\n",
    "        n_tv = len(X_trainval)\n",
    "        n_val = max(1, int(n_tv * val_size_ratio))\n",
    "        X_tr, y_tr = X_trainval[:-n_val], y_trainval[:-n_val]\n",
    "        X_val, y_val = X_trainval[-n_val:], y_trainval[-n_val:]\n",
    "        return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "    N = len(X_all)\n",
    "    n_test = max(1, int(N * test_size_ratio))\n",
    "    X_tv, y_tv = X_all[:-n_test], y_all[:-n_test]\n",
    "    X_test, y_test = X_all[-n_test:], y_all[-n_test:]\n",
    "\n",
    "    n_tv = len(X_tv)\n",
    "    n_val = max(1, int(n_tv * val_size_ratio))\n",
    "    X_tr, y_tr = X_tv[:-n_val], y_tv[:-n_val]\n",
    "    X_val, y_val = X_tv[-n_val:], y_tv[-n_val:]\n",
    "    return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "# ========= 2.5) 统一评估接口 =========\n",
    "\n",
    "def _compute_metrics_at_thr(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    tnr = tn / max(1, (tn + fp))\n",
    "    youdenJ = (recall_score(y_true, y_pred, zero_division=0) + tnr - 1.0)\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\":    recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\":        f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"youden\":    youdenJ,\n",
    "        \"pos_rate\":  y_pred.mean()\n",
    "    }\n",
    "\n",
    "def evaluate_with_optional_threshold(\n",
    "    y_true, y_prob,\n",
    "    optimize_metric=\"f1\",\n",
    "    thr_source=\"auto\",\n",
    "    fixed_thr=0.5,\n",
    "    constraint_min_precision=None,\n",
    "    constraint_min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    if optimize_metric in {\"auc\", \"ap\", \"logloss\"}:\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            return (-np.inf if optimize_metric == \"logloss\" else np.nan), None, {}\n",
    "        if optimize_metric == \"auc\":\n",
    "            return float(roc_auc_score(y_true, y_prob)), None, {}\n",
    "        elif optimize_metric == \"ap\":\n",
    "            return float(average_precision_score(y_true, y_prob)), None, {}\n",
    "        else:\n",
    "            ll = log_loss(y_true, np.vstack([1 - y_prob, y_prob]).T, labels=[0, 1])\n",
    "            return float(-ll), None, {\"raw_logloss\": ll}\n",
    "\n",
    "    if thr_source == \"auto\":\n",
    "        thr_source = \"youden\" if optimize_metric == \"youden\" else \"f1\"\n",
    "\n",
    "    if   thr_source == \"f1\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"f1\")\n",
    "    elif thr_source == \"youden\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"youden\")\n",
    "    elif thr_source == \"constraint\":\n",
    "        thr, row, _ = choose_threshold(\n",
    "            y_true, y_prob, method=\"constraint\",\n",
    "            min_precision=constraint_min_precision, min_recall=constraint_min_recall\n",
    "        )\n",
    "    elif thr_source == \"posrate\":\n",
    "        thr, row, _ = choose_threshold(\n",
    "            y_true, y_prob, method=\"posrate\", target_pos_rate=target_pos_rate\n",
    "        )\n",
    "    elif thr_source == \"fixed\":\n",
    "        thr = float(fixed_thr)\n",
    "        row = _compute_metrics_at_thr(y_true, y_prob, thr)\n",
    "    else:\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"f1\")\n",
    "\n",
    "    if optimize_metric not in {\"accuracy\", \"precision\", \"recall\", \"f1\", \"youden\"}:\n",
    "        optimize_metric = \"f1\"\n",
    "    score = float(row[optimize_metric])\n",
    "    return score, float(thr), row\n",
    "\n",
    "# ========= 5) Optuna + LightGBM 搜索（静默） =========\n",
    "\n",
    "def run_optuna_lgbm(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    n_trials=50,\n",
    "    method_for_thr=\"f1\",\n",
    "    constraint_min_precision=None, constraint_min_recall=None, target_pos_rate=None,\n",
    "    optimize_metric=\"f1\",\n",
    "    thr_source=\"auto\",\n",
    "    fixed_thr=0.5\n",
    "):\n",
    "    if thr_source == \"auto\":\n",
    "        thr_source = method_for_thr\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 512, log=True),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 200),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "            \"objective\": \"binary\",\n",
    "            \"verbosity\": -1,\n",
    "        }\n",
    "\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[\n",
    "                early_stopping(stopping_rounds=100, verbose=False),\n",
    "                log_evaluation(period=0)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_prob = model.predict_proba(X_val)[:, 1]\n",
    "        score, used_thr, row = evaluate_with_optional_threshold(\n",
    "            y_val, val_prob,\n",
    "            optimize_metric=optimize_metric,\n",
    "            thr_source=thr_source,\n",
    "            fixed_thr=fixed_thr,\n",
    "            constraint_min_precision=constraint_min_precision,\n",
    "            constraint_min_recall=constraint_min_recall,\n",
    "            target_pos_rate=target_pos_rate\n",
    "        )\n",
    "\n",
    "        trial.set_user_attr(\"metric\", optimize_metric)\n",
    "        trial.set_user_attr(\"thr_source\", thr_source)\n",
    "        trial.set_user_attr(\"thr\", used_thr)\n",
    "        for k in [\"precision\", \"recall\", \"f1\", \"accuracy\", \"youden\", \"pos_rate\"]:\n",
    "            if k in row:\n",
    "                trial.set_user_attr(k, row[k])\n",
    "        if \"raw_logloss\" in row:\n",
    "            trial.set_user_attr(\"raw_logloss\", row[\"raw_logloss\"])\n",
    "\n",
    "        return float(score)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "# ========= 6) 主流程 =========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 你需要先准备好 df_clean（含列 value_sort，索引为日期）\n",
    "    # 这里默认你已在外部构建好 df_clean 变量\n",
    "    # 例如：\n",
    "    # df_clean = pd.read_excel('基差_diff版.xlsx', parse_dates=['日期'], index_col='日期')\n",
    "    # assert 'value_sort' in df_clean.columns\n",
    "\n",
    "    # === 切分 ===\n",
    "    X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols = temporal_split(\n",
    "        df_clean, label_col=\"value_sort\", cutoff_date=None,\n",
    "        test_size_ratio=0.2, val_size_ratio=0.2\n",
    "    )\n",
    "\n",
    "    # === 漂移检查 ===\n",
    "    df_tr_fit = pd.DataFrame(X_tr_fit_raw, columns=feat_cols)\n",
    "    df_val    = pd.DataFrame(X_val_fit_raw, columns=feat_cols)\n",
    "    df_te     = pd.DataFrame(X_te_raw,     columns=feat_cols)\n",
    "\n",
    "    rep_tr_te = drift_report(df_tr_fit, df_te, categorical_cols=[], topk=30)\n",
    "    print(\"\\n==== Top Drifted Features (TrainFit vs Test) ====\")\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    print(rep_tr_te.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    # === 贝叶斯优化 ===\n",
    "    study = run_optuna_lgbm(\n",
    "        X_tr_fit_raw, y_tr_fit,\n",
    "        X_val_fit_raw, y_val_fit,\n",
    "        n_trials=100,\n",
    "        optimize_metric=\"f1\",\n",
    "        thr_source=\"f1\",\n",
    "        fixed_thr=0.5,\n",
    "        constraint_min_precision=None,\n",
    "        constraint_min_recall=None,\n",
    "        target_pos_rate=None,\n",
    "        method_for_thr=\"precision\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n==== Optuna Best (VAL by chosen metric) ====\")\n",
    "    print(\"Optimize metric:\", study.best_trial.user_attrs.get(\"metric\"))\n",
    "    print(\"Best score:\", study.best_value)\n",
    "    print(\"Best params:\", study.best_trial.params)\n",
    "    print(\"Best VAL thr_source:\", study.best_trial.user_attrs.get(\"thr_source\"))\n",
    "    print(\"Best VAL thr:\", study.best_trial.user_attrs.get(\"thr\"))\n",
    "    for k in [\"precision\", \"recall\", \"f1\", \"accuracy\", \"youden\", \"pos_rate\", \"raw_logloss\"]:\n",
    "        if k in study.best_trial.user_attrs:\n",
    "            print(f\"Best VAL {k}:\", study.best_trial.user_attrs[k])\n",
    "\n",
    "    # === 以最优参数训练最终模型 ===\n",
    "    best_params = study.best_trial.params\n",
    "    final_model = LGBMClassifier(\n",
    "        **best_params, objective=\"binary\", random_state=42, n_jobs=-1, verbosity=-1\n",
    "    )\n",
    "    final_model.fit(\n",
    "        X_tr_fit_raw, y_tr_fit,\n",
    "        eval_set=[(X_val_fit_raw, y_val_fit)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=100, verbose=False),\n",
    "            log_evaluation(period=0)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # === 在验证集上选“生产用阈值” ===\n",
    "    val_prob = final_model.predict_proba(X_val_fit_raw)[:, 1]\n",
    "    _, chosen_thr, row_any = evaluate_with_optional_threshold(\n",
    "        y_val_fit, val_prob,\n",
    "        optimize_metric=\"precision\",\n",
    "        thr_source=\"precision\"\n",
    "    )\n",
    "    print(f\"\\n[Threshold] VAL selected via F1: t*={chosen_thr:.3f}, \"\n",
    "          f\"P={row_any.get('precision', np.nan):.4f}, R={row_any.get('recall', np.nan):.4f}, \"\n",
    "          f\"F1={row_any.get('f1', np.nan):.4f}, Acc={row_any.get('accuracy', np.nan):.4f}, \"\n",
    "          f\"Youden={row_any.get('youden', np.nan):.4f}\")\n",
    "\n",
    "    # === 测试集评估（固定 chosen_thr） ===\n",
    "    y_te_prob = final_model.predict_proba(X_te_raw)[:, 1]\n",
    "    y_te_pred = (y_te_prob >= chosen_thr).astype(int)\n",
    "\n",
    "    test_auc  = safe_auc(y_te, y_te_prob)\n",
    "    test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "    test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== Test Performance (held-out, with chosen threshold) ====\")\n",
    "    print(f\"AUC:           {test_auc:.6f}\")\n",
    "    print(f\"AveragePrecision(PR-AUC): {test_ap:.6f}\")\n",
    "    print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "    print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "    print(f\"Precision@t*:  {test_prec:.6f}\")\n",
    "    print(f\"Recall@t*:     {test_rec:.6f}\")\n",
    "    print(f\"F1@t*:         {test_f1:.6f}\")\n",
    "    print(f\"(t* chosen on VAL: {chosen_thr:.3f})\")\n",
    "\n",
    "    # === 分数 PSI（可选） ===\n",
    "    tr_scores  = final_model.predict_proba(X_tr_fit_raw)[:, 1]\n",
    "    val_scores = final_model.predict_proba(X_val_fit_raw)[:, 1]\n",
    "    te_scores  = y_te_prob\n",
    "    print(\"\\nScore PSI (TrainFit→Val): \", f\"{score_psi(tr_scores, val_scores):.4f}\")\n",
    "    print(\"Score PSI (TrainFit→Test):\", f\"{score_psi(tr_scores, te_scores):.4f}\")\n",
    "\n",
    "    # ========== NEW (A): 因子重要性 ==========\n",
    "    feat_cols_series = pd.Index(feat_cols, dtype=str)\n",
    "    # 1) LGBM 原生重要性\n",
    "    split_imp = final_model.booster_.feature_importance(importance_type=\"split\")\n",
    "    gain_imp  = final_model.booster_.feature_importance(importance_type=\"gain\")\n",
    "    imp_df = pd.DataFrame({\n",
    "        \"feature\": feat_cols_series,\n",
    "        \"lgb_split\": split_imp,\n",
    "        \"lgb_gain\": gain_imp\n",
    "    })\n",
    "    imp_df[\"lgb_gain_norm\"] = imp_df[\"lgb_gain\"] / (imp_df[\"lgb_gain\"].sum() + 1e-12)\n",
    "    imp_df = imp_df.sort_values(\"lgb_gain\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # 2) Permutation Importance（在验证集上）\n",
    "    perm = permutation_importance(\n",
    "        final_model, X_val_fit_raw, y_val_fit,\n",
    "        scoring=\"f1\", n_repeats=10, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    imp_df[\"perm_importance_mean\"] = perm.importances_mean\n",
    "    imp_df[\"perm_importance_std\"]  = perm.importances_std\n",
    "\n",
    "    print(\"\\n==== Feature Importance (top 20 by LGB Gain) ====\")\n",
    "    print(imp_df.head(20).to_string(index=False, float_format=lambda x: f\"{x:.6f}\"))\n",
    "    imp_df.to_csv(\"feature_importance.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 简单柱状图（按 Gain 排）\n",
    "    topk = 15\n",
    "    plot_df = imp_df.head(topk).iloc[::-1]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(plot_df[\"feature\"], plot_df[\"lgb_gain_norm\"])\n",
    "    plt.xlabel(\"Normalized Gain Importance\")\n",
    "    plt.title(f\"Top-{topk} Feature Importance (LightGBM Gain)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"feature_importance_bar.png\", dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c687c815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Cumulative P&L (Test, next-day realized) ====\n",
      "Final Cum P&L: 4.419200\n",
      "Saved: pnl_detail.csv, cum_pnl.png\n"
     ]
    }
   ],
   "source": [
    "# ========== NEW (B): 累计价格损益（下一期结算，实盘口径，稳健对齐） ==========\n",
    "# 规则：t 日生成仓位 pos_t（预测涨=+1，预测跌=-1），在 t→t+1 期间以\n",
    "# Δbasis_{t+1} = basis_{t+1} - basis_t 结算：PnL_t = pos_t * Δbasis_{t+1}\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1) 读取“未差分”的原始基差 ---\n",
    "basis_excel_path = \"基差.xls\"  # 如路径不同请修改\n",
    "basis_series = None\n",
    "if os.path.exists(basis_excel_path):\n",
    "    try:\n",
    "        raw_basis = pd.read_excel(basis_excel_path).copy()\n",
    "        # 自动识别日期列\n",
    "        date_col = None\n",
    "        for c in raw_basis.columns:\n",
    "            if str(c).strip() in [\"日期\", \"date\", \"Date\", \"交易日\"]:\n",
    "                date_col = c; break\n",
    "        if date_col is not None:\n",
    "            raw_basis[date_col] = pd.to_datetime(raw_basis[date_col], errors=\"coerce\")\n",
    "            raw_basis.set_index(date_col, inplace=True)\n",
    "        else:\n",
    "            # 若无日期列，假设与 df_clean 索引一致\n",
    "            raw_basis.index = df_clean.index\n",
    "        # 自动识别“基差”列（若列名不是“基差”，请手动指定）\n",
    "        basis_col = None\n",
    "        for c in raw_basis.columns:\n",
    "            if \"基差\" in str(c):\n",
    "                basis_col = c; break\n",
    "        if basis_col is not None:\n",
    "            basis_series = raw_basis[basis_col].astype(float).sort_index()\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] 读取原始基差失败，将用差分累加近似重构。err={e}\")\n",
    "\n",
    "# --- 兜底：若未找到，则用 df_clean 中“基差差分”累加近似 ---\n",
    "if basis_series is None:\n",
    "    print(\"[WARN] 未找到未差分基差，将用 df_clean['基差(差分)'] 累加近似（可能与真实值有偏差）。\")\n",
    "    diff_basis_col = None\n",
    "    for c in df_clean.columns:\n",
    "        if \"基差\" in str(c):\n",
    "            diff_basis_col = c; break\n",
    "    if diff_basis_col is not None:\n",
    "        basis_series = df_clean[diff_basis_col].astype(float).sort_index().cumsum()\n",
    "    else:\n",
    "        raise RuntimeError(\"未在 df_clean 中找到含“基差”的列，无法计算累计损益。\")\n",
    "\n",
    "# --- 2) 稳健对齐测试期索引与基差序列 ---\n",
    "def _normalize_dtindex(idx) -> pd.DatetimeIndex:\n",
    "    idx = pd.to_datetime(idx, errors=\"coerce\")\n",
    "    if getattr(idx, \"tz\", None) is not None:\n",
    "        idx = idx.tz_localize(None)\n",
    "    return idx.normalize()  # 归一化到“日期”粒度\n",
    "\n",
    "# 规范化基差索引\n",
    "basis_series = basis_series.copy()\n",
    "basis_series.index = _normalize_dtindex(basis_series.index)\n",
    "basis_series = basis_series.sort_index()\n",
    "\n",
    "# 取得“测试期日期索引”：若 df_te.index 不是日期或大多为 NaT，就用 df_clean 末尾 N_te 天\n",
    "N_te = len(df_te)\n",
    "test_index_raw = df_te.index\n",
    "test_index_norm = _normalize_dtindex(test_index_raw)\n",
    "\n",
    "if (not isinstance(test_index_raw, pd.DatetimeIndex)) or (pd.isna(test_index_norm).mean() > 0.5):\n",
    "    idx_all = _normalize_dtindex(df_clean.sort_index().index)\n",
    "    assert len(idx_all) >= N_te, \"df_clean 行数少于测试集样本数，无法回推测试期日期。\"\n",
    "    test_index = idx_all[-N_te:]\n",
    "else:\n",
    "    test_index = test_index_norm\n",
    "\n",
    "# 先做“精确对齐”\n",
    "basis_test = basis_series.reindex(test_index)\n",
    "\n",
    "# 若大量 NaN，使用 merge_asof 向前对齐（容忍 5 天）\n",
    "if basis_test.isna().mean() > 0.5:\n",
    "    lo, hi = test_index.min() - pd.Timedelta(days=10), test_index.max() + pd.Timedelta(days=10)\n",
    "    basis_clip = basis_series.loc[(basis_series.index >= lo) & (basis_series.index <= hi)]\n",
    "    # left: 测试期日期（强制列名为 'date'）\n",
    "    left = pd.DataFrame({\"date\": pd.to_datetime(test_index)})\n",
    "    # right: 基差（两列，强制命名为 'date' 和 'basis'）\n",
    "    right = basis_clip.reset_index()\n",
    "    right.columns = [\"date\", \"basis\"]\n",
    "    right[\"date\"] = pd.to_datetime(right[\"date\"])\n",
    "    aligned = pd.merge_asof(\n",
    "        left.sort_values(\"date\"),\n",
    "        right.sort_values(\"date\"),\n",
    "        on=\"date\",\n",
    "        direction=\"backward\",\n",
    "        tolerance=pd.Timedelta(days=5)\n",
    "    )\n",
    "    basis_test = aligned.set_index(\"date\")[\"basis\"]\n",
    "\n",
    "# 若仍全 NaN，再次回退到 df_clean 的差分累加近似并强制对齐\n",
    "if basis_test.isna().all():\n",
    "    print(\"[WARN] 基差文件与测试期日期完全不匹配；使用 df_clean['基差'] 的差分累加近似。\")\n",
    "    diff_basis_col = None\n",
    "    for c in df_clean.columns:\n",
    "        if \"基差\" in str(c):\n",
    "            diff_basis_col = c; break\n",
    "    assert diff_basis_col is not None, \"回退失败：df_clean 中未找到‘基差’列。\"\n",
    "    approx_series = df_clean[diff_basis_col].astype(float).sort_index().cumsum()\n",
    "    approx_series.index = _normalize_dtindex(approx_series.index)\n",
    "    basis_test = approx_series.reindex(test_index).ffill().bfill()\n",
    "\n",
    "# 最终再做一次前后填补，确保无 NaN\n",
    "basis_test = basis_test.ffill().bfill()\n",
    "assert not basis_test.isna().all(), \"对齐失败：basis_test 仍为全 NaN，请检查基差文件日期或 df_clean 的索引。\"\n",
    "\n",
    "# --- 3) 生成仓位（预测明天涨→做多 +1；预测明天跌→做空 -1） ---\n",
    "pred_te = (y_te_prob >= chosen_thr).astype(int)    # 长度 N_te\n",
    "pos = np.where(pred_te == 1, 1, -1)                # +1/-1\n",
    "\n",
    "# --- 4) 计算 Δbasis_{t+1} 并用 t 的仓位结算 ---\n",
    "delta_next = basis_test.diff()                     # Δbasis_t\n",
    "pnl = pos[:-1] * delta_next.values[1:]            # 长度 N_te - 1\n",
    "\n",
    "# --- 5) 可选：加入换手成本 ---\n",
    "fee_per_change = 0.0                               # 单位与“基差”一致；如有手续费/滑点在此设置\n",
    "turnover = (pos[:-1] != pos[1:]).astype(int)       # 长度 N_te - 1\n",
    "pnl = pnl - turnover * fee_per_change\n",
    "\n",
    "# --- 6) 累计 & 保存结果 ---\n",
    "cum_pnl = np.cumsum(pnl)\n",
    "N = len(basis_test)\n",
    "assert len(pred_te) == N, f\"预测长度 {len(pred_te)} 与测试期 {N} 不一致\"\n",
    "assert len(pnl) == N-1 == len(turnover)\n",
    "\n",
    "pnl_df = pd.DataFrame({\n",
    "    \"date\":        basis_test.index[:-1],\n",
    "    \"basis_t\":     basis_test.values[:-1],\n",
    "    \"basis_t1\":    basis_test.values[1:],\n",
    "    \"delta_t1\":    delta_next.values[1:],\n",
    "    \"prob\":        np.asarray(y_te_prob)[:-1],\n",
    "    \"pred\":        np.asarray(pred_te)[:-1],\n",
    "    \"pos\":         np.asarray(pos)[:-1],\n",
    "    \"turnover\":    turnover,\n",
    "    \"pnl\":         pnl,\n",
    "    \"cum_pnl\":     cum_pnl\n",
    "}).set_index(\"date\")\n",
    "\n",
    "pnl_df.to_csv(\"pnl_detail.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(pnl_df.index, pnl_df[\"cum_pnl\"].values, linewidth=1.5)\n",
    "plt.title(\"Result on test\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"Cumulative P&L\")\n",
    "# 若曲线为常数（例如全 0），强制展开 y 轴\n",
    "if np.nanmin(pnl_df[\"cum_pnl\"].values) == np.nanmax(pnl_df[\"cum_pnl\"].values):\n",
    "    y0 = float(pnl_df[\"cum_pnl\"].iloc[-1])\n",
    "    plt.ylim(y0 - 1, y0 + 1)\n",
    "plt.tight_layout(); plt.savefig(\"cum_pnl.png\", dpi=150); plt.close()\n",
    "\n",
    "print(\"\\n==== Cumulative P&L (Test, next-day realized) ====\")\n",
    "print(f\"Final Cum P&L: {float(cum_pnl[-1]) if len(cum_pnl)>0 else float('nan'):.6f}\")\n",
    "print(\"Saved: pnl_detail.csv, cum_pnl.png\")\n",
    "\n",
    "# （可选）快速自检\n",
    "# print(\"[CHECK] test_index[:5]:\", test_index[:5])\n",
    "# print(\"[CHECK] basis_test.head():\\n\", basis_test.head())\n",
    "# print(\"[CHECK] NaN % in basis_test:\", float(basis_test.isna().mean())*100, \"%\")\n",
    "# print(\"[CHECK] pnl_df.head():\\n\", pnl_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lau",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
