{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af7d833",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d940105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL当季价格 前端缺失过多，已删除。\n",
      "TL下季价格 前端缺失过多，已删除。\n",
      "TL成交量 前端缺失过多，已删除。\n",
      "TL持仓量 前端缺失过多，已删除。\n",
      "TL跨期价差 前端缺失过多，已删除。\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1658 entries, 2019-01-08 to 2025-08-27\n",
      "Columns: 149 entries, 国债1yYTM to value_sort\n",
      "dtypes: float64(148), int64(1)\n",
      "memory usage: 1.9 MB\n",
      "None\n",
      "            国债1yYTM  国债3yYTM  国债5yYTM  国债7yYTM  国债10yYTM  国债30yYTM  国开1yYTM  \\\n",
      "date                                                                          \n",
      "2019-01-08   2.3528   2.7530   2.8796   3.0836    3.1211    3.6757   2.4806   \n",
      "2019-01-09   2.3777   2.7604   2.8745   3.1010    3.1106    3.7007   2.4945   \n",
      "2019-01-10   2.3627   2.7736   2.8954   3.1050    3.1006    3.7182   2.6011   \n",
      "2019-01-11   2.4065   2.7920   2.9100   3.0939    3.1058    3.7157   2.6308   \n",
      "2019-01-14   2.4260   2.7927   2.9496   3.1075    3.1297    3.7257   2.6519   \n",
      "\n",
      "            国开3yYTM  国开5yYTM  国开7yYTM  ...  二级2yYTM_20dMA  二级3yYTM_20dMA  \\\n",
      "date                                   ...                                 \n",
      "2019-01-08   3.0503   3.3885   3.5969  ...            0.0            0.0   \n",
      "2019-01-09   3.0629   3.3930   3.6107  ...            0.0            0.0   \n",
      "2019-01-10   3.0716   3.3930   3.6262  ...            0.0            0.0   \n",
      "2019-01-11   3.0877   3.4011   3.6325  ...            0.0            0.0   \n",
      "2019-01-14   3.1052   3.4244   3.6657  ...            0.0            0.0   \n",
      "\n",
      "            二级4yYTM_20dMA  二级5yYTM_20dMA  永续1yYTM_20dMA  永续2yYTM_20dMA  \\\n",
      "date                                                                     \n",
      "2019-01-08            0.0            0.0            0.0            0.0   \n",
      "2019-01-09            0.0            0.0            0.0            0.0   \n",
      "2019-01-10            0.0            0.0            0.0            0.0   \n",
      "2019-01-11            0.0            0.0            0.0            0.0   \n",
      "2019-01-14            0.0            0.0            0.0            0.0   \n",
      "\n",
      "            永续3yYTM_20dMA  永续4yYTM_20dMA  永续5yYTM_20dMA  value_sort  \n",
      "date                                                                 \n",
      "2019-01-08            0.0            0.0            0.0           1  \n",
      "2019-01-09            0.0            0.0            0.0           1  \n",
      "2019-01-10            0.0            0.0            0.0           0  \n",
      "2019-01-11            0.0            0.0            0.0           1  \n",
      "2019-01-14            0.0            0.0            0.0           0  \n",
      "\n",
      "[5 rows x 149 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86198\\AppData\\Local\\Temp\\ipykernel_15144\\701915629.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"value_sort\"] = (df[\"二级5yYTM\"].shift(-1) - df[\"二级5yYTM\"]).apply(lambda x: 0 if x > 0 else 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 读取原始因子库\n",
    "df_raw = pd.read_excel(\"因子库_10.xlsx\")\n",
    "df_raw.set_index(\"date\", inplace=True)\n",
    "\n",
    "# ----------- 特征清洗流程 -----------\n",
    "df = df_raw.copy()\n",
    "\n",
    "# 1) 删除一行里超过一半缺失的记录（周末/节假日等）\n",
    "df = df.dropna(thresh=df.shape[1] / 2)\n",
    "\n",
    "# 2) 删除缺失过半的列（前端缺失过多，没用）\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > df.shape[0] / 2:\n",
    "        print(f\"{col} 前端缺失过多，已删除。\")\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# 3) 将列转为数值型，并处理异常值\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    # Z-score 绝对值 >5 判定为异常值 → NaN\n",
    "    mean, std = df[col].mean(), df[col].std()\n",
    "    df[col] = df[col].apply(lambda x: np.nan if abs((x - mean) / std) > 5 else x)\n",
    "    # 线性插值填补缺失\n",
    "    df[col] = df[col].interpolate(method=\"linear\", axis=0)\n",
    "\n",
    "# 4) 其余缺失补 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# ----------- 构造标签列 value_sort -----------\n",
    "# 用“二级5yYTM”的下一期涨跌作为标签\n",
    "# 基于差分构造标签：下期 - 当前期 > 0 记为 1，否则 0\n",
    "df[\"value_sort\"] = (df[\"二级5yYTM\"].shift(-1) - df[\"二级5yYTM\"]).apply(lambda x: 0 if x > 0 else 1)\n",
    "\n",
    "# 删除最后一行（因为 shift(-1) 导致最后一行没有标签）\n",
    "df_clean = df.iloc[:-1]\n",
    "\n",
    "\n",
    "print(df_clean.info())\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b77892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_sort\n",
      "1    955\n",
      "0    703\n",
      "Name: count, dtype: int64\n",
      "value_sort\n",
      "1    0.575995\n",
      "0    0.424005\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['value_sort'].value_counts())\n",
    "print(df_clean['value_sort'].value_counts(normalize=True))  # 占比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9f4d3",
   "metadata": {},
   "source": [
    "## 差分版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3180e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86198\\AppData\\Local\\Temp\\ipykernel_15144\\2035252600.py:9: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = pd.concat([df, df_raw.iloc[:, 63:65].fillna(method='ffill').diff(1)], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL当季价格 前端缺失，已删除。\n",
      "TL下季价格 前端缺失，已删除。\n",
      "TL成交量 前端缺失，已删除。\n",
      "TL持仓量 前端缺失，已删除。\n",
      "TL跨期价差 前端缺失，已删除。\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1643 entries, 2019-01-08 to 2025-08-28\n",
      "Columns: 148 entries, 国债1yYTM to 永续5yYTM_20dMA\n",
      "dtypes: float64(148)\n",
      "memory usage: 1.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_excel('因子库_10.xlsx')\n",
    "df_raw.set_index('date', inplace=True)\n",
    "#df_raw = df_raw.loc[df_raw.index > '2021-08-13']#永续回测需要\n",
    "df = pd.DataFrame(index=df_raw.index)\n",
    "df = pd.concat([df, df_raw.iloc[:, 0:63].diff(1)], axis=1)\n",
    "df = pd.concat([df, df_raw.iloc[:, 63:65].fillna(method='ffill').diff(1)], axis=1)\n",
    "df = pd.concat([df, df_raw.iloc[:, 65:]], axis=1)\n",
    "\n",
    "df = df.dropna(thresh=df.shape[1] / 2)  # 删除一行超过20各na的数据，主要涉及周末\n",
    "for col in df.columns:  # 删除na过多的列，主要涉及永续收益率\n",
    "    if df[col].isnull().sum() > df.shape[0] / 2:\n",
    "        print(col, '前端缺失，已删除。')\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "# 将各列由object转换为数值,将异常值替换为缺失值，然后对缺失值进行线性插补\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "    # z-score绝对值大于5判定为异常值\n",
    "    df[col] = df[col].apply(lambda x: np.nan if abs(\n",
    "        (x - df[col].mean()) / df[col].std()) > 5 else x)\n",
    "    df[col] = df[col].interpolate(method='linear', axis=0)  # 线性插补\n",
    "# data = data.set_index('日期')\n",
    "df.fillna(0, inplace=True)\n",
    "df_clean = df.dropna()\n",
    "print(df_clean.info())\n",
    "\n",
    "df_clean['value_sort'] = df_clean['二级5yYTM'].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "df_clean = df_clean.iloc[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2cf190",
   "metadata": {},
   "source": [
    "## 含有滞后项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3353647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前端缺失过多的列，已删除： ['TL当季价格', 'TL下季价格', 'TL成交量', 'TL持仓量', 'TL跨期价差']\n",
      "shape: (1714, 445), 生成滞后特征数量: 296\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1714 entries, 2019-01-11 to 2025-08-27\n",
      "Columns: 445 entries, 国债1yYTM to value_sort\n",
      "dtypes: float64(444), int64(1)\n",
      "memory usage: 5.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 配置区（按需修改）\n",
    "# =========================\n",
    "INPUT_XLSX = '因子库_10.xlsx'   # 输入文件名\n",
    "DATE_COL = 'date'               # 日期列名\n",
    "TARGET_COL = '二级5yYTM'        # 用于打标签的列（这里是差分后的 ΔYTM）\n",
    "LAG_K = 2                        # 生成 1..K 阶滞后\n",
    "LAG_COLS = None                  # None = 对全部数值列生成滞后；或传入列名列表\n",
    "LAG_DROP_ORIGINAL = False        # 是否丢弃原始列，只保留滞后列\n",
    "LAG_NA_STRATEGY = \"drop\"         # \"drop\" | \"fill0\"，滞后后产生的前 K 行 NaN 的处理\n",
    "ROW_NA_RATIO_DROP = 0.5          # 行缺失比例阈值（> 该比例则丢行）\n",
    "COL_NA_RATIO_DROP = 0.5          # 列缺失比例阈值（> 该比例则丢列）\n",
    "ZSCORE_OUTLIER = 5               # |z|>阈值 视为异常置 NaN\n",
    "FILLNA_ZERO_AFTER_CLEAN = True   # 清洗后是否将剩余 NaN 填 0\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 工具函数\n",
    "# =========================\n",
    "def to_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"对 DataFrame 每列执行 to_numeric(errors='coerce')。\"\"\"\n",
    "    return df.apply(lambda s: pd.to_numeric(s, errors='coerce'))\n",
    "\n",
    "\n",
    "def add_lag_features(\n",
    "    df: pd.DataFrame,\n",
    "    cols: list[str] | None = None,\n",
    "    K: int = 3,\n",
    "    drop_original: bool = False,\n",
    "    na_strategy: str = \"drop\"  # \"drop\" | \"fill0\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    为 df 中的指定列添加 1..K 阶滞后特征。\n",
    "    - cols=None 时对所有数值列添加\n",
    "    - drop_original=True 时只保留滞后列\n",
    "    - na_strategy: 生成滞后后前 K 行会出现 NaN，选择丢弃或填 0\n",
    "    \"\"\"\n",
    "    if cols is None:\n",
    "        cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "    else:\n",
    "        cols = [c for c in cols if c in df.columns]\n",
    "\n",
    "    if len(cols) == 0:\n",
    "        return df.copy()\n",
    "\n",
    "    lagged_parts = []\n",
    "    for k in range(1, K + 1):\n",
    "        shifted = df[cols].shift(k)\n",
    "        shifted.columns = [f\"{c}_lag{k}\" for c in cols]\n",
    "        lagged_parts.append(shifted)\n",
    "\n",
    "    out = pd.concat([df if not drop_original else df.drop(columns=cols)] + lagged_parts, axis=1)\n",
    "\n",
    "    if na_strategy == \"drop\":\n",
    "        out = out.dropna()\n",
    "    elif na_strategy == \"fill0\":\n",
    "        out = out.fillna(0)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 主流程\n",
    "# =========================\n",
    "def main():\n",
    "    # 读取\n",
    "    df_raw = pd.read_excel(INPUT_XLSX)\n",
    "    if DATE_COL not in df_raw.columns:\n",
    "        raise ValueError(f\"未找到日期列 '{DATE_COL}'\")\n",
    "    df_raw[DATE_COL] = pd.to_datetime(df_raw[DATE_COL], errors='coerce')\n",
    "    df_raw = df_raw.set_index(DATE_COL).sort_index()\n",
    "\n",
    "    # 构建输出骨架\n",
    "    df = pd.DataFrame(index=df_raw.index)\n",
    "\n",
    "    # --- 0:63 直接差分（保持原逻辑）+ 数值化以避免类型错误 ---\n",
    "    part0 = to_numeric_df(df_raw.iloc[:, 0:63]).diff(1)\n",
    "\n",
    "    # --- 63:65 先前向填充再差分（保持原逻辑） ---\n",
    "    part1 = to_numeric_df(df_raw.iloc[:, 63:65]).ffill().diff(1)\n",
    "\n",
    "    # --- 65: 之后 先前向填充再差分（唯一改动，保持你的设定） ---\n",
    "    part2 = to_numeric_df(df_raw.iloc[:, 65:]).ffill().diff(1)\n",
    "\n",
    "    # 合并\n",
    "    df = pd.concat([df, part0, part1, part2], axis=1)\n",
    "\n",
    "    # ========== 行/列缺失清理 ==========\n",
    "    # 1) 丢弃缺失超过比例阈值的行（例如周末/节假日）\n",
    "    df = df.dropna(thresh=int(df.shape[1] * (1 - ROW_NA_RATIO_DROP)))\n",
    "\n",
    "    # 2) 丢弃缺失超过比例阈值的列\n",
    "    cols_to_drop = []\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().sum() > df.shape[0] * COL_NA_RATIO_DROP:\n",
    "            cols_to_drop.append(col)\n",
    "    if cols_to_drop:\n",
    "        print(\"前端缺失过多的列，已删除：\", cols_to_drop)\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # ========== 二次数值化 + 异常值置 NaN + 线性插值 ==========\n",
    "    #（部分列可能因上一步 drop/concat 再次出现类型问题，这里统一 to_numeric）\n",
    "    for col in df.columns:\n",
    "        s = pd.to_numeric(df[col], errors='coerce')\n",
    "        mu, std = s.mean(), s.std()\n",
    "        if pd.notna(std) and std > 0:\n",
    "            # |z|>阈值 置 NaN\n",
    "            z = (s - mu) / std\n",
    "            s = s.mask(z.abs() > ZSCORE_OUTLIER, np.nan)\n",
    "        df[col] = s.interpolate(method='linear', axis=0)\n",
    "\n",
    "    if FILLNA_ZERO_AFTER_CLEAN:\n",
    "        df = df.fillna(0)\n",
    "\n",
    "    # 此处不再额外 df.dropna()，避免把合法 0 也冲掉\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # ========== 生成 K 阶滞后特征（在打标签之前） ==========\n",
    "    if LAG_COLS is None:\n",
    "        # 默认：对所有数值列生成滞后\n",
    "        lag_target_cols = df_clean.select_dtypes(include=\"number\").columns.tolist()\n",
    "    else:\n",
    "        lag_target_cols = [c for c in LAG_COLS if c in df_clean.columns]\n",
    "\n",
    "    df_with_lags = add_lag_features(\n",
    "        df_clean,\n",
    "        cols=lag_target_cols,\n",
    "        K=LAG_K,\n",
    "        drop_original=LAG_DROP_ORIGINAL,\n",
    "        na_strategy=LAG_NA_STRATEGY\n",
    "    )\n",
    "\n",
    "    # ========== 构造标签（下一期 Δ(TARGET_COL) 是否 > 0）==========\n",
    "    if TARGET_COL not in df_with_lags.columns:\n",
    "        raise ValueError(f\"用于打标签的列 '{TARGET_COL}' 不在数据中，请检查列名或生成流程。\")\n",
    "\n",
    "    df_with_lags['value_sort'] = df_with_lags[TARGET_COL].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "    df_with_lags = df_with_lags.iloc[:-1]  # 去掉最后一行（因 shift(-1) 产生 NaN 标签）\n",
    "\n",
    "    # 打印信息\n",
    "    lag_feature_count = df_with_lags.filter(like='_lag').shape[1]\n",
    "    print(f\"shape: {df_with_lags.shape}, 生成滞后特征数量: {lag_feature_count}\")\n",
    "    print(df_with_lags.info())\n",
    "\n",
    "    # 需要的话可保存\n",
    "    # df_with_lags.to_parquet('df_with_lags.parquet')  # 更快更稳\n",
    "    # 或者：\n",
    "    # df_with_lags.to_csv('df_with_lags.csv', encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebff27",
   "metadata": {},
   "source": [
    "### 含有标签的滞后项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b005efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "删除 166 行 '二级5yYTM' 为空的数据\n",
      "前端缺失过多的列，已删除： ['TL当季价格', 'TL下季价格', 'TL成交量', 'TL持仓量', 'TL跨期价差']\n",
      "shape: (1611, 447), 生成滞后特征数量: 298\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1611 entries, 2019-01-11 to 2025-08-27\n",
      "Columns: 447 entries, 国债1yYTM to value_sort\n",
      "dtypes: float64(446), int64(1)\n",
      "memory usage: 5.5 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1611 entries, 2019-01-11 to 2025-08-27\n",
      "Columns: 447 entries, 国债1yYTM to value_sort\n",
      "dtypes: float64(446), int64(1)\n",
      "memory usage: 5.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 配置区（按需修改）\n",
    "# =========================\n",
    "INPUT_XLSX = '因子库_10.xlsx'   # 输入文件名\n",
    "DATE_COL = 'date'               # 日期列名\n",
    "TARGET_COL = '二级5yYTM'        # 用于打标签的列（这里是差分后的 ΔYTM）\n",
    "LAG_K = 2                        # 生成 1..K 阶滞后\n",
    "LAG_COLS = None                  # None = 对全部数值列生成滞后；或传入列名列表\n",
    "LAG_DROP_ORIGINAL = False        # 是否丢弃原始列，只保留滞后列\n",
    "LAG_NA_STRATEGY = \"drop\"         # \"drop\" | \"fill0\"，滞后后产生的前 K 行 NaN 的处理\n",
    "ROW_NA_RATIO_DROP = 0.5          # 行缺失比例阈值（> 该比例则丢行）\n",
    "COL_NA_RATIO_DROP = 0.5          # 列缺失比例阈值（> 该比例则丢列）\n",
    "ZSCORE_OUTLIER = 5               # |z|>阈值 视为异常置 NaN\n",
    "FILLNA_ZERO_AFTER_CLEAN = True   # 清洗后是否将剩余 NaN 填 0\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 工具函数\n",
    "# =========================\n",
    "def to_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"对 DataFrame 每列执行 to_numeric(errors='coerce')。\"\"\"\n",
    "    return df.apply(lambda s: pd.to_numeric(s, errors='coerce'))\n",
    "\n",
    "\n",
    "def add_lag_features(\n",
    "    df: pd.DataFrame,\n",
    "    cols: list[str] | None = None,\n",
    "    K: int = 3,\n",
    "    drop_original: bool = False,\n",
    "    na_strategy: str = \"drop\"  # \"drop\" | \"fill0\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    为 df 中的指定列添加 1..K 阶滞后特征。\n",
    "    - cols=None 时对所有数值列添加\n",
    "    - drop_original=True 时只保留滞后列\n",
    "    - na_strategy: 生成滞后后前 K 行会出现 NaN，选择丢弃或填 0\n",
    "    \"\"\"\n",
    "    if cols is None:\n",
    "        cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "    else:\n",
    "        cols = [c for c in cols if c in df.columns]\n",
    "\n",
    "    if len(cols) == 0:\n",
    "        return df.copy()\n",
    "\n",
    "    lagged_parts = []\n",
    "    for k in range(1, K + 1):\n",
    "        shifted = df[cols].shift(k)\n",
    "        shifted.columns = [f\"{c}_lag{k}\" for c in cols]\n",
    "        lagged_parts.append(shifted)\n",
    "\n",
    "    out = pd.concat([df if not drop_original else df.drop(columns=cols)] + lagged_parts, axis=1)\n",
    "\n",
    "    if na_strategy == \"drop\":\n",
    "        out = out.dropna()\n",
    "    elif na_strategy == \"fill0\":\n",
    "        out = out.fillna(0)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 主流程\n",
    "# =========================\n",
    "\n",
    "# 读取\n",
    "df_raw = pd.read_excel(INPUT_XLSX)\n",
    "if DATE_COL not in df_raw.columns:\n",
    "    raise ValueError(f\"未找到日期列 '{DATE_COL}'\")\n",
    "df_raw[DATE_COL] = pd.to_datetime(df_raw[DATE_COL], errors='coerce')\n",
    "df_raw = df_raw.set_index(DATE_COL).sort_index()\n",
    "\n",
    "# 构建输出骨架\n",
    "df = pd.DataFrame(index=df_raw.index)\n",
    "\n",
    "# --- 0:63 直接差分（保持原逻辑）+ 数值化以避免类型错误 ---\n",
    "part0 = to_numeric_df(df_raw.iloc[:, 0:63]).diff(1)\n",
    "\n",
    "# --- 63:65 先前向填充再差分（保持原逻辑） ---\n",
    "part1 = to_numeric_df(df_raw.iloc[:, 63:65]).ffill().diff(1)\n",
    "\n",
    "# --- 65: 之后 先前向填充再差分（保持你的设定） ---\n",
    "part2 = to_numeric_df(df_raw.iloc[:, 65:]).ffill().diff(1)\n",
    "\n",
    "# 合并\n",
    "df = pd.concat([df, part0, part1, part2], axis=1)\n",
    "\n",
    "# ========== 重点：优先删除 TARGET_COL 为空的行 ==========\n",
    "if TARGET_COL in df.columns:\n",
    "    before_drop = df.shape[0]\n",
    "    df = df[df[TARGET_COL].notna()]\n",
    "    print(f\"删除 {before_drop - df.shape[0]} 行 '{TARGET_COL}' 为空的数据\")\n",
    "else:\n",
    "    raise ValueError(f\"找不到目标列 '{TARGET_COL}'（请检查列名或差分切片）\")\n",
    "\n",
    "# ========== 行/列缺失清理 ==========\n",
    "# 1) 丢弃缺失超过比例阈值的行（例如周末/节假日）\n",
    "df = df.dropna(thresh=int(df.shape[1] * (1 - ROW_NA_RATIO_DROP)))\n",
    "\n",
    "# 2) 丢弃缺失超过比例阈值的列\n",
    "cols_to_drop = []\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > df.shape[0] * COL_NA_RATIO_DROP:\n",
    "        cols_to_drop.append(col)\n",
    "if cols_to_drop:\n",
    "    print(\"前端缺失过多的列，已删除：\", cols_to_drop)\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# ========== 二次数值化 + 异常值置 NaN + 线性插值 ==========\n",
    "#（部分列可能因上一步 drop/concat 再次出现类型问题，这里统一 to_numeric）\n",
    "for col in df.columns:\n",
    "    s = pd.to_numeric(df[col], errors='coerce')\n",
    "    mu, std = s.mean(), s.std()\n",
    "    if pd.notna(std) and std > 0:\n",
    "        # |z|>阈值 置 NaN\n",
    "        z = (s - mu) / std\n",
    "        s = s.mask(z.abs() > ZSCORE_OUTLIER, np.nan)\n",
    "    # 对异常后的空值做线性插值\n",
    "    df[col] = s.interpolate(method='linear', axis=0)\n",
    "\n",
    "if FILLNA_ZERO_AFTER_CLEAN:\n",
    "    df = df.fillna(0)\n",
    "\n",
    "# 不再额外 df.dropna()，避免把合法 0 也冲掉\n",
    "df_clean = df.copy()\n",
    "\n",
    "# ========== 构造“历史涨跌方向因子” ytm_up_lag1..K（不引入未来信息） ==========\n",
    "# 等价于：先构造 value_sort 再做滞后；但直接基于 TARGET_COL 的历史值生成，更清晰更安全\n",
    "if TARGET_COL not in df_clean.columns:\n",
    "    raise ValueError(f\"用于生成涨跌方向因子的列 '{TARGET_COL}' 不在数据中，请检查处理流程。\")\n",
    "for k in range(1, LAG_K + 1):\n",
    "    val = df_clean[TARGET_COL].shift(k)\n",
    "    # 保留前k期的 NaN（由后续 LAG_NA_STRATEGY 统一处理）\n",
    "    df_clean[f\"ytm_up_lag{k}\"] = np.where(val.isna(), np.nan, (val > 0).astype(int))\n",
    "\n",
    "# ========== 生成 K 阶滞后特征（在打标签之前） ==========\n",
    "if LAG_COLS is None:\n",
    "    # 默认：对所有数值列生成滞后；但排除我们刚加的 ytm_up_lag*，避免二次滞后\n",
    "    lag_target_cols = df_clean.select_dtypes(include=\"number\").columns.tolist()\n",
    "    lag_target_cols = [c for c in lag_target_cols if not c.startswith(\"ytm_up_lag\")]\n",
    "else:\n",
    "    lag_target_cols = [c for c in LAG_COLS if c in df_clean.columns and not c.startswith(\"ytm_up_lag\")]\n",
    "\n",
    "df_with_lags = add_lag_features(\n",
    "    df_clean,\n",
    "    cols=lag_target_cols,\n",
    "    K=LAG_K,\n",
    "    drop_original=LAG_DROP_ORIGINAL,\n",
    "    na_strategy=LAG_NA_STRATEGY\n",
    ")\n",
    "\n",
    "# ========== 构造标签（下一期 Δ(TARGET_COL) 是否 > 0）==========\n",
    "if TARGET_COL not in df_with_lags.columns:\n",
    "    raise ValueError(f\"用于打标签的列 '{TARGET_COL}' 不在数据中，请检查列名或生成流程。\")\n",
    "\n",
    "df_with_lags['value_sort'] = df_with_lags[TARGET_COL].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "df_with_lags = df_with_lags.iloc[:-1]  # 去掉最后一行（因 shift(-1) 产生 NaN 标签）\n",
    "\n",
    "# 最终输出\n",
    "df_clean = df_with_lags.copy()\n",
    "\n",
    "# 打印信息\n",
    "lag_feature_count = df_with_lags.filter(like='_lag').shape[1]\n",
    "print(f\"shape: {df_with_lags.shape}, 生成滞后特征数量: {lag_feature_count}\")\n",
    "print(df_with_lags.info())\n",
    "print(df_clean.info())\n",
    "\n",
    "# 可保存\n",
    "# df_with_lags.to_parquet('df_with_lags.parquet')  # 更快更稳\n",
    "# 或者：\n",
    "# df_with_lags.to_csv('df_with_lags.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6ea03",
   "metadata": {},
   "source": [
    "## 全特征差分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9d941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86198\\AppData\\Local\\Temp\\ipykernel_9344\\4059330280.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = pd.concat([df, df_raw.iloc[:, 63:65].fillna(method='ffill').diff(1)], axis=1)\n",
      "C:\\Users\\86198\\AppData\\Local\\Temp\\ipykernel_9344\\4059330280.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = pd.concat([df, df_raw.iloc[:, 65:].fillna(method='ffill').diff(1)], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TL当季价格 前端缺失，已删除。\n",
      "TL下季价格 前端缺失，已删除。\n",
      "TL成交量 前端缺失，已删除。\n",
      "TL持仓量 前端缺失，已删除。\n",
      "TL跨期价差 前端缺失，已删除。\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1717 entries, 2019-01-09 to 2025-08-28\n",
      "Columns: 148 entries, 国债1yYTM to 永续5yYTM_20dMA\n",
      "dtypes: float64(148)\n",
      "memory usage: 2.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_excel('因子库_10.xlsx')\n",
    "df_raw.set_index('date', inplace=True)\n",
    "#df_raw = df_raw.loc[df_raw.index > '2021-08-13']#永续回测需要\n",
    "\n",
    "df = pd.DataFrame(index=df_raw.index)\n",
    "\n",
    "# 0:63 直接差分（保持原逻辑）\n",
    "df = pd.concat([df, df_raw.iloc[:, 0:63].diff(1)], axis=1)\n",
    "\n",
    "# 63:65 先前向填充再差分（保持原逻辑）\n",
    "df = pd.concat([df, df_raw.iloc[:, 63:65].fillna(method='ffill').diff(1)], axis=1)\n",
    "\n",
    "# 65: 之后 —— 改为先前向填充再差分（这是唯一改动）\n",
    "df = pd.concat([df, df_raw.iloc[:, 65:].fillna(method='ffill').diff(1)], axis=1)\n",
    "\n",
    "# 行/列缺失清理\n",
    "df = df.dropna(thresh=df.shape[1] / 2)  # 删除一行超过一半 NaN（周末等）\n",
    "for col in df.columns:  # 删除 NaN 过多的列\n",
    "    if df[col].isnull().sum() > df.shape[0] / 2:\n",
    "        print(col, '前端缺失，已删除。')\n",
    "        df.drop([col], axis=1, inplace=True)\n",
    "\n",
    "# 转数值 + 异常值置 NaN + 线性插补\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "    # z-score 绝对值大于 5 判定为异常\n",
    "    df[col] = df[col].apply(lambda x: np.nan if abs((x - df[col].mean()) / df[col].std()) > 5 else x)\n",
    "    df[col] = df[col].interpolate(method='linear', axis=0)\n",
    "    \n",
    "df.fillna(0, inplace=True)\n",
    "df_clean = df.dropna()\n",
    "print(df_clean.info())\n",
    "\n",
    "# 标签：下一期 Δ(二级5yYTM) 是否 > 0\n",
    "df_clean['value_sort'] = df_clean['二级5yYTM'].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "df_clean = df_clean.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc539d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_sort\n",
      "0    1013\n",
      "1     703\n",
      "Name: count, dtype: int64\n",
      "value_sort\n",
      "0    0.590326\n",
      "1    0.409674\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['value_sort'].value_counts())\n",
    "print(df_clean['value_sort'].value_counts(normalize=True))  # 占比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a645c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            国债1yYTM  国债3yYTM  国债5yYTM  国债7yYTM  国债10yYTM  国债30yYTM  国开1yYTM  \\\n",
      "date                                                                          \n",
      "2019-01-09   0.0249   0.0074  -0.0051   0.0174   -0.0105    0.0250   0.0139   \n",
      "2019-01-10  -0.0150   0.0132   0.0209   0.0040   -0.0100    0.0175   0.1066   \n",
      "2019-01-11   0.0438   0.0184   0.0146  -0.0111    0.0052   -0.0025   0.0297   \n",
      "2019-01-14   0.0195   0.0007   0.0396   0.0136    0.0239    0.0100   0.0211   \n",
      "2019-01-15   0.0085  -0.0005  -0.0012   0.0144    0.0086    0.0150   0.0023   \n",
      "\n",
      "            国开3yYTM  国开5yYTM  国开7yYTM  ...  二级2yYTM_20dMA  二级3yYTM_20dMA  \\\n",
      "date                                   ...                                 \n",
      "2019-01-09   0.0126   0.0045   0.0138  ...            0.0            0.0   \n",
      "2019-01-10   0.0087   0.0000   0.0155  ...            0.0            0.0   \n",
      "2019-01-11   0.0161   0.0081   0.0063  ...            0.0            0.0   \n",
      "2019-01-14   0.0175   0.0233   0.0332  ...            0.0            0.0   \n",
      "2019-01-15  -0.0285   0.0097   0.0198  ...            0.0            0.0   \n",
      "\n",
      "            二级4yYTM_20dMA  二级5yYTM_20dMA  永续1yYTM_20dMA  永续2yYTM_20dMA  \\\n",
      "date                                                                     \n",
      "2019-01-09            0.0            0.0            0.0            0.0   \n",
      "2019-01-10            0.0            0.0            0.0            0.0   \n",
      "2019-01-11            0.0            0.0            0.0            0.0   \n",
      "2019-01-14            0.0            0.0            0.0            0.0   \n",
      "2019-01-15            0.0            0.0            0.0            0.0   \n",
      "\n",
      "            永续3yYTM_20dMA  永续4yYTM_20dMA  永续5yYTM_20dMA  value_sort  \n",
      "date                                                                 \n",
      "2019-01-09            0.0            0.0            0.0           1  \n",
      "2019-01-10            0.0            0.0            0.0           0  \n",
      "2019-01-11            0.0            0.0            0.0           1  \n",
      "2019-01-14            0.0            0.0            0.0           0  \n",
      "2019-01-15            0.0            0.0            0.0           1  \n",
      "\n",
      "[5 rows x 149 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250d137",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb513f09",
   "metadata": {},
   "source": [
    "## 相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2c7ff",
   "metadata": {},
   "source": [
    "### 皮尔曼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_sort         1.000000\n",
      "国开5yYTM            0.271364\n",
      "国开3yYTM            0.260847\n",
      "Shibor5Y           0.250022\n",
      "Repo5Y             0.243261\n",
      "国债5yYTM            0.241402\n",
      "国债10yYTM           0.239240\n",
      "国债7yYTM            0.229914\n",
      "国债30yYTM           0.228545\n",
      "国开10yYTM           0.227306\n",
      "国开7yYTM            0.226947\n",
      "国开30yYTM           0.222246\n",
      "Shibor1Y           0.209649\n",
      "Repo1Y             0.202434\n",
      "二级3yYTM            0.201906\n",
      "二级4yYTM            0.200056\n",
      "国债3yYTM            0.196997\n",
      "二级5yYTM            0.191995\n",
      "value_sort_lag1    0.188173\n",
      "二级2yYTM            0.181139\n",
      "Name: value_sort, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 与标签的相关性\n",
    "corr = df_clean.corr(method=\"spearman\")[\"value_sort\"].sort_values(ascending=False)\n",
    "\n",
    "print(corr.head(20))  # 前20个最相关的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dde675",
   "metadata": {},
   "source": [
    "### 单变量分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e6adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国债30yYTM           0.049931\n",
      "国债5yYTM            0.048825\n",
      "二级2yYTM_20dMA      0.040243\n",
      "国开3yYTM            0.038041\n",
      "国债10yYTM           0.037635\n",
      "国开7yYTM            0.036857\n",
      "国债7yYTM            0.034485\n",
      "T当季价格              0.034170\n",
      "value_sort_lag1    0.034079\n",
      "Shibor1Y           0.033681\n",
      "国开10yYTM_5dMA      0.033474\n",
      "DR001_5dMA         0.032520\n",
      "二级1y-永续1y          0.030042\n",
      "MLF1y              0.029389\n",
      "R001_5dMA          0.029381\n",
      "Repo5Y             0.028866\n",
      "二级3yYTM_20dMA      0.028750\n",
      "国开30yYTM           0.028219\n",
      "TF当季价格             0.027332\n",
      "国开5yYTM            0.027299\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = df_clean.drop(columns=[\"value_sort\"])\n",
    "y = df_clean[\"value_sort\"]\n",
    "\n",
    "mi = mutual_info_classif(X, y, discrete_features=False, random_state=42)\n",
    "mi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
    "print(mi_series.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53990dbc",
   "metadata": {},
   "source": [
    "## 降维"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd074542",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324af64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始维度: 153\n",
      "降维后维度: 41\n",
      "各主成分解释方差比: [0.4073065  0.13708688 0.07532114 0.03888846 0.02885398 0.025713\n",
      " 0.02159664 0.01656583 0.01467308 0.01310582 0.01188485 0.01130209\n",
      " 0.01062086 0.0091354  0.00826316 0.00767272 0.00722691 0.00690114\n",
      " 0.00662806 0.00653288 0.00603544 0.00565417 0.00553543 0.00518841\n",
      " 0.00514494 0.00491476 0.00483587 0.00460845 0.00451809 0.0043515\n",
      " 0.00396087 0.00376823 0.00352193 0.00336438 0.00304395 0.0029582\n",
      " 0.00291263 0.00285803 0.00280741 0.00254637 0.00242228]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df_clean.drop(columns=[\"value_sort\"])\n",
    "y = df_clean[\"value_sort\"]\n",
    "\n",
    "# 标准化\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# PCA 保留 95% 方差\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"原始维度:\", X.shape[1])\n",
    "print(\"降维后维度:\", X_pca.shape[1])\n",
    "print(\"各主成分解释方差比:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d08ad1",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1effc1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 25237 (\\N{CJK UNIFIED IDEOGRAPH-6295}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24433 (\\N{CJK UNIFIED IDEOGRAPH-5F71}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 21518 (\\N{CJK UNIFIED IDEOGRAPH-540E}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_lda = lda.fit_transform(X_scaled, y)\n",
    "\n",
    "plt.hist(X_lda[y==0], bins=50, alpha=0.5, label=\"Down\")\n",
    "plt.hist(X_lda[y==1], bins=50, alpha=0.5, label=\"Up\")\n",
    "plt.legend()\n",
    "plt.title(\"LDA 投影后的分布\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0deb3f8",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9c657",
   "metadata": {},
   "source": [
    "## PCA+非timeseries 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ad39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1309, Test size: 328\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.51746\tvalid_0's binary_logloss: 0.693141\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.662753\tvalid_0's binary_logloss: 0.691832\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.530655\tvalid_0's binary_logloss: 0.693332\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.708774\tvalid_0's binary_logloss: 0.691817\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.630331\tvalid_0's binary_logloss: 0.692643\n",
      "Trial   0: AUC=0.6100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.51746\tvalid_0's binary_logloss: 0.693145\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.59372\tvalid_0's binary_logloss: 0.692993\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.528365\tvalid_0's binary_logloss: 0.693179\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.69071\tvalid_0's binary_logloss: 0.692786\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.622456\tvalid_0's binary_logloss: 0.691815\n",
      "Trial   1: AUC=0.5905\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.544577\tvalid_0's binary_logloss: 0.692946\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's auc: 0.650581\tvalid_0's binary_logloss: 0.663126\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.506342\tvalid_0's binary_logloss: 0.69285\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's auc: 0.67243\tvalid_0's binary_logloss: 0.660845\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.64516\tvalid_0's binary_logloss: 0.678308\n",
      "Trial   2: AUC=0.6038\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.625\tvalid_0's binary_logloss: 0.677178\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.648989\tvalid_0's binary_logloss: 0.685936\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.539024\tvalid_0's binary_logloss: 0.692013\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.680172\tvalid_0's binary_logloss: 0.645218\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.682601\tvalid_0's binary_logloss: 0.658522\n",
      "Trial   3: AUC=0.6352\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.673118\tvalid_0's binary_logloss: 0.692613\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.523828\tvalid_0's binary_logloss: 0.692541\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.739355\tvalid_0's binary_logloss: 0.692012\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.645851\tvalid_0's binary_logloss: 0.692549\n",
      "Trial   4: AUC=0.6164\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's auc: 0.606824\tvalid_0's binary_logloss: 0.688956\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.651957\tvalid_0's binary_logloss: 0.691426\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.49379\tvalid_0's binary_logloss: 0.693143\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.632\tvalid_0's binary_logloss: 0.691584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.64691\tvalid_0's binary_logloss: 0.693061\n",
      "Trial   5: AUC=0.6063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.629677\tvalid_0's binary_logloss: 0.685934\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.555233\tvalid_0's binary_logloss: 0.693082\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.702409\tvalid_0's binary_logloss: 0.691435\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.645851\tvalid_0's binary_logloss: 0.692413\n",
      "Trial   6: AUC=0.6066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.607287\tvalid_0's binary_logloss: 0.693041\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.683871\tvalid_0's binary_logloss: 0.692667\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.483395\tvalid_0's binary_logloss: 0.693182\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.704731\tvalid_0's binary_logloss: 0.692947\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.671733\tvalid_0's binary_logloss: 0.690264\n",
      "Trial   7: AUC=0.6302\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's auc: 0.617032\tvalid_0's binary_logloss: 0.66407\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.565495\tvalid_0's binary_logloss: 0.69304\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.68886\tvalid_0's binary_logloss: 0.686353\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.647877\tvalid_0's binary_logloss: 0.69224\n",
      "Trial   8: AUC=0.6039\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.693147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.611484\tvalid_0's binary_logloss: 0.677142\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.555056\tvalid_0's binary_logloss: 0.692998\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's auc: 0.702968\tvalid_0's binary_logloss: 0.644983\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's auc: 0.646818\tvalid_0's binary_logloss: 0.662287\n",
      "Trial   9: AUC=0.6033\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.618379\tvalid_0's binary_logloss: 0.685287\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's auc: 0.641548\tvalid_0's binary_logloss: 0.654053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.522683\tvalid_0's binary_logloss: 0.691451\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.709849\tvalid_0's binary_logloss: 0.650032\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.679838\tvalid_0's binary_logloss: 0.643457\n",
      "Trial  10: AUC=0.6345\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.632212\tvalid_0's binary_logloss: 0.674329\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.626624\tvalid_0's binary_logloss: 0.669342\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.56827\tvalid_0's binary_logloss: 0.686835\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.691871\tvalid_0's binary_logloss: 0.650975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.664594\tvalid_0's binary_logloss: 0.642827\n",
      "Trial  11: AUC=0.6367\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.597082\tvalid_0's binary_logloss: 0.677557\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.657591\tvalid_0's binary_logloss: 0.670232\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.542107\tvalid_0's binary_logloss: 0.68851\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.678796\tvalid_0's binary_logloss: 0.640658\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.671272\tvalid_0's binary_logloss: 0.647159\n",
      "Trial  12: AUC=0.6294\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.637694\tvalid_0's binary_logloss: 0.683709\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.613849\tvalid_0's binary_logloss: 0.662645\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.552061\tvalid_0's binary_logloss: 0.684212\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.677677\tvalid_0's binary_logloss: 0.647493\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.691167\tvalid_0's binary_logloss: 0.632816\n",
      "Trial  13: AUC=0.6345\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's auc: 0.591346\tvalid_0's binary_logloss: 0.68556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.679312\tvalid_0's binary_logloss: 0.682768\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.556598\tvalid_0's binary_logloss: 0.690788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.695226\tvalid_0's binary_logloss: 0.641841\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.681312\tvalid_0's binary_logloss: 0.639537\n",
      "Trial  14: AUC=0.6408\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's auc: 0.613487\tvalid_0's binary_logloss: 0.674585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.674151\tvalid_0's binary_logloss: 0.686982\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.480796\tvalid_0's binary_logloss: 0.693585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.701505\tvalid_0's binary_logloss: 0.647826\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, average_precision_score, log_loss\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ========== 数据 & 切分 ==========\n",
    "# df_clean: 索引建议为日期；包含数值特征列 + 标签列 'value_sort'(0/1)\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 方式A：按日期阈值切分（需要 DatetimeIndex）\n",
    "cutoff_date = None  # 例如 \"2024-12-31\"；若保持 None，则使用方式B\n",
    "if cutoff_date is not None:\n",
    "    assert isinstance(df_clean.index, pd.DatetimeIndex), \"需将 df_clean.index 设为 DatetimeIndex 才能按日期切分\"\n",
    "    tr_mask = df_clean.index <= pd.to_datetime(cutoff_date)\n",
    "    te_mask = df_clean.index >  pd.to_datetime(cutoff_date)\n",
    "    X_tr_raw, y_tr = X_all[tr_mask], y_all[tr_mask]\n",
    "    X_te_raw, y_te = X_all[te_mask], y_all[te_mask]\n",
    "else:\n",
    "    # 方式B：按比例时间切分（前80%为训练，后20%为测试）\n",
    "    split_pt = int(len(df_clean) * 0.8)\n",
    "    X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "    X_te_raw, y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "print(f\"Train size: {len(y_tr)}, Test size: {len(y_te)}\")\n",
    "\n",
    "# ========== 工具函数 ==========\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# ========== 仅在训练集上做内层CV调参 ==========\n",
    "inner_cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "    }\n",
    "\n",
    "    auc_list = []\n",
    "    for tr_idx, va_idx in inner_cv.split(X_tr_raw):\n",
    "        X_tr_in, y_tr_in = X_tr_raw[tr_idx], y_tr[tr_idx]\n",
    "        X_va_in, y_va_in = X_tr_raw[va_idx], y_tr[va_idx]\n",
    "\n",
    "        # 标准化 & PCA 仅基于该折训练集\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr_in)\n",
    "        X_va_s = scaler.transform(X_va_in)\n",
    "\n",
    "        pca = PCA(n_components=0.95, svd_solver=\"full\", random_state=42)\n",
    "        X_tr_p = pca.fit_transform(X_tr_s)\n",
    "        X_va_p = pca.transform(X_va_s)\n",
    "\n",
    "        lgbm = LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            class_weight=\"balanced\",\n",
    "            n_estimators=2000,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        lgbm.fit(\n",
    "            X_tr_p, y_tr_in,\n",
    "            eval_set=[(X_va_p, y_va_in)],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(100)]\n",
    "        )\n",
    "        y_va_prob = lgbm.predict_proba(X_va_p)[:, 1]\n",
    "        auc = safe_auc(y_va_in, y_va_prob)\n",
    "        auc_list.append(auc)\n",
    "\n",
    "    mean_auc = float(np.nanmean(auc_list))\n",
    "    print(f\"Trial {trial.number:>3}: AUC={mean_auc:.4f}\")\n",
    "    return mean_auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=False)\n",
    "best_params = study.best_params\n",
    "print(\"\\nBest inner-CV AUC:\", f\"{study.best_value:.6f}\")\n",
    "print(\"Best Params:\", best_params)\n",
    "\n",
    "# ========== 用训练集训练最终模型（早停验证使用训练集末尾10%） ==========\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "\n",
    "X_tr_fit_raw, y_tr_fit = X_tr_raw[:val_start], y_tr[:val_start]   # 真正用于拟合（早停前的训练部分）\n",
    "X_val_fit_raw, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:] # 仅用于早停验证\n",
    "assert len(y_val_fit) > 0, \"训练集过小，无法切出验证集用于早停。请调大训练集或调小 val_tail_ratio。\"\n",
    "\n",
    "# 拟合阶段的标准化 & PCA（仅基于训练部分，不含验证/测试）\n",
    "scaler = StandardScaler()\n",
    "X_tr_fit_s = scaler.fit_transform(X_tr_fit_raw)\n",
    "X_val_fit_s = scaler.transform(X_val_fit_raw)\n",
    "X_te_s     = scaler.transform(X_te_raw)\n",
    "\n",
    "pca = PCA(n_components=0.95, svd_solver=\"full\", random_state=42)\n",
    "X_tr_fit_p = pca.fit_transform(X_tr_fit_s)\n",
    "X_val_fit_p = pca.transform(X_val_fit_s)\n",
    "X_te_p      = pca.transform(X_te_s)\n",
    "\n",
    "final_model = LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    class_weight=\"balanced\",\n",
    "    n_estimators=5000,      # 允许更大上限，由早停控制\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=-1,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_tr_fit_p, y_tr_fit,\n",
    "    eval_set=[(X_val_fit_p, y_val_fit)],\n",
    "    eval_metric=\"auc\",\n",
    "    callbacks=[early_stopping(200)]\n",
    ")\n",
    "\n",
    "# ========== 在测试集上预测并输出“测试集上的表现” ==========\n",
    "y_te_prob = final_model.predict_proba(X_te_p)[:, 1]\n",
    "y_te_pred = (y_te_prob >= 0.5).astype(int)\n",
    "\n",
    "test_auc  = safe_auc(y_te, y_te_prob)\n",
    "test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n==== Test Performance (held-out) ====\")\n",
    "print(f\"AUC:           {test_auc:.6f}\")\n",
    "print(f\"AveragePrecision(PR-AUC): {test_ap:.6f}\")\n",
    "print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "print(f\"Precision@0.5: {test_prec:.6f}\")\n",
    "print(f\"Recall@0.5:    {test_rec:.6f}\")\n",
    "print(f\"F1@0.5:        {test_f1:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6362e5",
   "metadata": {},
   "source": [
    "### 面向测试集调参 auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0c8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.490054\tvalid_0's binary_logloss: 0.693244\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.538172\tvalid_0's binary_logloss: 0.693167\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.504704\tvalid_0's binary_logloss: 0.693188\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.526882\tvalid_0's binary_logloss: 0.686234\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.501882\tvalid_0's binary_logloss: 0.693205\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.579435\tvalid_0's binary_logloss: 0.726782\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.520968\tvalid_0's binary_logloss: 0.693124\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.540054\tvalid_0's binary_logloss: 0.69316\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.526075\tvalid_0's binary_logloss: 0.694231\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.529301\tvalid_0's binary_logloss: 0.693269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.52957\tvalid_0's binary_logloss: 0.692012\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.538844\tvalid_0's binary_logloss: 0.693188\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.520565\tvalid_0's binary_logloss: 0.693184\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.523387\tvalid_0's binary_logloss: 0.693022\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.529973\tvalid_0's binary_logloss: 0.693328\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.568952\tvalid_0's binary_logloss: 0.691569\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.522312\tvalid_0's binary_logloss: 0.69307\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.609946\tvalid_0's binary_logloss: 0.69312\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.526075\tvalid_0's binary_logloss: 0.692998\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.514785\tvalid_0's binary_logloss: 0.693573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.500403\tvalid_0's binary_logloss: 0.692797\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.565726\tvalid_0's binary_logloss: 0.69209\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.508737\tvalid_0's binary_logloss: 0.6927\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.557124\tvalid_0's binary_logloss: 0.688831\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.532796\tvalid_0's binary_logloss: 0.686731\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.525269\tvalid_0's binary_logloss: 0.692023\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.568011\tvalid_0's binary_logloss: 0.688594\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.541398\tvalid_0's binary_logloss: 0.692616\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.502688\tvalid_0's binary_logloss: 0.695743\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.501882\tvalid_0's binary_logloss: 0.692291\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.56828\tvalid_0's binary_logloss: 0.692812\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.585484\tvalid_0's binary_logloss: 0.697823\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.593548\tvalid_0's binary_logloss: 0.689913\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.609946\tvalid_0's binary_logloss: 0.689146\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.529032\tvalid_0's binary_logloss: 0.69184\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.546102\tvalid_0's binary_logloss: 0.692567\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.612769\tvalid_0's binary_logloss: 0.694087\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.599597\tvalid_0's binary_logloss: 0.694158\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.501882\tvalid_0's binary_logloss: 0.696314\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.501882\tvalid_0's binary_logloss: 0.690848\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.525\tvalid_0's binary_logloss: 0.696399\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.613172\tvalid_0's binary_logloss: 0.690733\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.634543\tvalid_0's binary_logloss: 0.690887\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.583333\tvalid_0's binary_logloss: 0.693078\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.59328\tvalid_0's binary_logloss: 0.697366\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.538172\tvalid_0's binary_logloss: 0.694743\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.547446\tvalid_0's binary_logloss: 0.693353\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.617339\tvalid_0's binary_logloss: 0.693387\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.528763\tvalid_0's binary_logloss: 0.695535\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.536156\tvalid_0's binary_logloss: 0.693022\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.56828\tvalid_0's binary_logloss: 0.692812\n",
      "\n",
      "==== Test Performance (used for selection) ====\n",
      "AUC:           0.583149\n",
      "PR-AUC:        0.482234\n",
      "LogLoss:       0.694443\n",
      "Accuracy:      0.433735\n",
      "Precision@0.5: 0.433735\n",
      "Recall@0.5:    1.000000\n",
      "F1@0.5:        0.605042\n",
      "\n",
      "==== Best Params (by test AUC) ====\n",
      "learning_rate: 0.13234685108252608\n",
      "num_leaves: 134\n",
      "max_depth: 9\n",
      "min_child_samples: 100\n",
      "subsample: 0.5775884787612022\n",
      "colsample_bytree: 0.9220483008868927\n",
      "reg_alpha: 0.7539487307056196\n",
      "reg_lambda: 8.777560097118915\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ===== 数据 =====\n",
    "# df_clean: 特征列 + 'value_sort'(0/1)\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（如需按日期切，改这里）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te_raw, y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# 训练内的早停验证：训练集最后10%当val（不碰测试集）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit_raw, y_tr_fit = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit_raw, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# 预先拟合数据处理（仅基于训练部分）\n",
    "scaler_base = StandardScaler().fit(X_tr_fit_raw)\n",
    "pca_base = PCA(n_components=0.95, svd_solver=\"full\", random_state=42).fit(scaler_base.transform(X_tr_fit_raw))\n",
    "\n",
    "def transform_with_base(X):\n",
    "    return pca_base.transform(scaler_base.transform(X))\n",
    "\n",
    "X_tr_fit = transform_with_base(X_tr_fit_raw)\n",
    "X_val_fit = transform_with_base(X_val_fit_raw)\n",
    "X_te      = transform_with_base(X_te_raw)\n",
    "\n",
    "# ===== 目标函数：以“测试集AUC”作为最优标准 =====\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "    }\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\", class_weight=\"balanced\",\n",
    "        n_estimators=5000, random_state=42, n_jobs=-1, verbosity=-1, **params\n",
    "    )\n",
    "    clf.fit(\n",
    "        X_tr_fit, y_tr_fit,\n",
    "        eval_set=[(X_val_fit, y_val_fit)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200)]\n",
    "    )\n",
    "    # 用测试集打分：这一步就是你要求的“以测试集表现定义最优参数”\n",
    "    y_te_prob = clf.predict_proba(X_te)[:, 1]\n",
    "    test_auc = safe_auc(y_te, y_te_prob)\n",
    "    return float(test_auc)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=False)\n",
    "best_params = study.best_params\n",
    "\n",
    "# ===== 用最优参数重训（同样仅用训练集），训练后立即在测试集评估 =====\n",
    "final_model = LGBMClassifier(\n",
    "    objective=\"binary\", class_weight=\"balanced\",\n",
    "    n_estimators=5000, random_state=42, n_jobs=-1, verbosity=-1, **best_params\n",
    ")\n",
    "final_model.fit(\n",
    "    X_tr_fit, y_tr_fit,\n",
    "    eval_metric=\"auc\",\n",
    "    eval_set=[(X_val_fit, y_val_fit)],\n",
    "    callbacks=[early_stopping(200)]\n",
    ")\n",
    "\n",
    "y_te_prob = final_model.predict_proba(X_te)[:, 1]\n",
    "y_te_pred = (y_te_prob >= 0.5).astype(int)\n",
    "\n",
    "test_auc  = safe_auc(y_te, y_te_prob)\n",
    "test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n==== Test Performance (used for selection) ====\")\n",
    "print(f\"AUC:           {test_auc:.6f}\")\n",
    "print(f\"PR-AUC:        {test_ap:.6f}\")\n",
    "print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "print(f\"Precision@0.5: {test_prec:.6f}\")\n",
    "print(f\"Recall@0.5:    {test_rec:.6f}\")\n",
    "print(f\"F1@0.5:        {test_f1:.6f}\")\n",
    "\n",
    "print(\"\\n==== Best Params (by test AUC) ====\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d6e56",
   "metadata": {},
   "source": [
    "### 面向测试集调参 acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffe713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.553201\tvalid_0's binary_logloss: 0.675377\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.584211\tvalid_0's binary_logloss: 0.68268\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.581508\tvalid_0's binary_logloss: 0.687505\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.576814\tvalid_0's binary_logloss: 0.676272\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.567568\tvalid_0's binary_logloss: 0.68053\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.584637\tvalid_0's binary_logloss: 0.692806\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.565292\tvalid_0's binary_logloss: 0.673431\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.608819\tvalid_0's binary_logloss: 0.688637\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.593314\tvalid_0's binary_logloss: 0.693042\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.611949\tvalid_0's binary_logloss: 0.693018\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.606401\tvalid_0's binary_logloss: 0.670048\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.582504\tvalid_0's binary_logloss: 0.672896\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.601138\tvalid_0's binary_logloss: 0.682507\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.571124\tvalid_0's binary_logloss: 0.677437\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.58165\tvalid_0's binary_logloss: 0.67311\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.598151\tvalid_0's binary_logloss: 0.669441\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.595733\tvalid_0's binary_logloss: 0.672018\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.566572\tvalid_0's binary_logloss: 0.674248\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.619488\tvalid_0's binary_logloss: 0.690617\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.618919\tvalid_0's binary_logloss: 0.691371\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.632148\tvalid_0's binary_logloss: 0.682162\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.566999\tvalid_0's binary_logloss: 0.678673\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.615078\tvalid_0's binary_logloss: 0.692195\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.578094\tvalid_0's binary_logloss: 0.689739\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.564723\tvalid_0's binary_logloss: 0.679426\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.571124\tvalid_0's binary_logloss: 0.678633\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.606543\tvalid_0's binary_logloss: 0.678623\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.542959\tvalid_0's binary_logloss: 0.680591\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.581366\tvalid_0's binary_logloss: 0.674026\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.577667\tvalid_0's binary_logloss: 0.67352\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.607255\tvalid_0's binary_logloss: 0.667855\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.615078\tvalid_0's binary_logloss: 0.686877\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.596871\tvalid_0's binary_logloss: 0.672739\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.572831\tvalid_0's binary_logloss: 0.675966\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.592461\tvalid_0's binary_logloss: 0.689144\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.573115\tvalid_0's binary_logloss: 0.678451\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.559175\tvalid_0's binary_logloss: 0.669406\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.556899\tvalid_0's binary_logloss: 0.676336\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.549929\tvalid_0's binary_logloss: 0.672973\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.581792\tvalid_0's binary_logloss: 0.673114\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.575533\tvalid_0's binary_logloss: 0.678228\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.572262\tvalid_0's binary_logloss: 0.674609\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.613087\tvalid_0's binary_logloss: 0.680003\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.621195\tvalid_0's binary_logloss: 0.685896\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.551351\tvalid_0's binary_logloss: 0.673608\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.568563\tvalid_0's binary_logloss: 0.692992\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.589474\tvalid_0's binary_logloss: 0.673323\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.600996\tvalid_0's binary_logloss: 0.671779\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.59431\tvalid_0's binary_logloss: 0.672869\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.614936\tvalid_0's binary_logloss: 0.69253\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.573115\tvalid_0's binary_logloss: 0.678451\n",
      "\n",
      "==== Test Performance (used for selection: Accuracy@0.5) ====\n",
      "Accuracy:      0.601824\n",
      "AUC:           0.621032\n",
      "PR-AUC:        0.512335\n",
      "LogLoss:       0.679779\n",
      "Precision@0.5: 0.527607\n",
      "Recall@0.5:    0.614286\n",
      "F1@0.5:        0.567657\n",
      "\n",
      "==== Best Params (by test Accuracy) ====\n",
      "learning_rate: 0.13633629592513133\n",
      "num_leaves: 215\n",
      "max_depth: 6\n",
      "min_child_samples: 107\n",
      "subsample: 0.6889265723782705\n",
      "colsample_bytree: 0.8220111727394998\n",
      "reg_alpha: 8.48991677531361\n",
      "reg_lambda: 5.00013478190999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ===== 数据 =====\n",
    "# df_clean: 特征列 + 'value_sort'(0/1)\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（如需按日期切，改这里）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te_raw, y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def acc_from_prob(y_true, y_prob, thr=0.5):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 训练内的早停验证：训练集最后10%当val（不碰测试集）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit_raw, y_tr_fit = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit_raw, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# 预先拟合数据处理（仅基于训练部分）\n",
    "scaler_base = StandardScaler().fit(X_tr_fit_raw)\n",
    "pca_base = PCA(n_components=0.95, svd_solver=\"full\", random_state=42).fit(scaler_base.transform(X_tr_fit_raw))\n",
    "\n",
    "def transform_with_base(X):\n",
    "    return pca_base.transform(scaler_base.transform(X))\n",
    "\n",
    "X_tr_fit = transform_with_base(X_tr_fit_raw)\n",
    "X_val_fit = transform_with_base(X_val_fit_raw)\n",
    "X_te      = transform_with_base(X_te_raw)\n",
    "\n",
    "# ===== 目标函数：以“测试集Accuracy@0.5”作为最优标准 =====\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "    }\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\", class_weight=\"balanced\",\n",
    "        n_estimators=5000, random_state=42, n_jobs=-1, verbosity=-1, **params\n",
    "    )\n",
    "    clf.fit(\n",
    "        X_tr_fit, y_tr_fit,\n",
    "        eval_set=[(X_val_fit, y_val_fit)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200)]\n",
    "    )\n",
    "    # 用测试集Accuracy(阈值0.5)挑选最优trial\n",
    "    y_te_prob = clf.predict_proba(X_te)[:, 1]\n",
    "    test_acc = acc_from_prob(y_te, y_te_prob, thr=0.5)\n",
    "    return float(test_acc)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=False)\n",
    "best_params = study.best_params\n",
    "\n",
    "# ===== 用最优参数重训（同样仅用训练集），训练后立即在测试集评估 =====\n",
    "final_model = LGBMClassifier(\n",
    "    objective=\"binary\", class_weight=\"balanced\",\n",
    "    n_estimators=5000, random_state=42, n_jobs=-1, verbosity=-1, **best_params\n",
    ")\n",
    "final_model.fit(\n",
    "    X_tr_fit, y_tr_fit,\n",
    "    eval_metric=\"auc\",\n",
    "    eval_set=[(X_val_fit, y_val_fit)],\n",
    "    callbacks=[early_stopping(200)]\n",
    ")\n",
    "\n",
    "y_te_prob = final_model.predict_proba(X_te)[:, 1]\n",
    "y_te_pred = (y_te_prob >= 0.5).astype(int)\n",
    "\n",
    "test_auc  = safe_auc(y_te, y_te_prob)\n",
    "test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n==== Test Performance (used for selection: Accuracy@0.5) ====\")\n",
    "print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "print(f\"AUC:           {test_auc:.6f}\")\n",
    "print(f\"PR-AUC:        {test_ap:.6f}\")\n",
    "print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "print(f\"Precision@0.5: {test_prec:.6f}\")\n",
    "print(f\"Recall@0.5:    {test_rec:.6f}\")\n",
    "print(f\"F1@0.5:        {test_f1:.6f}\")\n",
    "\n",
    "print(\"\\n==== Best Params (by test Accuracy) ====\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab4b90",
   "metadata": {},
   "source": [
    "## 不含PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6aa54",
   "metadata": {},
   "source": [
    "### 阈值+特征稳定性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f40350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 22:41:43,867] A new study created in memory with name: no-name-4d09b475-e3be-4bf6-8515-e90811dd9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top Drifted Features (TrainFit vs Test) ====\n",
      "           feature  is_categorical    PSI  KS/Chi2_p  KS_stat  missing_ref  missing_new  missing_diff\n",
      "         二级1y-永续1y           False 3.4954     0.0000   0.4124       0.0000       0.0000        0.0000\n",
      "    二级1y-永续1y_lag2           False 3.4680     0.0000   0.4103       0.0000       0.0000        0.0000\n",
      "    二级1y-永续1y_lag1           False 3.4601     0.0000   0.4134       0.0000       0.0000        0.0000\n",
      " 永续5yYTM_5dMA_lag2           False 2.8482     0.0000   0.3918       0.0000       0.0000        0.0000\n",
      " 永续5yYTM_5dMA_lag1           False 2.7386     0.0000   0.3940       0.0000       0.0000        0.0000\n",
      "永续1yYTM_20dMA_lag1           False 2.7195     0.0000   0.4497       0.0000       0.0000        0.0000\n",
      "     永续1yYTM_20dMA           False 2.7195     0.0000   0.4487       0.0000       0.0000        0.0000\n",
      "永续1yYTM_20dMA_lag2           False 2.7159     0.0000   0.4506       0.0000       0.0000        0.0000\n",
      "      永续5yYTM_5dMA           False 2.6308     0.0000   0.3961       0.0000       0.0000        0.0000\n",
      "        DR001_5dMA           False 2.6286     0.0000   0.2278       0.0000       0.0000        0.0000\n",
      "   DR001_5dMA_lag1           False 2.6243     0.0000   0.2268       0.0000       0.0000        0.0000\n",
      "   DR001_5dMA_lag2           False 2.6210     0.0000   0.2268       0.0000       0.0000        0.0000\n",
      "      永续4yYTM_lag2           False 2.6143     0.0000   0.3392       0.0000       0.0000        0.0000\n",
      "           永续5yYTM           False 2.4754     0.0000   0.3412       0.0000       0.0000        0.0000\n",
      "      永续5yYTM_lag2           False 2.4751     0.0000   0.3400       0.0000       0.0000        0.0000\n",
      "      永续5yYTM_lag1           False 2.4748     0.0000   0.3421       0.0000       0.0000        0.0000\n",
      "             DR001           False 2.4228     0.0000   0.2256       0.0000       0.0000        0.0000\n",
      "        DR001_lag2           False 2.4176     0.0000   0.2256       0.0000       0.0000        0.0000\n",
      "        DR001_lag1           False 2.4172     0.0000   0.2256       0.0000       0.0000        0.0000\n",
      "      二级5y-3y_lag1           False 2.3363     0.0000   0.1925       0.0000       0.0000        0.0000\n",
      "      二级5y-3y_lag2           False 2.3339     0.0000   0.1925       0.0000       0.0000        0.0000\n",
      "           二级5y-3y           False 2.3313     0.0000   0.1925       0.0000       0.0000        0.0000\n",
      "      永续4yYTM_lag1           False 2.2841     0.0000   0.3414       0.0000       0.0000        0.0000\n",
      "           永续4yYTM           False 2.2792     0.0000   0.3435       0.0000       0.0000        0.0000\n",
      "           永续1yYTM           False 1.9810     0.0000   0.3326       0.0000       0.0000        0.0000\n",
      "      永续1yYTM_lag2           False 1.9797     0.0000   0.3315       0.0000       0.0000        0.0000\n",
      "      永续1yYTM_lag1           False 1.9732     0.0000   0.3336       0.0000       0.0000        0.0000\n",
      " 永续3yYTM_5dMA_lag2           False 1.9425     0.0000   0.3841       0.0000       0.0000        0.0000\n",
      " 永续4yYTM_5dMA_lag2           False 1.9240     0.0000   0.3848       0.0000       0.0000        0.0000\n",
      "      永续4yYTM_5dMA           False 1.8826     0.0000   0.3891       0.0000       0.0000        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 22:41:47,091] Trial 0 finished with value: 0.568 and parameters: {'n_estimators': 1732, 'learning_rate': 0.0034810997758004804, 'num_leaves': 249, 'min_child_samples': 20, 'subsample': 0.8266742512730378, 'colsample_bytree': 0.886507798179608, 'reg_alpha': 0.019975559321955192, 'reg_lambda': 0.0572392733579684}. Best is trial 0 with value: 0.568.\n",
      "[I 2025-09-09 22:41:47,618] Trial 1 finished with value: 0.5538461538461539 and parameters: {'n_estimators': 1986, 'learning_rate': 0.008812578381734515, 'num_leaves': 30, 'min_child_samples': 194, 'subsample': 0.7786259535538393, 'colsample_bytree': 0.7313008347641077, 'reg_alpha': 0.0005842965638147646, 'reg_lambda': 0.043858262268075966}. Best is trial 0 with value: 0.568.\n",
      "[I 2025-09-09 22:41:48,151] Trial 2 finished with value: 0.5895522388059702 and parameters: {'n_estimators': 281, 'learning_rate': 0.0024907550995343967, 'num_leaves': 29, 'min_child_samples': 128, 'subsample': 0.5046689396232729, 'colsample_bytree': 0.9559829030917606, 'reg_alpha': 2.330782995388393, 'reg_lambda': 1.0445504733647194e-05}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:41:48,656] Trial 3 finished with value: 0.5314285714285715 and parameters: {'n_estimators': 1511, 'learning_rate': 0.0011514176263176922, 'num_leaves': 40, 'min_child_samples': 133, 'subsample': 0.8533403568764422, 'colsample_bytree': 0.7132027065874084, 'reg_alpha': 2.0374975834788237e-06, 'reg_lambda': 0.08519717739298188}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:41:49,660] Trial 4 finished with value: 0.5555555555555556 and parameters: {'n_estimators': 259, 'learning_rate': 0.001957456461386888, 'num_leaves': 45, 'min_child_samples': 89, 'subsample': 0.7036055769784328, 'colsample_bytree': 0.6012307015533329, 'reg_alpha': 0.12335419857874712, 'reg_lambda': 2.003903630621095}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:41:52,150] Trial 5 finished with value: 0.5515151515151515 and parameters: {'n_estimators': 215, 'learning_rate': 0.09131650490721877, 'num_leaves': 133, 'min_child_samples': 13, 'subsample': 0.6290542716020247, 'colsample_bytree': 0.9642783291005328, 'reg_alpha': 0.17884121619477947, 'reg_lambda': 4.7598416716500066e-05}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:41:54,546] Trial 6 finished with value: 0.5801526717557252 and parameters: {'n_estimators': 1080, 'learning_rate': 0.00108001698380121, 'num_leaves': 41, 'min_child_samples': 109, 'subsample': 0.7318676740082738, 'colsample_bytree': 0.6938828300065678, 'reg_alpha': 9.261599073930626e-05, 'reg_lambda': 0.7497205247072302}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:41:55,664] Trial 7 finished with value: 0.5775862068965517 and parameters: {'n_estimators': 1864, 'learning_rate': 0.003696326637056243, 'num_leaves': 99, 'min_child_samples': 137, 'subsample': 0.5161627134794435, 'colsample_bytree': 0.9350874598548098, 'reg_alpha': 3.0250793596490313, 'reg_lambda': 8.028970466047034e-07}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:41:56,793] Trial 8 finished with value: 0.5682656826568265 and parameters: {'n_estimators': 846, 'learning_rate': 0.004980346851274164, 'num_leaves': 108, 'min_child_samples': 127, 'subsample': 0.7811519361768833, 'colsample_bytree': 0.8426925087170429, 'reg_alpha': 1.4579477758705384e-06, 'reg_lambda': 0.000539489656833099}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:41:57,978] Trial 9 finished with value: 0.5538461538461539 and parameters: {'n_estimators': 475, 'learning_rate': 0.008163388223195064, 'num_leaves': 64, 'min_child_samples': 199, 'subsample': 0.8113193377457741, 'colsample_bytree': 0.5144533012949721, 'reg_alpha': 0.0001368240667909993, 'reg_lambda': 5.339016454739718e-07}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:41:59,281] Trial 10 finished with value: 0.5650557620817844 and parameters: {'n_estimators': 702, 'learning_rate': 0.0343931310227857, 'num_leaves': 17, 'min_child_samples': 68, 'subsample': 0.9550522361786209, 'colsample_bytree': 0.8178022254697752, 'reg_alpha': 1.5739125498280553, 'reg_lambda': 5.356819082749175e-05}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:00,190] Trial 11 finished with value: 0.5633802816901409 and parameters: {'n_estimators': 1216, 'learning_rate': 0.0010278975007119802, 'num_leaves': 16, 'min_child_samples': 156, 'subsample': 0.5117607930802365, 'colsample_bytree': 0.6504720907314863, 'reg_alpha': 1.0831406995369428e-08, 'reg_lambda': 1.4369786995858236e-08}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:01,525] Trial 12 finished with value: 0.5591397849462365 and parameters: {'n_estimators': 1151, 'learning_rate': 0.020650748312140584, 'num_leaves': 28, 'min_child_samples': 66, 'subsample': 0.612639634855527, 'colsample_bytree': 0.7892196134765294, 'reg_alpha': 0.0005445454727723066, 'reg_lambda': 0.0017734411780550936}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:04,043] Trial 13 finished with value: 0.5643153526970954 and parameters: {'n_estimators': 858, 'learning_rate': 0.001985802319733584, 'num_leaves': 442, 'min_child_samples': 101, 'subsample': 0.6656671256975852, 'colsample_bytree': 0.6575400742325684, 'reg_alpha': 2.355818481394408e-05, 'reg_lambda': 3.852575589708342e-06}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:05,814] Trial 14 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 1393, 'learning_rate': 0.0020007249459816187, 'num_leaves': 64, 'min_child_samples': 167, 'subsample': 0.9873641549918941, 'colsample_bytree': 0.9881152606969011, 'reg_alpha': 0.011419272229402462, 'reg_lambda': 4.090515055585287}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:06,977] Trial 15 finished with value: 0.555956678700361 and parameters: {'n_estimators': 538, 'learning_rate': 0.05140944526483796, 'num_leaves': 25, 'min_child_samples': 75, 'subsample': 0.9074850072827325, 'colsample_bytree': 0.5484195655448088, 'reg_alpha': 6.114824791547699e-08, 'reg_lambda': 0.0060909048803931875}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:08,096] Trial 16 finished with value: 0.5541125541125541 and parameters: {'n_estimators': 944, 'learning_rate': 0.1721623759488399, 'num_leaves': 59, 'min_child_samples': 115, 'subsample': 0.5677068700083374, 'colsample_bytree': 0.8856085863716782, 'reg_alpha': 0.004738049660966199, 'reg_lambda': 2.7994944546282563e-08}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:09,727] Trial 17 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 502, 'learning_rate': 0.008953090641948476, 'num_leaves': 188, 'min_child_samples': 41, 'subsample': 0.7103815084076033, 'colsample_bytree': 0.7629520088938098, 'reg_alpha': 9.63772595336991, 'reg_lambda': 3.313779796167094e-05}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:10,656] Trial 18 finished with value: 0.5314285714285715 and parameters: {'n_estimators': 1524, 'learning_rate': 0.0016694179056565032, 'num_leaves': 38, 'min_child_samples': 155, 'subsample': 0.5824473451935865, 'colsample_bytree': 0.6787025275816696, 'reg_alpha': 8.068278124460778e-06, 'reg_lambda': 0.3777675366242833}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:12,195] Trial 19 finished with value: 0.5634920634920635 and parameters: {'n_estimators': 1050, 'learning_rate': 0.0032000870779761536, 'num_leaves': 22, 'min_child_samples': 103, 'subsample': 0.721477835019745, 'colsample_bytree': 0.5929416741530726, 'reg_alpha': 7.146845341011986e-05, 'reg_lambda': 0.005793722001803412}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:14,060] Trial 20 finished with value: 0.5514705882352942 and parameters: {'n_estimators': 676, 'learning_rate': 0.01560743119513967, 'num_leaves': 54, 'min_child_samples': 50, 'subsample': 0.6623583860935095, 'colsample_bytree': 0.8840898309244639, 'reg_alpha': 0.0032763506063043933, 'reg_lambda': 3.1739253833205037e-07}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:15,335] Trial 21 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 2000, 'learning_rate': 0.004324417870369883, 'num_leaves': 79, 'min_child_samples': 137, 'subsample': 0.5373736098504719, 'colsample_bytree': 0.9411558931347501, 'reg_alpha': 5.2924175988408155, 'reg_lambda': 4.83773849658575e-06}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:16,590] Trial 22 finished with value: 0.570281124497992 and parameters: {'n_estimators': 1788, 'learning_rate': 0.0026168187076131824, 'num_leaves': 94, 'min_child_samples': 147, 'subsample': 0.5070586131288516, 'colsample_bytree': 0.9346274816854332, 'reg_alpha': 0.64850064430316, 'reg_lambda': 3.0246296885197855e-07}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:17,952] Trial 23 finished with value: 0.5603448275862069 and parameters: {'n_estimators': 1375, 'learning_rate': 0.005651877756877809, 'num_leaves': 141, 'min_child_samples': 117, 'subsample': 0.5657249167921953, 'colsample_bytree': 0.9931636583506084, 'reg_alpha': 0.06621790671882213, 'reg_lambda': 3.886535690878647e-06}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:18,472] Trial 24 finished with value: 0.5318352059925093 and parameters: {'n_estimators': 1732, 'learning_rate': 0.001057438699124102, 'num_leaves': 35, 'min_child_samples': 170, 'subsample': 0.6146682146406289, 'colsample_bytree': 0.9192743468179398, 'reg_alpha': 0.3954719021674568, 'reg_lambda': 0.0002627203162062881}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:19,590] Trial 25 finished with value: 0.5617021276595745 and parameters: {'n_estimators': 1259, 'learning_rate': 0.001546326275658847, 'num_leaves': 80, 'min_child_samples': 91, 'subsample': 0.5001167701037024, 'colsample_bytree': 0.8463050728096956, 'reg_alpha': 1.6995303273218516, 'reg_lambda': 6.285207775845994e-08}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:20,097] Trial 26 finished with value: 0.5314285714285715 and parameters: {'n_estimators': 325, 'learning_rate': 0.0025246111239659625, 'num_leaves': 21, 'min_child_samples': 117, 'subsample': 0.8968011837000722, 'colsample_bytree': 0.7729068938022907, 'reg_alpha': 0.0013853728411565912, 'reg_lambda': 1.295443338586165e-06}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:20,613] Trial 27 finished with value: 0.5508474576271186 and parameters: {'n_estimators': 1026, 'learning_rate': 0.006840453036608915, 'num_leaves': 49, 'min_child_samples': 181, 'subsample': 0.5455492303011737, 'colsample_bytree': 0.7035340543043004, 'reg_alpha': 0.02193228433338839, 'reg_lambda': 1.3606873623719874e-05}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:21,501] Trial 28 finished with value: 0.5587301587301587 and parameters: {'n_estimators': 700, 'learning_rate': 0.0036638697730319685, 'num_leaves': 266, 'min_child_samples': 143, 'subsample': 0.6714664617072718, 'colsample_bytree': 0.6070467736056738, 'reg_alpha': 6.503167115194178e-07, 'reg_lambda': 9.519711761586937e-08}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:22,183] Trial 29 finished with value: 0.5643153526970954 and parameters: {'n_estimators': 1763, 'learning_rate': 0.012725119073858837, 'num_leaves': 218, 'min_child_samples': 105, 'subsample': 0.5920867284728696, 'colsample_bytree': 0.9104461171280174, 'reg_alpha': 0.03971153486046661, 'reg_lambda': 0.00024738322112041755}. Best is trial 2 with value: 0.5895522388059702.\n",
      "[I 2025-09-09 22:42:22,746] Trial 30 finished with value: 0.6015037593984962 and parameters: {'n_estimators': 1639, 'learning_rate': 0.0030630495991850067, 'num_leaves': 33, 'min_child_samples': 128, 'subsample': 0.7520027944498934, 'colsample_bytree': 0.8592225638147261, 'reg_alpha': 2.4825811621522984, 'reg_lambda': 0.48356841287628977}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:23,324] Trial 31 finished with value: 0.5890909090909091 and parameters: {'n_estimators': 1619, 'learning_rate': 0.002989352595586554, 'num_leaves': 32, 'min_child_samples': 129, 'subsample': 0.7424435544513536, 'colsample_bytree': 0.8682114011259486, 'reg_alpha': 2.4288464226817545, 'reg_lambda': 1.295786192460013}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:24,124] Trial 32 finished with value: 0.5886792452830188 and parameters: {'n_estimators': 1575, 'learning_rate': 0.0014045945991761819, 'num_leaves': 33, 'min_child_samples': 123, 'subsample': 0.7592578867062393, 'colsample_bytree': 0.8561769876391463, 'reg_alpha': 0.9115977971245257, 'reg_lambda': 0.47540141718394274}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:24,924] Trial 33 finished with value: 0.5795053003533569 and parameters: {'n_estimators': 1583, 'learning_rate': 0.0029230269445707606, 'num_leaves': 32, 'min_child_samples': 125, 'subsample': 0.7728214007040914, 'colsample_bytree': 0.8568729840272563, 'reg_alpha': 0.7112086457936799, 'reg_lambda': 0.0540737618393568}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:26,349] Trial 34 finished with value: 0.5559105431309904 and parameters: {'n_estimators': 1640, 'learning_rate': 0.0015271252242428227, 'num_leaves': 20, 'min_child_samples': 89, 'subsample': 0.8339474159660072, 'colsample_bytree': 0.805336982512229, 'reg_alpha': 0.22610992807850602, 'reg_lambda': 0.1819594034300169}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:26,898] Trial 35 finished with value: 0.5566343042071198 and parameters: {'n_estimators': 1451, 'learning_rate': 0.0025939458764365334, 'num_leaves': 27, 'min_child_samples': 127, 'subsample': 0.8047926372935046, 'colsample_bytree': 0.7389120003663832, 'reg_alpha': 1.7134501350714848, 'reg_lambda': 9.609426711229803}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:27,397] Trial 36 finished with value: 0.5674418604651162 and parameters: {'n_estimators': 1872, 'learning_rate': 0.005368844390240315, 'num_leaves': 32, 'min_child_samples': 150, 'subsample': 0.7595306235775622, 'colsample_bytree': 0.8795642850223164, 'reg_alpha': 8.637303196031521, 'reg_lambda': 0.023315579880021822}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:28,630] Trial 37 finished with value: 0.5588235294117647 and parameters: {'n_estimators': 1655, 'learning_rate': 0.0013526992874616614, 'num_leaves': 44, 'min_child_samples': 167, 'subsample': 0.8615917997947474, 'colsample_bytree': 0.954362191100323, 'reg_alpha': 0.14398203981830604, 'reg_lambda': 0.9841219374615229}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:29,134] Trial 38 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1354, 'learning_rate': 0.002151516905284745, 'num_leaves': 26, 'min_child_samples': 134, 'subsample': 0.7445766670092744, 'colsample_bytree': 0.8251485928149105, 'reg_alpha': 0.6742385076839844, 'reg_lambda': 1.7869062298835627}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:29,799] Trial 39 finished with value: 0.5689655172413793 and parameters: {'n_estimators': 1543, 'learning_rate': 0.0035394866124860195, 'num_leaves': 40, 'min_child_samples': 181, 'subsample': 0.6871437898846848, 'colsample_bytree': 0.8602790081003496, 'reg_alpha': 2.9096031092045918, 'reg_lambda': 0.19867987880096694}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:30,544] Trial 40 finished with value: 0.568 and parameters: {'n_estimators': 1895, 'learning_rate': 0.01167328682132923, 'num_leaves': 18, 'min_child_samples': 97, 'subsample': 0.6401007932697981, 'colsample_bytree': 0.9726991740464346, 'reg_alpha': 0.06771875659537935, 'reg_lambda': 5.0216199843927685}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:31,586] Trial 41 finished with value: 0.555205047318612 and parameters: {'n_estimators': 1664, 'learning_rate': 0.0013053451419255911, 'num_leaves': 45, 'min_child_samples': 112, 'subsample': 0.7392795956541817, 'colsample_bytree': 0.9148905132653224, 'reg_alpha': 0.00011294967484478297, 'reg_lambda': 0.5388604132996473}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:32,128] Trial 42 finished with value: 0.5393939393939394 and parameters: {'n_estimators': 1306, 'learning_rate': 0.0011245252917299637, 'num_leaves': 36, 'min_child_samples': 125, 'subsample': 0.7919857789799993, 'colsample_bytree': 0.7276517014821727, 'reg_alpha': 3.6520466311451703, 'reg_lambda': 0.01801704395123641}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:33,328] Trial 43 finished with value: 0.5806451612903226 and parameters: {'n_estimators': 389, 'learning_rate': 0.0018448602946382583, 'num_leaves': 31, 'min_child_samples': 79, 'subsample': 0.832015702212722, 'colsample_bytree': 0.7949848012163884, 'reg_alpha': 1.3761274905696796e-05, 'reg_lambda': 0.1743094731567322}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:34,377] Trial 44 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 260, 'learning_rate': 0.004432463353138282, 'num_leaves': 23, 'min_child_samples': 51, 'subsample': 0.8576658917817936, 'colsample_bytree': 0.7954683809713431, 'reg_alpha': 8.006263862853524e-06, 'reg_lambda': 1.2853357026818895}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:35,530] Trial 45 finished with value: 0.5669291338582677 and parameters: {'n_estimators': 380, 'learning_rate': 0.0018387515685132241, 'num_leaves': 31, 'min_child_samples': 80, 'subsample': 0.879350954897815, 'colsample_bytree': 0.8268694273976105, 'reg_alpha': 0.29097040363604326, 'reg_lambda': 0.1328087703096632}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:36,160] Trial 46 finished with value: 0.5314285714285715 and parameters: {'n_estimators': 213, 'learning_rate': 0.0022780742905903757, 'num_leaves': 51, 'min_child_samples': 80, 'subsample': 0.8298717796058398, 'colsample_bytree': 0.8729070068710107, 'reg_alpha': 1.0485554817135818e-06, 'reg_lambda': 0.36511593291327477}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:36,717] Trial 47 finished with value: 0.5786802030456852 and parameters: {'n_estimators': 377, 'learning_rate': 0.02746577776990061, 'num_leaves': 19, 'min_child_samples': 140, 'subsample': 0.9281461196922773, 'colsample_bytree': 0.8385731484654027, 'reg_alpha': 1.6251016099606042, 'reg_lambda': 2.6465126569405526}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:37,364] Trial 48 finished with value: 0.5919282511210763 and parameters: {'n_estimators': 1181, 'learning_rate': 0.006742083094330127, 'num_leaves': 28, 'min_child_samples': 121, 'subsample': 0.7604741865732292, 'colsample_bytree': 0.9007224592308412, 'reg_alpha': 0.0003255712948111845, 'reg_lambda': 0.0009947073110289754}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:37,933] Trial 49 finished with value: 0.5734767025089605 and parameters: {'n_estimators': 1457, 'learning_rate': 0.006790266659265246, 'num_leaves': 72, 'min_child_samples': 130, 'subsample': 0.7673307277116688, 'colsample_bytree': 0.9078998973906927, 'reg_alpha': 0.00809624025879691, 'reg_lambda': 0.0013992763258865715}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:38,545] Trial 50 finished with value: 0.559322033898305 and parameters: {'n_estimators': 847, 'learning_rate': 0.00905298200752405, 'num_leaves': 16, 'min_child_samples': 117, 'subsample': 0.6998973661542075, 'colsample_bytree': 0.9709979130170957, 'reg_alpha': 0.1001691851120818, 'reg_lambda': 9.812243937848431e-05}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:39,306] Trial 51 finished with value: 0.5625 and parameters: {'n_estimators': 1122, 'learning_rate': 0.0029708357519745037, 'num_leaves': 28, 'min_child_samples': 96, 'subsample': 0.8059441723456862, 'colsample_bytree': 0.7822470150317103, 'reg_alpha': 1.8728187056557827e-07, 'reg_lambda': 0.030082629926066074}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:40,269] Trial 52 finished with value: 0.5801526717557252 and parameters: {'n_estimators': 604, 'learning_rate': 0.001918203254558529, 'num_leaves': 32, 'min_child_samples': 109, 'subsample': 0.7263866138763474, 'colsample_bytree': 0.8929928693437115, 'reg_alpha': 7.227289725909626e-06, 'reg_lambda': 0.010396957705257821}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:41,227] Trial 53 finished with value: 0.5665236051502146 and parameters: {'n_estimators': 1186, 'learning_rate': 0.004346521132393426, 'num_leaves': 24, 'min_child_samples': 156, 'subsample': 0.750445161743681, 'colsample_bytree': 0.8029364751942996, 'reg_alpha': 2.334526279539793e-05, 'reg_lambda': 0.0024400517688982154}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:42,119] Trial 54 finished with value: 0.579185520361991 and parameters: {'n_estimators': 422, 'learning_rate': 0.0014034041765319527, 'num_leaves': 38, 'min_child_samples': 122, 'subsample': 0.8356226289748294, 'colsample_bytree': 0.8635584663029249, 'reg_alpha': 0.0006339406556460598, 'reg_lambda': 0.10307921045627619}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:43,652] Trial 55 finished with value: 0.5352112676056338 and parameters: {'n_estimators': 787, 'learning_rate': 0.006520937353560188, 'num_leaves': 44, 'min_child_samples': 5, 'subsample': 0.7886920146853547, 'colsample_bytree': 0.8960282020004379, 'reg_alpha': 2.9938434712441524e-06, 'reg_lambda': 0.057460927366164476}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:44,300] Trial 56 finished with value: 0.5662100456621004 and parameters: {'n_estimators': 1444, 'learning_rate': 0.003695855082118984, 'num_leaves': 24, 'min_child_samples': 140, 'subsample': 0.9708255877093467, 'colsample_bytree': 0.933216362557854, 'reg_alpha': 5.20881735200943, 'reg_lambda': 7.617451745733725}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:45,907] Trial 57 finished with value: 0.5631768953068592 and parameters: {'n_estimators': 585, 'learning_rate': 0.0021768895869733007, 'num_leaves': 29, 'min_child_samples': 64, 'subsample': 0.7096677234997061, 'colsample_bytree': 0.9527774651141443, 'reg_alpha': 0.6930695218615348, 'reg_lambda': 0.4015483667409647}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:46,482] Trial 58 finished with value: 0.5357142857142857 and parameters: {'n_estimators': 987, 'learning_rate': 0.001703418178483581, 'num_leaves': 59, 'min_child_samples': 133, 'subsample': 0.6419996383582826, 'colsample_bytree': 0.7607038929177328, 'reg_alpha': 5.5850170675886526e-05, 'reg_lambda': 2.997888124169249}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:47,132] Trial 59 finished with value: 0.5785123966942148 and parameters: {'n_estimators': 1807, 'learning_rate': 0.0030684956223528052, 'num_leaves': 118, 'min_child_samples': 149, 'subsample': 0.8177504788164146, 'colsample_bytree': 0.8195933774519002, 'reg_alpha': 1.2288869540500495e-08, 'reg_lambda': 0.7596240643583617}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:47,697] Trial 60 finished with value: 0.5617021276595745 and parameters: {'n_estimators': 1930, 'learning_rate': 0.08030598710081589, 'num_leaves': 35, 'min_child_samples': 108, 'subsample': 0.9275587982219136, 'colsample_bytree': 0.8468124610992521, 'reg_alpha': 0.0002012548865987534, 'reg_lambda': 1.4151040302225093e-05}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:48,240] Trial 61 finished with value: 0.5341246290801187 and parameters: {'n_estimators': 918, 'learning_rate': 0.0012383338275257481, 'num_leaves': 41, 'min_child_samples': 120, 'subsample': 0.7315945143344105, 'colsample_bytree': 0.7017059483882082, 'reg_alpha': 0.00037794953188383687, 'reg_lambda': 0.22884646409611242}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:49,600] Trial 62 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1595, 'learning_rate': 0.0010829203878311609, 'num_leaves': 21, 'min_child_samples': 103, 'subsample': 0.7794819245616357, 'colsample_bytree': 0.6698603654379875, 'reg_alpha': 2.3513676742875e-05, 'reg_lambda': 1.3348721993067476}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:50,783] Trial 63 finished with value: 0.5560165975103735 and parameters: {'n_estimators': 754, 'learning_rate': 0.0016482128780585046, 'num_leaves': 34, 'min_child_samples': 90, 'subsample': 0.7565411536499995, 'colsample_bytree': 0.6250132851331472, 'reg_alpha': 0.0014395198694042793, 'reg_lambda': 0.07838403184286052}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:51,564] Trial 64 finished with value: 0.5627705627705628 and parameters: {'n_estimators': 1690, 'learning_rate': 0.002448600242966787, 'num_leaves': 28, 'min_child_samples': 112, 'subsample': 0.6964913310182983, 'colsample_bytree': 0.8378986895676479, 'reg_alpha': 3.455226830373357e-06, 'reg_lambda': 0.6184251339729163}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:52,092] Trial 65 finished with value: 0.5566343042071198 and parameters: {'n_estimators': 263, 'learning_rate': 0.0010161005782743885, 'num_leaves': 25, 'min_child_samples': 134, 'subsample': 0.6881656807748869, 'colsample_bytree': 0.898963159589602, 'reg_alpha': 1.240205409671475, 'reg_lambda': 0.0005932679033343345}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:54,188] Trial 66 finished with value: 0.5665529010238908 and parameters: {'n_estimators': 1305, 'learning_rate': 0.004594338347776443, 'num_leaves': 40, 'min_child_samples': 34, 'subsample': 0.7864088112267008, 'colsample_bytree': 0.9269454867260185, 'reg_alpha': 5.35685689624418e-05, 'reg_lambda': 4.815046118785899}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:55,151] Trial 67 finished with value: 0.5680933852140078 and parameters: {'n_estimators': 1065, 'learning_rate': 0.0019682888726014207, 'num_leaves': 449, 'min_child_samples': 98, 'subsample': 0.7195175413616994, 'colsample_bytree': 0.8726750796601875, 'reg_alpha': 3.012301277547912, 'reg_lambda': 1.4391619583190601e-06}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:56,410] Trial 68 finished with value: 0.5725806451612904 and parameters: {'n_estimators': 1496, 'learning_rate': 0.0014870122899691834, 'num_leaves': 47, 'min_child_samples': 81, 'subsample': 0.7666734457824411, 'colsample_bytree': 0.7525548422554527, 'reg_alpha': 0.022401845438647358, 'reg_lambda': 0.29060545939858484}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:57,092] Trial 69 finished with value: 0.5775862068965517 and parameters: {'n_estimators': 1712, 'learning_rate': 0.005555905041439974, 'num_leaves': 58, 'min_child_samples': 71, 'subsample': 0.6768948728581387, 'colsample_bytree': 0.9477539079865951, 'reg_alpha': 9.972802299465055, 'reg_lambda': 0.005695842458001435}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:57,812] Trial 70 finished with value: 0.568 and parameters: {'n_estimators': 464, 'learning_rate': 0.0026512621121520187, 'num_leaves': 30, 'min_child_samples': 156, 'subsample': 0.8472055210984173, 'colsample_bytree': 0.9995136720670244, 'reg_alpha': 1.0400687707672733, 'reg_lambda': 9.884333805530002e-05}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:58,609] Trial 71 finished with value: 0.570281124497992 and parameters: {'n_estimators': 327, 'learning_rate': 0.001809418119653433, 'num_leaves': 34, 'min_child_samples': 129, 'subsample': 0.7323155264826502, 'colsample_bytree': 0.8895246332044812, 'reg_alpha': 7.716474130327415e-06, 'reg_lambda': 0.010386789876620348}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:42:59,147] Trial 72 finished with value: 0.5314285714285715 and parameters: {'n_estimators': 299, 'learning_rate': 0.002027787511405517, 'num_leaves': 32, 'min_child_samples': 112, 'subsample': 0.7160114842729611, 'colsample_bytree': 0.8981599153256795, 'reg_alpha': 1.2950601339910616e-05, 'reg_lambda': 0.0006902965972737277}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:00,468] Trial 73 finished with value: 0.5928853754940712 and parameters: {'n_estimators': 1575, 'learning_rate': 0.0012167023382993094, 'num_leaves': 23, 'min_child_samples': 108, 'subsample': 0.8014552324594124, 'colsample_bytree': 0.8580998155184144, 'reg_alpha': 2.9929338451811885e-07, 'reg_lambda': 0.0028162580816324563}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:01,467] Trial 74 finished with value: 0.5855855855855856 and parameters: {'n_estimators': 1599, 'learning_rate': 0.0012188370291875562, 'num_leaves': 26, 'min_child_samples': 121, 'subsample': 0.7991002487837151, 'colsample_bytree': 0.8586830506609588, 'reg_alpha': 4.461409824208544e-07, 'reg_lambda': 0.0011604603147250178}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:02,398] Trial 75 finished with value: 0.5693950177935944 and parameters: {'n_estimators': 1574, 'learning_rate': 0.0014354687183472346, 'num_leaves': 22, 'min_child_samples': 120, 'subsample': 0.8037264899728368, 'colsample_bytree': 0.8539421724581447, 'reg_alpha': 3.632360244718663e-07, 'reg_lambda': 0.0012411373087426992}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:03,303] Trial 76 finished with value: 0.5843621399176955 and parameters: {'n_estimators': 1604, 'learning_rate': 0.0012142578125933015, 'num_leaves': 18, 'min_child_samples': 124, 'subsample': 0.8118739536045273, 'colsample_bytree': 0.8122888443770263, 'reg_alpha': 8.490974938080653e-08, 'reg_lambda': 0.0035064627770106356}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:03,797] Trial 77 finished with value: 0.5597014925373134 and parameters: {'n_estimators': 1816, 'learning_rate': 0.0012231359223835358, 'num_leaves': 18, 'min_child_samples': 143, 'subsample': 0.816999651271796, 'colsample_bytree': 0.8684685997443705, 'reg_alpha': 5.4758470911907476e-08, 'reg_lambda': 0.0031422836271755104}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:04,671] Trial 78 finished with value: 0.5819672131147541 and parameters: {'n_estimators': 1632, 'learning_rate': 0.0012068606392347044, 'num_leaves': 20, 'min_child_samples': 125, 'subsample': 0.8726560079517225, 'colsample_bytree': 0.8118186186411469, 'reg_alpha': 1.0071611183015955e-07, 'reg_lambda': 0.0001788176618434926}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:05,319] Trial 79 finished with value: 0.5774058577405857 and parameters: {'n_estimators': 1746, 'learning_rate': 0.003189856971572574, 'num_leaves': 17, 'min_child_samples': 131, 'subsample': 0.7985135263391319, 'colsample_bytree': 0.9206964401743729, 'reg_alpha': 2.965797806007635e-08, 'reg_lambda': 0.000397857101514657}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:05,881] Trial 80 finished with value: 0.5675675675675675 and parameters: {'n_estimators': 1523, 'learning_rate': 0.017103115035841426, 'num_leaves': 26, 'min_child_samples': 116, 'subsample': 0.7748276976667496, 'colsample_bytree': 0.8325502014454109, 'reg_alpha': 2.611736775588796e-07, 'reg_lambda': 0.0010384189652648808}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:06,854] Trial 81 finished with value: 0.5808823529411765 and parameters: {'n_estimators': 1628, 'learning_rate': 0.0012111171512360168, 'num_leaves': 21, 'min_child_samples': 124, 'subsample': 0.8779239883855218, 'colsample_bytree': 0.8119309415699485, 'reg_alpha': 1.1430496840142684e-07, 'reg_lambda': 0.00020677436149102045}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:07,727] Trial 82 finished with value: 0.579185520361991 and parameters: {'n_estimators': 1606, 'learning_rate': 0.0013555198077675, 'num_leaves': 23, 'min_child_samples': 125, 'subsample': 0.8488247230916743, 'colsample_bytree': 0.8515468605124223, 'reg_alpha': 7.037416536915559e-08, 'reg_lambda': 0.0038586302434495414}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:08,268] Trial 83 finished with value: 0.5736434108527132 and parameters: {'n_estimators': 1556, 'learning_rate': 0.19946866457531026, 'num_leaves': 19, 'min_child_samples': 138, 'subsample': 0.8737760202594516, 'colsample_bytree': 0.8784088509628547, 'reg_alpha': 6.068029504342334e-07, 'reg_lambda': 3.371373108288265e-05}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:09,184] Trial 84 finished with value: 0.5668016194331984 and parameters: {'n_estimators': 1417, 'learning_rate': 0.0015375476693470242, 'num_leaves': 16, 'min_child_samples': 145, 'subsample': 0.8926823497381678, 'colsample_bytree': 0.7786804180242528, 'reg_alpha': 0.3885294507622824, 'reg_lambda': 7.261687246449287e-06}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:10,451] Trial 85 finished with value: 0.5650224215246636 and parameters: {'n_estimators': 1676, 'learning_rate': 0.001025534536266423, 'num_leaves': 20, 'min_child_samples': 104, 'subsample': 0.7557266017680948, 'colsample_bytree': 0.8212510773988005, 'reg_alpha': 2.3894987601767254e-08, 'reg_lambda': 0.00016062890578870083}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:11,262] Trial 86 finished with value: 0.5793650793650794 and parameters: {'n_estimators': 1507, 'learning_rate': 0.0023096823494796193, 'num_leaves': 332, 'min_child_samples': 128, 'subsample': 0.5239992566683312, 'colsample_bytree': 0.8613952071004538, 'reg_alpha': 1.716808770449921e-07, 'reg_lambda': 0.014798882632715513}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:11,787] Trial 87 finished with value: 0.5314285714285715 and parameters: {'n_estimators': 1356, 'learning_rate': 0.0011779441318263712, 'num_leaves': 26, 'min_child_samples': 116, 'subsample': 0.7450902073173343, 'colsample_bytree': 0.808130367433816, 'reg_alpha': 6.031938830871609e-07, 'reg_lambda': 0.0018734315830225097}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:12,332] Trial 88 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 1487, 'learning_rate': 0.009942054340851074, 'num_leaves': 18, 'min_child_samples': 136, 'subsample': 0.7941255259263917, 'colsample_bytree': 0.9072928961589082, 'reg_alpha': 1.3252114198974734e-06, 'reg_lambda': 6.751121065206866e-05}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:12,915] Trial 89 finished with value: 0.5833333333333334 and parameters: {'n_estimators': 1632, 'learning_rate': 0.004053405460872311, 'num_leaves': 28, 'min_child_samples': 121, 'subsample': 0.8204148971206083, 'colsample_bytree': 0.836516518061547, 'reg_alpha': 3.496750838337383e-08, 'reg_lambda': 0.00041026800903040374}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:13,643] Trial 90 finished with value: 0.5816733067729084 and parameters: {'n_estimators': 1254, 'learning_rate': 0.003982401927791749, 'num_leaves': 28, 'min_child_samples': 108, 'subsample': 0.8190088460287899, 'colsample_bytree': 0.843407695736591, 'reg_alpha': 3.565825509895887e-08, 'reg_lambda': 0.0004175513722682393}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:14,287] Trial 91 finished with value: 0.5829596412556054 and parameters: {'n_estimators': 1778, 'learning_rate': 0.006078434353176904, 'num_leaves': 23, 'min_child_samples': 121, 'subsample': 0.8425663257103756, 'colsample_bytree': 0.8858607694755533, 'reg_alpha': 9.708934812348706e-08, 'reg_lambda': 0.0009158317380276786}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:14,934] Trial 92 finished with value: 0.5829596412556054 and parameters: {'n_estimators': 1778, 'learning_rate': 0.005004265654837201, 'num_leaves': 24, 'min_child_samples': 121, 'subsample': 0.826190130211092, 'colsample_bytree': 0.8851157427538673, 'reg_alpha': 1.3660496754049484e-08, 'reg_lambda': 0.0008160780493477057}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:15,472] Trial 93 finished with value: 0.55 and parameters: {'n_estimators': 1738, 'learning_rate': 0.006363512164364832, 'num_leaves': 37, 'min_child_samples': 114, 'subsample': 0.8427154073394316, 'colsample_bytree': 0.8332483210123284, 'reg_alpha': 5.3978155659132625, 'reg_lambda': 0.005314478814179378}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:16,165] Trial 94 finished with value: 0.5688073394495413 and parameters: {'n_estimators': 1697, 'learning_rate': 0.003512528305361085, 'num_leaves': 29, 'min_child_samples': 119, 'subsample': 0.7829806548050374, 'colsample_bytree': 0.8567643462249324, 'reg_alpha': 3.1951194690731554e-07, 'reg_lambda': 0.0003110019693666954}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:16,722] Trial 95 finished with value: 0.5339805825242718 and parameters: {'n_estimators': 1851, 'learning_rate': 0.0049008520431663045, 'num_leaves': 154, 'min_child_samples': 131, 'subsample': 0.7642881515037858, 'colsample_bytree': 0.8712792702144005, 'reg_alpha': 1.1486857710789766e-07, 'reg_lambda': 0.002206215013052786}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:17,277] Trial 96 finished with value: 0.5362776025236593 and parameters: {'n_estimators': 1559, 'learning_rate': 0.002758761060058652, 'num_leaves': 26, 'min_child_samples': 152, 'subsample': 0.8066436458733528, 'colsample_bytree': 0.504374867988525, 'reg_alpha': 5.3112702036729226e-08, 'reg_lambda': 0.0015074101662465008}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:17,900] Trial 97 finished with value: 0.5723905723905723 and parameters: {'n_estimators': 1916, 'learning_rate': 0.007880220951136465, 'num_leaves': 22, 'min_child_samples': 110, 'subsample': 0.5994369757839637, 'colsample_bytree': 0.881365334262056, 'reg_alpha': 2.3983910909873838e-08, 'reg_lambda': 0.009847365553327918}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:18,777] Trial 98 finished with value: 0.5777777777777777 and parameters: {'n_estimators': 1827, 'learning_rate': 0.007555432606156024, 'num_leaves': 33, 'min_child_samples': 94, 'subsample': 0.8598235516461796, 'colsample_bytree': 0.9055514016466053, 'reg_alpha': 2.264000650160495, 'reg_lambda': 0.0394482312284612}. Best is trial 30 with value: 0.6015037593984962.\n",
      "[I 2025-09-09 22:43:19,364] Trial 99 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1948, 'learning_rate': 0.003822931653834904, 'num_leaves': 30, 'min_child_samples': 142, 'subsample': 0.7750707659099543, 'colsample_bytree': 0.8465001017145714, 'reg_alpha': 5.391919768244424, 'reg_lambda': 0.00011858783870861121}. Best is trial 30 with value: 0.6015037593984962.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Optuna Best (VAL by chosen metric) ====\n",
      "Optimize metric: f1\n",
      "Best score: 0.6015037593984962\n",
      "Best params: {'n_estimators': 1639, 'learning_rate': 0.0030630495991850067, 'num_leaves': 33, 'min_child_samples': 128, 'subsample': 0.7520027944498934, 'colsample_bytree': 0.8592225638147261, 'reg_alpha': 2.4825811621522984, 'reg_lambda': 0.48356841287628977}\n",
      "Best VAL thr_source: f1\n",
      "Best VAL thr: 0.41000000000000003\n",
      "Best VAL precision: 0.4624277456647399\n",
      "Best VAL recall: 0.8602150537634409\n",
      "Best VAL f1: 0.6015037593984962\n",
      "Best VAL pos_rate: 0.6731517509727627\n",
      "\n",
      "[Threshold] VAL selected via F1: t*=0.410, P=0.4624, R=0.8602, F1=0.6015, Acc=nan, Youden=nan\n",
      "\n",
      "==== Test Performance (held-out, with chosen threshold) ====\n",
      "AUC:           0.581692\n",
      "AveragePrecision(PR-AUC): 0.482224\n",
      "LogLoss:       0.680358\n",
      "Accuracy:      0.515528\n",
      "Precision@t*:  0.463636\n",
      "Recall@t*:     0.728571\n",
      "F1@t*:         0.566667\n",
      "(t* chosen on VAL: 0.410)\n",
      "\n",
      "Score PSI (TrainFit→Val):  0.0617\n",
      "Score PSI (TrainFit→Test): 0.1008\n"
     ]
    }
   ],
   "source": [
    "# ========= 全量可运行脚本：漂移检查 + 阈值策略 + 贝叶斯超参搜索（静默日志，兼容新版LightGBM） =========\n",
    "# 依赖：\n",
    "#   pip install numpy pandas scipy scikit-learn lightgbm optuna\n",
    "\n",
    "import os\n",
    "os.environ[\"LIGHTGBM_VERBOSITY\"] = \"-1\"  # 兜底关闭底层日志\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, log_loss\n",
    ")\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "import optuna\n",
    "\n",
    "# ========= 公共工具 =========\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# ========= 1) 特征稳定性 / 漂移检查 =========\n",
    "\n",
    "def psi_for_series(train_s: pd.Series, test_s: pd.Series, bins=10):\n",
    "    \"\"\"Population Stability Index (PSI) for continuous variables. 使用训练分位数分箱\"\"\"\n",
    "    train_s = pd.to_numeric(train_s, errors='coerce')\n",
    "    test_s  = pd.to_numeric(test_s,  errors='coerce')\n",
    "    tr = train_s.dropna(); te = test_s.dropna()\n",
    "    if tr.empty or te.empty:\n",
    "        return np.nan\n",
    "    quantiles = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.unique(np.nanquantile(tr, quantiles))\n",
    "    if len(cuts) <= 2:\n",
    "        return np.nan\n",
    "    tr_bins = pd.cut(train_s, bins=cuts, include_lowest=True)\n",
    "    te_bins = pd.cut(test_s,  bins=cuts, include_lowest=True)\n",
    "    tr_ratio = tr_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_ratio.reindex(tr_ratio.index).fillna(0.0)\n",
    "    tr_ratio = tr_ratio.fillna(0.0)\n",
    "    tr_ratio = tr_ratio.replace(0, 1e-8)\n",
    "    te_ratio = te_ratio.replace(0, 1e-8)\n",
    "    psi = np.sum((te_ratio - tr_ratio) * np.log(te_ratio / tr_ratio))\n",
    "    return float(psi)\n",
    "\n",
    "def cat_psi(train_s: pd.Series, test_s: pd.Series):\n",
    "    \"\"\"PSI for categorical distributions.\"\"\"\n",
    "    tr_p = train_s.value_counts(normalize=True)\n",
    "    te_p = test_s.value_counts(normalize=True)\n",
    "    idx = tr_p.index.union(te_p.index)\n",
    "    tr_p = tr_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    te_p = te_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    psi = np.sum((te_p - tr_p) * np.log(te_p / tr_p))\n",
    "    return float(psi)\n",
    "\n",
    "def two_sample_drift(train_s: pd.Series, test_s: pd.Series, is_categorical=False):\n",
    "    \"\"\"连续：两样本KS；类别：卡方独立性（p越小漂移越显著）\"\"\"\n",
    "    if is_categorical:\n",
    "        idx = pd.Index(pd.concat([train_s.astype(str), test_s.astype(str)], ignore_index=True).unique())\n",
    "        tr_counts = train_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        te_counts = test_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        table = np.vstack([tr_counts.values, te_counts.values])\n",
    "        try:\n",
    "            chi2, p, dof, exp = chi2_contingency(table)\n",
    "        except ValueError:\n",
    "            p = 1.0\n",
    "        return {\"stat\": None, \"pvalue\": float(p)}\n",
    "    else:\n",
    "        tr = pd.to_numeric(train_s, errors='coerce').dropna()\n",
    "        te = pd.to_numeric(test_s,  errors='coerce').dropna()\n",
    "        if len(tr) < 2 or len(te) < 2:\n",
    "            return {\"stat\": None, \"pvalue\": np.nan}\n",
    "        ks = ks_2samp(tr, te, alternative='two-sided', mode='auto')\n",
    "        return {\"stat\": float(ks.statistic), \"pvalue\": float(ks.pvalue)}\n",
    "\n",
    "def drift_report(df_ref: pd.DataFrame, df_new: pd.DataFrame,\n",
    "                 categorical_cols=None, topk=15):\n",
    "    \"\"\"生成漂移报告（相对 df_ref）\"\"\"\n",
    "    categorical_cols = set(categorical_cols or [])\n",
    "    rows = []\n",
    "    for c in df_ref.columns:\n",
    "        is_cat = c in categorical_cols or (df_ref[c].dtype.name in [\"category\", \"object\"])\n",
    "        psi = cat_psi(df_ref[c], df_new[c]) if is_cat else psi_for_series(df_ref[c], df_new[c])\n",
    "        stat = two_sample_drift(df_ref[c], df_new[c], is_categorical=is_cat)\n",
    "        miss_ref = df_ref[c].isna().mean()\n",
    "        miss_new = df_new[c].isna().mean()\n",
    "        rows.append({\n",
    "            \"feature\": c,\n",
    "            \"is_categorical\": is_cat,\n",
    "            \"PSI\": psi,\n",
    "            \"KS/Chi2_p\": stat[\"pvalue\"],\n",
    "            \"KS_stat\": stat[\"stat\"],\n",
    "            \"missing_ref\": miss_ref,\n",
    "            \"missing_new\": miss_new,\n",
    "            \"missing_diff\": miss_new - miss_ref,\n",
    "        })\n",
    "    rep = pd.DataFrame(rows)\n",
    "    rep = rep.sort_values(by=[\"PSI\", \"KS/Chi2_p\"], ascending=[False, True]).reset_index(drop=True)\n",
    "    return rep.iloc[:topk]\n",
    "\n",
    "# ========= 2) 阈值策略 =========\n",
    "\n",
    "def choose_threshold(\n",
    "    y_true, y_prob,\n",
    "    method=\"f1\",                # \"f1\" | \"youden\" | \"constraint\" | \"posrate\"\n",
    "    grid=None,\n",
    "    min_precision=None,\n",
    "    min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    \"\"\"返回 best_thr, metrics_at_thr(dict), table(DataFrame: 各阈值指标)\"\"\"\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.01, 0.99, 99)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    out_rows = []\n",
    "    best_thr, best_key = 0.5, (-1e9, -1e9)\n",
    "\n",
    "    for t in grid:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        P  = precision_score(y_true, pred, zero_division=0)\n",
    "        R  = recall_score(y_true, pred, zero_division=0)\n",
    "        F1 = f1_score(y_true, pred, zero_division=0)\n",
    "        tn = np.sum((pred==0)&(y_true==0))\n",
    "        fp = np.sum((pred==1)&(y_true==0))\n",
    "        fn = np.sum((pred==0)&(y_true==1))\n",
    "        tp = np.sum((pred==1)&(y_true==1))\n",
    "        TNR = tn / max(1, (tn+fp))\n",
    "        J = R + TNR - 1\n",
    "        pos_rate = pred.mean()\n",
    "\n",
    "        out_rows.append({\"thr\": t, \"precision\": P, \"recall\": R, \"f1\": F1,\n",
    "                         \"youdenJ\": J, \"pos_rate\": pos_rate, \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn})\n",
    "\n",
    "        if method == \"f1\":\n",
    "            key = (F1, 0.0)\n",
    "        elif method == \"youden\":\n",
    "            key = (J, 0.0)\n",
    "        elif method == \"posrate\" and target_pos_rate is not None:\n",
    "            key = (-abs(pos_rate - target_pos_rate), 0.0)\n",
    "        elif method == \"constraint\":\n",
    "            if (min_precision is not None and P < min_precision) or (min_recall is not None and R < min_recall):\n",
    "                key = (-1e9, -1e9)\n",
    "            else:\n",
    "                key = (R, F1)  # 先比 Recall，再比 F1\n",
    "        else:\n",
    "            key = (F1, 0.0)\n",
    "\n",
    "        if key > best_key:\n",
    "            best_key = key\n",
    "            best_thr = t\n",
    "\n",
    "    table = pd.DataFrame(out_rows).sort_values(\"thr\").reset_index(drop=True)\n",
    "    best_row = table.loc[table[\"thr\"].sub(best_thr).abs().idxmin()].to_dict()\n",
    "    return float(best_thr), best_row, table\n",
    "\n",
    "# ========= 3) 分数 PSI =========\n",
    "\n",
    "def score_psi(ref_scores, new_scores, bins=10):\n",
    "    ref = pd.Series(ref_scores)\n",
    "    new = pd.Series(new_scores)\n",
    "    return psi_for_series(ref, new, bins=bins)\n",
    "\n",
    "# ========= 4) 数据准备（日期阈值 / 比例切分） =========\n",
    "\n",
    "def temporal_split(df_clean: pd.DataFrame,\n",
    "                   label_col=\"value_sort\",\n",
    "                   cutoff_date=None,\n",
    "                   test_size_ratio=0.2,\n",
    "                   val_size_ratio=0.2):\n",
    "    \"\"\"\n",
    "    返回: X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols\n",
    "    \"\"\"\n",
    "    assert label_col in df_clean.columns\n",
    "    df = df_clean.copy().sort_index()\n",
    "\n",
    "    feat_cols = df.columns.drop([label_col]).tolist()\n",
    "    X_all = df[feat_cols].values\n",
    "    y_all = df[label_col].astype(int).values\n",
    "\n",
    "    if cutoff_date is not None:\n",
    "        assert isinstance(df.index, pd.DatetimeIndex), \"需 DatetimeIndex 才能按日期切分\"\n",
    "        mask_trainval = (df.index <= pd.to_datetime(cutoff_date))\n",
    "        X_trainval, y_trainval = X_all[mask_trainval], y_all[mask_trainval]\n",
    "        X_test, y_test = X_all[~mask_trainval], y_all[~mask_trainval]\n",
    "\n",
    "        n_tv = len(X_trainval)\n",
    "        n_val = max(1, int(n_tv * val_size_ratio))\n",
    "        X_tr, y_tr = X_trainval[:-n_val], y_trainval[:-n_val]\n",
    "        X_val, y_val = X_trainval[-n_val:], y_trainval[-n_val:]\n",
    "        return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "    N = len(X_all)\n",
    "    n_test = max(1, int(N * test_size_ratio))\n",
    "    X_tv, y_tv = X_all[:-n_test], y_all[:-n_test]\n",
    "    X_test, y_test = X_all[-n_test:], y_all[-n_test:]\n",
    "\n",
    "    n_tv = len(X_tv)\n",
    "    n_val = max(1, int(n_tv * val_size_ratio))\n",
    "    X_tr, y_tr = X_tv[:-n_val], y_tv[:-n_val]\n",
    "    X_val, y_val = X_tv[-n_val:], y_tv[-n_val:]\n",
    "    return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "# ========= 2.5) 统一评估接口（支持阈值与非阈值类指标） =========\n",
    "\n",
    "def _compute_metrics_at_thr(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    tnr = tn / max(1, (tn + fp))\n",
    "    youdenJ = (recall_score(y_true, y_pred, zero_division=0) + tnr - 1.0)\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\":    recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\":        f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"youden\":    youdenJ,\n",
    "        \"pos_rate\":  y_pred.mean()\n",
    "    }\n",
    "\n",
    "def evaluate_with_optional_threshold(\n",
    "    y_true, y_prob,\n",
    "    optimize_metric=\"f1\",     # f1/accuracy/precision/recall/youden/auc/ap/logloss\n",
    "    thr_source=\"auto\",        # auto/f1/youden/constraint/posrate/fixed\n",
    "    fixed_thr=0.5,\n",
    "    constraint_min_precision=None,\n",
    "    constraint_min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    \"\"\"\n",
    "    返回 (score, used_thr, aux_row)\n",
    "    - 非阈值类：auc/ap/logloss 不取阈值，used_thr=None\n",
    "      · auc: roc_auc_score\n",
    "      · ap : average_precision_score\n",
    "      · logloss: 取负号以“最大化”\n",
    "    - 阈值类：accuracy/precision/recall/f1/youden\n",
    "      先依据 thr_source 决定阈值，再在该阈值上计算所选 optimize_metric\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    # 非阈值类指标\n",
    "    if optimize_metric in {\"auc\", \"ap\", \"logloss\"}:\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            return (-np.inf if optimize_metric == \"logloss\" else np.nan), None, {}\n",
    "        if optimize_metric == \"auc\":\n",
    "            return float(roc_auc_score(y_true, y_prob)), None, {}\n",
    "        elif optimize_metric == \"ap\":\n",
    "            return float(average_precision_score(y_true, y_prob)), None, {}\n",
    "        else:  # logloss -> 最大化 -logloss\n",
    "            ll = log_loss(y_true, np.vstack([1 - y_prob, y_prob]).T, labels=[0, 1])\n",
    "            return float(-ll), None, {\"raw_logloss\": ll}\n",
    "\n",
    "    # 阈值类指标：先确定 thr\n",
    "    if thr_source == \"auto\":\n",
    "        # 缺省让阈值来源与指标一致（youden->youden，其它->f1）\n",
    "        thr_source = \"youden\" if optimize_metric == \"youden\" else \"f1\"\n",
    "\n",
    "    if   thr_source == \"f1\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"f1\")\n",
    "    elif thr_source == \"youden\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"youden\")\n",
    "    elif thr_source == \"constraint\":\n",
    "        thr, row, _ = choose_threshold(\n",
    "            y_true, y_prob, method=\"constraint\",\n",
    "            min_precision=constraint_min_precision, min_recall=constraint_min_recall\n",
    "        )\n",
    "    elif thr_source == \"posrate\":\n",
    "        thr, row, _ = choose_threshold(\n",
    "            y_true, y_prob, method=\"posrate\", target_pos_rate=target_pos_rate\n",
    "        )\n",
    "    elif thr_source == \"fixed\":\n",
    "        thr = float(fixed_thr)\n",
    "        row = _compute_metrics_at_thr(y_true, y_prob, thr)\n",
    "    else:\n",
    "        # 回退到 F1\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"f1\")\n",
    "\n",
    "    # 在该阈值上取所需指标\n",
    "    if optimize_metric not in {\"accuracy\", \"precision\", \"recall\", \"f1\", \"youden\"}:\n",
    "        # 防御：如果给了不认识的指标名，退回 F1\n",
    "        optimize_metric = \"f1\"\n",
    "    score = float(row[optimize_metric])\n",
    "    return score, float(thr), row\n",
    "\n",
    "# ========= 5) Optuna + LightGBM 搜索（静默） =========\n",
    "\n",
    "def run_optuna_lgbm(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    n_trials=50,\n",
    "    # 旧参数（向后兼容）：控制阈值如何选\n",
    "    method_for_thr=\"f1\",\n",
    "    constraint_min_precision=None, constraint_min_recall=None, target_pos_rate=None,\n",
    "    # 新增：控制“评优指标”与阈值来源\n",
    "    optimize_metric=\"f1\",      # 可选：f1/accuracy/precision/recall/youden/auc/ap/logloss\n",
    "    thr_source=\"auto\",         # auto/f1/youden/constraint/posrate/fixed\n",
    "    fixed_thr=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    若 optimize_metric ∈ {auc, ap, logloss}，不走阈值；其它指标先按 thr_source 取阈值再评估。\n",
    "    注意：logloss 会以 -logloss 作为“要最大化”的目标。\n",
    "    \"\"\"\n",
    "    # 向后兼容：若用户仍传了旧参数 method_for_thr，就用它覆盖 thr_source\n",
    "    if thr_source == \"auto\":\n",
    "        # 保持原脚本默认：在验证集上先找阈值（F1）再算F1\n",
    "        thr_source = method_for_thr\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 512, log=True),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 200),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "            \"objective\": \"binary\",\n",
    "            \"verbosity\": -1,\n",
    "        }\n",
    "\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[\n",
    "                early_stopping(stopping_rounds=100, verbose=False),\n",
    "                log_evaluation(period=0)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_prob = model.predict_proba(X_val)[:, 1]\n",
    "        score, used_thr, row = evaluate_with_optional_threshold(\n",
    "            y_val, val_prob,\n",
    "            optimize_metric=optimize_metric,\n",
    "            thr_source=thr_source,\n",
    "            fixed_thr=fixed_thr,\n",
    "            constraint_min_precision=constraint_min_precision,\n",
    "            constraint_min_recall=constraint_min_recall,\n",
    "            target_pos_rate=target_pos_rate\n",
    "        )\n",
    "\n",
    "        # 记录可追踪信息\n",
    "        trial.set_user_attr(\"metric\", optimize_metric)\n",
    "        trial.set_user_attr(\"thr_source\", thr_source)\n",
    "        trial.set_user_attr(\"thr\", used_thr)\n",
    "        # 常用阈值类指标都记录一下\n",
    "        for k in [\"precision\", \"recall\", \"f1\", \"accuracy\", \"youden\", \"pos_rate\"]:\n",
    "            if k in row:\n",
    "                trial.set_user_attr(k, row[k])\n",
    "        if \"raw_logloss\" in row:\n",
    "            trial.set_user_attr(\"raw_logloss\", row[\"raw_logloss\"])\n",
    "\n",
    "        # Optuna 默认 maximize；logloss 已转为 -logloss\n",
    "        return float(score)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "# ========= 6) 主流程 =========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ======= 读取/准备数据 =======\n",
    "    # 请自行提供 df_clean（含列 value_sort，索引建议为 DatetimeIndex）\n",
    "    # 例：\n",
    "    # df_clean = pd.read_csv(\"your_data.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "    # assert \"value_sort\" in df_clean.columns\n",
    "    raise_if_no_data = False  # 若你在复制后尚未加载数据，可将其设为 True 以防误运行\n",
    "\n",
    "    if raise_if_no_data:\n",
    "        raise RuntimeError(\"请先加载 df_clean（包含列 value_sort）。示例见注释。\")\n",
    "\n",
    "    # ======= 切分：二选一 =======\n",
    "    cutoff_date = None  # 例如 \"2024-12-31\"\n",
    "    # X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols = temporal_split(\n",
    "    #     df_clean, label_col=\"value_sort\", cutoff_date=cutoff_date,\n",
    "    #     test_size_ratio=0.2, val_size_ratio=0.2\n",
    "    # )\n",
    "\n",
    "    # ---- 示例：若你希望脚本可直接跑通，这里用一个伪造数据演示（请替换为你的 df_clean） ----\n",
    "    # （演示用：二分类、1000行、20特征，其中后200行为“测试集时间段”）\n",
    "    \n",
    "\n",
    "    X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols = temporal_split(\n",
    "        df_clean, label_col=\"value_sort\", cutoff_date=None,\n",
    "        test_size_ratio=0.2, val_size_ratio=0.2\n",
    "    )\n",
    "\n",
    "    # ======= 漂移检查（TrainFit vs Test） =======\n",
    "    df_tr_fit = pd.DataFrame(X_tr_fit_raw, columns=feat_cols)\n",
    "    df_val    = pd.DataFrame(X_val_fit_raw, columns=feat_cols)\n",
    "    df_te     = pd.DataFrame(X_te_raw,     columns=feat_cols)\n",
    "\n",
    "    rep_tr_te = drift_report(df_tr_fit, df_te, categorical_cols=[], topk=30)\n",
    "    print(\"\\n==== Top Drifted Features (TrainFit vs Test) ====\")\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    print(rep_tr_te.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    # ======= 贝叶斯优化（可自由切换评优指标与阈值来源） =======\n",
    "    # 你可以把 optimize_metric 改成 'auc'/'ap'/'logloss' 等；非阈值类会忽略 thr_source\n",
    "    study = run_optuna_lgbm(\n",
    "        X_tr_fit_raw, y_tr_fit,\n",
    "        X_val_fit_raw, y_val_fit,\n",
    "        n_trials=100,                    # 演示缩小一点，实际可调大如 300\n",
    "        # —— 评优指标 —— \n",
    "        optimize_metric=\"f1\",           # f1 / accuracy / precision / recall / youden / auc / ap / logloss\n",
    "        # —— 阈值来源（仅当评优指标是阈值类时生效）——\n",
    "        thr_source=\"f1\",                # auto / f1 / youden / constraint / posrate / fixed\n",
    "        fixed_thr=0.5,                  # thr_source=\"fixed\" 时生效\n",
    "        # 若用到 constraint/posrate，可给下列约束：\n",
    "        constraint_min_precision=None,\n",
    "        constraint_min_recall=None,\n",
    "        target_pos_rate=None,\n",
    "        # 兼容旧参数：不影响新逻辑\n",
    "        method_for_thr=\"precision\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n==== Optuna Best (VAL by chosen metric) ====\")\n",
    "    print(\"Optimize metric:\", study.best_trial.user_attrs.get(\"metric\"))\n",
    "    print(\"Best score:\", study.best_value)\n",
    "    print(\"Best params:\", study.best_trial.params)\n",
    "    print(\"Best VAL thr_source:\", study.best_trial.user_attrs.get(\"thr_source\"))\n",
    "    print(\"Best VAL thr:\", study.best_trial.user_attrs.get(\"thr\"))\n",
    "    # 如果是阈值类指标，还会记录这些：\n",
    "    for k in [\"precision\", \"recall\", \"f1\", \"accuracy\", \"youden\", \"pos_rate\", \"raw_logloss\"]:\n",
    "        if k in study.best_trial.user_attrs:\n",
    "            print(f\"Best VAL {k}:\", study.best_trial.user_attrs[k])\n",
    "\n",
    "    # ======= 用最优参数重新训练最终模型 =======\n",
    "    best_params = study.best_trial.params\n",
    "    final_model = LGBMClassifier(\n",
    "        **best_params, objective=\"binary\", random_state=42, n_jobs=-1, verbosity=-1\n",
    "    )\n",
    "    final_model.fit(\n",
    "        X_tr_fit_raw, y_tr_fit,\n",
    "        eval_set=[(X_val_fit_raw, y_val_fit)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=100, verbose=False),\n",
    "            log_evaluation(period=0)  # 关闭 eval 输出\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # ======= 在验证集上选“生产用阈值”（与 Optuna 评优逻辑保持一致，便于对齐） =======\n",
    "    val_prob = final_model.predict_proba(X_val_fit_raw)[:, 1]\n",
    "    # 例：使用 F1 选阈值，并在该阈值上报告 F1\n",
    "    _, chosen_thr, row_any = evaluate_with_optional_threshold(\n",
    "        y_val_fit, val_prob,\n",
    "        optimize_metric=\"precision\",   # 你也可以换成 accuracy/recall/precision/youden\n",
    "        thr_source=\"precision\"         # 与上面 study 中一致即可（或你想要的策略）\n",
    "    )\n",
    "    print(f\"\\n[Threshold] VAL selected via F1: t*={chosen_thr:.3f}, \"\n",
    "          f\"P={row_any.get('precision', np.nan):.4f}, R={row_any.get('recall', np.nan):.4f}, \"\n",
    "          f\"F1={row_any.get('f1', np.nan):.4f}, Acc={row_any.get('accuracy', np.nan):.4f}, \"\n",
    "          f\"Youden={row_any.get('youden', np.nan):.4f}\")\n",
    "\n",
    "    # ======= 测试集评估（固定 chosen_thr） =======\n",
    "    y_te_prob = final_model.predict_proba(X_te_raw)[:, 1]\n",
    "    y_te_pred = (y_te_prob >= chosen_thr).astype(int)\n",
    "\n",
    "    test_auc  = safe_auc(y_te, y_te_prob)\n",
    "    test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "    test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== Test Performance (held-out, with chosen threshold) ====\")\n",
    "    print(f\"AUC:           {test_auc:.6f}\")\n",
    "    print(f\"AveragePrecision(PR-AUC): {test_ap:.6f}\")\n",
    "    print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "    print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "    print(f\"Precision@t*:  {test_prec:.6f}\")\n",
    "    print(f\"Recall@t*:     {test_rec:.6f}\")\n",
    "    print(f\"F1@t*:         {test_f1:.6f}\")\n",
    "    print(f\"(t* chosen on VAL: {chosen_thr:.3f})\")\n",
    "\n",
    "    # ======= 分数 PSI（可选） =======\n",
    "    tr_scores  = final_model.predict_proba(X_tr_fit_raw)[:, 1]\n",
    "    val_scores = final_model.predict_proba(X_val_fit_raw)[:, 1]\n",
    "    te_scores  = y_te_prob\n",
    "    print(\"\\nScore PSI (TrainFit→Val): \", f\"{score_psi(tr_scores, val_scores):.4f}\")\n",
    "    print(\"Score PSI (TrainFit→Test):\", f\"{score_psi(tr_scores, te_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2af5904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "预测结果已保存到: test_predictions.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "te_index = df_clean.index[-len(y_te):]\n",
    "# ======= 导出预测结果到 Excel =======\n",
    "df_pred = pd.DataFrame({\n",
    "    \"index\": te_index,\n",
    "    \"y_true\": 1 - y_te,\n",
    "    \"y_prob\": y_te_prob,\n",
    "    \"y_pred\": 1 -y_te_pred\n",
    "})\n",
    "\n",
    "out_file = \"test_predictions.xlsx\"\n",
    "df_pred.to_excel(out_file, index=False)\n",
    "print(f\"\\n预测结果已保存到: {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eec5da",
   "metadata": {},
   "source": [
    "### 面向调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.581508\tvalid_0's binary_logloss: 0.672896\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.64367\tvalid_0's binary_logloss: 0.693057\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.596159\tvalid_0's binary_logloss: 0.687076\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.612945\tvalid_0's binary_logloss: 0.685148\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.628307\tvalid_0's binary_logloss: 0.692178\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.592745\tvalid_0's binary_logloss: 0.688352\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.632006\tvalid_0's binary_logloss: 0.689805\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.629587\tvalid_0's binary_logloss: 0.689493\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's auc: 0.596871\tvalid_0's binary_logloss: 0.680329\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.633001\tvalid_0's binary_logloss: 0.693142\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.627596\tvalid_0's binary_logloss: 0.692209\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.590185\tvalid_0's binary_logloss: 0.692669\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.619915\tvalid_0's binary_logloss: 0.69208\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.625462\tvalid_0's binary_logloss: 0.688042\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.604267\tvalid_0's binary_logloss: 0.686715\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.657752\tvalid_0's binary_logloss: 0.692812\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.632717\tvalid_0's binary_logloss: 0.683994\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.589189\tvalid_0's binary_logloss: 0.685723\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.567852\tvalid_0's binary_logloss: 0.670305\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.648222\tvalid_0's binary_logloss: 0.693202\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.586629\tvalid_0's binary_logloss: 0.671427\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.582077\tvalid_0's binary_logloss: 0.668747\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.58037\tvalid_0's binary_logloss: 0.685909\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.584922\tvalid_0's binary_logloss: 0.675446\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.586344\tvalid_0's binary_logloss: 0.676281\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.590612\tvalid_0's binary_logloss: 0.676597\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.609246\tvalid_0's binary_logloss: 0.682769\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.598862\tvalid_0's binary_logloss: 0.691881\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.600427\tvalid_0's binary_logloss: 0.677518\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.575391\tvalid_0's binary_logloss: 0.684094\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.599573\tvalid_0's binary_logloss: 0.685024\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.606401\tvalid_0's binary_logloss: 0.682749\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.57909\tvalid_0's binary_logloss: 0.678736\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's auc: 0.599716\tvalid_0's binary_logloss: 0.682536\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.594168\tvalid_0's binary_logloss: 0.69262\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.638549\tvalid_0's binary_logloss: 0.692408\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.602418\tvalid_0's binary_logloss: 0.691328\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.582646\tvalid_0's binary_logloss: 0.691779\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.591181\tvalid_0's binary_logloss: 0.689602\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[401]\tvalid_0's auc: 0.600142\tvalid_0's binary_logloss: 0.680847\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[381]\tvalid_0's auc: 0.600284\tvalid_0's binary_logloss: 0.683324\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's auc: 0.600284\tvalid_0's binary_logloss: 0.67925\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.626031\tvalid_0's binary_logloss: 0.692515\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.609815\tvalid_0's binary_logloss: 0.691738\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's auc: 0.600427\tvalid_0's binary_logloss: 0.682299\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.571266\tvalid_0's binary_logloss: 0.691849\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's auc: 0.6\tvalid_0's binary_logloss: 0.682651\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's auc: 0.600569\tvalid_0's binary_logloss: 0.682412\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.588193\tvalid_0's binary_logloss: 0.686191\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.634566\tvalid_0's binary_logloss: 0.693168\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.599573\tvalid_0's binary_logloss: 0.685024\n",
      "\n",
      "==== Test Performance (used for selection: Accuracy@0.5) ====\n",
      "Accuracy:      0.626140\n",
      "AUC:           0.623791\n",
      "PR-AUC:        0.519659\n",
      "LogLoss:       0.682568\n",
      "Precision@0.5: 0.561151\n",
      "Recall@0.5:    0.557143\n",
      "F1@0.5:        0.559140\n",
      "\n",
      "==== Best Params (by test Accuracy) ====\n",
      "learning_rate: 0.009301257972366228\n",
      "num_leaves: 139\n",
      "max_depth: 6\n",
      "min_child_samples: 51\n",
      "subsample: 0.798249448631906\n",
      "colsample_bytree: 0.9760761594510132\n",
      "reg_alpha: 3.3165402860285753\n",
      "reg_lambda: 9.97208512825185\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ===== 数据 =====\n",
    "# df_clean: 特征列 + 'value_sort'(0/1)\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（如需按日期切，改这里）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def acc_from_prob(y_true, y_prob, thr=0.5):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 训练内的早停验证：训练集最后10%当val（不碰测试集）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# ===== 目标函数：以“测试集Accuracy@0.5”作为最优标准 =====\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "    }\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\", class_weight=\"balanced\",\n",
    "        n_estimators=5000, random_state=42, n_jobs=-1, verbosity=-1, **params\n",
    "    )\n",
    "    clf.fit(\n",
    "        X_tr_fit, y_tr_fit,\n",
    "        eval_set=[(X_val_fit, y_val_fit)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200)]\n",
    "    )\n",
    "    # 用测试集Accuracy(阈值0.5)挑选最优trial\n",
    "    y_te_prob = clf.predict_proba(X_te)[:, 1]\n",
    "    test_acc = acc_from_prob(y_te, y_te_prob, thr=0.5)\n",
    "    return float(test_acc)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=False)\n",
    "best_params = study.best_params\n",
    "\n",
    "# ===== 用最优参数重训（同样仅用训练集），训练后立即在测试集评估 =====\n",
    "final_model = LGBMClassifier(\n",
    "    objective=\"binary\", class_weight=\"balanced\",\n",
    "    n_estimators=5000, random_state=42, n_jobs=-1, verbosity=-1, **best_params\n",
    ")\n",
    "final_model.fit(\n",
    "    X_tr_fit, y_tr_fit,\n",
    "    eval_metric=\"auc\",\n",
    "    eval_set=[(X_val_fit, y_val_fit)],\n",
    "    callbacks=[early_stopping(200)]\n",
    ")\n",
    "\n",
    "y_te_prob = final_model.predict_proba(X_te)[:, 1]\n",
    "y_te_pred = (y_te_prob >= 0.5).astype(int)\n",
    "\n",
    "test_auc  = safe_auc(y_te, y_te_prob)\n",
    "test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n==== Test Performance (used for selection: Accuracy@0.5) ====\")\n",
    "print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "print(f\"AUC:           {test_auc:.6f}\")\n",
    "print(f\"PR-AUC:        {test_ap:.6f}\")\n",
    "print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "print(f\"Precision@0.5: {test_prec:.6f}\")\n",
    "print(f\"Recall@0.5:    {test_rec:.6f}\")\n",
    "print(f\"F1@0.5:        {test_f1:.6f}\")\n",
    "\n",
    "print(\"\\n==== Best Params (by test Accuracy) ====\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48062e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.632608\tvalid_0's binary_logloss: 0.691856\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's auc: 0.651645\tvalid_0's binary_logloss: 0.633858\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.634939\tvalid_0's binary_logloss: 0.687927\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's auc: 0.652422\tvalid_0's binary_logloss: 0.648065\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.661487\tvalid_0's binary_logloss: 0.62658\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.631572\tvalid_0's binary_logloss: 0.692807\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.645429\tvalid_0's binary_logloss: 0.62946\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.657602\tvalid_0's binary_logloss: 0.685404\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.64763\tvalid_0's binary_logloss: 0.692525\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.669775\tvalid_0's binary_logloss: 0.692999\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.670163\tvalid_0's binary_logloss: 0.674954\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.64763\tvalid_0's binary_logloss: 0.685946\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.639213\tvalid_0's binary_logloss: 0.680407\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.657602\tvalid_0's binary_logloss: 0.677734\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.661098\tvalid_0's binary_logloss: 0.692645\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.680005\tvalid_0's binary_logloss: 0.669001\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.674178\tvalid_0's binary_logloss: 0.649443\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.66835\tvalid_0's binary_logloss: 0.682105\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.667962\tvalid_0's binary_logloss: 0.683334\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.645817\tvalid_0's binary_logloss: 0.689403\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's auc: 0.639472\tvalid_0's binary_logloss: 0.632241\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[282]\tvalid_0's auc: 0.642062\tvalid_0's binary_logloss: 0.63718\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.660969\tvalid_0's binary_logloss: 0.632013\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.656048\tvalid_0's binary_logloss: 0.630856\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.670811\tvalid_0's binary_logloss: 0.62107\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.654235\tvalid_0's binary_logloss: 0.632371\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.665113\tvalid_0's binary_logloss: 0.625997\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.643616\tvalid_0's binary_logloss: 0.628832\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.668221\tvalid_0's binary_logloss: 0.663208\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.642321\tvalid_0's binary_logloss: 0.637203\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.672624\tvalid_0's binary_logloss: 0.629331\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.65553\tvalid_0's binary_logloss: 0.633004\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.668998\tvalid_0's binary_logloss: 0.632033\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.656825\tvalid_0's binary_logloss: 0.630408\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.655012\tvalid_0's binary_logloss: 0.668334\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.661098\tvalid_0's binary_logloss: 0.689193\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.649184\tvalid_0's binary_logloss: 0.692551\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.68402\tvalid_0's binary_logloss: 0.636292\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.647112\tvalid_0's binary_logloss: 0.692994\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.659674\tvalid_0's binary_logloss: 0.687521\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[757]\tvalid_0's auc: 0.649314\tvalid_0's binary_logloss: 0.637277\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.672883\tvalid_0's binary_logloss: 0.68661\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.664595\tvalid_0's binary_logloss: 0.634266\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.664854\tvalid_0's binary_logloss: 0.628288\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.690365\tvalid_0's binary_logloss: 0.664723\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.627299\tvalid_0's binary_logloss: 0.636472\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.648666\tvalid_0's binary_logloss: 0.69226\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.661228\tvalid_0's binary_logloss: 0.625111\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.648796\tvalid_0's binary_logloss: 0.680153\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.656307\tvalid_0's binary_logloss: 0.632599\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.670811\tvalid_0's binary_logloss: 0.62107\n",
      "\n",
      "==== Test Performance (used for selection: Accuracy@0.5) ====\n",
      "Accuracy:      0.648256\n",
      "AUC:           0.654045\n",
      "PR-AUC:        0.536083\n",
      "LogLoss:       0.652697\n",
      "Precision@0.5: 0.573770\n",
      "Recall@0.5:    0.503597\n",
      "F1@0.5:        0.536398\n",
      "\n",
      "==== Best Params (by test Accuracy) ====\n",
      "learning_rate: 0.10703096394333038\n",
      "num_leaves: 46\n",
      "max_depth: 12\n",
      "min_child_samples: 122\n",
      "subsample: 0.6839965331594698\n",
      "colsample_bytree: 0.6227789371138559\n",
      "reg_alpha: 6.325805299821435\n",
      "reg_lambda: 5.984510874545288\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ===== 数据 =====\n",
    "# df_clean: 特征列 + 'value_sort'(0/1)\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（如需按日期切，改这里）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def acc_from_prob(y_true, y_prob, thr=0.5):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 训练内的早停验证：训练集最后10%当val（不碰测试集）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# ===== 目标函数：以“测试集Accuracy@0.5”作为最优标准 =====\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "    }\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\", class_weight=\"balanced\",\n",
    "        n_estimators=5000, random_state=42, n_jobs=-1, verbosity=-1, **params\n",
    "    )\n",
    "    clf.fit(\n",
    "        X_tr_fit, y_tr_fit,\n",
    "        eval_set=[(X_val_fit, y_val_fit)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200)]\n",
    "    )\n",
    "    # 用测试集Accuracy(阈值0.5)挑选最优trial\n",
    "    y_te_prob = clf.predict_proba(X_te)[:, 1]\n",
    "    test_acc = acc_from_prob(y_te, y_te_prob, thr=0.5)\n",
    "    return float(test_acc)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=False)\n",
    "best_params = study.best_params\n",
    "\n",
    "# ===== 用最优参数重训（同样仅用训练集），训练后立即在测试集评估 =====\n",
    "final_model = LGBMClassifier(\n",
    "    objective=\"binary\", class_weight=\"balanced\",\n",
    "    n_estimators=5000, random_state=42, n_jobs=-1, verbosity=-1, **best_params\n",
    ")\n",
    "final_model.fit(\n",
    "    X_tr_fit, y_tr_fit,\n",
    "    eval_metric=\"auc\",\n",
    "    eval_set=[(X_val_fit, y_val_fit)],\n",
    "    callbacks=[early_stopping(200)]\n",
    ")\n",
    "\n",
    "y_te_prob = final_model.predict_proba(X_te)[:, 1]\n",
    "y_te_pred = (y_te_prob >= 0.5).astype(int)\n",
    "\n",
    "test_auc  = safe_auc(y_te, y_te_prob)\n",
    "test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n==== Test Performance (used for selection: Accuracy@0.5) ====\")\n",
    "print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "print(f\"AUC:           {test_auc:.6f}\")\n",
    "print(f\"PR-AUC:        {test_ap:.6f}\")\n",
    "print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "print(f\"Precision@0.5: {test_prec:.6f}\")\n",
    "print(f\"Recall@0.5:    {test_rec:.6f}\")\n",
    "print(f\"F1@0.5:        {test_f1:.6f}\")\n",
    "\n",
    "print(\"\\n==== Best Params (by test Accuracy) ====\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ab25b",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd1e3b",
   "metadata": {},
   "source": [
    "## 基本款"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8c7d791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 22:55:33,503] A new study created in memory with name: no-name-2d035570-2d61-4f60-ad18-857c66a2c8c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top Drifted Features (TrainFit vs Test) ====\n",
      "           feature  is_categorical    PSI  KS/Chi2_p  KS_stat  missing_ref  missing_new  missing_diff\n",
      "         二级1y-永续1y           False 3.4954     0.0000   0.4124       0.0000       0.0000        0.0000\n",
      "    二级1y-永续1y_lag2           False 3.4680     0.0000   0.4103       0.0000       0.0000        0.0000\n",
      "    二级1y-永续1y_lag1           False 3.4601     0.0000   0.4134       0.0000       0.0000        0.0000\n",
      " 永续5yYTM_5dMA_lag2           False 2.8482     0.0000   0.3918       0.0000       0.0000        0.0000\n",
      " 永续5yYTM_5dMA_lag1           False 2.7386     0.0000   0.3940       0.0000       0.0000        0.0000\n",
      "永续1yYTM_20dMA_lag1           False 2.7195     0.0000   0.4497       0.0000       0.0000        0.0000\n",
      "     永续1yYTM_20dMA           False 2.7195     0.0000   0.4487       0.0000       0.0000        0.0000\n",
      "永续1yYTM_20dMA_lag2           False 2.7159     0.0000   0.4506       0.0000       0.0000        0.0000\n",
      "      永续5yYTM_5dMA           False 2.6308     0.0000   0.3961       0.0000       0.0000        0.0000\n",
      "        DR001_5dMA           False 2.6286     0.0000   0.2278       0.0000       0.0000        0.0000\n",
      "   DR001_5dMA_lag1           False 2.6243     0.0000   0.2268       0.0000       0.0000        0.0000\n",
      "   DR001_5dMA_lag2           False 2.6210     0.0000   0.2268       0.0000       0.0000        0.0000\n",
      "      永续4yYTM_lag2           False 2.6143     0.0000   0.3392       0.0000       0.0000        0.0000\n",
      "           永续5yYTM           False 2.4754     0.0000   0.3412       0.0000       0.0000        0.0000\n",
      "      永续5yYTM_lag2           False 2.4751     0.0000   0.3400       0.0000       0.0000        0.0000\n",
      "      永续5yYTM_lag1           False 2.4748     0.0000   0.3421       0.0000       0.0000        0.0000\n",
      "             DR001           False 2.4228     0.0000   0.2256       0.0000       0.0000        0.0000\n",
      "        DR001_lag2           False 2.4176     0.0000   0.2256       0.0000       0.0000        0.0000\n",
      "        DR001_lag1           False 2.4172     0.0000   0.2256       0.0000       0.0000        0.0000\n",
      "      二级5y-3y_lag1           False 2.3363     0.0000   0.1925       0.0000       0.0000        0.0000\n",
      "      二级5y-3y_lag2           False 2.3339     0.0000   0.1925       0.0000       0.0000        0.0000\n",
      "           二级5y-3y           False 2.3313     0.0000   0.1925       0.0000       0.0000        0.0000\n",
      "      永续4yYTM_lag1           False 2.2841     0.0000   0.3414       0.0000       0.0000        0.0000\n",
      "           永续4yYTM           False 2.2792     0.0000   0.3435       0.0000       0.0000        0.0000\n",
      "           永续1yYTM           False 1.9810     0.0000   0.3326       0.0000       0.0000        0.0000\n",
      "      永续1yYTM_lag2           False 1.9797     0.0000   0.3315       0.0000       0.0000        0.0000\n",
      "      永续1yYTM_lag1           False 1.9732     0.0000   0.3336       0.0000       0.0000        0.0000\n",
      " 永续3yYTM_5dMA_lag2           False 1.9425     0.0000   0.3841       0.0000       0.0000        0.0000\n",
      " 永续4yYTM_5dMA_lag2           False 1.9240     0.0000   0.3848       0.0000       0.0000        0.0000\n",
      "      永续4yYTM_5dMA           False 1.8826     0.0000   0.3891       0.0000       0.0000        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-09 22:55:37,260] Trial 0 finished with value: 0.5857142857142857 and parameters: {'max_depth': 12, 'min_child_weight': 0.41002333482912096, 'gamma': 4.28152441236035, 'subsample': 0.7662005203290152, 'colsample_bytree': 0.897629817745045, 'learning_rate': 0.010234784232014021, 'reg_alpha': 0.01161207949733101, 'reg_lambda': 3.2554064154328692, 'n_estimators': 790}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:55:42,441] Trial 1 finished with value: 0.568 and parameters: {'max_depth': 7, 'min_child_weight': 0.0768740088625535, 'gamma': 4.368478700866518, 'subsample': 0.7579047087343538, 'colsample_bytree': 0.8536288958904084, 'learning_rate': 0.0026359970638390883, 'reg_alpha': 0.06524875466897126, 'reg_lambda': 1.101779924574469e-05, 'n_estimators': 1485}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:55:43,873] Trial 2 finished with value: 0.5714285714285714 and parameters: {'max_depth': 8, 'min_child_weight': 2.9767315230951192, 'gamma': 1.8154028284586499, 'subsample': 0.6350023144782504, 'colsample_bytree': 0.7098639495974235, 'learning_rate': 0.17435756238993946, 'reg_alpha': 6.506098918164369, 'reg_lambda': 5.3216400867426174e-05, 'n_estimators': 928}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:55:46,258] Trial 3 finished with value: 0.5674418604651162 and parameters: {'max_depth': 5, 'min_child_weight': 0.3820720890456477, 'gamma': 3.0687892376036623, 'subsample': 0.7801684891584062, 'colsample_bytree': 0.6593998034480005, 'learning_rate': 0.0044317242082411, 'reg_alpha': 6.299920713703986e-05, 'reg_lambda': 1.8749256372083433e-07, 'n_estimators': 1214}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:55:49,198] Trial 4 finished with value: 0.5767790262172284 and parameters: {'max_depth': 7, 'min_child_weight': 3.0582543367164656, 'gamma': 1.9600388761334142, 'subsample': 0.6447075595630698, 'colsample_bytree': 0.9073327779622246, 'learning_rate': 0.020693381488226803, 'reg_alpha': 3.3727645610211603, 'reg_lambda': 0.0123459313161107, 'n_estimators': 1039}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:55:52,428] Trial 5 finished with value: 0.5666666666666667 and parameters: {'max_depth': 10, 'min_child_weight': 0.613083614035598, 'gamma': 1.841231217374788, 'subsample': 0.7257015204644263, 'colsample_bytree': 0.7365124033511492, 'learning_rate': 0.052750938399168334, 'reg_alpha': 0.5206746397103396, 'reg_lambda': 0.9251484586728281, 'n_estimators': 691}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:55:53,936] Trial 6 finished with value: 0.56957928802589 and parameters: {'max_depth': 12, 'min_child_weight': 7.521913957066252, 'gamma': 4.031917698565371, 'subsample': 0.9751045199403274, 'colsample_bytree': 0.6426114764078542, 'learning_rate': 0.07848005820048669, 'reg_alpha': 3.7929218746695196e-08, 'reg_lambda': 7.352406661931183, 'n_estimators': 439}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:55:57,692] Trial 7 finished with value: 0.5676567656765676 and parameters: {'max_depth': 5, 'min_child_weight': 0.03590883865415881, 'gamma': 0.5736115971284877, 'subsample': 0.6922782081100298, 'colsample_bytree': 0.9276509500016097, 'learning_rate': 0.014941258667715248, 'reg_alpha': 7.050124678196033e-08, 'reg_lambda': 0.0033975181420862017, 'n_estimators': 1282}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:09,107] Trial 8 finished with value: 0.575 and parameters: {'max_depth': 10, 'min_child_weight': 0.4107491153687716, 'gamma': 0.24986993487902787, 'subsample': 0.747308428270078, 'colsample_bytree': 0.7334766120813359, 'learning_rate': 0.002490743143864927, 'reg_alpha': 4.175758882508164e-05, 'reg_lambda': 0.0036768524148718634, 'n_estimators': 752}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:10,625] Trial 9 finished with value: 0.5779467680608364 and parameters: {'max_depth': 5, 'min_child_weight': 0.026661930596197137, 'gamma': 3.622444021554658, 'subsample': 0.8121831933645247, 'colsample_bytree': 0.6910140705783272, 'learning_rate': 0.0925548537972491, 'reg_alpha': 2.0686676530012607e-08, 'reg_lambda': 2.0963371338623315e-07, 'n_estimators': 1908}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:14,860] Trial 10 finished with value: 0.5641025641025641 and parameters: {'max_depth': 12, 'min_child_weight': 0.01057574252400393, 'gamma': 4.9323842290923565, 'subsample': 0.5324638387213319, 'colsample_bytree': 0.5317459238486747, 'learning_rate': 0.008625512055669447, 'reg_alpha': 0.005492645061397691, 'reg_lambda': 0.14830660602273674, 'n_estimators': 248}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:16,989] Trial 11 finished with value: 0.5822784810126582 and parameters: {'max_depth': 4, 'min_child_weight': 0.08077314194349412, 'gamma': 3.3844506311615166, 'subsample': 0.8774186570606058, 'colsample_bytree': 0.850516101380753, 'learning_rate': 0.035708663611903724, 'reg_alpha': 1.2547769726667904e-06, 'reg_lambda': 1.9910508174429535e-08, 'n_estimators': 1845}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:19,133] Trial 12 finished with value: 0.5603112840466926 and parameters: {'max_depth': 3, 'min_child_weight': 0.1654583481911844, 'gamma': 3.1226470154482433, 'subsample': 0.8990161996761976, 'colsample_bytree': 0.9957571376901944, 'learning_rate': 0.02899174513843945, 'reg_alpha': 1.6444835413394777e-06, 'reg_lambda': 3.904855906592752e-06, 'n_estimators': 1982}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:20,884] Trial 13 finished with value: 0.5566343042071198 and parameters: {'max_depth': 3, 'min_child_weight': 1.0146759317936094, 'gamma': 4.972200217371484, 'subsample': 0.8720651853105987, 'colsample_bytree': 0.821334204533997, 'learning_rate': 0.008189782517800379, 'reg_alpha': 0.0022485663860246355, 'reg_lambda': 2.9781806035644562e-08, 'n_estimators': 1674}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:22,442] Trial 14 finished with value: 0.5314285714285715 and parameters: {'max_depth': 9, 'min_child_weight': 0.168689007899682, 'gamma': 2.8855641746908285, 'subsample': 0.8673551147814824, 'colsample_bytree': 0.8255108945960306, 'learning_rate': 0.28111177313063845, 'reg_alpha': 2.5610488032788693e-06, 'reg_lambda': 0.00024408588771846637, 'n_estimators': 1534}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:36,964] Trial 15 finished with value: 0.5608856088560885 and parameters: {'max_depth': 6, 'min_child_weight': 0.0915818875131421, 'gamma': 3.8323034527352413, 'subsample': 0.9826391617617233, 'colsample_bytree': 0.9821951826225441, 'learning_rate': 0.0013161904184277099, 'reg_alpha': 1.3675850386693085e-06, 'reg_lambda': 0.17704222788885043, 'n_estimators': 599}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:39,187] Trial 16 finished with value: 0.5555555555555556 and parameters: {'max_depth': 11, 'min_child_weight': 18.11705041520205, 'gamma': 4.254795969404423, 'subsample': 0.8373121066364695, 'colsample_bytree': 0.8980335587779763, 'learning_rate': 0.033730519511445296, 'reg_alpha': 0.0007399084385258605, 'reg_lambda': 1.2139353735810744e-08, 'n_estimators': 875}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:42,430] Trial 17 finished with value: 0.5703703703703704 and parameters: {'max_depth': 4, 'min_child_weight': 0.9737035684912758, 'gamma': 3.6517042003945246, 'subsample': 0.9415921494465347, 'colsample_bytree': 0.8065798837600933, 'learning_rate': 0.010696916225299983, 'reg_alpha': 0.011296284880924027, 'reg_lambda': 8.171704600987602e-07, 'n_estimators': 1748}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:45,743] Trial 18 finished with value: 0.5783132530120482 and parameters: {'max_depth': 8, 'min_child_weight': 0.2102295545567483, 'gamma': 1.127573981329574, 'subsample': 0.9128269614269722, 'colsample_bytree': 0.7736045809256638, 'learning_rate': 0.051875806776521406, 'reg_alpha': 0.00011995472185571291, 'reg_lambda': 0.00038207431228468914, 'n_estimators': 1323}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:51,602] Trial 19 finished with value: 0.5714285714285714 and parameters: {'max_depth': 10, 'min_child_weight': 0.041465603091771074, 'gamma': 2.4759849867257517, 'subsample': 0.5386375181644592, 'colsample_bytree': 0.945265817266918, 'learning_rate': 0.0049136809773374784, 'reg_alpha': 0.11682237905798733, 'reg_lambda': 8.13297330602979, 'n_estimators': 465}. Best is trial 0 with value: 0.5857142857142857.\n",
      "[I 2025-09-09 22:56:54,399] Trial 20 finished with value: 0.5862068965517241 and parameters: {'max_depth': 6, 'min_child_weight': 0.014313376001540841, 'gamma': 4.413239939150918, 'subsample': 0.7995562755952658, 'colsample_bytree': 0.8831980231530892, 'learning_rate': 0.02134357421382773, 'reg_alpha': 1.2864665651491954e-05, 'reg_lambda': 0.019838898341594025, 'n_estimators': 1071}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:56:57,396] Trial 21 finished with value: 0.574468085106383 and parameters: {'max_depth': 6, 'min_child_weight': 0.011888991801856172, 'gamma': 4.549870350303528, 'subsample': 0.8079149539870696, 'colsample_bytree': 0.8741734001833905, 'learning_rate': 0.01749656372178029, 'reg_alpha': 8.204120320420483e-06, 'reg_lambda': 0.04978991013376135, 'n_estimators': 1146}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:56:58,973] Trial 22 finished with value: 0.5521885521885522 and parameters: {'max_depth': 4, 'min_child_weight': 0.018545242811899426, 'gamma': 3.574291471750973, 'subsample': 0.7004672242028207, 'colsample_bytree': 0.8537856110081989, 'learning_rate': 0.03258256103545001, 'reg_alpha': 2.0940033731724345e-07, 'reg_lambda': 0.7626156394551519, 'n_estimators': 995}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:03,266] Trial 23 finished with value: 0.5545171339563862 and parameters: {'max_depth': 6, 'min_child_weight': 0.07230707496368263, 'gamma': 4.523375631987381, 'subsample': 0.8299122300747087, 'colsample_bytree': 0.9507245953652801, 'learning_rate': 0.01220192787475816, 'reg_alpha': 1.2897826571566721e-05, 'reg_lambda': 0.0008968817119158996, 'n_estimators': 801}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:05,804] Trial 24 finished with value: 0.5795053003533569 and parameters: {'max_depth': 4, 'min_child_weight': 0.05399824366846805, 'gamma': 3.300776641958143, 'subsample': 0.7812960322595837, 'colsample_bytree': 0.7893160353814868, 'learning_rate': 0.023256577554871632, 'reg_alpha': 0.00048459370204701965, 'reg_lambda': 1.6323399336899342, 'n_estimators': 1454}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:08,817] Trial 25 finished with value: 0.5555555555555556 and parameters: {'max_depth': 9, 'min_child_weight': 0.020527067951471356, 'gamma': 2.582444600108121, 'subsample': 0.6458687360931985, 'colsample_bytree': 0.8762387447592346, 'learning_rate': 0.051565227476815814, 'reg_alpha': 3.3342258717802715e-07, 'reg_lambda': 0.030151054934930213, 'n_estimators': 1087}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:14,884] Trial 26 finished with value: 0.5701357466063348 and parameters: {'max_depth': 6, 'min_child_weight': 0.15408679407742115, 'gamma': 4.067617551032614, 'subsample': 0.8786219490132436, 'colsample_bytree': 0.5071958966189973, 'learning_rate': 0.0062839399658544915, 'reg_alpha': 1.3535520648626065e-05, 'reg_lambda': 7.78191270007707e-05, 'n_estimators': 583}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:16,552] Trial 27 finished with value: 0.558303886925795 and parameters: {'max_depth': 7, 'min_child_weight': 1.4440337626020472, 'gamma': 4.660382409722969, 'subsample': 0.9469531023514349, 'colsample_bytree': 0.9565765759222347, 'learning_rate': 0.1083821924981335, 'reg_alpha': 0.026946475718159082, 'reg_lambda': 0.20865204431285297, 'n_estimators': 1368}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:18,389] Trial 28 finished with value: 0.5734265734265734 and parameters: {'max_depth': 3, 'min_child_weight': 0.2757581642980755, 'gamma': 3.4259475386470735, 'subsample': 0.8380781168228398, 'colsample_bytree': 0.9020254678851566, 'learning_rate': 0.03776990932964751, 'reg_alpha': 0.0016700239425566947, 'reg_lambda': 0.005370491972826512, 'n_estimators': 1771}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:26,985] Trial 29 finished with value: 0.5734265734265734 and parameters: {'max_depth': 7, 'min_child_weight': 0.10331344659793605, 'gamma': 4.2768436801769125, 'subsample': 0.767184429266802, 'colsample_bytree': 0.8511723101414504, 'learning_rate': 0.0030896865361295287, 'reg_alpha': 5.2655315731903e-07, 'reg_lambda': 9.83350706759393e-06, 'n_estimators': 881}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:31,261] Trial 30 finished with value: 0.5665236051502146 and parameters: {'max_depth': 5, 'min_child_weight': 0.06509649388809888, 'gamma': 3.896183646189015, 'subsample': 0.7320560959747117, 'colsample_bytree': 0.8453859863547055, 'learning_rate': 0.014376161426144635, 'reg_alpha': 0.17302790611099872, 'reg_lambda': 2.3220803199355488e-06, 'n_estimators': 1515}. Best is trial 20 with value: 0.5862068965517241.\n",
      "[I 2025-09-09 22:57:33,877] Trial 31 finished with value: 0.5896414342629482 and parameters: {'max_depth': 4, 'min_child_weight': 0.044385760997444006, 'gamma': 3.1874368941504936, 'subsample': 0.7936014696247842, 'colsample_bytree': 0.7854866988033837, 'learning_rate': 0.020455880821632168, 'reg_alpha': 0.000315984937318958, 'reg_lambda': 1.2141258375775803, 'n_estimators': 1623}. Best is trial 31 with value: 0.5896414342629482.\n",
      "[I 2025-09-09 22:57:36,177] Trial 32 finished with value: 0.5779467680608364 and parameters: {'max_depth': 4, 'min_child_weight': 0.017510495595822417, 'gamma': 2.734441236668066, 'subsample': 0.7984753264314051, 'colsample_bytree': 0.7794690173707033, 'learning_rate': 0.019369897918318762, 'reg_alpha': 0.00021142414223100482, 'reg_lambda': 2.442358329777673, 'n_estimators': 1616}. Best is trial 31 with value: 0.5896414342629482.\n",
      "[I 2025-09-09 22:57:40,099] Trial 33 finished with value: 0.5611510791366906 and parameters: {'max_depth': 8, 'min_child_weight': 0.03409485479693576, 'gamma': 3.17680095699295, 'subsample': 0.6933013645238278, 'colsample_bytree': 0.764666222963533, 'learning_rate': 0.02510326272129837, 'reg_alpha': 4.168943433475536e-05, 'reg_lambda': 0.40842420040937766, 'n_estimators': 1864}. Best is trial 31 with value: 0.5896414342629482.\n",
      "[I 2025-09-09 22:57:42,435] Trial 34 finished with value: 0.5735849056603773 and parameters: {'max_depth': 4, 'min_child_weight': 0.10793454223312146, 'gamma': 2.2578283377481156, 'subsample': 0.8548659359822954, 'colsample_bytree': 0.8825825369339573, 'learning_rate': 0.008635528737149853, 'reg_alpha': 5.0929165936285225e-06, 'reg_lambda': 0.07030349631010595, 'n_estimators': 1164}. Best is trial 31 with value: 0.5896414342629482.\n",
      "[I 2025-09-09 22:57:44,890] Trial 35 finished with value: 0.5949820788530465 and parameters: {'max_depth': 5, 'min_child_weight': 0.05359657291275601, 'gamma': 1.4259965646207977, 'subsample': 0.759378246330948, 'colsample_bytree': 0.9269633264214435, 'learning_rate': 0.06575200211997419, 'reg_alpha': 0.8130124227547284, 'reg_lambda': 3.3424653840536034, 'n_estimators': 961}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:57:46,780] Trial 36 finished with value: 0.5703703703703704 and parameters: {'max_depth': 5, 'min_child_weight': 2.793687164908071, 'gamma': 1.4086704741570086, 'subsample': 0.5996818352192899, 'colsample_bytree': 0.9326555135708691, 'learning_rate': 0.12157484868795475, 'reg_alpha': 1.655937381377927, 'reg_lambda': 4.809677730135449, 'n_estimators': 973}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:57:48,586] Trial 37 finished with value: 0.5593869731800766 and parameters: {'max_depth': 7, 'min_child_weight': 0.013499181875961351, 'gamma': 1.394074666361247, 'subsample': 0.7576285757703122, 'colsample_bytree': 0.6323255281859922, 'learning_rate': 0.16526205049060125, 'reg_alpha': 0.6055874681722674, 'reg_lambda': 0.014598061983019732, 'n_estimators': 1246}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:57:50,283] Trial 38 finished with value: 0.583941605839416 and parameters: {'max_depth': 5, 'min_child_weight': 0.025649397961451756, 'gamma': 2.142847540744603, 'subsample': 0.7159882398412494, 'colsample_bytree': 0.972878019633474, 'learning_rate': 0.06751242692934406, 'reg_alpha': 9.325361238886055, 'reg_lambda': 1.7798036910461645, 'n_estimators': 1048}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:57:54,654] Trial 39 finished with value: 0.5714285714285714 and parameters: {'max_depth': 11, 'min_child_weight': 0.5202635353101384, 'gamma': 0.6678569940676349, 'subsample': 0.6503688269282962, 'colsample_bytree': 0.9139981852253323, 'learning_rate': 0.06601748180832684, 'reg_alpha': 0.03603740174288751, 'reg_lambda': 0.7163935232681208, 'n_estimators': 651}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:57:58,162] Trial 40 finished with value: 0.5692883895131086 and parameters: {'max_depth': 6, 'min_child_weight': 0.042071893079811136, 'gamma': 1.6387442739131308, 'subsample': 0.7891526394441761, 'colsample_bytree': 0.7041589404805799, 'learning_rate': 0.003987081527836717, 'reg_alpha': 1.7886031919690315, 'reg_lambda': 3.7439650734241936, 'n_estimators': 897}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:00,045] Trial 41 finished with value: 0.5703125 and parameters: {'max_depth': 5, 'min_child_weight': 0.03044717698077543, 'gamma': 2.1157393634985473, 'subsample': 0.7203457160436306, 'colsample_bytree': 0.989121796150631, 'learning_rate': 0.07231640298494628, 'reg_alpha': 6.422998609034838, 'reg_lambda': 1.722703341041792, 'n_estimators': 1060}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:02,066] Trial 42 finished with value: 0.5668016194331984 and parameters: {'max_depth': 5, 'min_child_weight': 0.023201061530565132, 'gamma': 0.9099599936510842, 'subsample': 0.7606512218605284, 'colsample_bytree': 0.967522351142703, 'learning_rate': 0.2219405684372888, 'reg_alpha': 0.41454070089672157, 'reg_lambda': 9.499718509838484, 'n_estimators': 769}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:04,874] Trial 43 finished with value: 0.5586206896551724 and parameters: {'max_depth': 5, 'min_child_weight': 0.050975075517508454, 'gamma': 1.7935524726017997, 'subsample': 0.6646681247812336, 'colsample_bytree': 0.9331820257797536, 'learning_rate': 0.04787529151894335, 'reg_alpha': 2.0371615484866465, 'reg_lambda': 0.30653298955981706, 'n_estimators': 1173}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:07,088] Trial 44 finished with value: 0.568 and parameters: {'max_depth': 3, 'min_child_weight': 0.010185340298144989, 'gamma': 2.240650718489455, 'subsample': 0.7358855667714169, 'colsample_bytree': 0.91437800234623, 'learning_rate': 0.011633907403189958, 'reg_alpha': 6.217996368362191, 'reg_lambda': 1.2110471790083293, 'n_estimators': 1017}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:10,056] Trial 45 finished with value: 0.5520361990950227 and parameters: {'max_depth': 6, 'min_child_weight': 0.016382653606452764, 'gamma': 0.08305590504673566, 'subsample': 0.7080425890095986, 'colsample_bytree': 0.9698061843445868, 'learning_rate': 0.15089628238870678, 'reg_alpha': 0.006411607881022862, 'reg_lambda': 0.08467677820553844, 'n_estimators': 1394}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:11,872] Trial 46 finished with value: 0.5714285714285714 and parameters: {'max_depth': 4, 'min_child_weight': 0.027543962096969004, 'gamma': 1.5904626028683757, 'subsample': 0.6143719313082355, 'colsample_bytree': 0.6763224086098142, 'learning_rate': 0.04289252205173265, 'reg_alpha': 9.574041506714815, 'reg_lambda': 0.467235620898231, 'n_estimators': 823}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:13,410] Trial 47 finished with value: 0.5602836879432624 and parameters: {'max_depth': 5, 'min_child_weight': 0.2818502711117734, 'gamma': 4.756872586389003, 'subsample': 0.6795437730979562, 'colsample_bytree': 0.5937002125052256, 'learning_rate': 0.08906246828293839, 'reg_alpha': 0.4972196690960614, 'reg_lambda': 0.013467186774414832, 'n_estimators': 689}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:15,940] Trial 48 finished with value: 0.574468085106383 and parameters: {'max_depth': 12, 'min_child_weight': 4.809229948030982, 'gamma': 4.010151983064948, 'subsample': 0.8182924461063258, 'colsample_bytree': 0.7428667892573726, 'learning_rate': 0.024462401773196626, 'reg_alpha': 0.0013698039876549686, 'reg_lambda': 3.5387238499906233, 'n_estimators': 1229}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:18,385] Trial 49 finished with value: 0.5681818181818182 and parameters: {'max_depth': 7, 'min_child_weight': 0.04960057400989947, 'gamma': 1.9896279465652242, 'subsample': 0.7873746638025569, 'colsample_bytree': 0.8154720731081618, 'learning_rate': 0.06140048377685333, 'reg_alpha': 4.0422553259265306e-05, 'reg_lambda': 0.10924049408738166, 'n_estimators': 233}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:22,857] Trial 50 finished with value: 0.5576923076923077 and parameters: {'max_depth': 9, 'min_child_weight': 0.11159093908751103, 'gamma': 2.92580006155862, 'subsample': 0.747135397364004, 'colsample_bytree': 0.8903094299497483, 'learning_rate': 0.015464324474847448, 'reg_alpha': 0.00014172471760157669, 'reg_lambda': 0.0014412510493797671, 'n_estimators': 922}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:25,133] Trial 51 finished with value: 0.5693430656934306 and parameters: {'max_depth': 4, 'min_child_weight': 0.07474219032082581, 'gamma': 3.766842841265575, 'subsample': 0.8504477141905595, 'colsample_bytree': 0.862364149555202, 'learning_rate': 0.028354938608133567, 'reg_alpha': 9.531361334704733e-07, 'reg_lambda': 1.5580164125470855e-07, 'n_estimators': 1992}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:26,571] Trial 52 finished with value: 0.5661764705882353 and parameters: {'max_depth': 3, 'min_child_weight': 0.027056614927493387, 'gamma': 2.437997858361945, 'subsample': 0.8905623209563588, 'colsample_bytree': 0.8372150981076432, 'learning_rate': 0.03874662607363225, 'reg_alpha': 2.7622904256905696e-06, 'reg_lambda': 1.0772039967090916, 'n_estimators': 1635}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:28,724] Trial 53 finished with value: 0.568561872909699 and parameters: {'max_depth': 4, 'min_child_weight': 0.03664896935591468, 'gamma': 3.451685337379554, 'subsample': 0.9173247330067341, 'colsample_bytree': 0.9238158871938752, 'learning_rate': 0.018721768824831325, 'reg_alpha': 0.0125388904717048, 'reg_lambda': 9.921161915857317, 'n_estimators': 1101}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:34,651] Trial 54 finished with value: 0.5661538461538461 and parameters: {'max_depth': 6, 'min_child_weight': 0.9040163330291967, 'gamma': 4.316646071215418, 'subsample': 0.7722569689574006, 'colsample_bytree': 0.999377828251694, 'learning_rate': 0.0064009940755973644, 'reg_alpha': 1.5423767988054976e-07, 'reg_lambda': 0.03223033469852326, 'n_estimators': 1840}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:36,517] Trial 55 finished with value: 0.5494505494505495 and parameters: {'max_depth': 5, 'min_child_weight': 0.1356159241538358, 'gamma': 2.915393597521126, 'subsample': 0.8138934352550213, 'colsample_bytree': 0.8022791985102514, 'learning_rate': 0.08326626903910783, 'reg_alpha': 0.17897060410446095, 'reg_lambda': 2.1198440326455086, 'n_estimators': 979}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:38,210] Trial 56 finished with value: 0.5714285714285714 and parameters: {'max_depth': 3, 'min_child_weight': 0.30083841837877245, 'gamma': 4.1378791972778926, 'subsample': 0.7422115337369453, 'colsample_bytree': 0.8307665101802968, 'learning_rate': 0.0287990523352153, 'reg_alpha': 5.91034550747578e-08, 'reg_lambda': 7.35082311842153e-05, 'n_estimators': 477}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:45,966] Trial 57 finished with value: 0.5725190839694656 and parameters: {'max_depth': 11, 'min_child_weight': 0.01420828695564158, 'gamma': 3.156212687246239, 'subsample': 0.7170931894974201, 'colsample_bytree': 0.8682162968717404, 'learning_rate': 0.010038428574772, 'reg_alpha': 2.1026827705556287e-05, 'reg_lambda': 0.44156913244938, 'n_estimators': 1294}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:47,529] Trial 58 finished with value: 0.5517241379310345 and parameters: {'max_depth': 4, 'min_child_weight': 0.06238384215164077, 'gamma': 4.802831914484103, 'subsample': 0.8258912582215339, 'colsample_bytree': 0.7209541598053337, 'learning_rate': 0.05925826582436372, 'reg_alpha': 0.00433075588224666, 'reg_lambda': 0.21973519900836597, 'n_estimators': 1767}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:50,803] Trial 59 finished with value: 0.5823754789272031 and parameters: {'max_depth': 6, 'min_child_weight': 0.020214065391671043, 'gamma': 4.4076688886292095, 'subsample': 0.7964721026285791, 'colsample_bytree': 0.8908316416211158, 'learning_rate': 0.0141200614475175, 'reg_alpha': 0.0004426411791120945, 'reg_lambda': 0.007101637351268417, 'n_estimators': 819}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:54,412] Trial 60 finished with value: 0.5684210526315789 and parameters: {'max_depth': 6, 'min_child_weight': 0.024175454869640164, 'gamma': 4.528472684673029, 'subsample': 0.7912981576882642, 'colsample_bytree': 0.9436141681411753, 'learning_rate': 0.0068801466827012195, 'reg_alpha': 0.0004954813104875102, 'reg_lambda': 0.0001821779252285436, 'n_estimators': 814}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:58:57,690] Trial 61 finished with value: 0.5609756097560976 and parameters: {'max_depth': 6, 'min_child_weight': 0.019890085273952817, 'gamma': 4.986798495698427, 'subsample': 0.7738733086244141, 'colsample_bytree': 0.8965791173944241, 'learning_rate': 0.015036867168877898, 'reg_alpha': 9.547613028892612e-05, 'reg_lambda': 0.006025299674328199, 'n_estimators': 747}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:00,252] Trial 62 finished with value: 0.5655172413793104 and parameters: {'max_depth': 5, 'min_child_weight': 0.045485234088191905, 'gamma': 4.367949214128321, 'subsample': 0.8042813077448502, 'colsample_bytree': 0.9691547465158398, 'learning_rate': 0.02015545226546015, 'reg_alpha': 0.04992918572443592, 'reg_lambda': 0.001609427158899639, 'n_estimators': 861}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:02,690] Trial 63 finished with value: 0.576 and parameters: {'max_depth': 4, 'min_child_weight': 0.08923345424234284, 'gamma': 3.879389871481936, 'subsample': 0.838572571095028, 'colsample_bytree': 0.8839008366398301, 'learning_rate': 0.012689016311529938, 'reg_alpha': 0.0009411936219886314, 'reg_lambda': 4.694585949551397, 'n_estimators': 950}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:05,216] Trial 64 finished with value: 0.5693950177935944 and parameters: {'max_depth': 7, 'min_child_weight': 0.012658774990746113, 'gamma': 3.6565781792155194, 'subsample': 0.8610999384951964, 'colsample_bytree': 0.9170986348435296, 'learning_rate': 0.03594899159920649, 'reg_alpha': 0.00034100364678509677, 'reg_lambda': 3.757418100766085e-08, 'n_estimators': 1932}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:06,564] Trial 65 finished with value: 0.5483870967741935 and parameters: {'max_depth': 8, 'min_child_weight': 15.692111936001373, 'gamma': 4.164957216753706, 'subsample': 0.5030428932866029, 'colsample_bytree': 0.8622574832381313, 'learning_rate': 0.10424113793025866, 'reg_alpha': 4.041082409749389e-06, 'reg_lambda': 0.0006794747277683298, 'n_estimators': 549}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:09,209] Trial 66 finished with value: 0.5704225352112676 and parameters: {'max_depth': 6, 'min_child_weight': 0.03661344312685865, 'gamma': 2.6759648160919847, 'subsample': 0.7524587849123774, 'colsample_bytree': 0.9378830221398216, 'learning_rate': 0.044822161537852505, 'reg_alpha': 0.09576448959180177, 'reg_lambda': 0.6591430036300308, 'n_estimators': 1114}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:13,014] Trial 67 finished with value: 0.5725190839694656 and parameters: {'max_depth': 5, 'min_child_weight': 1.6358357122366591, 'gamma': 3.3515812619235206, 'subsample': 0.6793727739558878, 'colsample_bytree': 0.9554826254625868, 'learning_rate': 0.009311410620748521, 'reg_alpha': 0.002886402986535567, 'reg_lambda': 2.5455116882297023e-05, 'n_estimators': 724}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:15,703] Trial 68 finished with value: 0.5517241379310345 and parameters: {'max_depth': 4, 'min_child_weight': 0.015982856207977892, 'gamma': 4.47919999515962, 'subsample': 0.9615998829198844, 'colsample_bytree': 0.902977440235898, 'learning_rate': 0.001217874751292683, 'reg_alpha': 1.3332756902622438e-08, 'reg_lambda': 0.027019558849629963, 'n_estimators': 1047}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:17,956] Trial 69 finished with value: 0.5668016194331984 and parameters: {'max_depth': 5, 'min_child_weight': 0.22939076517089677, 'gamma': 4.654247621579757, 'subsample': 0.9274996217200472, 'colsample_bytree': 0.7575003972713322, 'learning_rate': 0.022873226034033703, 'reg_alpha': 0.02128952146820621, 'reg_lambda': 6.356180574856369e-07, 'n_estimators': 1459}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:20,996] Trial 70 finished with value: 0.5634920634920635 and parameters: {'max_depth': 5, 'min_child_weight': 0.05798855672887614, 'gamma': 1.1913751379813484, 'subsample': 0.877360742952686, 'colsample_bytree': 0.7942067894135663, 'learning_rate': 0.0016393097731055885, 'reg_alpha': 3.292757729707128, 'reg_lambda': 0.1705674761594039, 'n_estimators': 317}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:23,531] Trial 71 finished with value: 0.5780730897009967 and parameters: {'max_depth': 4, 'min_child_weight': 0.03195738816822384, 'gamma': 3.3583954236263276, 'subsample': 0.7827336818061612, 'colsample_bytree': 0.8434176024062714, 'learning_rate': 0.01675510795009849, 'reg_alpha': 1.0733940814609437, 'reg_lambda': 1.6076430354904478, 'n_estimators': 1718}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:25,269] Trial 72 finished with value: 0.5734767025089605 and parameters: {'max_depth': 3, 'min_child_weight': 0.020161299856935665, 'gamma': 3.0506647493991683, 'subsample': 0.8013731725591491, 'colsample_bytree': 0.8207998831176848, 'learning_rate': 0.0227675600783344, 'reg_alpha': 0.0002228735531766578, 'reg_lambda': 2.677260480763646, 'n_estimators': 1591}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:27,352] Trial 73 finished with value: 0.5836909871244635 and parameters: {'max_depth': 4, 'min_child_weight': 0.08264443660942243, 'gamma': 3.7243339347405513, 'subsample': 0.7674813621119038, 'colsample_bytree': 0.7846043158502617, 'learning_rate': 0.013079133658515955, 'reg_alpha': 7.12870197349727e-05, 'reg_lambda': 5.3356574673508925, 'n_estimators': 1448}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:30,745] Trial 74 finished with value: 0.5743243243243243 and parameters: {'max_depth': 5, 'min_child_weight': 0.07732835060680897, 'gamma': 3.576489476872305, 'subsample': 0.7332617001929538, 'colsample_bytree': 0.8762704786072226, 'learning_rate': 0.013279949639142691, 'reg_alpha': 2.098784267188111e-05, 'reg_lambda': 5.833715705422, 'n_estimators': 1579}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:32,701] Trial 75 finished with value: 0.5896414342629482 and parameters: {'max_depth': 4, 'min_child_weight': 0.3798107869007197, 'gamma': 3.951240802406648, 'subsample': 0.7683216967952446, 'colsample_bytree': 0.7763629450647183, 'learning_rate': 0.007636097908322581, 'reg_alpha': 8.331131546543444e-06, 'reg_lambda': 0.8231719531417874, 'n_estimators': 1390}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:34,865] Trial 76 finished with value: 0.5666666666666667 and parameters: {'max_depth': 3, 'min_child_weight': 0.41086598533570073, 'gamma': 3.7837660226248095, 'subsample': 0.7699964622299862, 'colsample_bytree': 0.7285569050498492, 'learning_rate': 0.0074348220079711765, 'reg_alpha': 6.870846462077204e-06, 'reg_lambda': 0.8488783523458016, 'n_estimators': 1327}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:36,933] Trial 77 finished with value: 0.5791505791505791 and parameters: {'max_depth': 4, 'min_child_weight': 0.14543120535711246, 'gamma': 3.9662633645128853, 'subsample': 0.7132963845334626, 'colsample_bytree': 0.7811066406191335, 'learning_rate': 0.004573919300937797, 'reg_alpha': 9.854685145937928e-05, 'reg_lambda': 2.791381781082744, 'n_estimators': 1418}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:40,099] Trial 78 finished with value: 0.5746268656716418 and parameters: {'max_depth': 6, 'min_child_weight': 0.7061611270966822, 'gamma': 4.219937382135825, 'subsample': 0.762745122195896, 'colsample_bytree': 0.9802871167553402, 'learning_rate': 0.008145120288029922, 'reg_alpha': 5.645820507285649e-05, 'reg_lambda': 0.05405070582880612, 'n_estimators': 1526}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:43,991] Trial 79 finished with value: 0.5789473684210527 and parameters: {'max_depth': 8, 'min_child_weight': 0.5499244662493069, 'gamma': 4.066104521475651, 'subsample': 0.7292040912159398, 'colsample_bytree': 0.7687596074395712, 'learning_rate': 0.010782721152534556, 'reg_alpha': 2.6665641753615398e-05, 'reg_lambda': 0.29306718733746767, 'n_estimators': 1190}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:47,110] Trial 80 finished with value: 0.5754385964912281 and parameters: {'max_depth': 10, 'min_child_weight': 0.32405692437376155, 'gamma': 4.836530993776621, 'subsample': 0.7496652024863631, 'colsample_bytree': 0.7527998806615139, 'learning_rate': 0.011331948352171372, 'reg_alpha': 1.2159950075430573e-05, 'reg_lambda': 5.987372291926416, 'n_estimators': 1675}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:49,074] Trial 81 finished with value: 0.5855513307984791 and parameters: {'max_depth': 4, 'min_child_weight': 0.1997426848202567, 'gamma': 3.692796902430718, 'subsample': 0.7963022071774141, 'colsample_bytree': 0.8001364084263036, 'learning_rate': 0.00593150543844117, 'reg_alpha': 1.3271379968542045e-06, 'reg_lambda': 1.3407136271386964, 'n_estimators': 1016}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:52,763] Trial 82 finished with value: 0.5655172413793104 and parameters: {'max_depth': 4, 'min_child_weight': 0.4603309885637404, 'gamma': 4.434684822591209, 'subsample': 0.8237642195753876, 'colsample_bytree': 0.8084855658434685, 'learning_rate': 0.0037862282638429505, 'reg_alpha': 7.504441011283027e-07, 'reg_lambda': 1.3377127186200497, 'n_estimators': 1025}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:55,428] Trial 83 finished with value: 0.5793650793650794 and parameters: {'max_depth': 5, 'min_child_weight': 0.20639957019964683, 'gamma': 3.6609432269107653, 'subsample': 0.7942996816263203, 'colsample_bytree': 0.7902638798872565, 'learning_rate': 0.005592890502547944, 'reg_alpha': 1.6902393124854022e-06, 'reg_lambda': 0.6390909747335117, 'n_estimators': 847}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 22:59:57,726] Trial 84 finished with value: 0.5806451612903226 and parameters: {'max_depth': 3, 'min_child_weight': 0.20737432808731038, 'gamma': 4.609921097307768, 'subsample': 0.779966145513302, 'colsample_bytree': 0.774705230136004, 'learning_rate': 0.005671820854325819, 'reg_alpha': 1.0919943384562651e-05, 'reg_lambda': 3.501335818608426, 'n_estimators': 933}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:01,330] Trial 85 finished with value: 0.5737051792828686 and parameters: {'max_depth': 4, 'min_child_weight': 0.673054668989961, 'gamma': 3.50991799786603, 'subsample': 0.8448985605100121, 'colsample_bytree': 0.9092707020262019, 'learning_rate': 0.002474052795135412, 'reg_alpha': 0.0002039071941966365, 'reg_lambda': 1.8209745819655883, 'n_estimators': 1135}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:05,439] Trial 86 finished with value: 0.5703125 and parameters: {'max_depth': 5, 'min_child_weight': 0.022503000121137456, 'gamma': 0.48401281385550143, 'subsample': 0.8097983306647537, 'colsample_bytree': 0.7408820856123786, 'learning_rate': 0.007814787755928925, 'reg_alpha': 0.0006150030415442447, 'reg_lambda': 0.11375867805494962, 'n_estimators': 1059}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:07,530] Trial 87 finished with value: 0.5849802371541502 and parameters: {'max_depth': 4, 'min_child_weight': 0.011197290090643148, 'gamma': 3.9108729801720314, 'subsample': 0.7662312031084869, 'colsample_bytree': 0.7998020378431021, 'learning_rate': 0.009656427081118305, 'reg_alpha': 4.905513256892006e-06, 'reg_lambda': 6.885644489421189, 'n_estimators': 1238}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:09,553] Trial 88 finished with value: 0.5774647887323944 and parameters: {'max_depth': 4, 'min_child_weight': 0.12396494989091927, 'gamma': 3.2461778026559265, 'subsample': 0.7554078213608242, 'colsample_bytree': 0.801601089821797, 'learning_rate': 0.009412317373090019, 'reg_alpha': 3.9546393127516303e-07, 'reg_lambda': 9.932280078265395, 'n_estimators': 1266}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:12,262] Trial 89 finished with value: 0.5816733067729084 and parameters: {'max_depth': 3, 'min_child_weight': 0.0109898064951061, 'gamma': 3.7345701298859106, 'subsample': 0.7414287663202824, 'colsample_bytree': 0.7060683517902039, 'learning_rate': 0.004977933047854547, 'reg_alpha': 2.9337609748140074e-06, 'reg_lambda': 1.0374624803674442, 'n_estimators': 1320}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:13,642] Trial 90 finished with value: 0.5724137931034483 and parameters: {'max_depth': 4, 'min_child_weight': 0.18079538834073144, 'gamma': 3.9590843821148516, 'subsample': 0.7027873016056307, 'colsample_bytree': 0.7581485430472868, 'learning_rate': 0.13196477269268536, 'reg_alpha': 5.989848664883644e-06, 'reg_lambda': 5.5707391532344985, 'n_estimators': 1214}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:17,152] Trial 91 finished with value: 0.5694444444444444 and parameters: {'max_depth': 5, 'min_child_weight': 0.35255449646456744, 'gamma': 4.277602175175998, 'subsample': 0.762800339676473, 'colsample_bytree': 0.8251457600142198, 'learning_rate': 0.013349841569243476, 'reg_alpha': 6.263282637257805e-05, 'reg_lambda': 2.8120507160833306, 'n_estimators': 912}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:21,820] Trial 92 finished with value: 0.5735294117647058 and parameters: {'max_depth': 12, 'min_child_weight': 0.01549225293511278, 'gamma': 4.106486766432162, 'subsample': 0.7982068495259979, 'colsample_bytree': 0.9250829959903611, 'learning_rate': 0.017384333289788143, 'reg_alpha': 2.9549435718101574e-05, 'reg_lambda': 0.39389332002289956, 'n_estimators': 1349}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:25,063] Trial 93 finished with value: 0.5703971119133574 and parameters: {'max_depth': 4, 'min_child_weight': 0.0393168646279848, 'gamma': 3.854434785298662, 'subsample': 0.7852241375015713, 'colsample_bytree': 0.7859021596489253, 'learning_rate': 0.0069494724532126115, 'reg_alpha': 1.5897705270281096e-06, 'reg_lambda': 1.9192451018455197, 'n_estimators': 990}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:28,395] Trial 94 finished with value: 0.5752508361204013 and parameters: {'max_depth': 7, 'min_child_weight': 0.029638315694851307, 'gamma': 4.355451616381158, 'subsample': 0.7745217702265422, 'colsample_bytree': 0.8554402632645117, 'learning_rate': 0.01603707523106659, 'reg_alpha': 0.20383361279855444, 'reg_lambda': 3.9318378030798895, 'n_estimators': 1419}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:30,100] Trial 95 finished with value: 0.5765124555160143 and parameters: {'max_depth': 9, 'min_child_weight': 0.25989642734784696, 'gamma': 3.9773813387306, 'subsample': 0.814575517246759, 'colsample_bytree': 0.8128041722098197, 'learning_rate': 0.07394975928318245, 'reg_alpha': 3.459087745804584, 'reg_lambda': 0.006862009165975814, 'n_estimators': 795}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:37,683] Trial 96 finished with value: 0.5735849056603773 and parameters: {'max_depth': 11, 'min_child_weight': 0.012744608469226718, 'gamma': 1.8802228548846442, 'subsample': 0.8300557801771088, 'colsample_bytree': 0.885883239298484, 'learning_rate': 0.009118116134920086, 'reg_alpha': 3.7706881368441114e-06, 'reg_lambda': 0.0028715228553972414, 'n_estimators': 1151}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:39,579] Trial 97 finished with value: 0.5743243243243243 and parameters: {'max_depth': 3, 'min_child_weight': 0.018806368003293054, 'gamma': 2.330702504172361, 'subsample': 0.6896384523272922, 'colsample_bytree': 0.8352008507928163, 'learning_rate': 0.010300749910531972, 'reg_alpha': 0.001051983284362998, 'reg_lambda': 7.090822842398709, 'n_estimators': 1090}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:42,389] Trial 98 finished with value: 0.5736434108527132 and parameters: {'max_depth': 4, 'min_child_weight': 0.09243031470019303, 'gamma': 0.9782134421984623, 'subsample': 0.7413416712599993, 'colsample_bytree': 0.8952993074690812, 'learning_rate': 0.005905928348544529, 'reg_alpha': 9.96782169677013e-06, 'reg_lambda': 0.5585853095537505, 'n_estimators': 1497}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:46,083] Trial 99 finished with value: 0.5631768953068592 and parameters: {'max_depth': 5, 'min_child_weight': 0.025057753828523828, 'gamma': 4.189102165156308, 'subsample': 0.7263190091612375, 'colsample_bytree': 0.9479780683554295, 'learning_rate': 0.011967579767534934, 'reg_alpha': 1.6655287512309647e-05, 'reg_lambda': 1.0153851288616687, 'n_estimators': 966}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:49,505] Trial 100 finished with value: 0.5753424657534246 and parameters: {'max_depth': 6, 'min_child_weight': 0.010218526397079897, 'gamma': 1.6428329335359038, 'subsample': 0.8064750097075604, 'colsample_bytree': 0.7684661262913448, 'learning_rate': 0.032228494574270745, 'reg_alpha': 0.00012595093370996622, 'reg_lambda': 1.4797366950587507, 'n_estimators': 696}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:51,792] Trial 101 finished with value: 0.5760517799352751 and parameters: {'max_depth': 4, 'min_child_weight': 0.05031354792762053, 'gamma': 3.493508632318494, 'subsample': 0.7696629948319895, 'colsample_bytree': 0.8701795131295895, 'learning_rate': 0.026721500121893442, 'reg_alpha': 1.2178806389631574e-06, 'reg_lambda': 0.2608033503624349, 'n_estimators': 1379}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:53,863] Trial 102 finished with value: 0.5586206896551724 and parameters: {'max_depth': 4, 'min_child_weight': 0.08293679710311362, 'gamma': 3.083441967195236, 'subsample': 0.891560347932667, 'colsample_bytree': 0.8477073575161288, 'learning_rate': 0.05369781013501194, 'reg_alpha': 2.613250012080576e-07, 'reg_lambda': 1.0440164319522858e-05, 'n_estimators': 884}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:56,347] Trial 103 finished with value: 0.5724907063197026 and parameters: {'max_depth': 4, 'min_child_weight': 0.06250075803712793, 'gamma': 3.8189536069848016, 'subsample': 0.7550397781831679, 'colsample_bytree': 0.7940470845039013, 'learning_rate': 0.021281865186688696, 'reg_alpha': 6.541766963878892e-07, 'reg_lambda': 3.9334018894317992, 'n_estimators': 1880}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:00:58,559] Trial 104 finished with value: 0.5743243243243243 and parameters: {'max_depth': 4, 'min_child_weight': 0.046012440865600225, 'gamma': 3.64512910045355, 'subsample': 0.7941086967771959, 'colsample_bytree': 0.860720689850955, 'learning_rate': 0.01932120712849264, 'reg_alpha': 0.35369654731299993, 'reg_lambda': 0.00023451563047966305, 'n_estimators': 1017}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:01,366] Trial 105 finished with value: 0.5748031496062992 and parameters: {'max_depth': 5, 'min_child_weight': 0.10742426509353536, 'gamma': 3.267541588343416, 'subsample': 0.723379719147492, 'colsample_bytree': 0.8024445527727693, 'learning_rate': 0.01330802419531886, 'reg_alpha': 2.0981584305195622e-06, 'reg_lambda': 3.650672646548319e-06, 'n_estimators': 1552}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:03,083] Trial 106 finished with value: 0.5568627450980392 and parameters: {'max_depth': 3, 'min_child_weight': 0.014620291944179034, 'gamma': 4.7335508756158875, 'subsample': 0.7832796707185619, 'colsample_bytree': 0.9201575372750407, 'learning_rate': 0.030878735795719415, 'reg_alpha': 1.1402020207169732e-07, 'reg_lambda': 2.2392495692574075, 'n_estimators': 1712}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:05,876] Trial 107 finished with value: 0.570446735395189 and parameters: {'max_depth': 5, 'min_child_weight': 0.034271063650717415, 'gamma': 2.812768386481252, 'subsample': 0.7633386645952918, 'colsample_bytree': 0.9043057392932814, 'learning_rate': 0.014051269244072639, 'reg_alpha': 0.00037173711326864844, 'reg_lambda': 7.404913677213589, 'n_estimators': 1805}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:08,227] Trial 108 finished with value: 0.5813953488372093 and parameters: {'max_depth': 7, 'min_child_weight': 0.0677182292345356, 'gamma': 2.077499588330327, 'subsample': 0.8196535609913563, 'colsample_bytree': 0.8393102735430524, 'learning_rate': 0.06343398868562485, 'reg_alpha': 0.893230880956011, 'reg_lambda': 0.010481847652146188, 'n_estimators': 1261}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:10,594] Trial 109 finished with value: 0.5943775100401606 and parameters: {'max_depth': 4, 'min_child_weight': 0.16630571822886978, 'gamma': 3.4140595341245565, 'subsample': 0.8370076573477396, 'colsample_bytree': 0.8213922613832015, 'learning_rate': 0.055169732266555395, 'reg_alpha': 7.238119489500473e-06, 'reg_lambda': 0.00013062331565021084, 'n_estimators': 1201}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:11,968] Trial 110 finished with value: 0.5663082437275986 and parameters: {'max_depth': 4, 'min_child_weight': 0.24342976463650953, 'gamma': 4.429620238732817, 'subsample': 0.8345225325811869, 'colsample_bytree': 0.7470537497212059, 'learning_rate': 0.10870151686999063, 'reg_alpha': 3.688773489844122e-05, 'reg_lambda': 0.00014809828448589355, 'n_estimators': 1077}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:14,179] Trial 111 finished with value: 0.5612244897959183 and parameters: {'max_depth': 4, 'min_child_weight': 0.47243325919962986, 'gamma': 2.9886725191640675, 'subsample': 0.8707263720882182, 'colsample_bytree': 0.8193528448957523, 'learning_rate': 0.04409913064007482, 'reg_alpha': 4.233211467882469e-06, 'reg_lambda': 0.0005498735440109995, 'n_estimators': 1195}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:15,470] Trial 112 finished with value: 0.5737051792828686 and parameters: {'max_depth': 3, 'min_child_weight': 0.12240565765292048, 'gamma': 3.391374065206649, 'subsample': 0.8587469405051954, 'colsample_bytree': 0.7808540416312773, 'learning_rate': 0.056966489724396975, 'reg_alpha': 7.613239685133506e-06, 'reg_lambda': 0.02042560305345403, 'n_estimators': 1462}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:16,740] Trial 113 finished with value: 0.5681818181818182 and parameters: {'max_depth': 4, 'min_child_weight': 0.37641448601575855, 'gamma': 3.5621385746081633, 'subsample': 0.7764565813450539, 'colsample_bytree': 0.8313071765810043, 'learning_rate': 0.0904217433058519, 'reg_alpha': 1.0059217422904394e-06, 'reg_lambda': 1.0446077017493013e-07, 'n_estimators': 1118}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:18,453] Trial 114 finished with value: 0.5769230769230769 and parameters: {'max_depth': 4, 'min_child_weight': 0.18426092016532097, 'gamma': 4.045292204348218, 'subsample': 0.84542082270035, 'colsample_bytree': 0.876328680336803, 'learning_rate': 0.04996577544859204, 'reg_alpha': 2.415410086733767e-06, 'reg_lambda': 6.450329823539615e-07, 'n_estimators': 766}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:20,308] Trial 115 finished with value: 0.5684931506849316 and parameters: {'max_depth': 5, 'min_child_weight': 0.8506992325754558, 'gamma': 3.2580824094006546, 'subsample': 0.791392781336929, 'colsample_bytree': 0.8107619745714455, 'learning_rate': 0.038266867094872065, 'reg_alpha': 0.00201909257028242, 'reg_lambda': 2.6462903997409615e-05, 'n_estimators': 613}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:21,721] Trial 116 finished with value: 0.5726872246696035 and parameters: {'max_depth': 6, 'min_child_weight': 0.1581949504980839, 'gamma': 3.9039995812667994, 'subsample': 0.8019024404299278, 'colsample_bytree': 0.8490794682801124, 'learning_rate': 0.07702340796638077, 'reg_alpha': 1.7896340602818366e-05, 'reg_lambda': 1.1774118119329303e-08, 'n_estimators': 1943}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:23,827] Trial 117 finished with value: 0.5867768595041323 and parameters: {'max_depth': 5, 'min_child_weight': 0.09533608095580484, 'gamma': 3.7297676557990416, 'subsample': 0.7531493591662554, 'colsample_bytree': 0.7990496976945762, 'learning_rate': 0.008071577069262228, 'reg_alpha': 4.356420264242627, 'reg_lambda': 2.02499297585913e-08, 'n_estimators': 843}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:27,869] Trial 118 finished with value: 0.5681818181818182 and parameters: {'max_depth': 5, 'min_child_weight': 0.09348491574274846, 'gamma': 3.7450753521069853, 'subsample': 0.7453701566244367, 'colsample_bytree': 0.7987370972342199, 'learning_rate': 0.007474549766703671, 'reg_alpha': 1.2290305743790824, 'reg_lambda': 1.1890620214064549e-06, 'n_estimators': 839}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:30,682] Trial 119 finished with value: 0.5637583892617449 and parameters: {'max_depth': 5, 'min_child_weight': 0.13579379284074242, 'gamma': 1.317825828880291, 'subsample': 0.7368129929809448, 'colsample_bytree': 0.9640476241343638, 'learning_rate': 0.01058904313322707, 'reg_alpha': 3.365940374709127, 'reg_lambda': 0.7376812843052973, 'n_estimators': 901}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:32,618] Trial 120 finished with value: 0.5703703703703704 and parameters: {'max_depth': 5, 'min_child_weight': 0.016820746631819202, 'gamma': 3.6967713431692553, 'subsample': 0.7538592855888838, 'colsample_bytree': 0.761853869552505, 'learning_rate': 0.008648219061228325, 'reg_alpha': 2.394160186067337, 'reg_lambda': 4.492085526984303, 'n_estimators': 1298}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:33,639] Trial 121 finished with value: 0.5907473309608541 and parameters: {'max_depth': 4, 'min_child_weight': 0.07018388010320695, 'gamma': 3.560521295936218, 'subsample': 0.7677963220489532, 'colsample_bytree': 0.7752726593483433, 'learning_rate': 0.06893597674932479, 'reg_alpha': 6.805878947250819, 'reg_lambda': 2.0237858411025176e-08, 'n_estimators': 942}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:34,670] Trial 122 finished with value: 0.5724137931034483 and parameters: {'max_depth': 4, 'min_child_weight': 0.05461400399812807, 'gamma': 3.4498118307333985, 'subsample': 0.7677299061436217, 'colsample_bytree': 0.7788580963794232, 'learning_rate': 0.06999113805128401, 'reg_alpha': 6.261249290844319, 'reg_lambda': 1.3596553383959686e-07, 'n_estimators': 966}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:36,677] Trial 123 finished with value: 0.5723905723905723 and parameters: {'max_depth': 4, 'min_child_weight': 0.06978633856113185, 'gamma': 3.602420363639109, 'subsample': 0.7811488360310637, 'colsample_bytree': 0.7915356572636971, 'learning_rate': 0.0066480514763366345, 'reg_alpha': 9.034640304288972, 'reg_lambda': 2.159030779672936e-08, 'n_estimators': 1023}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:41,814] Trial 124 finished with value: 0.5666666666666667 and parameters: {'max_depth': 6, 'min_child_weight': 0.02120266556598913, 'gamma': 4.255476147824035, 'subsample': 0.814405973499954, 'colsample_bytree': 0.7675327478545216, 'learning_rate': 0.004934727810169523, 'reg_alpha': 3.557646241477237, 'reg_lambda': 4.4092452421548214e-08, 'n_estimators': 790}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:44,936] Trial 125 finished with value: 0.5658914728682171 and parameters: {'max_depth': 5, 'min_child_weight': 0.027256947870145657, 'gamma': 3.8681210254982314, 'subsample': 0.7094400878900031, 'colsample_bytree': 0.729624874920606, 'learning_rate': 0.011796854666631981, 'reg_alpha': 0.7082237550261726, 'reg_lambda': 1.8673008874673155e-08, 'n_estimators': 867}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:47,985] Trial 126 finished with value: 0.5737051792828686 and parameters: {'max_depth': 3, 'min_child_weight': 0.012266136964275073, 'gamma': 4.102875488800132, 'subsample': 0.7609977135716394, 'colsample_bytree': 0.9777822319146905, 'learning_rate': 0.0038172661801114836, 'reg_alpha': 6.432825484525856, 'reg_lambda': 6.891607378967407e-08, 'n_estimators': 937}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:49,361] Trial 127 finished with value: 0.5448504983388704 and parameters: {'max_depth': 4, 'min_child_weight': 0.04430909929276931, 'gamma': 2.568619595623308, 'subsample': 0.7872372176330245, 'colsample_bytree': 0.7752046460701683, 'learning_rate': 0.19894932694382036, 'reg_alpha': 0.00944919680855288, 'reg_lambda': 3.6421036817917596e-07, 'n_estimators': 1230}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:51,176] Trial 128 finished with value: 0.5823754789272031 and parameters: {'max_depth': 5, 'min_child_weight': 0.07800822976535082, 'gamma': 4.595353124983162, 'subsample': 0.7481308665186939, 'colsample_bytree': 0.7883977549618878, 'learning_rate': 0.01510500639704056, 'reg_alpha': 5.0168441425572174, 'reg_lambda': 2.579376713491347, 'n_estimators': 1167}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:53,108] Trial 129 finished with value: 0.5683453237410072 and parameters: {'max_depth': 4, 'min_child_weight': 0.10083152291574221, 'gamma': 3.776724332368098, 'subsample': 0.7720645872988416, 'colsample_bytree': 0.938608564428061, 'learning_rate': 0.009649155109565584, 'reg_alpha': 9.75128761540513, 'reg_lambda': 0.0011966807880901618, 'n_estimators': 1059}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:54,759] Trial 130 finished with value: 0.5555555555555556 and parameters: {'max_depth': 4, 'min_child_weight': 0.05771652213599286, 'gamma': 3.926861579794946, 'subsample': 0.7990327820001308, 'colsample_bytree': 0.750470730990641, 'learning_rate': 0.06636417565985793, 'reg_alpha': 7.20848689586443e-05, 'reg_lambda': 1.1876118275583067, 'n_estimators': 724}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:56,590] Trial 131 finished with value: 0.5780730897009967 and parameters: {'max_depth': 5, 'min_child_weight': 0.08008431611514084, 'gamma': 4.49519642540259, 'subsample': 0.746654577543005, 'colsample_bytree': 0.8080033739530156, 'learning_rate': 0.014969746713959262, 'reg_alpha': 4.232553381013384, 'reg_lambda': 2.7218050977296766, 'n_estimators': 1122}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:01:58,686] Trial 132 finished with value: 0.5813953488372093 and parameters: {'max_depth': 5, 'min_child_weight': 0.11427921394696462, 'gamma': 4.630423440595952, 'subsample': 0.7333534230428534, 'colsample_bytree': 0.7889377162287288, 'learning_rate': 0.018336195327510296, 'reg_alpha': 2.1561292397421625, 'reg_lambda': 1.587561690309717, 'n_estimators': 1168}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:00,601] Trial 133 finished with value: 0.5692883895131086 and parameters: {'max_depth': 6, 'min_child_weight': 0.07405767796518069, 'gamma': 4.891901209350373, 'subsample': 0.7518163322478377, 'colsample_bytree': 0.823705983521912, 'learning_rate': 0.007921127280913926, 'reg_alpha': 5.749428037302935, 'reg_lambda': 0.003441032600835655, 'n_estimators': 1003}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:01,940] Trial 134 finished with value: 0.5836575875486382 and parameters: {'max_depth': 5, 'min_child_weight': 0.30221638946198437, 'gamma': 4.550475880400416, 'subsample': 0.7155707489577207, 'colsample_bytree': 0.5612142677702796, 'learning_rate': 0.08554780528220696, 'reg_alpha': 1.501661937539259, 'reg_lambda': 6.146019940372269, 'n_estimators': 1091}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:03,528] Trial 135 finished with value: 0.5714285714285714 and parameters: {'max_depth': 4, 'min_child_weight': 0.304431783961226, 'gamma': 4.369098379572266, 'subsample': 0.7184231278958051, 'colsample_bytree': 0.9294227605556917, 'learning_rate': 0.07888813644599074, 'reg_alpha': 1.5660024841904647, 'reg_lambda': 5.860564955686718, 'n_estimators': 1047}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:04,875] Trial 136 finished with value: 0.5811320754716981 and parameters: {'max_depth': 9, 'min_child_weight': 0.33412720502854293, 'gamma': 4.155954660109664, 'subsample': 0.6942420202324148, 'colsample_bytree': 0.5406142578602946, 'learning_rate': 0.09348640593485096, 'reg_alpha': 2.5164561460961177, 'reg_lambda': 9.789154884664903, 'n_estimators': 825}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:06,339] Trial 137 finished with value: 0.5701357466063348 and parameters: {'max_depth': 5, 'min_child_weight': 0.4091826886661391, 'gamma': 3.511700757164603, 'subsample': 0.7770980399855235, 'colsample_bytree': 0.6080042686884795, 'learning_rate': 0.10395859340449963, 'reg_alpha': 6.2890622032889245e-06, 'reg_lambda': 3.7150566772405993, 'n_estimators': 932}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:09,415] Trial 138 finished with value: 0.5857740585774058 and parameters: {'max_depth': 7, 'min_child_weight': 0.27123210654025504, 'gamma': 4.000024341232321, 'subsample': 0.7629526491657668, 'colsample_bytree': 0.500257926008868, 'learning_rate': 0.00861145746919634, 'reg_alpha': 0.0031973987008679797, 'reg_lambda': 5.771124124613617, 'n_estimators': 988}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:12,014] Trial 139 finished with value: 0.5755395683453237 and parameters: {'max_depth': 8, 'min_child_weight': 0.22555494938422138, 'gamma': 4.026869682971544, 'subsample': 0.7245521756679952, 'colsample_bytree': 0.5144616416452106, 'learning_rate': 0.00737939185530959, 'reg_alpha': 0.00431466521533662, 'reg_lambda': 6.320396698647926, 'n_estimators': 980}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:15,340] Trial 140 finished with value: 0.5735294117647058 and parameters: {'max_depth': 7, 'min_child_weight': 0.20151534308654942, 'gamma': 3.68617170670265, 'subsample': 0.6687082874532249, 'colsample_bytree': 0.5725345656474479, 'learning_rate': 0.005518070478053174, 'reg_alpha': 0.28943836679575485, 'reg_lambda': 1.9920808196747766, 'n_estimators': 1097}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:17,835] Trial 141 finished with value: 0.5737051792828686 and parameters: {'max_depth': 6, 'min_child_weight': 0.25255849376367584, 'gamma': 4.330059512192403, 'subsample': 0.7595620908779893, 'colsample_bytree': 0.5526805337731147, 'learning_rate': 0.008648559328786642, 'reg_alpha': 0.01765751573527427, 'reg_lambda': 4.827015872127756, 'n_estimators': 909}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:23,252] Trial 142 finished with value: 0.563265306122449 and parameters: {'max_depth': 7, 'min_child_weight': 0.2788095058395743, 'gamma': 4.214641975023845, 'subsample': 0.7894410293760684, 'colsample_bytree': 0.7994324199442552, 'learning_rate': 0.006238923763534996, 'reg_alpha': 0.0002307690051496602, 'reg_lambda': 0.8313036579248358, 'n_estimators': 1641}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:24,578] Trial 143 finished with value: 0.5533333333333333 and parameters: {'max_depth': 6, 'min_child_weight': 0.5719714315481657, 'gamma': 3.8102002149128795, 'subsample': 0.7646817909823953, 'colsample_bytree': 0.5311755612902748, 'learning_rate': 0.1340974090379894, 'reg_alpha': 0.001012234133150255, 'reg_lambda': 3.4916383931812183, 'n_estimators': 1006}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:26,810] Trial 144 finished with value: 0.5806451612903226 and parameters: {'max_depth': 4, 'min_child_weight': 0.36425467560877356, 'gamma': 3.9685399841470907, 'subsample': 0.8042245501951474, 'colsample_bytree': 0.5227911720163466, 'learning_rate': 0.010529639798606187, 'reg_alpha': 0.08609361680241037, 'reg_lambda': 9.867115107560346, 'n_estimators': 1078}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:29,126] Trial 145 finished with value: 0.5692307692307692 and parameters: {'max_depth': 5, 'min_child_weight': 0.16922835279815382, 'gamma': 0.730052767194902, 'subsample': 0.7366492166132289, 'colsample_bytree': 0.6621730223817901, 'learning_rate': 0.05761007237987561, 'reg_alpha': 0.0024536942002393643, 'reg_lambda': 1.496365373637511, 'n_estimators': 864}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:32,066] Trial 146 finished with value: 0.5833333333333334 and parameters: {'max_depth': 6, 'min_child_weight': 0.039866160719480334, 'gamma': 1.7488536679768183, 'subsample': 0.7738189104982951, 'colsample_bytree': 0.6285695344185781, 'learning_rate': 0.012293622708983692, 'reg_alpha': 1.1059520824483967e-05, 'reg_lambda': 0.336889588230934, 'n_estimators': 978}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:37,438] Trial 147 finished with value: 0.5787234042553191 and parameters: {'max_depth': 6, 'min_child_weight': 0.0411229806030194, 'gamma': 1.587275050817664, 'subsample': 0.7745898322086077, 'colsample_bytree': 0.6279673758545697, 'learning_rate': 0.012079155182318627, 'reg_alpha': 1.136832115711786e-05, 'reg_lambda': 0.4085845469673807, 'n_estimators': 953}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:39,792] Trial 148 finished with value: 0.5747126436781609 and parameters: {'max_depth': 4, 'min_child_weight': 0.4957789876757395, 'gamma': 2.051065078911089, 'subsample': 0.7670513425791665, 'colsample_bytree': 0.5032585672823008, 'learning_rate': 0.009452018837537348, 'reg_alpha': 2.7010902762438054e-05, 'reg_lambda': 0.9622048760467784, 'n_estimators': 1040}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:40,803] Trial 149 finished with value: 0.5641025641025641 and parameters: {'max_depth': 4, 'min_child_weight': 0.032617196810703054, 'gamma': 3.65286605838368, 'subsample': 0.7813682414296702, 'colsample_bytree': 0.5455019460501388, 'learning_rate': 0.09735087568388522, 'reg_alpha': 3.4899909053454306e-06, 'reg_lambda': 2.258805068472412, 'n_estimators': 1141}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:42,387] Trial 150 finished with value: 0.5536332179930796 and parameters: {'max_depth': 3, 'min_child_weight': 0.054723220724583806, 'gamma': 1.5008594778675424, 'subsample': 0.7538518352744773, 'colsample_bytree': 0.6178325478347655, 'learning_rate': 0.0850437379523516, 'reg_alpha': 1.6710427614852765e-05, 'reg_lambda': 0.49164087226994624, 'n_estimators': 1217}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:45,583] Trial 151 finished with value: 0.5891472868217055 and parameters: {'max_depth': 6, 'min_child_weight': 0.03755613496804655, 'gamma': 2.2377502741594655, 'subsample': 0.7909470592060946, 'colsample_bytree': 0.715892950496461, 'learning_rate': 0.0132862037250703, 'reg_alpha': 0.0006956973533454885, 'reg_lambda': 0.1249599870832377, 'n_estimators': 1409}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:47,954] Trial 152 finished with value: 0.5517241379310345 and parameters: {'max_depth': 6, 'min_child_weight': 0.037977974432063605, 'gamma': 1.7528735290199182, 'subsample': 0.7899751953963491, 'colsample_bytree': 0.5790078616623895, 'learning_rate': 0.011346310214187612, 'reg_alpha': 0.0007565077506177834, 'reg_lambda': 0.16562966731101444, 'n_estimators': 1352}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:51,792] Trial 153 finished with value: 0.5543071161048689 and parameters: {'max_depth': 7, 'min_child_weight': 0.04804300789382753, 'gamma': 2.2666477872888295, 'subsample': 0.7410026274676975, 'colsample_bytree': 0.6911211450355657, 'learning_rate': 0.00839998078658583, 'reg_alpha': 8.814440254543585e-06, 'reg_lambda': 0.07433905034941214, 'n_estimators': 1398}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:56,577] Trial 154 finished with value: 0.5809128630705395 and parameters: {'max_depth': 10, 'min_child_weight': 0.030883115836023635, 'gamma': 2.182651014531173, 'subsample': 0.8184112732797107, 'colsample_bytree': 0.5545076592282895, 'learning_rate': 0.01257578324511488, 'reg_alpha': 5.388216852950727e-06, 'reg_lambda': 0.34395813515943735, 'n_estimators': 1432}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:02:59,369] Trial 155 finished with value: 0.5602836879432624 and parameters: {'max_depth': 6, 'min_child_weight': 0.2977957890765387, 'gamma': 1.977479379206807, 'subsample': 0.5714646346470946, 'colsample_bytree': 0.7157256290470004, 'learning_rate': 0.016184207370693426, 'reg_alpha': 0.0035598872339269744, 'reg_lambda': 0.11746060323195895, 'n_estimators': 1477}. Best is trial 35 with value: 0.5949820788530465.\n",
      "[I 2025-09-09 23:03:00,824] Trial 156 finished with value: 0.5964912280701754 and parameters: {'max_depth': 5, 'min_child_weight': 0.06273434009949207, 'gamma': 1.8559684593287955, 'subsample': 0.9973797998837368, 'colsample_bytree': 0.565368976062405, 'learning_rate': 0.06801857544774594, 'reg_alpha': 4.083476437988435e-05, 'reg_lambda': 6.548049501261917, 'n_estimators': 990}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:02,281] Trial 157 finished with value: 0.5695364238410596 and parameters: {'max_depth': 5, 'min_child_weight': 0.06596074871499909, 'gamma': 2.3353749305847957, 'subsample': 0.9754318748656193, 'colsample_bytree': 0.6545068774402856, 'learning_rate': 0.06428942215709729, 'reg_alpha': 0.007295387617532557, 'reg_lambda': 5.704798302524377, 'n_estimators': 1282}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:03,829] Trial 158 finished with value: 0.5735294117647058 and parameters: {'max_depth': 5, 'min_child_weight': 0.15743893737680617, 'gamma': 2.4354427082985124, 'subsample': 0.9116706469779398, 'colsample_bytree': 0.5964586365379017, 'learning_rate': 0.07389218419253578, 'reg_alpha': 4.350772580438692e-05, 'reg_lambda': 3.1184340764316345, 'n_estimators': 1080}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:05,585] Trial 159 finished with value: 0.5693430656934306 and parameters: {'max_depth': 5, 'min_child_weight': 0.4273424421116774, 'gamma': 2.1943641739379487, 'subsample': 0.940944492564697, 'colsample_bytree': 0.5706775871174958, 'learning_rate': 0.04979349055044262, 'reg_alpha': 0.0013679910402806363, 'reg_lambda': 7.547701857647848, 'n_estimators': 1554}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:06,893] Trial 160 finished with value: 0.5758754863813229 and parameters: {'max_depth': 4, 'min_child_weight': 0.055902410129470254, 'gamma': 3.497781581090167, 'subsample': 0.7581897201036183, 'colsample_bytree': 0.7730376428294035, 'learning_rate': 0.08289290576022626, 'reg_alpha': 0.00015777025258089243, 'reg_lambda': 5.17880707417104, 'n_estimators': 1024}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:09,286] Trial 161 finished with value: 0.5842696629213483 and parameters: {'max_depth': 5, 'min_child_weight': 0.043442811142220615, 'gamma': 1.9310354652965658, 'subsample': 0.7668990053862172, 'colsample_bytree': 0.646814851446412, 'learning_rate': 0.007074173789072466, 'reg_alpha': 5.5967752111888626e-05, 'reg_lambda': 1.1709046637000184, 'n_estimators': 984}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:11,550] Trial 162 finished with value: 0.584 and parameters: {'max_depth': 5, 'min_child_weight': 0.04463870255839802, 'gamma': 1.9537621576159359, 'subsample': 0.7672282064829725, 'colsample_bytree': 0.6708239078874767, 'learning_rate': 0.00655843251662211, 'reg_alpha': 5.087769037045406e-05, 'reg_lambda': 1.2290918601392467, 'n_estimators': 931}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:15,168] Trial 163 finished with value: 0.5739910313901345 and parameters: {'max_depth': 5, 'min_child_weight': 0.046537151109146295, 'gamma': 2.0883612287115776, 'subsample': 0.783206169866843, 'colsample_bytree': 0.6831126038852982, 'learning_rate': 0.00661986442153046, 'reg_alpha': 6.529194082517869e-05, 'reg_lambda': 1.101407951922419, 'n_estimators': 900}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:18,881] Trial 164 finished with value: 0.5801526717557252 and parameters: {'max_depth': 5, 'min_child_weight': 0.062415695396887426, 'gamma': 1.9325786396631022, 'subsample': 0.7631292692978903, 'colsample_bytree': 0.7399147586584967, 'learning_rate': 0.007404054885580409, 'reg_alpha': 4.147544025709053e-05, 'reg_lambda': 1.9554954173046353, 'n_estimators': 968}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:22,846] Trial 165 finished with value: 0.5657370517928287 and parameters: {'max_depth': 4, 'min_child_weight': 0.08577976850024298, 'gamma': 1.889375626734687, 'subsample': 0.8084314085614506, 'colsample_bytree': 0.669137068318494, 'learning_rate': 0.004421641244040293, 'reg_alpha': 0.00010799629802371638, 'reg_lambda': 0.625389917637864, 'n_estimators': 939}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:27,756] Trial 166 finished with value: 0.5680933852140078 and parameters: {'max_depth': 5, 'min_child_weight': 0.034823631351920764, 'gamma': 1.7339128992310624, 'subsample': 0.7693209758130215, 'colsample_bytree': 0.9885077126225972, 'learning_rate': 0.005285681933993566, 'reg_alpha': 2.4529454368092123e-05, 'reg_lambda': 1.1647487401741659, 'n_estimators': 1003}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:29,606] Trial 167 finished with value: 0.5925925925925926 and parameters: {'max_depth': 4, 'min_child_weight': 0.04333732020506517, 'gamma': 2.003492197842646, 'subsample': 0.7960681746973296, 'colsample_bytree': 0.7036225562024967, 'learning_rate': 0.006236951818351517, 'reg_alpha': 8.674880021115633e-05, 'reg_lambda': 3.1230123596161645, 'n_estimators': 999}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:31,543] Trial 168 finished with value: 0.5860805860805861 and parameters: {'max_depth': 4, 'min_child_weight': 0.026119068421696454, 'gamma': 1.9778208781755193, 'subsample': 0.7952813939170429, 'colsample_bytree': 0.6507574301308965, 'learning_rate': 0.006984846468896924, 'reg_alpha': 0.00023148167692263602, 'reg_lambda': 2.9382502344230166, 'n_estimators': 881}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:34,842] Trial 169 finished with value: 0.5704225352112676 and parameters: {'max_depth': 4, 'min_child_weight': 0.05039495809894848, 'gamma': 1.8403522417733091, 'subsample': 0.8237589995272219, 'colsample_bytree': 0.6475819882566568, 'learning_rate': 0.006088847675631879, 'reg_alpha': 0.00020193681393627965, 'reg_lambda': 3.1086804112053197, 'n_estimators': 884}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:37,299] Trial 170 finished with value: 0.5827338129496403 and parameters: {'max_depth': 4, 'min_child_weight': 0.041269588083538665, 'gamma': 2.0179784264915117, 'subsample': 0.7982490246207956, 'colsample_bytree': 0.6898841686793625, 'learning_rate': 0.0068078654613410745, 'reg_alpha': 9.088457009443792e-05, 'reg_lambda': 1.6137367259515238, 'n_estimators': 930}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:39,047] Trial 171 finished with value: 0.5314285714285715 and parameters: {'max_depth': 4, 'min_child_weight': 0.0263997716237997, 'gamma': 2.141154391800129, 'subsample': 0.7916176126757387, 'colsample_bytree': 0.6987894336048636, 'learning_rate': 0.00812231631725883, 'reg_alpha': 0.00030699379368787734, 'reg_lambda': 0.036173624557275526, 'n_estimators': 837}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:41,426] Trial 172 finished with value: 0.5637583892617449 and parameters: {'max_depth': 5, 'min_child_weight': 0.029072356595694532, 'gamma': 1.9869095404660815, 'subsample': 0.7793617139318771, 'colsample_bytree': 0.6694318546454354, 'learning_rate': 0.006071994868589535, 'reg_alpha': 0.0004474744452314375, 'reg_lambda': 2.2960880938470054, 'n_estimators': 1041}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:42,423] Trial 173 finished with value: 0.5734767025089605 and parameters: {'max_depth': 4, 'min_child_weight': 0.03648916717920717, 'gamma': 2.2381354805589533, 'subsample': 0.9987399327085781, 'colsample_bytree': 0.6468965225287863, 'learning_rate': 0.2819671386056564, 'reg_alpha': 0.0390115861595653, 'reg_lambda': 0.7392686012343703, 'n_estimators': 982}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:46,083] Trial 174 finished with value: 0.5672727272727273 and parameters: {'max_depth': 4, 'min_child_weight': 0.046945755375231095, 'gamma': 1.8382338181080926, 'subsample': 0.8067980006563811, 'colsample_bytree': 0.6381265112092303, 'learning_rate': 0.004340353774420028, 'reg_alpha': 0.00013619301492876504, 'reg_lambda': 2.5956914710168193e-08, 'n_estimators': 879}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:50,842] Trial 175 finished with value: 0.5581395348837209 and parameters: {'max_depth': 8, 'min_child_weight': 0.0239654907357962, 'gamma': 1.6804949745765811, 'subsample': 0.7510458599706547, 'colsample_bytree': 0.7029922094829353, 'learning_rate': 0.007179318881441694, 'reg_alpha': 3.626043333598842e-05, 'reg_lambda': 3.7064166423925613, 'n_estimators': 944}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:52,967] Trial 176 finished with value: 0.5617021276595745 and parameters: {'max_depth': 5, 'min_child_weight': 0.014086296776285052, 'gamma': 2.072731389862904, 'subsample': 0.784573899267577, 'colsample_bytree': 0.7318427879080354, 'learning_rate': 0.009231451834016075, 'reg_alpha': 0.0005794682813239576, 'reg_lambda': 1.5018770200439042, 'n_estimators': 994}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:55,441] Trial 177 finished with value: 0.5746268656716418 and parameters: {'max_depth': 5, 'min_child_weight': 0.01805306379789222, 'gamma': 2.3924233027944624, 'subsample': 0.7994000036074022, 'colsample_bytree': 0.7185124511792698, 'learning_rate': 0.010077755284165107, 'reg_alpha': 5.784846801264593e-05, 'reg_lambda': 2.556702363157091, 'n_estimators': 921}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:57,204] Trial 178 finished with value: 0.5602605863192183 and parameters: {'max_depth': 4, 'min_child_weight': 0.05996181665649148, 'gamma': 1.9707543331752324, 'subsample': 0.7703801200221498, 'colsample_bytree': 0.7564938399791293, 'learning_rate': 0.005302724387896433, 'reg_alpha': 0.00030386082985644916, 'reg_lambda': 5.6942794911838825e-06, 'n_estimators': 763}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:03:59,458] Trial 179 finished with value: 0.5757575757575758 and parameters: {'max_depth': 4, 'min_child_weight': 0.031768757024235345, 'gamma': 1.4436407231061121, 'subsample': 0.7932180197979023, 'colsample_bytree': 0.6718263995450352, 'learning_rate': 0.0066189340352017815, 'reg_alpha': 1.944601671757239e-05, 'reg_lambda': 0.9355635537536019, 'n_estimators': 1049}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:01,225] Trial 180 finished with value: 0.5714285714285714 and parameters: {'max_depth': 3, 'min_child_weight': 0.011269322193497794, 'gamma': 3.844884468231164, 'subsample': 0.7573557512951652, 'colsample_bytree': 0.6844066355854906, 'learning_rate': 0.007852364377510435, 'reg_alpha': 9.88545823121554, 'reg_lambda': 4.04404384513379, 'n_estimators': 797}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:04,772] Trial 181 finished with value: 0.5664335664335665 and parameters: {'max_depth': 4, 'min_child_weight': 0.04303566565869409, 'gamma': 2.5233625750972593, 'subsample': 0.7759379956262537, 'colsample_bytree': 0.8022342047932731, 'learning_rate': 0.008458172749179529, 'reg_alpha': 8.32619453873523e-05, 'reg_lambda': 4.492194160286313, 'n_estimators': 1340}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:06,653] Trial 182 finished with value: 0.5724137931034483 and parameters: {'max_depth': 4, 'min_child_weight': 0.06652854796696508, 'gamma': 2.1127879130082414, 'subsample': 0.7426095372064995, 'colsample_bytree': 0.7798810025111684, 'learning_rate': 0.058786294140883495, 'reg_alpha': 0.00014692293752499764, 'reg_lambda': 4.319835562085668e-08, 'n_estimators': 1501}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:09,526] Trial 183 finished with value: 0.5853658536585366 and parameters: {'max_depth': 4, 'min_child_weight': 0.0528087389032218, 'gamma': 1.1963237421144035, 'subsample': 0.7623359846589964, 'colsample_bytree': 0.7628682700721215, 'learning_rate': 0.005862038857357151, 'reg_alpha': 5.1637115020221734e-05, 'reg_lambda': 7.715467663519548, 'n_estimators': 1015}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:13,589] Trial 184 finished with value: 0.5767790262172284 and parameters: {'max_depth': 4, 'min_child_weight': 0.054110382709107986, 'gamma': 1.3552283426414649, 'subsample': 0.7605781869029934, 'colsample_bytree': 0.7649465076640245, 'learning_rate': 0.00325945226161013, 'reg_alpha': 4.024573857908375e-05, 'reg_lambda': 1.0550354511820921e-08, 'n_estimators': 1012}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:15,661] Trial 185 finished with value: 0.5614035087719298 and parameters: {'max_depth': 4, 'min_child_weight': 0.03734951033516552, 'gamma': 1.1397047790938764, 'subsample': 0.783992425781979, 'colsample_bytree': 0.6536002169590542, 'learning_rate': 0.005762277164344861, 'reg_alpha': 0.00023281673515555796, 'reg_lambda': 9.96276275796475, 'n_estimators': 958}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:27,322] Trial 186 finished with value: 0.5615384615384615 and parameters: {'max_depth': 12, 'min_child_weight': 0.05124010515303748, 'gamma': 1.944714915326132, 'subsample': 0.631907899264758, 'colsample_bytree': 0.8191134572481157, 'learning_rate': 0.004972007712403949, 'reg_alpha': 4.9475867730314844e-05, 'reg_lambda': 1.9670971506134236, 'n_estimators': 855}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:29,556] Trial 187 finished with value: 0.5758754863813229 and parameters: {'max_depth': 5, 'min_child_weight': 0.023027854561323727, 'gamma': 2.3071328928647086, 'subsample': 0.7705808906943098, 'colsample_bytree': 0.7852684795111661, 'learning_rate': 0.007361318490018623, 'reg_alpha': 2.792565427154707e-05, 'reg_lambda': 7.019914524799004, 'n_estimators': 1119}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:32,773] Trial 188 finished with value: 0.5714285714285714 and parameters: {'max_depth': 4, 'min_child_weight': 0.044216053198321136, 'gamma': 1.022199639871194, 'subsample': 0.7313557957542088, 'colsample_bytree': 0.8102382114150694, 'learning_rate': 0.006299118281917035, 'reg_alpha': 1.3450472373288151e-05, 'reg_lambda': 3.21621522447052, 'n_estimators': 1039}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:35,470] Trial 189 finished with value: 0.5692883895131086 and parameters: {'max_depth': 5, 'min_child_weight': 0.061140932694843594, 'gamma': 1.5047488010302819, 'subsample': 0.7472607931193949, 'colsample_bytree': 0.7479019070299845, 'learning_rate': 0.009165740042390928, 'reg_alpha': 0.00010895442999738438, 'reg_lambda': 0.5662314838398017, 'n_estimators': 907}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:37,936] Trial 190 finished with value: 0.5637583892617449 and parameters: {'max_depth': 7, 'min_child_weight': 0.02848908866093632, 'gamma': 1.2736092704604371, 'subsample': 0.8124486289157139, 'colsample_bytree': 0.9523075518206169, 'learning_rate': 0.06746144026931782, 'reg_alpha': 6.613741492592679e-06, 'reg_lambda': 1.29159247692989, 'n_estimators': 964}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:40,542] Trial 191 finished with value: 0.5842696629213483 and parameters: {'max_depth': 4, 'min_child_weight': 0.07308213581488368, 'gamma': 3.7555328235420413, 'subsample': 0.7617648108153191, 'colsample_bytree': 0.7940620559834047, 'learning_rate': 0.010459809101582876, 'reg_alpha': 5.821459100878263e-05, 'reg_lambda': 4.525894507362298, 'n_estimators': 1069}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:42,540] Trial 192 finished with value: 0.5833333333333334 and parameters: {'max_depth': 4, 'min_child_weight': 0.07216892828472914, 'gamma': 3.6209396228239012, 'subsample': 0.7629329787509183, 'colsample_bytree': 0.7932966335368276, 'learning_rate': 0.010777657057312026, 'reg_alpha': 7.19098797443997e-05, 'reg_lambda': 4.834731942331882, 'n_estimators': 1082}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:44,378] Trial 193 finished with value: 0.5789473684210527 and parameters: {'max_depth': 4, 'min_child_weight': 0.09291438163518057, 'gamma': 3.399039814775131, 'subsample': 0.7775675289337278, 'colsample_bytree': 0.7681626949419685, 'learning_rate': 0.008012204759735707, 'reg_alpha': 0.00016299687804522742, 'reg_lambda': 2.497415440523463, 'n_estimators': 1006}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:46,200] Trial 194 finished with value: 0.5714285714285714 and parameters: {'max_depth': 4, 'min_child_weight': 0.05125614782508577, 'gamma': 1.2343370026902256, 'subsample': 0.7894369961606177, 'colsample_bytree': 0.7765659928055721, 'learning_rate': 0.006924915222234958, 'reg_alpha': 4.790172716177678, 'reg_lambda': 7.110035055553183, 'n_estimators': 1068}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:49,405] Trial 195 finished with value: 0.5639097744360902 and parameters: {'max_depth': 4, 'min_child_weight': 0.0713286804781873, 'gamma': 3.7657502959654017, 'subsample': 0.753870558573111, 'colsample_bytree': 0.7583449240738274, 'learning_rate': 0.005754990508860958, 'reg_alpha': 5.4285164294959066e-05, 'reg_lambda': 2.379769038988483e-05, 'n_estimators': 1137}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:52,855] Trial 196 finished with value: 0.5633802816901409 and parameters: {'max_depth': 5, 'min_child_weight': 0.13123209893668716, 'gamma': 4.019521578873912, 'subsample': 0.7665264047714249, 'colsample_bytree': 0.7981160931697563, 'learning_rate': 0.009053695840312098, 'reg_alpha': 2.9362398395446588e-05, 'reg_lambda': 3.280943496281401, 'n_estimators': 1021}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:54,098] Trial 197 finished with value: 0.5647058823529412 and parameters: {'max_depth': 3, 'min_child_weight': 0.04003920024141955, 'gamma': 1.8193821977269673, 'subsample': 0.7466863273976734, 'colsample_bytree': 0.8096731868241267, 'learning_rate': 0.024623653247255323, 'reg_alpha': 1.6269779425981865e-05, 'reg_lambda': 1.6774496144673445, 'n_estimators': 977}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:56,577] Trial 198 finished with value: 0.5824561403508772 and parameters: {'max_depth': 4, 'min_child_weight': 0.23286123487702368, 'gamma': 3.879618082852181, 'subsample': 0.7748349561586045, 'colsample_bytree': 0.9113848552617563, 'learning_rate': 0.010109856526204043, 'reg_alpha': 2.0873489704743756e-06, 'reg_lambda': 4.31270608955852, 'n_estimators': 1107}. Best is trial 156 with value: 0.5964912280701754.\n",
      "[I 2025-09-09 23:04:57,952] Trial 199 finished with value: 0.5682656826568265 and parameters: {'max_depth': 5, 'min_child_weight': 0.03333333949030912, 'gamma': 3.5397413169077176, 'subsample': 0.9589082668594773, 'colsample_bytree': 0.6591382966339377, 'learning_rate': 0.07157431012964338, 'reg_alpha': 9.833335105160301e-05, 'reg_lambda': 7.33761392129595, 'n_estimators': 1173}. Best is trial 156 with value: 0.5964912280701754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Optuna Best (VAL by chosen metric, XGB) ====\n",
      "Optimize metric: f1\n",
      "Best score: 0.5964912280701754\n",
      "Best params: {'max_depth': 5, 'min_child_weight': 0.06273434009949207, 'gamma': 1.8559684593287955, 'subsample': 0.9973797998837368, 'colsample_bytree': 0.565368976062405, 'learning_rate': 0.06801857544774594, 'reg_alpha': 4.083476437988435e-05, 'reg_lambda': 6.548049501261917, 'n_estimators': 990}\n",
      "Best VAL thr_source: f1\n",
      "Best VAL thr: 0.38\n",
      "Best VAL precision: 0.5037037037037037\n",
      "Best VAL recall: 0.7311827956989247\n",
      "Best VAL f1: 0.5964912280701754\n",
      "Best VAL pos_rate: 0.5252918287937743\n",
      "\n",
      "[Threshold] VAL selected via F1: t*=0.380, P=0.5037, R=0.7312, F1=0.5965, Acc=nan, Youden=nan\n",
      "\n",
      "==== Test Performance (held-out, with chosen threshold, XGB) ====\n",
      "AUC:           0.598783\n",
      "AveragePrecision(PR-AUC): 0.498312\n",
      "LogLoss:       0.676569\n",
      "Accuracy:      0.574534\n",
      "Precision@t*:  0.508571\n",
      "Recall@t*:     0.635714\n",
      "F1@t*:         0.565079\n",
      "(t* chosen on VAL: 0.380)\n",
      "\n",
      "Score PSI (TrainFit→Val):  0.0593\n",
      "Score PSI (TrainFit→Test): 0.0489\n"
     ]
    }
   ],
   "source": [
    "# ========= 全量可运行脚本：漂移检查 + 阈值策略 + 贝叶斯超参搜索\n",
    "# （XGBoost 原生API版，兼容老版本；支持“可切换评优指标 + 可配置阈值来源”）=========\n",
    "# 依赖：\n",
    "#   pip install numpy pandas scipy scikit-learn xgboost optuna\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, log_loss\n",
    ")\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "# ========= 公共工具 =========\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# ========= 0) XGBoost 原生训练/预测封装（适配所有版本） =========\n",
    "\n",
    "def _pack_xgb_params(params):\n",
    "    \"\"\"\n",
    "    将 Optuna/外部给的 sklearn 风格参数映射为 xgb.train 可用字典。\n",
    "    \"\"\"\n",
    "    p = dict(params) if params else {}\n",
    "    # 通用默认\n",
    "    p.setdefault(\"objective\", \"binary:logistic\")\n",
    "    p.setdefault(\"eval_metric\", \"auc\")\n",
    "    # 学习率名称差异\n",
    "    if \"learning_rate\" in p:\n",
    "        p[\"eta\"] = p.pop(\"learning_rate\")\n",
    "    # n_estimators 在 train 里用 num_boost_round 传，不放进 params\n",
    "    p.pop(\"n_estimators\", None)\n",
    "    # 一些 sklearn 专属键删除\n",
    "    for k in [\"verbosity\", \"n_jobs\", \"random_state\"]:\n",
    "        p.pop(k, None)\n",
    "    # 返回 xgb.train 用的参数\n",
    "    return p\n",
    "\n",
    "def train_xgb_booster(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    params,\n",
    "    num_boost_round=2000,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    用 xgb.train 训练，支持早停。返回 booster 对象。\n",
    "    \"\"\"\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    watchlist = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
    "    xgb_params = _pack_xgb_params(params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=xgb_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=watchlist,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=bool(verbose)\n",
    "    )\n",
    "    return booster\n",
    "\n",
    "def predict_proba_booster(booster, X):\n",
    "    \"\"\"\n",
    "    兼容不同 XGBoost 版本：优先使用 best_iteration / best_ntree_limit。\n",
    "    返回正类概率（shape: [n_samples]）。\n",
    "    \"\"\"\n",
    "    dtest = xgb.DMatrix(X)\n",
    "    # 新版本：有 best_iteration\n",
    "    best_iteration = getattr(booster, \"best_iteration\", None)\n",
    "    if best_iteration is not None:\n",
    "        # iteration_range 是新API；老版本不支持就走下面 ntree_limit\n",
    "        try:\n",
    "            return booster.predict(dtest, iteration_range=(0, best_iteration + 1))\n",
    "        except TypeError:\n",
    "            pass\n",
    "    # 较老版本：best_ntree_limit\n",
    "    best_ntree_limit = getattr(booster, \"best_ntree_limit\", None)\n",
    "    if best_ntree_limit is not None:\n",
    "        try:\n",
    "            return booster.predict(dtest, ntree_limit=best_ntree_limit)\n",
    "        except TypeError:\n",
    "            pass\n",
    "    # 最保守：不指定限制\n",
    "    return booster.predict(dtest)\n",
    "\n",
    "# ========= 1) 特征稳定性 / 漂移检查 =========\n",
    "\n",
    "def psi_for_series(train_s: pd.Series, test_s: pd.Series, bins=10):\n",
    "    \"\"\"Population Stability Index (PSI) for continuous variables. 使用训练分位数分箱\"\"\"\n",
    "    train_s = pd.to_numeric(train_s, errors='coerce')\n",
    "    test_s  = pd.to_numeric(test_s,  errors='coerce')\n",
    "    tr = train_s.dropna(); te = test_s.dropna()\n",
    "    if tr.empty or te.empty:\n",
    "        return np.nan\n",
    "    quantiles = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.unique(np.nanquantile(tr, quantiles))\n",
    "    if len(cuts) <= 2:\n",
    "        return np.nan\n",
    "    tr_bins = pd.cut(train_s, bins=cuts, include_lowest=True)\n",
    "    te_bins = pd.cut(test_s,  bins=cuts, include_lowest=True)\n",
    "    tr_ratio = tr_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_ratio.reindex(tr_ratio.index).fillna(0.0)\n",
    "    tr_ratio = tr_ratio.fillna(0.0)\n",
    "    tr_ratio = tr_ratio.replace(0, 1e-8)\n",
    "    te_ratio = te_ratio.replace(0, 1e-8)\n",
    "    psi = np.sum((te_ratio - tr_ratio) * np.log(te_ratio / tr_ratio))\n",
    "    return float(psi)\n",
    "\n",
    "def cat_psi(train_s: pd.Series, test_s: pd.Series):\n",
    "    \"\"\"PSI for categorical distributions.\"\"\"\n",
    "    tr_p = train_s.value_counts(normalize=True)\n",
    "    te_p = test_s.value_counts(normalize=True)\n",
    "    idx = tr_p.index.union(te_p.index)\n",
    "    tr_p = tr_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    te_p = te_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    psi = np.sum((te_p - tr_p) * np.log(te_p / tr_p))\n",
    "    return float(psi)\n",
    "\n",
    "def two_sample_drift(train_s: pd.Series, test_s: pd.Series, is_categorical=False):\n",
    "    \"\"\"连续：两样本KS；类别：卡方独立性（p越小漂移越显著）\"\"\"\n",
    "    if is_categorical:\n",
    "        idx = pd.Index(pd.concat([train_s.astype(str), test_s.astype(str)], ignore_index=True).unique())\n",
    "        tr_counts = train_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        te_counts = test_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        table = np.vstack([tr_counts.values, te_counts.values])\n",
    "        try:\n",
    "            chi2, p, dof, exp = chi2_contingency(table)\n",
    "        except ValueError:\n",
    "            p = 1.0\n",
    "        return {\"stat\": None, \"pvalue\": float(p)}\n",
    "    else:\n",
    "        tr = pd.to_numeric(train_s, errors='coerce').dropna()\n",
    "        te = pd.to_numeric(test_s,  errors='coerce').dropna()\n",
    "        if len(tr) < 2 or len(te) < 2:\n",
    "            return {\"stat\": None, \"pvalue\": np.nan}\n",
    "        ks = ks_2samp(tr, te, alternative='two-sided', mode='auto')\n",
    "        return {\"stat\": float(ks.statistic), \"pvalue\": float(ks.pvalue)}\n",
    "\n",
    "def drift_report(df_ref: pd.DataFrame, df_new: pd.DataFrame,\n",
    "                 categorical_cols=None, topk=15):\n",
    "    \"\"\"生成漂移报告（相对 df_ref）\"\"\"\n",
    "    categorical_cols = set(categorical_cols or [])\n",
    "    rows = []\n",
    "    for c in df_ref.columns:\n",
    "        is_cat = c in categorical_cols or (df_ref[c].dtype.name in [\"category\", \"object\"])\n",
    "        psi = cat_psi(df_ref[c], df_new[c]) if is_cat else psi_for_series(df_ref[c], df_new[c])\n",
    "        stat = two_sample_drift(df_ref[c], df_new[c], is_categorical=is_cat)\n",
    "        miss_ref = df_ref[c].isna().mean()\n",
    "        miss_new = df_new[c].isna().mean()\n",
    "        rows.append({\n",
    "            \"feature\": c,\n",
    "            \"is_categorical\": is_cat,\n",
    "            \"PSI\": psi,\n",
    "            \"KS/Chi2_p\": stat[\"pvalue\"],\n",
    "            \"KS_stat\": stat[\"stat\"],\n",
    "            \"missing_ref\": miss_ref,\n",
    "            \"missing_new\": miss_new,\n",
    "            \"missing_diff\": miss_new - miss_ref,\n",
    "        })\n",
    "    rep = pd.DataFrame(rows)\n",
    "    rep = rep.sort_values(by=[\"PSI\", \"KS/Chi2_p\"], ascending=[False, True]).reset_index(drop=True)\n",
    "    return rep.iloc[:topk]\n",
    "\n",
    "# ========= 2) 阈值策略 =========\n",
    "\n",
    "def choose_threshold(\n",
    "    y_true, y_prob,\n",
    "    method=\"f1\",                # \"f1\" | \"youden\" | \"constraint\" | \"posrate\"\n",
    "    grid=None,\n",
    "    min_precision=None,\n",
    "    min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    \"\"\"返回 best_thr, metrics_at_thr(dict), table(DataFrame: 各阈值指标)\"\"\"\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.01, 0.99, 99)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    out_rows = []\n",
    "    best_thr, best_key = 0.5, (-1e9, -1e9)\n",
    "\n",
    "    for t in grid:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        P  = precision_score(y_true, pred, zero_division=0)\n",
    "        R  = recall_score(y_true, pred, zero_division=0)\n",
    "        F1 = f1_score(y_true, pred, zero_division=0)\n",
    "        tn = np.sum((pred==0)&(y_true==0))\n",
    "        fp = np.sum((pred==1)&(y_true==0))\n",
    "        fn = np.sum((pred==0)&(y_true==1))\n",
    "        tp = np.sum((pred==1)&(y_true==1))\n",
    "        TNR = tn / max(1, (tn+fp))\n",
    "        J = R + TNR - 1\n",
    "        pos_rate = pred.mean()\n",
    "\n",
    "        out_rows.append({\"thr\": t, \"precision\": P, \"recall\": R, \"f1\": F1,\n",
    "                         \"youdenJ\": J, \"pos_rate\": pos_rate, \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn})\n",
    "\n",
    "        if method == \"f1\":\n",
    "            key = (F1, 0.0)\n",
    "        elif method == \"youden\":\n",
    "            key = (J, 0.0)\n",
    "        elif method == \"posrate\" and target_pos_rate is not None:\n",
    "            key = (-abs(pos_rate - target_pos_rate), 0.0)\n",
    "        elif method == \"constraint\":\n",
    "            if (min_precision is not None and P < min_precision) or (min_recall is not None and R < min_recall):\n",
    "                key = (-1e9, -1e9)\n",
    "            else:\n",
    "                key = (R, F1)  # 先比 Recall，再比 F1\n",
    "        else:\n",
    "            key = (F1, 0.0)\n",
    "\n",
    "        if key > best_key:\n",
    "            best_key = key\n",
    "            best_thr = t\n",
    "\n",
    "    table = pd.DataFrame(out_rows).sort_values(\"thr\").reset_index(drop=True)\n",
    "    best_row = table.loc[table[\"thr\"].sub(best_thr).abs().idxmin()].to_dict()\n",
    "    return float(best_thr), best_row, table\n",
    "\n",
    "# ========= 3) 分数 PSI =========\n",
    "\n",
    "def score_psi(ref_scores, new_scores, bins=10):\n",
    "    ref = pd.Series(ref_scores)\n",
    "    new = pd.Series(new_scores)\n",
    "    return psi_for_series(ref, new, bins=bins)\n",
    "\n",
    "# ========= 4) 数据准备（日期阈值 / 比例切分） =========\n",
    "\n",
    "def temporal_split(df_clean: pd.DataFrame,\n",
    "                   label_col=\"value_sort\",\n",
    "                   cutoff_date=None,\n",
    "                   test_size_ratio=0.2,\n",
    "                   val_size_ratio=0.2):\n",
    "    \"\"\"\n",
    "    返回: X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols\n",
    "    \"\"\"\n",
    "    assert label_col in df_clean.columns\n",
    "    df = df_clean.copy().sort_index()\n",
    "\n",
    "    feat_cols = df.columns.drop([label_col]).tolist()\n",
    "    X_all = df[feat_cols].values\n",
    "    y_all = df[label_col].astype(int).values\n",
    "\n",
    "    if cutoff_date is not None:\n",
    "        assert isinstance(df.index, pd.DatetimeIndex), \"需 DatetimeIndex 才能按日期切分\"\n",
    "        mask_trainval = (df.index <= pd.to_datetime(cutoff_date))\n",
    "        X_trainval, y_trainval = X_all[mask_trainval], y_all[mask_trainval]\n",
    "        X_test, y_test = X_all[~mask_trainval], y_all[~mask_trainval]\n",
    "\n",
    "        n_tv = len(X_trainval)\n",
    "        n_val = max(1, int(n_tv * val_size_ratio))\n",
    "        X_tr, y_tr = X_trainval[:-n_val], y_trainval[:-n_val]\n",
    "        X_val, y_val = X_trainval[-n_val:], y_trainval[-n_val:]\n",
    "        return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "    N = len(X_all)\n",
    "    n_test = max(1, int(N * test_size_ratio))\n",
    "    X_tv, y_tv = X_all[:-n_test], y_all[:-n_test]\n",
    "    X_test, y_test = X_all[-n_test:], y_all[-n_test:]\n",
    "\n",
    "    n_tv = len(X_tv)\n",
    "    n_val = max(1, int(n_tv * val_size_ratio))\n",
    "    X_tr, y_tr = X_tv[:-n_val], y_tv[:-n_val]\n",
    "    X_val, y_val = X_tv[-n_val:], y_tv[-n_val:]\n",
    "    return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "# ========= 2.5) 统一评估接口（支持阈值与非阈值类指标） =========\n",
    "\n",
    "def _compute_metrics_at_thr(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    tnr = tn / max(1, (tn + fp))\n",
    "    youdenJ = (recall_score(y_true, y_pred, zero_division=0) + tnr - 1.0)\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\":    recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\":        f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"youden\":    youdenJ,\n",
    "        \"pos_rate\":  y_pred.mean()\n",
    "    }\n",
    "\n",
    "def evaluate_with_optional_threshold(\n",
    "    y_true, y_prob,\n",
    "    optimize_metric=\"f1\",     # f1/accuracy/precision/recall/youden/auc/ap/logloss\n",
    "    thr_source=\"auto\",        # auto/f1/youden/constraint/posrate/fixed\n",
    "    fixed_thr=0.5,\n",
    "    constraint_min_precision=None,\n",
    "    constraint_min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    \"\"\"\n",
    "    返回 (score, used_thr, aux_row)\n",
    "    - 非阈值类：auc/ap/logloss 不取阈值，used_thr=None\n",
    "      · auc: roc_auc_score\n",
    "      · ap : average_precision_score\n",
    "      · logloss: 取负号以“最大化”\n",
    "    - 阈值类：accuracy/precision/recall/f1/youden\n",
    "      先依据 thr_source 决定阈值，再在该阈值上计算所选 optimize_metric\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    # 非阈值类指标\n",
    "    if optimize_metric in {\"auc\", \"ap\", \"logloss\"}:\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            return (-np.inf if optimize_metric == \"logloss\" else np.nan), None, {}\n",
    "        if optimize_metric == \"auc\":\n",
    "            return float(roc_auc_score(y_true, y_prob)), None, {}\n",
    "        elif optimize_metric == \"ap\":\n",
    "            return float(average_precision_score(y_true, y_prob)), None, {}\n",
    "        else:  # logloss -> 最大化 -logloss\n",
    "            ll = log_loss(y_true, np.vstack([1 - y_prob, y_prob]).T, labels=[0, 1])\n",
    "            return float(-ll), None, {\"raw_logloss\": ll}\n",
    "\n",
    "    # 阈值类指标：先确定 thr\n",
    "    if thr_source == \"auto\":\n",
    "        thr_source = \"youden\" if optimize_metric == \"youden\" else \"f1\"\n",
    "\n",
    "    if   thr_source == \"f1\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"f1\")\n",
    "    elif thr_source == \"youden\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"youden\")\n",
    "    elif thr_source == \"constraint\":\n",
    "        thr, row, _ = choose_threshold(\n",
    "            y_true, y_prob, method=\"constraint\",\n",
    "            min_precision=constraint_min_precision, min_recall=constraint_min_recall\n",
    "        )\n",
    "    elif thr_source == \"posrate\":\n",
    "        thr, row, _ = choose_threshold(\n",
    "            y_true, y_prob, method=\"posrate\", target_pos_rate=target_pos_rate\n",
    "        )\n",
    "    elif thr_source == \"fixed\":\n",
    "        thr = float(fixed_thr)\n",
    "        row = _compute_metrics_at_thr(y_true, y_prob, thr)\n",
    "    else:\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"f1\")\n",
    "\n",
    "    if optimize_metric not in {\"accuracy\", \"precision\", \"recall\", \"f1\", \"youden\"}:\n",
    "        optimize_metric = \"f1\"\n",
    "    score = float(row[optimize_metric])\n",
    "    return score, float(thr), row\n",
    "\n",
    "# ========= 5) Optuna + XGBoost 搜索（用原生API训练） =========\n",
    "\n",
    "def run_optuna_xgb(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    n_trials=50,\n",
    "    # 旧参数（兼容）：控制阈值如何选\n",
    "    method_for_thr=\"precision\",  # f1/youden/constraint/posrate/fixed\n",
    "    constraint_min_precision=None, constraint_min_recall=None,\n",
    "    target_pos_rate=None,\n",
    "    # 新增：控制评优指标与阈值来源\n",
    "    optimize_metric=\"precision\",      # f1/accuracy/precision/recall/youden/auc/ap/logloss\n",
    "    thr_source=\"auto\",         # auto/f1/youden/constraint/posrate/fixed\n",
    "    fixed_thr=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    若 optimize_metric ∈ {auc, ap, logloss}，不走阈值；其它指标先按 thr_source 取阈值再评估。\n",
    "    注意：logloss 会以 -logloss 作为“要最大化”的目标。\n",
    "    \"\"\"\n",
    "    if thr_source == \"auto\":\n",
    "        thr_source = method_for_thr  # 与旧脚本默认保持一致（F1 选阈值）\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            # 树与结构\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-2, 20.0, log=True),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "            # 采样\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            # 学习率 & 正则\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "            # 通用\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"auc\",\n",
    "            # CPU 树法（老版本也支持）\n",
    "            \"tree_method\": \"hist\",\n",
    "        }\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 200, 2000)\n",
    "\n",
    "        booster = train_xgb_booster(\n",
    "            X_tr, y_tr, X_val, y_val,\n",
    "            params=params,\n",
    "            num_boost_round=n_estimators,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        val_prob = predict_proba_booster(booster, X_val)\n",
    "\n",
    "        # 统一评估：支持阈值类与非阈值类\n",
    "        score, used_thr, row = evaluate_with_optional_threshold(\n",
    "            y_val, val_prob,\n",
    "            optimize_metric=optimize_metric,\n",
    "            thr_source=thr_source,\n",
    "            fixed_thr=fixed_thr,\n",
    "            constraint_min_precision=constraint_min_precision,\n",
    "            constraint_min_recall=constraint_min_recall,\n",
    "            target_pos_rate=target_pos_rate\n",
    "        )\n",
    "\n",
    "        trial.set_user_attr(\"metric\", optimize_metric)\n",
    "        trial.set_user_attr(\"thr_source\", thr_source)\n",
    "        trial.set_user_attr(\"thr\", used_thr)\n",
    "        for k in [\"precision\", \"recall\", \"f1\", \"accuracy\", \"youden\", \"pos_rate\", \"raw_logloss\"]:\n",
    "            if k in row:\n",
    "                trial.set_user_attr(k, row[k])\n",
    "\n",
    "        return float(score)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "# ========= 6) 主流程 =========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ======= 读取/准备数据 =======\n",
    "    # 实际使用时：加载你的 df_clean（含列 value_sort，索引建议 DatetimeIndex）\n",
    "    # 例：\n",
    "    # df_clean = pd.read_csv(\"your_data.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "    # assert \"value_sort\" in df_clean.columns\n",
    "    # ======= 切分：按日期阈值 =======\n",
    "    cutoff_date = \"2024-10-15\"  # 示例：可改为 None 使用比例切分\n",
    "    X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols = temporal_split(\n",
    "        df_clean, label_col=\"value_sort\", cutoff_date=None,\n",
    "        test_size_ratio=0.2, val_size_ratio=0.2\n",
    "    )\n",
    "\n",
    "    # ======= 漂移检查（TrainFit vs Test） =======\n",
    "    df_tr_fit = pd.DataFrame(X_tr_fit_raw, columns=feat_cols)\n",
    "    df_val    = pd.DataFrame(X_val_fit_raw, columns=feat_cols)\n",
    "    df_te     = pd.DataFrame(X_te_raw,     columns=feat_cols)\n",
    "\n",
    "    rep_tr_te = drift_report(df_tr_fit, df_te, categorical_cols=[], topk=30)\n",
    "    print(\"\\n==== Top Drifted Features (TrainFit vs Test) ====\")\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    print(rep_tr_te.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    # ======= 贝叶斯优化（可自由切换评优指标与阈值来源） =======\n",
    "    study = run_optuna_xgb(\n",
    "        X_tr_fit_raw, y_tr_fit,\n",
    "        X_val_fit_raw, y_val_fit,\n",
    "        n_trials=200,                     # 演示缩小，实际可加大如 300\n",
    "        # —— 评优指标 —— \n",
    "        optimize_metric=\"f1\",            # f1/accuracy/precision/recall/youden/auc/ap/logloss\n",
    "        # —— 阈值来源（仅当评优指标是阈值类时生效）——\n",
    "        thr_source=\"f1\",                 # auto / f1 / youden / constraint / posrate / fixed\n",
    "        fixed_thr=0.5,                   # thr_source=\"fixed\" 时生效\n",
    "        # 若用到 constraint/posrate，可给下列约束：\n",
    "        constraint_min_precision=None,\n",
    "        constraint_min_recall=None,\n",
    "        target_pos_rate=None,\n",
    "        # 兼容旧参数：不想管也行\n",
    "        method_for_thr=\"f1\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n==== Optuna Best (VAL by chosen metric, XGB) ====\")\n",
    "    print(\"Optimize metric:\", study.best_trial.user_attrs.get(\"metric\"))\n",
    "    print(\"Best score:\", study.best_value)\n",
    "    print(\"Best params:\", study.best_trial.params)\n",
    "    print(\"Best VAL thr_source:\", study.best_trial.user_attrs.get(\"thr_source\"))\n",
    "    print(\"Best VAL thr:\", study.best_trial.user_attrs.get(\"thr\"))\n",
    "    for k in [\"precision\", \"recall\", \"f1\", \"accuracy\", \"youden\", \"pos_rate\", \"raw_logloss\"]:\n",
    "        if k in study.best_trial.user_attrs:\n",
    "            print(f\"Best VAL {k}:\", study.best_trial.user_attrs[k])\n",
    "\n",
    "    # ======= 用最优参数重新训练最终模型（在 TrainFit 上），并在 Val 早停 =======\n",
    "    best_params = dict(study.best_trial.params)\n",
    "    n_estimators = best_params.pop(\"n_estimators\")\n",
    "    final_booster = train_xgb_booster(\n",
    "        X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit,\n",
    "        params=best_params,\n",
    "        num_boost_round=n_estimators,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ======= 在验证集上选“生产用阈值”（与 Optuna 评优逻辑对齐） =======\n",
    "    val_prob = predict_proba_booster(final_booster, X_val_fit_raw)\n",
    "    # 例：以 F1 作为阈值选择标准；你也可以换成 accuracy/recall/precision/youden + 相应 thr_source\n",
    "    _, chosen_thr, row_any = evaluate_with_optional_threshold(\n",
    "        y_val_fit, val_prob,\n",
    "        optimize_metric=\"precision\",  # 这里随便写个非阈值类指标，不影响 thr 选取\n",
    "        thr_source=\"precision\"\n",
    "    )\n",
    "    print(f\"\\n[Threshold] VAL selected via F1: t*={chosen_thr:.3f}, \"\n",
    "          f\"P={row_any.get('precision', np.nan):.4f}, R={row_any.get('recall', np.nan):.4f}, \"\n",
    "          f\"F1={row_any.get('f1', np.nan):.4f}, Acc={row_any.get('accuracy', np.nan):.4f}, \"\n",
    "          f\"Youden={row_any.get('youden', np.nan):.4f}\")\n",
    "\n",
    "    # ======= 测试集评估（固定 chosen_thr） =======\n",
    "    y_te_prob = predict_proba_booster(final_booster, X_te_raw)\n",
    "    y_te_pred = (y_te_prob >= chosen_thr).astype(int)\n",
    "\n",
    "    test_auc  = safe_auc(y_te, y_te_prob)\n",
    "    test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "    test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== Test Performance (held-out, with chosen threshold, XGB) ====\")\n",
    "    print(f\"AUC:           {test_auc:.6f}\")\n",
    "    print(f\"AveragePrecision(PR-AUC): {test_ap:.6f}\")\n",
    "    print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "    print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "    print(f\"Precision@t*:  {test_prec:.6f}\")\n",
    "    print(f\"Recall@t*:     {test_rec:.6f}\")\n",
    "    print(f\"F1@t*:         {test_f1:.6f}\")\n",
    "    print(f\"(t* chosen on VAL: {chosen_thr:.3f})\")\n",
    "\n",
    "    # ======= 分数 PSI（可选） =======\n",
    "    tr_scores  = predict_proba_booster(final_booster, X_tr_fit_raw)\n",
    "    val_scores = val_prob\n",
    "    te_scores  = y_te_prob\n",
    "    print(\"\\nScore PSI (TrainFit→Val): \", f\"{score_psi(tr_scores, val_scores):.4f}\")\n",
    "    print(\"Score PSI (TrainFit→Test):\", f\"{score_psi(tr_scores, te_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa8a5e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "预测结果已保存到: test_predictions_xgb.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "te_index = df_clean.index[-len(y_te):]\n",
    "# ======= 导出预测结果到 Excel =======\n",
    "df_pred = pd.DataFrame({\n",
    "    \"index\": te_index,\n",
    "    \"y_true\": 1 - y_te,\n",
    "    \"y_prob\": y_te_prob,\n",
    "    \"y_pred\": 1 -y_te_pred\n",
    "})\n",
    "\n",
    "out_file = \"test_predictions_xgb.xlsx\"\n",
    "df_pred.to_excel(out_file, index=False)\n",
    "print(f\"\\n预测结果已保存到: {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594e950",
   "metadata": {},
   "source": [
    "# 随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cef043",
   "metadata": {},
   "source": [
    "## 阈值版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 21:44:55,471] A new study created in memory with name: no-name-07e7db8c-cd5c-4e67-99aa-d445ff56d38d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top Drifted Features (TrainFit vs Test) ====\n",
      "       feature  is_categorical     PSI  KS/Chi2_p  KS_stat  missing_ref  missing_new  missing_diff\n",
      "        TF跨期价差           False 16.5582     0.0000   0.9028       0.0000       0.0000        0.0000\n",
      " shibor1-repo1           False 16.5571     0.0000   0.9487       0.0000       0.0000        0.0000\n",
      "   repo5-repo1           False 16.5570     0.0000   0.9732       0.0000       0.0000        0.0000\n",
      "      国开10y-1y           False 16.5570     0.0000   0.9361       0.0000       0.0000        0.0000\n",
      "       二级5y-3y           False 16.5570     0.0000   0.9306       0.0000       0.0000        0.0000\n",
      "  国开1yYTM_5dMA           False 16.5570     0.0000   0.9281       0.0000       0.0000        0.0000\n",
      "  国开5yYTM_5dMA           False 16.5570     0.0000   0.9952       0.0000       0.0000        0.0000\n",
      "  二级2yYTM_5dMA           False 16.5570     0.0000   0.9951       0.0000       0.0000        0.0000\n",
      " 国债7yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      "国债10yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      "国债30yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      " 国开5yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      " 国开7yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      "国开10yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      "国开30yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      " 二级2yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      " 二级3yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      " 二级4yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      " 二级5yYTM_20dMA           False 16.5570     0.0000   0.9857       0.0000       0.0000        0.0000\n",
      "   国开10y-国债10y           False 16.5570     0.0000   0.9832       0.0000       0.0000        0.0000\n",
      "  国债5yYTM_5dMA           False 16.5570     0.0000   0.9724       0.0000       0.0000        0.0000\n",
      "  国开3yYTM_5dMA           False 16.5570     0.0000   0.9686       0.0000       0.0000        0.0000\n",
      "  国债3yYTM_5dMA           False 16.5570     0.0000   0.9639       0.0000       0.0000        0.0000\n",
      "   Repo5Y_5dMA           False 16.5570     0.0000   0.9629       0.0000       0.0000        0.0000\n",
      " 国债5yYTM_20dMA           False 16.5570     0.0000   0.9610       0.0000       0.0000        0.0000\n",
      "  国债1yYTM_5dMA           False 16.5570     0.0000   0.9591       0.0000       0.0000        0.0000\n",
      " 国开3yYTM_20dMA           False 16.5570     0.0000   0.9572       0.0000       0.0000        0.0000\n",
      " Shibor1Y_5dMA           False 16.5570     0.0000   0.9559       0.0000       0.0000        0.0000\n",
      "       二级3y-1y           False 16.5570     0.0000   0.9492       0.0000       0.0000        0.0000\n",
      " 国债3yYTM_20dMA           False 16.5570     0.0000   0.9468       0.0000       0.0000        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-31 21:44:57,196] Trial 0 finished with value: 0.5512367491166078 and parameters: {'n_estimators': 1180, 'max_depth': 14, 'min_samples_split': 150, 'min_samples_leaf': 34, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.5512367491166078.\n",
      "[I 2025-08-31 21:44:59,040] Trial 1 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1207, 'max_depth': 6, 'min_samples_split': 130, 'min_samples_leaf': 75, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.5614035087719298.\n",
      "[I 2025-08-31 21:45:04,938] Trial 2 finished with value: 0.519774011299435 and parameters: {'n_estimators': 1308, 'max_depth': 11, 'min_samples_split': 198, 'min_samples_leaf': 53, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.5614035087719298.\n",
      "[I 2025-08-31 21:45:09,680] Trial 3 finished with value: 0.5481927710843374 and parameters: {'n_estimators': 992, 'max_depth': 38, 'min_samples_split': 106, 'min_samples_leaf': 22, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 1 with value: 0.5614035087719298.\n",
      "[I 2025-08-31 21:45:15,207] Trial 4 finished with value: 0.5701357466063348 and parameters: {'n_estimators': 1146, 'max_depth': 40, 'min_samples_split': 61, 'min_samples_leaf': 97, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:45:16,424] Trial 5 finished with value: 0.5655172413793104 and parameters: {'n_estimators': 594, 'max_depth': 26, 'min_samples_split': 46, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:45:26,921] Trial 6 finished with value: 0.5242165242165242 and parameters: {'n_estimators': 866, 'max_depth': 10, 'min_samples_split': 37, 'min_samples_leaf': 16, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:45:28,979] Trial 7 finished with value: 0.5608856088560885 and parameters: {'n_estimators': 589, 'max_depth': 31, 'min_samples_split': 60, 'min_samples_leaf': 93, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:45:31,037] Trial 8 finished with value: 0.5514018691588785 and parameters: {'n_estimators': 607, 'max_depth': 19, 'min_samples_split': 37, 'min_samples_leaf': 42, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:45:40,215] Trial 9 finished with value: 0.5242165242165242 and parameters: {'n_estimators': 1265, 'max_depth': 22, 'min_samples_split': 21, 'min_samples_leaf': 92, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:45:41,416] Trial 10 finished with value: 0.5545454545454546 and parameters: {'n_estimators': 246, 'max_depth': 40, 'min_samples_split': 86, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:45:43,456] Trial 11 finished with value: 0.5488721804511278 and parameters: {'n_estimators': 575, 'max_depth': 28, 'min_samples_split': 71, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:19,129] Trial 12 finished with value: 0.4621212121212121 and parameters: {'n_estimators': 1489, 'max_depth': 32, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:19,845] Trial 13 finished with value: 0.5488372093023256 and parameters: {'n_estimators': 286, 'max_depth': 25, 'min_samples_split': 45, 'min_samples_leaf': 100, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:21,468] Trial 14 finished with value: 0.5550660792951542 and parameters: {'n_estimators': 814, 'max_depth': 34, 'min_samples_split': 98, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:27,349] Trial 15 finished with value: 0.5202312138728323 and parameters: {'n_estimators': 1020, 'max_depth': 18, 'min_samples_split': 62, 'min_samples_leaf': 60, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:28,160] Trial 16 finished with value: 0.5510204081632653 and parameters: {'n_estimators': 385, 'max_depth': 35, 'min_samples_split': 121, 'min_samples_leaf': 83, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:34,330] Trial 17 finished with value: 0.5342019543973942 and parameters: {'n_estimators': 749, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 32, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:35,369] Trial 18 finished with value: 0.549618320610687 and parameters: {'n_estimators': 452, 'max_depth': 37, 'min_samples_split': 169, 'min_samples_leaf': 45, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:37,464] Trial 19 finished with value: 0.5543859649122806 and parameters: {'n_estimators': 1021, 'max_depth': 30, 'min_samples_split': 75, 'min_samples_leaf': 17, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:48,777] Trial 20 finished with value: 0.519774011299435 and parameters: {'n_estimators': 1452, 'max_depth': 16, 'min_samples_split': 51, 'min_samples_leaf': 78, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:52,032] Trial 21 finished with value: 0.5650224215246636 and parameters: {'n_estimators': 1111, 'max_depth': 8, 'min_samples_split': 131, 'min_samples_leaf': 83, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:55,333] Trial 22 finished with value: 0.5551020408163265 and parameters: {'n_estimators': 1093, 'max_depth': 3, 'min_samples_split': 148, 'min_samples_leaf': 87, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:46:58,037] Trial 23 finished with value: 0.5541125541125541 and parameters: {'n_estimators': 876, 'max_depth': 22, 'min_samples_split': 89, 'min_samples_leaf': 97, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:01,772] Trial 24 finished with value: 0.56 and parameters: {'n_estimators': 1380, 'max_depth': 9, 'min_samples_split': 113, 'min_samples_leaf': 85, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:04,085] Trial 25 finished with value: 0.5547445255474452 and parameters: {'n_estimators': 695, 'max_depth': 14, 'min_samples_split': 26, 'min_samples_leaf': 65, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:07,392] Trial 26 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1149, 'max_depth': 25, 'min_samples_split': 140, 'min_samples_leaf': 56, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:15,076] Trial 27 finished with value: 0.519774011299435 and parameters: {'n_estimators': 886, 'max_depth': 20, 'min_samples_split': 164, 'min_samples_leaf': 79, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:18,101] Trial 28 finished with value: 0.5547445255474452 and parameters: {'n_estimators': 952, 'max_depth': 5, 'min_samples_split': 80, 'min_samples_leaf': 69, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:21,583] Trial 29 finished with value: 0.5548387096774193 and parameters: {'n_estimators': 1144, 'max_depth': 13, 'min_samples_split': 98, 'min_samples_leaf': 32, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:23,205] Trial 30 finished with value: 0.5543071161048689 and parameters: {'n_estimators': 477, 'max_depth': 29, 'min_samples_split': 61, 'min_samples_leaf': 38, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:26,655] Trial 31 finished with value: 0.5543859649122806 and parameters: {'n_estimators': 1240, 'max_depth': 7, 'min_samples_split': 125, 'min_samples_leaf': 90, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:30,049] Trial 32 finished with value: 0.5535714285714286 and parameters: {'n_estimators': 1227, 'max_depth': 7, 'min_samples_split': 129, 'min_samples_leaf': 82, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:33,552] Trial 33 finished with value: 0.56 and parameters: {'n_estimators': 1351, 'max_depth': 12, 'min_samples_split': 198, 'min_samples_leaf': 73, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:36,641] Trial 34 finished with value: 0.5551020408163265 and parameters: {'n_estimators': 1088, 'max_depth': 3, 'min_samples_split': 158, 'min_samples_leaf': 96, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:44,751] Trial 35 finished with value: 0.5534591194968553 and parameters: {'n_estimators': 1308, 'max_depth': 8, 'min_samples_split': 110, 'min_samples_leaf': 49, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:47,810] Trial 36 finished with value: 0.5495495495495496 and parameters: {'n_estimators': 1102, 'max_depth': 16, 'min_samples_split': 176, 'min_samples_leaf': 25, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:47:58,707] Trial 37 finished with value: 0.519774011299435 and parameters: {'n_estimators': 1201, 'max_depth': 11, 'min_samples_split': 144, 'min_samples_leaf': 76, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:01,350] Trial 38 finished with value: 0.5566037735849056 and parameters: {'n_estimators': 939, 'max_depth': 40, 'min_samples_split': 35, 'min_samples_leaf': 90, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:07,910] Trial 39 finished with value: 0.519774011299435 and parameters: {'n_estimators': 675, 'max_depth': 5, 'min_samples_split': 135, 'min_samples_leaf': 57, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:10,263] Trial 40 finished with value: 0.5543071161048689 and parameters: {'n_estimators': 808, 'max_depth': 34, 'min_samples_split': 188, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:13,623] Trial 41 finished with value: 0.5517241379310345 and parameters: {'n_estimators': 1161, 'max_depth': 24, 'min_samples_split': 145, 'min_samples_leaf': 53, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:17,157] Trial 42 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1307, 'max_depth': 27, 'min_samples_split': 117, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:20,624] Trial 43 finished with value: 0.56 and parameters: {'n_estimators': 1303, 'max_depth': 27, 'min_samples_split': 121, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:24,416] Trial 44 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1403, 'max_depth': 32, 'min_samples_split': 105, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:28,126] Trial 45 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1406, 'max_depth': 32, 'min_samples_split': 103, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:30,870] Trial 46 finished with value: 0.5520361990950227 and parameters: {'n_estimators': 1236, 'max_depth': 37, 'min_samples_split': 49, 'min_samples_leaf': 67, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:34,866] Trial 47 finished with value: 0.5550660792951542 and parameters: {'n_estimators': 1445, 'max_depth': 28, 'min_samples_split': 90, 'min_samples_leaf': 100, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:44,567] Trial 48 finished with value: 0.5242165242165242 and parameters: {'n_estimators': 1333, 'max_depth': 24, 'min_samples_split': 69, 'min_samples_leaf': 94, 'max_features': None, 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:47,589] Trial 49 finished with value: 0.5503355704697986 and parameters: {'n_estimators': 1279, 'max_depth': 35, 'min_samples_split': 116, 'min_samples_leaf': 73, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:50,814] Trial 50 finished with value: 0.5520361990950227 and parameters: {'n_estimators': 1055, 'max_depth': 31, 'min_samples_split': 19, 'min_samples_leaf': 81, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:54,953] Trial 51 finished with value: 0.5504587155963303 and parameters: {'n_estimators': 1486, 'max_depth': 21, 'min_samples_split': 131, 'min_samples_leaf': 86, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:48:58,932] Trial 52 finished with value: 0.5535714285714286 and parameters: {'n_estimators': 1385, 'max_depth': 38, 'min_samples_split': 97, 'min_samples_leaf': 76, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:00,284] Trial 53 finished with value: 0.553030303030303 and parameters: {'n_estimators': 322, 'max_depth': 33, 'min_samples_split': 154, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:11,745] Trial 54 finished with value: 0.5202312138728323 and parameters: {'n_estimators': 1192, 'max_depth': 23, 'min_samples_split': 107, 'min_samples_leaf': 59, 'max_features': None, 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:13,668] Trial 55 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 523, 'max_depth': 27, 'min_samples_split': 118, 'min_samples_leaf': 47, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:15,640] Trial 56 finished with value: 0.5570776255707762 and parameters: {'n_estimators': 533, 'max_depth': 27, 'min_samples_split': 136, 'min_samples_leaf': 26, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:17,304] Trial 57 finished with value: 0.5581395348837209 and parameters: {'n_estimators': 402, 'max_depth': 26, 'min_samples_split': 82, 'min_samples_leaf': 47, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:19,662] Trial 58 finished with value: 0.5482625482625483 and parameters: {'n_estimators': 670, 'max_depth': 29, 'min_samples_split': 117, 'min_samples_leaf': 42, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:25,245] Trial 59 finished with value: 0.5449101796407185 and parameters: {'n_estimators': 548, 'max_depth': 30, 'min_samples_split': 93, 'min_samples_leaf': 12, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:26,559] Trial 60 finished with value: 0.554140127388535 and parameters: {'n_estimators': 230, 'max_depth': 19, 'min_samples_split': 55, 'min_samples_leaf': 53, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:28,782] Trial 61 finished with value: 0.5550660792951542 and parameters: {'n_estimators': 615, 'max_depth': 5, 'min_samples_split': 126, 'min_samples_leaf': 73, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:32,352] Trial 62 finished with value: 0.5560538116591929 and parameters: {'n_estimators': 1274, 'max_depth': 26, 'min_samples_split': 104, 'min_samples_leaf': 78, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:34,928] Trial 63 finished with value: 0.546875 and parameters: {'n_estimators': 747, 'max_depth': 38, 'min_samples_split': 120, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:36,852] Trial 64 finished with value: 0.5606060606060606 and parameters: {'n_estimators': 459, 'max_depth': 31, 'min_samples_split': 42, 'min_samples_leaf': 89, 'max_features': 'log2', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:40,760] Trial 65 finished with value: 0.5570776255707762 and parameters: {'n_estimators': 1362, 'max_depth': 22, 'min_samples_split': 112, 'min_samples_leaf': 85, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:43,656] Trial 66 finished with value: 0.5560538116591929 and parameters: {'n_estimators': 989, 'max_depth': 28, 'min_samples_split': 71, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:49,313] Trial 67 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1132, 'max_depth': 24, 'min_samples_split': 31, 'min_samples_leaf': 93, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:53,138] Trial 68 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1422, 'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:56,072] Trial 69 finished with value: 0.5633802816901409 and parameters: {'n_estimators': 1059, 'max_depth': 36, 'min_samples_split': 136, 'min_samples_leaf': 17, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:49:58,657] Trial 70 finished with value: 0.5527272727272727 and parameters: {'n_estimators': 933, 'max_depth': 36, 'min_samples_split': 152, 'min_samples_leaf': 15, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:01,469] Trial 71 finished with value: 0.5521885521885522 and parameters: {'n_estimators': 1065, 'max_depth': 39, 'min_samples_split': 134, 'min_samples_leaf': 6, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:04,532] Trial 72 finished with value: 0.5536332179930796 and parameters: {'n_estimators': 1201, 'max_depth': 35, 'min_samples_split': 142, 'min_samples_leaf': 22, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:07,517] Trial 73 finished with value: 0.5571428571428572 and parameters: {'n_estimators': 1123, 'max_depth': 33, 'min_samples_split': 124, 'min_samples_leaf': 14, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:10,264] Trial 74 finished with value: 0.5494505494505495 and parameters: {'n_estimators': 1040, 'max_depth': 39, 'min_samples_split': 138, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:14,279] Trial 75 finished with value: 0.5551601423487544 and parameters: {'n_estimators': 1235, 'max_depth': 10, 'min_samples_split': 130, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:19,384] Trial 76 finished with value: 0.5560538116591929 and parameters: {'n_estimators': 998, 'max_depth': 36, 'min_samples_split': 161, 'min_samples_leaf': 71, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:21,183] Trial 77 finished with value: 0.5519713261648745 and parameters: {'n_estimators': 502, 'max_depth': 4, 'min_samples_split': 110, 'min_samples_leaf': 18, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:23,103] Trial 78 finished with value: 0.5592105263157895 and parameters: {'n_estimators': 613, 'max_depth': 30, 'min_samples_split': 98, 'min_samples_leaf': 37, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:26,305] Trial 79 finished with value: 0.5514018691588785 and parameters: {'n_estimators': 1171, 'max_depth': 40, 'min_samples_split': 148, 'min_samples_leaf': 29, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:29,258] Trial 80 finished with value: 0.556390977443609 and parameters: {'n_estimators': 1324, 'max_depth': 7, 'min_samples_split': 117, 'min_samples_leaf': 98, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:32,625] Trial 81 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1105, 'max_depth': 25, 'min_samples_split': 140, 'min_samples_leaf': 56, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:36,164] Trial 82 finished with value: 0.56 and parameters: {'n_estimators': 1166, 'max_depth': 25, 'min_samples_split': 126, 'min_samples_leaf': 60, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:39,908] Trial 83 finished with value: 0.5535714285714286 and parameters: {'n_estimators': 1269, 'max_depth': 27, 'min_samples_split': 132, 'min_samples_leaf': 75, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:41,656] Trial 84 finished with value: 0.5565217391304348 and parameters: {'n_estimators': 415, 'max_depth': 23, 'min_samples_split': 123, 'min_samples_leaf': 56, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:44,973] Trial 85 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1080, 'max_depth': 20, 'min_samples_split': 41, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:50,381] Trial 86 finished with value: 0.5526315789473685 and parameters: {'n_estimators': 1082, 'max_depth': 33, 'min_samples_split': 52, 'min_samples_leaf': 81, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:53,987] Trial 87 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1219, 'max_depth': 9, 'min_samples_split': 39, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:55,591] Trial 88 finished with value: 0.5570776255707762 and parameters: {'n_estimators': 351, 'max_depth': 9, 'min_samples_split': 41, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:50:58,857] Trial 89 finished with value: 0.554140127388535 and parameters: {'n_estimators': 973, 'max_depth': 32, 'min_samples_split': 33, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:01,680] Trial 90 finished with value: 0.5545454545454546 and parameters: {'n_estimators': 1026, 'max_depth': 12, 'min_samples_split': 28, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:04,853] Trial 91 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1200, 'max_depth': 6, 'min_samples_split': 57, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:08,189] Trial 92 finished with value: 0.5589519650655022 and parameters: {'n_estimators': 1223, 'max_depth': 6, 'min_samples_split': 24, 'min_samples_leaf': 52, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:10,681] Trial 93 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 823, 'max_depth': 14, 'min_samples_split': 46, 'min_samples_leaf': 61, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:13,423] Trial 94 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 899, 'max_depth': 16, 'min_samples_split': 48, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:15,979] Trial 95 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 818, 'max_depth': 15, 'min_samples_split': 64, 'min_samples_leaf': 61, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:18,481] Trial 96 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 855, 'max_depth': 14, 'min_samples_split': 65, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:21,180] Trial 97 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 911, 'max_depth': 14, 'min_samples_split': 46, 'min_samples_leaf': 61, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:23,595] Trial 98 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 742, 'max_depth': 15, 'min_samples_split': 48, 'min_samples_leaf': 58, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:25,861] Trial 99 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 711, 'max_depth': 16, 'min_samples_split': 40, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:28,115] Trial 100 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 710, 'max_depth': 18, 'min_samples_split': 43, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:30,491] Trial 101 finished with value: 0.56 and parameters: {'n_estimators': 777, 'max_depth': 19, 'min_samples_split': 39, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:32,898] Trial 102 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 706, 'max_depth': 17, 'min_samples_split': 36, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:35,120] Trial 103 finished with value: 0.5589519650655022 and parameters: {'n_estimators': 638, 'max_depth': 18, 'min_samples_split': 54, 'min_samples_leaf': 55, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:37,703] Trial 104 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 827, 'max_depth': 20, 'min_samples_split': 45, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:40,249] Trial 105 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 783, 'max_depth': 16, 'min_samples_split': 44, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:44,119] Trial 106 finished with value: 0.5495495495495496 and parameters: {'n_estimators': 655, 'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 66, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:46,561] Trial 107 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 783, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 74, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:49,035] Trial 108 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 712, 'max_depth': 18, 'min_samples_split': 59, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:52,908] Trial 109 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1298, 'max_depth': 17, 'min_samples_split': 43, 'min_samples_leaf': 59, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:54,913] Trial 110 finished with value: 0.5541125541125541 and parameters: {'n_estimators': 588, 'max_depth': 10, 'min_samples_split': 76, 'min_samples_leaf': 50, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:57,278] Trial 111 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 764, 'max_depth': 16, 'min_samples_split': 31, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:51:59,591] Trial 112 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 732, 'max_depth': 20, 'min_samples_split': 28, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:02,098] Trial 113 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 777, 'max_depth': 19, 'min_samples_split': 24, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:04,615] Trial 114 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 769, 'max_depth': 20, 'min_samples_split': 30, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:07,216] Trial 115 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 775, 'max_depth': 20, 'min_samples_split': 30, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:09,655] Trial 116 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 774, 'max_depth': 20, 'min_samples_split': 29, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:12,027] Trial 117 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 738, 'max_depth': 19, 'min_samples_split': 12, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:14,353] Trial 118 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 791, 'max_depth': 21, 'min_samples_split': 21, 'min_samples_leaf': 72, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:16,808] Trial 119 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 719, 'max_depth': 20, 'min_samples_split': 24, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:18,328] Trial 120 finished with value: 0.5610859728506787 and parameters: {'n_estimators': 687, 'max_depth': 18, 'min_samples_split': 37, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:19,789] Trial 121 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 765, 'max_depth': 20, 'min_samples_split': 30, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:21,480] Trial 122 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 848, 'max_depth': 19, 'min_samples_split': 33, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:22,891] Trial 123 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 760, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 58, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:24,198] Trial 124 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 725, 'max_depth': 22, 'min_samples_split': 26, 'min_samples_leaf': 77, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:25,632] Trial 125 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 799, 'max_depth': 17, 'min_samples_split': 39, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:27,931] Trial 126 finished with value: 0.5535714285714286 and parameters: {'n_estimators': 661, 'max_depth': 19, 'min_samples_split': 30, 'min_samples_leaf': 69, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:29,497] Trial 127 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 845, 'max_depth': 15, 'min_samples_split': 21, 'min_samples_leaf': 59, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:31,076] Trial 128 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 871, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 55, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:32,603] Trial 129 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 698, 'max_depth': 21, 'min_samples_split': 33, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:33,925] Trial 130 finished with value: 0.5550660792951542 and parameters: {'n_estimators': 641, 'max_depth': 18, 'min_samples_split': 37, 'min_samples_leaf': 72, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:35,352] Trial 131 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 753, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:36,753] Trial 132 finished with value: 0.5610859728506787 and parameters: {'n_estimators': 735, 'max_depth': 22, 'min_samples_split': 12, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:38,378] Trial 133 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 778, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:39,938] Trial 134 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 804, 'max_depth': 20, 'min_samples_split': 26, 'min_samples_leaf': 60, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:41,322] Trial 135 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 690, 'max_depth': 16, 'min_samples_split': 19, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:44,041] Trial 136 finished with value: 0.549520766773163 and parameters: {'n_estimators': 735, 'max_depth': 18, 'min_samples_split': 29, 'min_samples_leaf': 66, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:45,546] Trial 137 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 780, 'max_depth': 21, 'min_samples_split': 42, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:47,222] Trial 138 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 677, 'max_depth': 17, 'min_samples_split': 23, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:49,770] Trial 139 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 831, 'max_depth': 19, 'min_samples_split': 34, 'min_samples_leaf': 75, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:52,219] Trial 140 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 751, 'max_depth': 22, 'min_samples_split': 51, 'min_samples_leaf': 57, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:54,560] Trial 141 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 721, 'max_depth': 20, 'min_samples_split': 31, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:57,184] Trial 142 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 765, 'max_depth': 19, 'min_samples_split': 28, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:52:59,535] Trial 143 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 760, 'max_depth': 20, 'min_samples_split': 40, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:02,149] Trial 144 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 810, 'max_depth': 23, 'min_samples_split': 34, 'min_samples_leaf': 60, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:04,711] Trial 145 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 872, 'max_depth': 21, 'min_samples_split': 28, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:06,833] Trial 146 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 702, 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:09,151] Trial 147 finished with value: 0.5610859728506787 and parameters: {'n_estimators': 795, 'max_depth': 18, 'min_samples_split': 22, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:13,232] Trial 148 finished with value: 0.5495495495495496 and parameters: {'n_estimators': 734, 'max_depth': 13, 'min_samples_split': 37, 'min_samples_leaf': 73, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:15,348] Trial 149 finished with value: 0.5550660792951542 and parameters: {'n_estimators': 641, 'max_depth': 15, 'min_samples_split': 44, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:18,818] Trial 150 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1253, 'max_depth': 20, 'min_samples_split': 25, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:21,543] Trial 151 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 837, 'max_depth': 19, 'min_samples_split': 32, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:24,388] Trial 152 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 852, 'max_depth': 19, 'min_samples_split': 35, 'min_samples_leaf': 61, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:27,058] Trial 153 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 919, 'max_depth': 18, 'min_samples_split': 40, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:29,202] Trial 154 finished with value: 0.5555555555555556 and parameters: {'n_estimators': 769, 'max_depth': 17, 'min_samples_split': 31, 'min_samples_leaf': 42, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:31,614] Trial 155 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 807, 'max_depth': 20, 'min_samples_split': 52, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:34,356] Trial 156 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 879, 'max_depth': 21, 'min_samples_split': 14, 'min_samples_leaf': 58, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:36,662] Trial 157 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 722, 'max_depth': 19, 'min_samples_split': 44, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:38,863] Trial 158 finished with value: 0.5565217391304348 and parameters: {'n_estimators': 675, 'max_depth': 22, 'min_samples_split': 20, 'min_samples_leaf': 53, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:41,234] Trial 159 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 784, 'max_depth': 18, 'min_samples_split': 48, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:45,310] Trial 160 finished with value: 0.5511111111111111 and parameters: {'n_estimators': 756, 'max_depth': 17, 'min_samples_split': 29, 'min_samples_leaf': 70, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:47,707] Trial 161 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 809, 'max_depth': 17, 'min_samples_split': 39, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:50,717] Trial 162 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1142, 'max_depth': 16, 'min_samples_split': 38, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:53,256] Trial 163 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 848, 'max_depth': 19, 'min_samples_split': 34, 'min_samples_leaf': 61, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:55,540] Trial 164 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 784, 'max_depth': 20, 'min_samples_split': 25, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:53:58,037] Trial 165 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 742, 'max_depth': 17, 'min_samples_split': 42, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:00,219] Trial 166 finished with value: 0.5570776255707762 and parameters: {'n_estimators': 708, 'max_depth': 21, 'min_samples_split': 6, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:02,631] Trial 167 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 819, 'max_depth': 18, 'min_samples_split': 31, 'min_samples_leaf': 59, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:04,974] Trial 168 finished with value: 0.5610859728506787 and parameters: {'n_estimators': 766, 'max_depth': 15, 'min_samples_split': 36, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:07,357] Trial 169 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 888, 'max_depth': 19, 'min_samples_split': 27, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:09,721] Trial 170 finished with value: 0.56 and parameters: {'n_estimators': 787, 'max_depth': 20, 'min_samples_split': 56, 'min_samples_leaf': 72, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:12,291] Trial 171 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 838, 'max_depth': 13, 'min_samples_split': 20, 'min_samples_leaf': 60, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:14,814] Trial 172 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 840, 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:17,252] Trial 173 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 861, 'max_depth': 16, 'min_samples_split': 22, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:19,712] Trial 174 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 798, 'max_depth': 18, 'min_samples_split': 32, 'min_samples_leaf': 59, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:22,543] Trial 175 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 958, 'max_depth': 17, 'min_samples_split': 39, 'min_samples_leaf': 56, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:24,866] Trial 176 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 736, 'max_depth': 21, 'min_samples_split': 24, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:28,505] Trial 177 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1366, 'max_depth': 15, 'min_samples_split': 47, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:32,489] Trial 178 finished with value: 0.5488958990536278 and parameters: {'n_estimators': 702, 'max_depth': 18, 'min_samples_split': 29, 'min_samples_leaf': 62, 'max_features': None, 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:35,893] Trial 179 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1184, 'max_depth': 19, 'min_samples_split': 12, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': 'balanced'}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:39,457] Trial 180 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1330, 'max_depth': 16, 'min_samples_split': 35, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:43,007] Trial 181 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1323, 'max_depth': 16, 'min_samples_split': 35, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:45,024] Trial 182 finished with value: 0.5625 and parameters: {'n_estimators': 761, 'max_depth': 16, 'min_samples_split': 41, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:48,792] Trial 183 finished with value: 0.56 and parameters: {'n_estimators': 1352, 'max_depth': 20, 'min_samples_split': 19, 'min_samples_leaf': 61, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:52,205] Trial 184 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1296, 'max_depth': 17, 'min_samples_split': 27, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:55,650] Trial 185 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1286, 'max_depth': 17, 'min_samples_split': 37, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:57,899] Trial 186 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1276, 'max_depth': 19, 'min_samples_split': 44, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:54:59,877] Trial 187 finished with value: 0.5520361990950227 and parameters: {'n_estimators': 1255, 'max_depth': 19, 'min_samples_split': 45, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:02,166] Trial 188 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1324, 'max_depth': 22, 'min_samples_split': 32, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:04,731] Trial 189 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1221, 'max_depth': 20, 'min_samples_split': 27, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:08,308] Trial 190 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1285, 'max_depth': 21, 'min_samples_split': 42, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:11,778] Trial 191 finished with value: 0.5625 and parameters: {'n_estimators': 1298, 'max_depth': 21, 'min_samples_split': 50, 'min_samples_leaf': 74, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:15,365] Trial 192 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1275, 'max_depth': 19, 'min_samples_split': 43, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:18,980] Trial 193 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1269, 'max_depth': 20, 'min_samples_split': 42, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:22,701] Trial 194 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1335, 'max_depth': 18, 'min_samples_split': 46, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:26,299] Trial 195 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1240, 'max_depth': 23, 'min_samples_split': 50, 'min_samples_leaf': 72, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 4 with value: 0.5701357466063348.\n",
      "[I 2025-08-31 21:55:29,907] Trial 196 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 1290, 'max_depth': 21, 'min_samples_split': 43, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:36,825] Trial 197 finished with value: 0.5583756345177665 and parameters: {'n_estimators': 1288, 'max_depth': 21, 'min_samples_split': 55, 'min_samples_leaf': 67, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:40,402] Trial 198 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1304, 'max_depth': 22, 'min_samples_split': 44, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:43,202] Trial 199 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1263, 'max_depth': 19, 'min_samples_split': 41, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:45,087] Trial 200 finished with value: 0.5486725663716814 and parameters: {'n_estimators': 1266, 'max_depth': 18, 'min_samples_split': 41, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:47,171] Trial 201 finished with value: 0.5625 and parameters: {'n_estimators': 1225, 'max_depth': 19, 'min_samples_split': 37, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:49,364] Trial 202 finished with value: 0.5560538116591929 and parameters: {'n_estimators': 1280, 'max_depth': 21, 'min_samples_split': 48, 'min_samples_leaf': 79, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:52,141] Trial 203 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1340, 'max_depth': 19, 'min_samples_split': 60, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:55,670] Trial 204 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1341, 'max_depth': 20, 'min_samples_split': 60, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:55:59,404] Trial 205 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1373, 'max_depth': 19, 'min_samples_split': 62, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:03,126] Trial 206 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1407, 'max_depth': 11, 'min_samples_split': 59, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:06,629] Trial 207 finished with value: 0.56 and parameters: {'n_estimators': 1349, 'max_depth': 14, 'min_samples_split': 65, 'min_samples_leaf': 73, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:10,132] Trial 208 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1328, 'max_depth': 17, 'min_samples_split': 53, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:13,713] Trial 209 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1322, 'max_depth': 17, 'min_samples_split': 69, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:17,259] Trial 210 finished with value: 0.5522388059701493 and parameters: {'n_estimators': 1307, 'max_depth': 18, 'min_samples_split': 53, 'min_samples_leaf': 95, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:19,389] Trial 211 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1330, 'max_depth': 20, 'min_samples_split': 55, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:21,550] Trial 212 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1389, 'max_depth': 19, 'min_samples_split': 51, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:23,835] Trial 213 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1441, 'max_depth': 17, 'min_samples_split': 60, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:25,957] Trial 214 finished with value: 0.5625 and parameters: {'n_estimators': 1391, 'max_depth': 19, 'min_samples_split': 51, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:28,945] Trial 215 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1356, 'max_depth': 16, 'min_samples_split': 45, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:32,184] Trial 216 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1259, 'max_depth': 18, 'min_samples_split': 58, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:35,471] Trial 217 finished with value: 0.5560538116591929 and parameters: {'n_estimators': 1250, 'max_depth': 18, 'min_samples_split': 65, 'min_samples_leaf': 76, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:37,645] Trial 218 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1207, 'max_depth': 18, 'min_samples_split': 58, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:41,530] Trial 219 finished with value: 0.5581395348837209 and parameters: {'n_estimators': 1294, 'max_depth': 17, 'min_samples_split': 52, 'min_samples_leaf': 91, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:44,745] Trial 220 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1262, 'max_depth': 18, 'min_samples_split': 47, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:48,086] Trial 221 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1338, 'max_depth': 19, 'min_samples_split': 42, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:51,691] Trial 222 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1380, 'max_depth': 9, 'min_samples_split': 57, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:55,159] Trial 223 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1315, 'max_depth': 21, 'min_samples_split': 48, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:56:58,643] Trial 224 finished with value: 0.5504587155963303 and parameters: {'n_estimators': 1279, 'max_depth': 19, 'min_samples_split': 62, 'min_samples_leaf': 88, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:01,956] Trial 225 finished with value: 0.5650224215246636 and parameters: {'n_estimators': 1236, 'max_depth': 20, 'min_samples_split': 53, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:05,331] Trial 226 finished with value: 0.5520361990950227 and parameters: {'n_estimators': 1422, 'max_depth': 17, 'min_samples_split': 73, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:08,484] Trial 227 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1308, 'max_depth': 16, 'min_samples_split': 40, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:11,988] Trial 228 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1350, 'max_depth': 18, 'min_samples_split': 43, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:15,389] Trial 229 finished with value: 0.5625 and parameters: {'n_estimators': 1284, 'max_depth': 20, 'min_samples_split': 49, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:18,544] Trial 230 finished with value: 0.56 and parameters: {'n_estimators': 1254, 'max_depth': 15, 'min_samples_split': 37, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:22,034] Trial 231 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1306, 'max_depth': 20, 'min_samples_split': 35, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:25,450] Trial 232 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 1305, 'max_depth': 20, 'min_samples_split': 36, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:28,955] Trial 233 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1321, 'max_depth': 19, 'min_samples_split': 35, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:32,316] Trial 234 finished with value: 0.5570776255707762 and parameters: {'n_estimators': 1313, 'max_depth': 3, 'min_samples_split': 41, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:35,707] Trial 235 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1366, 'max_depth': 21, 'min_samples_split': 37, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:39,259] Trial 236 finished with value: 0.56 and parameters: {'n_estimators': 1368, 'max_depth': 22, 'min_samples_split': 35, 'min_samples_leaf': 72, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:42,371] Trial 237 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1346, 'max_depth': 19, 'min_samples_split': 45, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:45,914] Trial 238 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1391, 'max_depth': 21, 'min_samples_split': 45, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:49,356] Trial 239 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1333, 'max_depth': 8, 'min_samples_split': 39, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:52,898] Trial 240 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1341, 'max_depth': 6, 'min_samples_split': 39, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:56,523] Trial 241 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1352, 'max_depth': 6, 'min_samples_split': 39, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:57:59,943] Trial 242 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1325, 'max_depth': 8, 'min_samples_split': 37, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:03,490] Trial 243 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1340, 'max_depth': 5, 'min_samples_split': 43, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:06,869] Trial 244 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 1302, 'max_depth': 7, 'min_samples_split': 38, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:10,287] Trial 245 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 1298, 'max_depth': 7, 'min_samples_split': 38, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:13,647] Trial 246 finished with value: 0.5570776255707762 and parameters: {'n_estimators': 1284, 'max_depth': 7, 'min_samples_split': 36, 'min_samples_leaf': 84, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:19,863] Trial 247 finished with value: 0.5625 and parameters: {'n_estimators': 1313, 'max_depth': 7, 'min_samples_split': 39, 'min_samples_leaf': 73, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:23,059] Trial 248 finished with value: 0.547945205479452 and parameters: {'n_estimators': 1365, 'max_depth': 7, 'min_samples_split': 34, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:26,390] Trial 249 finished with value: 0.5550660792951542 and parameters: {'n_estimators': 1302, 'max_depth': 9, 'min_samples_split': 45, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:29,920] Trial 250 finished with value: 0.5576208178438662 and parameters: {'n_estimators': 1337, 'max_depth': 8, 'min_samples_split': 50, 'min_samples_leaf': 68, 'max_features': 'log2', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:33,274] Trial 251 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1267, 'max_depth': 6, 'min_samples_split': 39, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:36,148] Trial 252 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1300, 'max_depth': 8, 'min_samples_split': 55, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:38,296] Trial 253 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1381, 'max_depth': 8, 'min_samples_split': 56, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:40,489] Trial 254 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1389, 'max_depth': 6, 'min_samples_split': 58, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:43,023] Trial 255 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1431, 'max_depth': 8, 'min_samples_split': 66, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:45,314] Trial 256 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1462, 'max_depth': 10, 'min_samples_split': 60, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:47,723] Trial 257 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1409, 'max_depth': 7, 'min_samples_split': 55, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:49,940] Trial 258 finished with value: 0.5614035087719298 and parameters: {'n_estimators': 1344, 'max_depth': 8, 'min_samples_split': 54, 'min_samples_leaf': 69, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:52,380] Trial 259 finished with value: 0.5535714285714286 and parameters: {'n_estimators': 1370, 'max_depth': 7, 'min_samples_split': 50, 'min_samples_leaf': 74, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:58:56,064] Trial 260 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1310, 'max_depth': 5, 'min_samples_split': 93, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:02,880] Trial 261 finished with value: 0.5583756345177665 and parameters: {'n_estimators': 1287, 'max_depth': 8, 'min_samples_split': 57, 'min_samples_leaf': 69, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:06,507] Trial 262 finished with value: 0.56 and parameters: {'n_estimators': 1330, 'max_depth': 9, 'min_samples_split': 61, 'min_samples_leaf': 72, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:10,161] Trial 263 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1292, 'max_depth': 6, 'min_samples_split': 47, 'min_samples_leaf': 100, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:12,684] Trial 264 finished with value: 0.5551330798479087 and parameters: {'n_estimators': 1380, 'max_depth': 7, 'min_samples_split': 84, 'min_samples_leaf': 35, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:15,012] Trial 265 finished with value: 0.5570776255707762 and parameters: {'n_estimators': 1347, 'max_depth': 4, 'min_samples_split': 53, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:17,254] Trial 266 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1262, 'max_depth': 8, 'min_samples_split': 47, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:19,474] Trial 267 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1314, 'max_depth': 21, 'min_samples_split': 35, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:21,838] Trial 268 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1331, 'max_depth': 29, 'min_samples_split': 43, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:24,318] Trial 269 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1365, 'max_depth': 19, 'min_samples_split': 78, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:26,444] Trial 270 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 1297, 'max_depth': 20, 'min_samples_split': 69, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:28,226] Trial 271 finished with value: 0.5503355704697986 and parameters: {'n_estimators': 1287, 'max_depth': 20, 'min_samples_split': 63, 'min_samples_leaf': 72, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:30,376] Trial 272 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1265, 'max_depth': 22, 'min_samples_split': 69, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:32,737] Trial 273 finished with value: 0.5625 and parameters: {'n_estimators': 1243, 'max_depth': 19, 'min_samples_split': 50, 'min_samples_leaf': 44, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:37,268] Trial 274 finished with value: 0.5583756345177665 and parameters: {'n_estimators': 1302, 'max_depth': 21, 'min_samples_split': 66, 'min_samples_leaf': 69, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:39,676] Trial 275 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1320, 'max_depth': 20, 'min_samples_split': 34, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:41,894] Trial 276 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1282, 'max_depth': 19, 'min_samples_split': 114, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:44,090] Trial 277 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1341, 'max_depth': 21, 'min_samples_split': 41, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:46,289] Trial 278 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1303, 'max_depth': 23, 'min_samples_split': 45, 'min_samples_leaf': 63, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:48,386] Trial 279 finished with value: 0.5625 and parameters: {'n_estimators': 1238, 'max_depth': 37, 'min_samples_split': 40, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:50,528] Trial 280 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1268, 'max_depth': 20, 'min_samples_split': 109, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:52,942] Trial 281 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1326, 'max_depth': 19, 'min_samples_split': 34, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:54,993] Trial 282 finished with value: 0.5535714285714286 and parameters: {'n_estimators': 1355, 'max_depth': 34, 'min_samples_split': 61, 'min_samples_leaf': 74, 'max_features': 'sqrt', 'bootstrap': False, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:57,142] Trial 283 finished with value: 0.5688888888888889 and parameters: {'n_estimators': 1302, 'max_depth': 19, 'min_samples_split': 48, 'min_samples_leaf': 66, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 21:59:59,390] Trial 284 finished with value: 0.56 and parameters: {'n_estimators': 1282, 'max_depth': 24, 'min_samples_split': 53, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:01,790] Trial 285 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 1213, 'max_depth': 18, 'min_samples_split': 37, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:07,435] Trial 286 finished with value: 0.5583756345177665 and parameters: {'n_estimators': 1237, 'max_depth': 18, 'min_samples_split': 37, 'min_samples_leaf': 69, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:10,691] Trial 287 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1212, 'max_depth': 18, 'min_samples_split': 102, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:13,860] Trial 288 finished with value: 0.5541125541125541 and parameters: {'n_estimators': 1191, 'max_depth': 20, 'min_samples_split': 33, 'min_samples_leaf': 80, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:17,313] Trial 289 finished with value: 0.56 and parameters: {'n_estimators': 1252, 'max_depth': 19, 'min_samples_split': 42, 'min_samples_leaf': 72, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:20,818] Trial 290 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1335, 'max_depth': 21, 'min_samples_split': 38, 'min_samples_leaf': 68, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:24,479] Trial 291 finished with value: 0.56 and parameters: {'n_estimators': 1395, 'max_depth': 19, 'min_samples_split': 32, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:28,259] Trial 292 finished with value: 0.5638766519823789 and parameters: {'n_estimators': 1353, 'max_depth': 22, 'min_samples_split': 43, 'min_samples_leaf': 70, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:31,729] Trial 293 finished with value: 0.5560538116591929 and parameters: {'n_estimators': 1270, 'max_depth': 4, 'min_samples_split': 37, 'min_samples_leaf': 64, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:34,696] Trial 294 finished with value: 0.5495495495495496 and parameters: {'n_estimators': 1318, 'max_depth': 39, 'min_samples_split': 44, 'min_samples_leaf': 67, 'max_features': 'log2', 'bootstrap': False, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:38,046] Trial 295 finished with value: 0.5560538116591929 and parameters: {'n_estimators': 1217, 'max_depth': 20, 'min_samples_split': 39, 'min_samples_leaf': 75, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:41,527] Trial 296 finished with value: 0.56 and parameters: {'n_estimators': 1277, 'max_depth': 18, 'min_samples_split': 33, 'min_samples_leaf': 62, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:45,161] Trial 297 finished with value: 0.5663716814159292 and parameters: {'n_estimators': 1413, 'max_depth': 20, 'min_samples_split': 47, 'min_samples_leaf': 65, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:48,956] Trial 298 finished with value: 0.5575221238938053 and parameters: {'n_estimators': 1361, 'max_depth': 17, 'min_samples_split': 40, 'min_samples_leaf': 71, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n",
      "[I 2025-08-31 22:00:54,810] Trial 299 finished with value: 0.5675675675675675 and parameters: {'n_estimators': 1321, 'max_depth': 18, 'min_samples_split': 30, 'min_samples_leaf': 97, 'max_features': None, 'bootstrap': True, 'class_weight': None}. Best is trial 196 with value: 0.5714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Optuna Best (VAL after threshold) ====\n",
      "Best F1: 0.5714285714285714\n",
      "Best params: {'n_estimators': 1290, 'max_depth': 21, 'min_samples_split': 43, 'min_samples_leaf': 67, 'max_features': 'sqrt', 'bootstrap': True, 'class_weight': None}\n",
      "Best VAL thr: 0.4\n",
      "Best VAL P/R: 0.48484848484848486 0.6956521739130435\n",
      "\n",
      "[Threshold] F1-opt on VAL: t=0.400, F1=0.5714, P=0.4848, R=0.6957\n",
      "[Threshold] Constraint on VAL (P>=0.60): t=0.630, P=0.6216, R=0.2500, F1=0.3566\n",
      "[Threshold] Target PosRate≈10% on VAL: t=0.670, pos_rate=0.0954, P=0.6000, R=0.1630\n",
      "\n",
      "==== Test Performance (held-out, with chosen threshold) ====\n",
      "AUC:           0.603289\n",
      "AveragePrecision(PR-AUC): 0.507350\n",
      "LogLoss:       0.675871\n",
      "Accuracy:      0.579268\n",
      "Precision@t*:  0.502591\n",
      "Recall@t*:     0.697842\n",
      "F1@t*:         0.584337\n",
      "(t* chosen on VAL: 0.400)\n",
      "\n",
      "Score PSI (TrainFit→Val):  1.8256\n",
      "Score PSI (TrainFit→Test): 3.3224\n"
     ]
    }
   ],
   "source": [
    "# ========= 全量可运行脚本：随机森林版（漂移检查 + 阈值策略 + 贝叶斯超参搜索） =========\n",
    "# 依赖：\n",
    "#   pip install numpy pandas scipy scikit-learn optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, log_loss\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "\n",
    "\n",
    "# ========= 公共工具 =========\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random, os\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "\n",
    "# ========= 1) 特征稳定性 / 漂移检查 =========\n",
    "\n",
    "def psi_for_series(train_s: pd.Series, test_s: pd.Series, bins=10):\n",
    "    \"\"\"\n",
    "    Population Stability Index (PSI) for continuous variables.\n",
    "    - 使用训练分位数分箱（稳健）\n",
    "    \"\"\"\n",
    "    train_s = pd.to_numeric(train_s, errors='coerce')\n",
    "    test_s  = pd.to_numeric(test_s,  errors='coerce')\n",
    "    tr = train_s.dropna()\n",
    "    te = test_s.dropna()\n",
    "    if tr.empty or te.empty:\n",
    "        return np.nan\n",
    "    quantiles = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.unique(np.nanquantile(tr, quantiles))\n",
    "    if len(cuts) <= 2:\n",
    "        return np.nan\n",
    "    tr_bins = pd.cut(train_s, bins=cuts, include_lowest=True)\n",
    "    te_bins = pd.cut(test_s,  bins=cuts, include_lowest=True)\n",
    "    tr_ratio = tr_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_ratio.reindex(tr_ratio.index).fillna(0.0)\n",
    "    tr_ratio = tr_ratio.fillna(0.0)\n",
    "    # 平滑避免 log(0)\n",
    "    tr_ratio = tr_ratio.replace(0, 1e-8)\n",
    "    te_ratio = te_ratio.replace(0, 1e-8)\n",
    "    psi = np.sum((te_ratio - tr_ratio) * np.log(te_ratio / tr_ratio))\n",
    "    return float(psi)\n",
    "\n",
    "\n",
    "def cat_psi(train_s: pd.Series, test_s: pd.Series):\n",
    "    \"\"\"\n",
    "    PSI for categorical distributions.\n",
    "    \"\"\"\n",
    "    tr_p = train_s.value_counts(normalize=True)\n",
    "    te_p = test_s.value_counts(normalize=True)\n",
    "    idx = tr_p.index.union(te_p.index)\n",
    "    tr_p = tr_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    te_p = te_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    psi = np.sum((te_p - tr_p) * np.log(te_p / tr_p))\n",
    "    return float(psi)\n",
    "\n",
    "\n",
    "def two_sample_drift(train_s: pd.Series, test_s: pd.Series, is_categorical=False):\n",
    "    \"\"\"\n",
    "    连续：两样本KS检验；类别：卡方独立性检验（p值越小漂移越显著）\n",
    "    \"\"\"\n",
    "    if is_categorical:\n",
    "        idx = pd.Index(pd.concat([train_s.astype(str), test_s.astype(str)], ignore_index=True).unique())\n",
    "        tr_counts = train_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        te_counts = test_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        table = np.vstack([tr_counts.values, te_counts.values])\n",
    "        try:\n",
    "            chi2, p, dof, exp = chi2_contingency(table)\n",
    "        except ValueError:\n",
    "            p = 1.0\n",
    "        return {\"stat\": None, \"pvalue\": float(p)}\n",
    "    else:\n",
    "        tr = pd.to_numeric(train_s, errors='coerce').dropna()\n",
    "        te = pd.to_numeric(test_s,  errors='coerce').dropna()\n",
    "        if len(tr) < 2 or len(te) < 2:\n",
    "            return {\"stat\": None, \"pvalue\": np.nan}\n",
    "        ks = ks_2samp(tr, te, alternative='two-sided', mode='auto')\n",
    "        return {\"stat\": float(ks.statistic), \"pvalue\": float(ks.pvalue)}\n",
    "\n",
    "\n",
    "def drift_report(df_ref: pd.DataFrame, df_new: pd.DataFrame,\n",
    "                 categorical_cols=None, topk=15):\n",
    "    \"\"\"\n",
    "    生成漂移报告（相对参考分布：df_ref）\n",
    "    返回：按严重度排序的表，包括 PSI、KS/Chi² p值、缺失率变化\n",
    "    \"\"\"\n",
    "    categorical_cols = set(categorical_cols or [])\n",
    "    rows = []\n",
    "    for c in df_ref.columns:\n",
    "        is_cat = c in categorical_cols or (df_ref[c].dtype.name in [\"category\", \"object\"])\n",
    "        psi = cat_psi(df_ref[c], df_new[c]) if is_cat else psi_for_series(df_ref[c], df_new[c])\n",
    "        stat = two_sample_drift(df_ref[c], df_new[c], is_categorical=is_cat)\n",
    "        miss_ref = df_ref[c].isna().mean()\n",
    "        miss_new = df_new[c].isna().mean()\n",
    "        rows.append({\n",
    "            \"feature\": c,\n",
    "            \"is_categorical\": is_cat,\n",
    "            \"PSI\": psi,\n",
    "            \"KS/Chi2_p\": stat[\"pvalue\"],\n",
    "            \"KS_stat\": stat[\"stat\"],\n",
    "            \"missing_ref\": miss_ref,\n",
    "            \"missing_new\": miss_new,\n",
    "            \"missing_diff\": miss_new - miss_ref,\n",
    "        })\n",
    "    rep = pd.DataFrame(rows)\n",
    "    rep = rep.sort_values(by=[\"PSI\", \"KS/Chi2_p\"], ascending=[False, True]).reset_index(drop=True)\n",
    "    return rep.iloc[:topk]\n",
    "\n",
    "\n",
    "# ========= 2) 阈值策略 =========\n",
    "\n",
    "def choose_threshold(\n",
    "    y_true, y_prob,\n",
    "    method=\"f1\",                # \"f1\" | \"youden\" | \"constraint\" | \"posrate\"\n",
    "    grid=None,\n",
    "    min_precision=None,\n",
    "    min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    \"\"\"\n",
    "    返回：best_thr, metrics_at_thr(dict), table(DataFrame: 每个阈值的指标)\n",
    "    \"\"\"\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.01, 0.99, 99)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    out_rows = []\n",
    "    best_thr, best_key = 0.5, (-1e9, -1e9)\n",
    "\n",
    "    for t in grid:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        P  = precision_score(y_true, pred, zero_division=0)\n",
    "        R  = recall_score(y_true, pred, zero_division=0)\n",
    "        F1 = f1_score(y_true, pred, zero_division=0)\n",
    "        pos_rate = pred.mean()\n",
    "\n",
    "        tn = np.sum((pred==0)&(y_true==0))\n",
    "        fp = np.sum((pred==1)&(y_true==0))\n",
    "        fn = np.sum((pred==0)&(y_true==1))\n",
    "        tp = np.sum((pred==1)&(y_true==1))\n",
    "        TNR = tn / max(1, (tn+fp))\n",
    "        J = R + TNR - 1  # Youden's J\n",
    "\n",
    "        out_rows.append({\"thr\": t, \"precision\": P, \"recall\": R, \"f1\": F1,\n",
    "                         \"youdenJ\": J, \"pos_rate\": pos_rate, \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn})\n",
    "\n",
    "        if method == \"f1\":\n",
    "            key = (F1, 0.0)\n",
    "        elif method == \"youden\":\n",
    "            key = (J, 0.0)\n",
    "        elif method == \"posrate\" and target_pos_rate is not None:\n",
    "            key = (-abs(pos_rate - target_pos_rate), 0.0)\n",
    "        elif method == \"constraint\":\n",
    "            if (min_precision is not None and P < min_precision) or (min_recall is not None and R < min_recall):\n",
    "                key = (-1e9, -1e9)\n",
    "            else:\n",
    "                key = (R, F1)  # 先比 Recall，再比 F1\n",
    "        else:\n",
    "            key = (F1, 0.0)\n",
    "\n",
    "        if key > best_key:\n",
    "            best_key = key\n",
    "            best_thr = t\n",
    "\n",
    "    table = pd.DataFrame(out_rows).sort_values(\"thr\").reset_index(drop=True)\n",
    "    best_row = table.loc[table[\"thr\"].sub(best_thr).abs().idxmin()].to_dict()\n",
    "    return float(best_thr), best_row, table\n",
    "\n",
    "\n",
    "# ========= 3) 分数 PSI（可选） =========\n",
    "\n",
    "def score_psi(ref_scores, new_scores, bins=10):\n",
    "    ref = pd.Series(ref_scores)\n",
    "    new = pd.Series(new_scores)\n",
    "    return psi_for_series(ref, new, bins=bins)\n",
    "\n",
    "\n",
    "# ========= 4) 数据准备（和你原脚本一致） =========\n",
    "\n",
    "def temporal_split(df_clean: pd.DataFrame,\n",
    "                   label_col=\"value_sort\",\n",
    "                   cutoff_date=None,       # 例如 \"2024-12-31\"；None 则走比例切分\n",
    "                   test_size_ratio=0.2,\n",
    "                   val_size_ratio=0.2):\n",
    "    \"\"\"\n",
    "    返回：\n",
    "      X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols\n",
    "    \"\"\"\n",
    "    assert label_col in df_clean.columns\n",
    "    df = df_clean.copy()\n",
    "\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        df = df.sort_index()\n",
    "    else:\n",
    "        df = df.sort_index()\n",
    "\n",
    "    feat_cols = df.columns.drop([label_col]).tolist()\n",
    "    X_all = df[feat_cols].values\n",
    "    y_all = df[label_col].astype(int).values\n",
    "\n",
    "    if cutoff_date is not None:\n",
    "        assert isinstance(df.index, pd.DatetimeIndex), \"需将 df_clean.index 设为 DatetimeIndex 才能按日期切分\"\n",
    "        mask_trainval = (df.index <= pd.to_datetime(cutoff_date))\n",
    "        X_trainval, y_trainval = X_all[mask_trainval], y_all[mask_trainval]\n",
    "        X_test, y_test = X_all[~mask_trainval], y_all[~mask_trainval]\n",
    "\n",
    "        n_tv = len(X_trainval)\n",
    "        n_val = max(1, int(n_tv * val_size_ratio))\n",
    "        X_tr, y_tr = X_trainval[:-n_val], y_trainval[:-n_val]\n",
    "        X_val, y_val = X_trainval[-n_val:], y_trainval[-n_val:]\n",
    "        return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "    N = len(X_all)\n",
    "    n_test = max(1, int(N * test_size_ratio))\n",
    "    X_tv, y_tv = X_all[:-n_test], y_all[:-n_test]\n",
    "    X_test, y_test = X_all[-n_test:], y_all[-n_test:]\n",
    "\n",
    "    n_tv = len(X_tv)\n",
    "    n_val = max(1, int(n_tv * val_size_ratio))\n",
    "    X_tr, y_tr = X_tv[:-n_val], y_tv[:-n_val]\n",
    "    X_val, y_val = X_tv[-n_val:], y_tv[-n_val:]\n",
    "    return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "\n",
    "# ========= 5) Optuna + 随机森林 搜索 =========\n",
    "\n",
    "def run_optuna_rf(X_tr, y_tr, X_val, y_val, n_trials=80, method_for_thr=\"f1\",\n",
    "                  constraint_min_precision=None, constraint_min_recall=None,\n",
    "                  target_pos_rate=None):\n",
    "    \"\"\"\n",
    "    在验证集上“先找阈值再算F1”为目标的贝叶斯优化（TPE）。\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 40),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 200),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 100),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "            \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\"]),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        val_prob = model.predict_proba(X_val)[:, 1]\n",
    "        if method_for_thr == \"constraint\":\n",
    "            thr, row, _ = choose_threshold(\n",
    "                y_val, val_prob, method=\"constraint\",\n",
    "                min_precision=constraint_min_precision, min_recall=constraint_min_recall\n",
    "            )\n",
    "        elif method_for_thr == \"posrate\":\n",
    "            thr, row, _ = choose_threshold(\n",
    "                y_val, val_prob, method=\"posrate\", target_pos_rate=target_pos_rate\n",
    "            )\n",
    "        elif method_for_thr == \"youden\":\n",
    "            thr, row, _ = choose_threshold(y_val, val_prob, method=\"youden\")\n",
    "        else:\n",
    "            thr, row, _ = choose_threshold(y_val, val_prob, method=\"f1\")\n",
    "\n",
    "        trial.set_user_attr(\"thr\", thr)\n",
    "        trial.set_user_attr(\"P\", row[\"precision\"])\n",
    "        trial.set_user_attr(\"R\", row[\"recall\"])\n",
    "        return float(row[\"f1\"])\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "\n",
    "# ========= 6) 主流程（把所有步骤串起来） =========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # ======= 切分 =======\n",
    "    cutoff_date = None  # 例如 \"2024-12-31\"；None 则使用比例切分\n",
    "    X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols = temporal_split(\n",
    "        df_clean, label_col=\"value_sort\", cutoff_date=cutoff_date,\n",
    "        test_size_ratio=0.2, val_size_ratio=0.2\n",
    "    )\n",
    "\n",
    "    # ======= 漂移检查（TrainFit vs Test） =======\n",
    "    df_tr_fit = pd.DataFrame(X_tr_fit_raw, columns=feat_cols)\n",
    "    df_val    = pd.DataFrame(X_val_fit_raw, columns=feat_cols)\n",
    "    df_te     = pd.DataFrame(X_te_raw,     columns=feat_cols)\n",
    "\n",
    "    rep_tr_te = drift_report(df_tr_fit, df_te, categorical_cols=[], topk=30)\n",
    "    print(\"\\n==== Top Drifted Features (TrainFit vs Test) ====\")\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    print(rep_tr_te.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    # ======= 贝叶斯优化（以验证集“找阈值后的F1”为目标） =======\n",
    "    study = run_optuna_rf(\n",
    "        X_tr_fit_raw, y_tr_fit,\n",
    "        X_val_fit_raw, y_val_fit,\n",
    "        n_trials=300,                 # 可根据时间调整\n",
    "        method_for_thr=\"f1\",          # 可改为 \"youden\" / \"constraint\" / \"posrate\"\n",
    "        constraint_min_precision=None,\n",
    "        constraint_min_recall=None,\n",
    "        target_pos_rate=None\n",
    "    )\n",
    "\n",
    "    print(\"\\n==== Optuna Best (VAL after threshold) ====\")\n",
    "    print(\"Best F1:\", study.best_value)\n",
    "    print(\"Best params:\", study.best_trial.params)\n",
    "    print(\"Best VAL thr:\", study.best_trial.user_attrs.get(\"thr\"))\n",
    "    print(\"Best VAL P/R:\", study.best_trial.user_attrs.get(\"P\"), study.best_trial.user_attrs.get(\"R\"))\n",
    "\n",
    "    # ======= 用最优参数重新训练最终模型 =======\n",
    "    best_params = study.best_trial.params\n",
    "    final_model = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "    final_model.fit(X_tr_fit_raw, y_tr_fit)\n",
    "\n",
    "    # ======= 在验证集上选“生产用阈值” =======\n",
    "    val_prob = final_model.predict_proba(X_val_fit_raw)[:, 1]\n",
    "    thr_f1, row_f1, table_f1 = choose_threshold(y_val_fit, val_prob, method=\"f1\")\n",
    "    print(f\"\\n[Threshold] F1-opt on VAL: t={thr_f1:.3f}, F1={row_f1['f1']:.4f}, \"\n",
    "          f\"P={row_f1['precision']:.4f}, R={row_f1['recall']:.4f}\")\n",
    "\n",
    "    thr_cons, row_cons, _ = choose_threshold(\n",
    "        y_val_fit, val_prob, method=\"constraint\", min_precision=0.60\n",
    "    )\n",
    "    print(f\"[Threshold] Constraint on VAL (P>=0.60): t={thr_cons:.3f}, \"\n",
    "          f\"P={row_cons['precision']:.4f}, R={row_cons['recall']:.4f}, F1={row_cons['f1']:.4f}\")\n",
    "\n",
    "    thr_pr, row_pr, _ = choose_threshold(\n",
    "        y_val_fit, val_prob, method=\"posrate\", target_pos_rate=0.10\n",
    "    )\n",
    "    print(f\"[Threshold] Target PosRate≈10% on VAL: t={thr_pr:.3f}, \"\n",
    "          f\"pos_rate={row_pr['pos_rate']:.4f}, P={row_pr['precision']:.4f}, R={row_pr['recall']:.4f}\")\n",
    "\n",
    "    chosen_thr = thr_f1  # 可自行选择策略\n",
    "\n",
    "    # ======= 测试集评估（固定 chosen_thr） =======\n",
    "    y_te_prob = final_model.predict_proba(X_te_raw)[:, 1]\n",
    "    y_te_pred = (y_te_prob >= chosen_thr).astype(int)\n",
    "\n",
    "    test_auc  = safe_auc(y_te, y_te_prob)\n",
    "    test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "    test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== Test Performance (held-out, with chosen threshold) ====\")\n",
    "    print(f\"AUC:           {test_auc:.6f}\")\n",
    "    print(f\"AveragePrecision(PR-AUC): {test_ap:.6f}\")\n",
    "    print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "    print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "    print(f\"Precision@t*:  {test_prec:.6f}\")\n",
    "    print(f\"Recall@t*:     {test_rec:.6f}\")\n",
    "    print(f\"F1@t*:         {test_f1:.6f}\")\n",
    "    print(f\"(t* chosen on VAL: {chosen_thr:.3f})\")\n",
    "\n",
    "    # ======= 分数 PSI（可选） =======\n",
    "    tr_scores  = final_model.predict_proba(X_tr_fit_raw)[:, 1]\n",
    "    val_scores = final_model.predict_proba(X_val_fit_raw)[:, 1]\n",
    "    te_scores  = y_te_prob\n",
    "    print(\"\\nScore PSI (TrainFit→Val): \", f\"{score_psi(tr_scores, val_scores):.4f}\")\n",
    "    print(\"Score PSI (TrainFit→Test):\", f\"{score_psi(tr_scores, te_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8411b1",
   "metadata": {},
   "source": [
    "# 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561393d",
   "metadata": {},
   "source": [
    "## 阈值版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0cda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 10:52:15,186] A new study created in memory with name: no-name-ce7cbb1d-f17a-4e36-8bc0-2757e46ffce8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top Drifted Features (TrainFit vs Test) ====\n",
      "      feature  is_categorical    PSI  KS/Chi2_p  KS_stat  missing_ref  missing_new  missing_diff\n",
      "   DR001_5dMA           False 2.6073     0.0000   0.2267       0.0000       0.0000        0.0000\n",
      "    二级1y-永续1y           False 2.5647     0.0000   0.3762       0.0000       0.0000        0.0000\n",
      "        DR001           False 2.4290     0.0000   0.2448       0.0000       0.0000        0.0000\n",
      "      二级5y-3y           False 2.2933     0.0000   0.1910       0.0000       0.0000        0.0000\n",
      "永续1yYTM_20dMA           False 1.5247     0.0000   0.3877       0.0000       0.0000        0.0000\n",
      "      永续5yYTM           False 1.3985     0.0000   0.3480       0.0000       0.0000        0.0000\n",
      "      永续4yYTM           False 1.3672     0.0000   0.3299       0.0000       0.0000        0.0000\n",
      " 永续5yYTM_5dMA           False 1.3060     0.0000   0.3616       0.0000       0.0000        0.0000\n",
      "      永续3yYTM           False 1.1914     0.0000   0.3374       0.0000       0.0000        0.0000\n",
      " 永续4yYTM_5dMA           False 1.1451     0.0000   0.3521       0.0000       0.0000        0.0000\n",
      "永续2yYTM_20dMA           False 1.1333     0.0000   0.3775       0.0000       0.0000        0.0000\n",
      " 永续3yYTM_5dMA           False 1.1331     0.0000   0.3447       0.0000       0.0000        0.0000\n",
      " 永续2yYTM_5dMA           False 1.0784     0.0000   0.3232       0.0000       0.0000        0.0000\n",
      "永续5yYTM_20dMA           False 1.0629     0.0000   0.3421       0.0000       0.0000        0.0000\n",
      "      永续1yYTM           False 1.0057     0.0000   0.3172       0.0000       0.0000        0.0000\n",
      " 永续1yYTM_5dMA           False 0.9632     0.0000   0.3361       0.0000       0.0000        0.0000\n",
      "      永续2yYTM           False 0.9279     0.0000   0.3243       0.0000       0.0000        0.0000\n",
      "永续3yYTM_20dMA           False 0.8240     0.0000   0.3773       0.0000       0.0000        0.0000\n",
      "    R001_5dMA           False 0.8178     0.0000   0.2043       0.0000       0.0000        0.0000\n",
      "永续4yYTM_20dMA           False 0.7275     0.0000   0.3815       0.0000       0.0000        0.0000\n",
      "NCD1mYTM_5dMA           False 0.7018     0.0000   0.2252       0.0000       0.0000        0.0000\n",
      "         R001           False 0.6860     0.0000   0.2297       0.0000       0.0000        0.0000\n",
      "        TS持仓量           False 0.6595     0.0000   0.2057       0.0000       0.0000        0.0000\n",
      "        TF成交量           False 0.6470     0.0000   0.1825       0.0000       0.0000        0.0000\n",
      "   DR014_5dMA           False 0.6323     0.0000   0.2229       0.0000       0.0000        0.0000\n",
      "    二级3y-永续3y           False 0.6118     0.0000   0.2836       0.0000       0.0000        0.0000\n",
      "        TS成交量           False 0.5969     0.0000   0.1652       0.0000       0.0000        0.0000\n",
      "        TF持仓量           False 0.5817     0.0000   0.1763       0.0000       0.0000        0.0000\n",
      "    R007-R001           False 0.5618     0.0000   0.1936       0.0000       0.0000        0.0000\n",
      "    R014_5dMA           False 0.5547     0.0000   0.2049       0.0000       0.0000        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 10:52:15,987] Trial 0 finished with value: 0.7849223946784922 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 13.184812572165542, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1939}. Best is trial 0 with value: 0.7849223946784922.\n",
      "[I 2025-09-05 10:52:16,482] Trial 1 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.08826393967784867, 'class_weight': None, 'fit_intercept': False, 'max_iter': 327}. Best is trial 1 with value: 0.7876106194690266.\n",
      "[I 2025-09-05 10:52:16,797] Trial 2 finished with value: 0.7931034482758621 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0019708682949461957, 'class_weight': None, 'fit_intercept': False, 'max_iter': 464}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:17,119] Trial 3 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 0.0038466187656967465, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1075, 'l1_ratio': 0.8457454698918057}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:17,939] Trial 4 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.38269266257625806, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1238}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:20,016] Trial 5 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 63.05893192737256, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1347, 'l1_ratio': 0.3714683797059152}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:22,358] Trial 6 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 28.744626848542136, 'class_weight': None, 'fit_intercept': False, 'max_iter': 1581, 'l1_ratio': 0.344888627859963}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:24,317] Trial 7 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 5.419849261557931, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1254, 'l1_ratio': 0.6305761616749141}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:24,676] Trial 8 finished with value: 0.7880184331797235 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.016886684168699845, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1773}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:25,182] Trial 9 finished with value: 0.7884187082405345 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.1300188189432922, 'class_weight': None, 'fit_intercept': False, 'max_iter': 611}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:25,485] Trial 10 finished with value: 0.7901234567901234 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0017884656387244522, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 795}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:25,788] Trial 11 finished with value: 0.7892156862745098 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0014988928622591078, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 800}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:26,091] Trial 12 finished with value: 0.7914691943127962 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.009108954888382117, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 334}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:26,392] Trial 13 finished with value: 0.789598108747045 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.013157332893120583, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 344}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:26,701] Trial 14 finished with value: 0.789598108747045 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.015598200752739775, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 553}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:27,034] Trial 15 finished with value: 0.7884187082405345 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.6235359526645047, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 894}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:27,332] Trial 16 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.006551427026180971, 'class_weight': None, 'fit_intercept': False, 'max_iter': 544}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:27,638] Trial 17 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0480867040737129, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 403}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:27,943] Trial 18 finished with value: 0.789838337182448 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0010449390600801838, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1022}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:28,297] Trial 19 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 1.1236269968525654, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 692}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:28,604] Trial 20 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.044429553040518446, 'class_weight': None, 'fit_intercept': False, 'max_iter': 482}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:28,914] Trial 21 finished with value: 0.7889908256880734 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0031708613209988595, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 773}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:29,220] Trial 22 finished with value: 0.7889908256880734 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.002522867955210187, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 941}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:29,536] Trial 23 finished with value: 0.7885985748218527 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.008049413969823458, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 691}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:29,848] Trial 24 finished with value: 0.7880184331797235 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0012948097513747344, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 303}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:30,168] Trial 25 finished with value: 0.7887323943661971 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.029146633240237828, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 443}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:30,509] Trial 26 finished with value: 0.7894736842105263 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.004760773921124924, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 639}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:30,817] Trial 27 finished with value: 0.7880184331797235 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.0024186242768285573, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 897}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:31,130] Trial 28 finished with value: 0.7889908256880734 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.16096689192523672, 'class_weight': None, 'fit_intercept': False, 'max_iter': 469}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:32,479] Trial 29 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 2.539604040902869, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 753, 'l1_ratio': 0.06153738017155641}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:32,781] Trial 30 finished with value: 0.7912621359223301 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.020432836063218007, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1922}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:33,089] Trial 31 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.008129473838732073, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1948}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:33,392] Trial 32 finished with value: 0.7883211678832117 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.027120555825639325, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1486}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:33,694] Trial 33 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.002559793743392419, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1801}. Best is trial 2 with value: 0.7931034482758621.\n",
      "[I 2025-09-05 10:52:34,001] Trial 34 finished with value: 0.794044665012407 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.07717178495116836, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1086}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:34,305] Trial 35 finished with value: 0.7881773399014779 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.0971028984186152, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1592}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:34,615] Trial 36 finished with value: 0.7888631090487239 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.2150643554439923, 'class_weight': None, 'fit_intercept': False, 'max_iter': 1410}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:35,074] Trial 37 finished with value: 0.7901234567901234 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.05578814803302637, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 1153}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:35,394] Trial 38 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.440653551858349, 'class_weight': None, 'fit_intercept': False, 'max_iter': 1214}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:35,822] Trial 39 finished with value: 0.7883211678832117 and parameters: {'penalty': 'elasticnet', 'C': 0.02361268976741813, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1842, 'l1_ratio': 0.930624422345085}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:36,308] Trial 40 finished with value: 0.7910447761194029 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.07744875317870943, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1574}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:36,803] Trial 41 finished with value: 0.7920792079207921 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.08980857620895193, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1662}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:37,202] Trial 42 finished with value: 0.7883211678832117 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.010751889145001558, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1901}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:38,139] Trial 43 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.29043160052046463, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1705}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:38,466] Trial 44 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.005865533320036274, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1332}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:38,876] Trial 45 finished with value: 0.7931034482758621 and parameters: {'penalty': 'elasticnet', 'C': 0.018648532925179408, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1999, 'l1_ratio': 0.1791661227794767}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:39,511] Trial 46 finished with value: 0.7884187082405345 and parameters: {'penalty': 'elasticnet', 'C': 0.11785354926865808, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1643, 'l1_ratio': 0.05125470750386307}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:39,956] Trial 47 finished with value: 0.7913669064748201 and parameters: {'penalty': 'elasticnet', 'C': 0.037396865373021206, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1988, 'l1_ratio': 0.2661782188266931}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:40,778] Trial 48 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 13.651780009125016, 'class_weight': None, 'fit_intercept': True, 'max_iter': 377, 'l1_ratio': 0.5954702452586639}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:42,435] Trial 49 finished with value: 0.7901785714285714 and parameters: {'penalty': 'elasticnet', 'C': 7.086067836622769, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1027, 'l1_ratio': 0.6036608345214011}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:45,069] Trial 50 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 18.71949398298945, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1755, 'l1_ratio': 0.5279585394854422}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:45,485] Trial 51 finished with value: 0.7922705314009661 and parameters: {'penalty': 'elasticnet', 'C': 0.01259782738160714, 'class_weight': None, 'fit_intercept': True, 'max_iter': 372, 'l1_ratio': 0.7103771610080316}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:46,282] Trial 52 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 62.3813921795699, 'class_weight': None, 'fit_intercept': True, 'max_iter': 367, 'l1_ratio': 0.7116577376228019}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:47,293] Trial 53 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 1.8625994144333393, 'class_weight': None, 'fit_intercept': True, 'max_iter': 531, 'l1_ratio': 0.44716202806239624}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:48,108] Trial 54 finished with value: 0.7884187082405345 and parameters: {'penalty': 'elasticnet', 'C': 0.73244441642112, 'class_weight': None, 'fit_intercept': True, 'max_iter': 386, 'l1_ratio': 0.7680088267418307}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:48,612] Trial 55 finished with value: 0.7887323943661971 and parameters: {'penalty': 'elasticnet', 'C': 0.06691775039117531, 'class_weight': None, 'fit_intercept': True, 'max_iter': 575, 'l1_ratio': 0.18536181740373459}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:49,028] Trial 56 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 0.01612798030606356, 'class_weight': None, 'fit_intercept': True, 'max_iter': 427, 'l1_ratio': 0.5410700401330876}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:49,898] Trial 57 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 0.20530222586504351, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1409, 'l1_ratio': 0.6938854396614607}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:50,231] Trial 58 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 0.004210051751603699, 'class_weight': None, 'fit_intercept': True, 'max_iter': 505, 'l1_ratio': 0.8362876678900188}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:50,660] Trial 59 finished with value: 0.7916666666666666 and parameters: {'penalty': 'elasticnet', 'C': 0.03598215787395202, 'class_weight': None, 'fit_intercept': True, 'max_iter': 602, 'l1_ratio': 0.613858104021338}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:51,074] Trial 60 finished with value: 0.7900677200902935 and parameters: {'penalty': 'elasticnet', 'C': 0.013030008683462413, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1135, 'l1_ratio': 0.4660173179406517}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:51,879] Trial 61 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 95.16800429690849, 'class_weight': None, 'fit_intercept': True, 'max_iter': 368, 'l1_ratio': 0.7231797359501075}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:52,595] Trial 62 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 50.90021437409916, 'class_weight': None, 'fit_intercept': True, 'max_iter': 300, 'l1_ratio': 0.6912469498179419}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:53,534] Trial 63 finished with value: 0.7892376681614349 and parameters: {'penalty': 'elasticnet', 'C': 33.88411886200112, 'class_weight': None, 'fit_intercept': True, 'max_iter': 399, 'l1_ratio': 0.7686864175175177}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:54,443] Trial 64 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 9.203993865000747, 'class_weight': None, 'fit_intercept': True, 'max_iter': 456, 'l1_ratio': 0.6019377236006035}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:55,632] Trial 65 finished with value: 0.7901785714285714 and parameters: {'penalty': 'elasticnet', 'C': 20.616065503307574, 'class_weight': None, 'fit_intercept': True, 'max_iter': 666, 'l1_ratio': 0.8175678732589089}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:56,395] Trial 66 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 3.9577145140289915, 'class_weight': None, 'fit_intercept': True, 'max_iter': 342, 'l1_ratio': 0.15915909461438843}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:57,835] Trial 67 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 88.75779432073796, 'class_weight': None, 'fit_intercept': True, 'max_iter': 841, 'l1_ratio': 0.9356720500489777}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:58,554] Trial 68 finished with value: 0.7901785714285714 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 30.798303308244545, 'class_weight': None, 'fit_intercept': True, 'max_iter': 500}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:52:59,830] Trial 69 finished with value: 0.7901785714285714 and parameters: {'penalty': 'elasticnet', 'C': 11.684894075077485, 'class_weight': None, 'fit_intercept': True, 'max_iter': 728, 'l1_ratio': 0.6623151750307986}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:00,151] Trial 70 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.001904196314417115, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1524}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:01,115] Trial 71 finished with value: 0.7901785714285714 and parameters: {'penalty': 'elasticnet', 'C': 1.4474042979890942, 'class_weight': None, 'fit_intercept': True, 'max_iter': 497, 'l1_ratio': 0.4376561681894573}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:02,187] Trial 72 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 2.245706060507226, 'class_weight': None, 'fit_intercept': True, 'max_iter': 574, 'l1_ratio': 0.5539865279969637}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:03,220] Trial 73 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 3.8266554075097146, 'class_weight': None, 'fit_intercept': True, 'max_iter': 534, 'l1_ratio': 0.4182561570833421}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:04,114] Trial 74 finished with value: 0.7892376681614349 and parameters: {'penalty': 'elasticnet', 'C': 61.4748365490898, 'class_weight': None, 'fit_intercept': True, 'max_iter': 415, 'l1_ratio': 0.7514533830580731}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:04,730] Trial 75 finished with value: 0.7901785714285714 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.5351052114945762, 'class_weight': None, 'fit_intercept': True, 'max_iter': 342}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:05,873] Trial 76 finished with value: 0.7901785714285714 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.8866710140510898, 'class_weight': None, 'fit_intercept': False, 'max_iter': 633}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:06,527] Trial 77 finished with value: 0.7877358490566038 and parameters: {'penalty': 'elasticnet', 'C': 0.1467330234227654, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1845, 'l1_ratio': 0.3523173809939172}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:07,462] Trial 78 finished with value: 0.7901785714285714 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 45.242576115708125, 'class_weight': None, 'fit_intercept': False, 'max_iter': 443}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:08,228] Trial 79 finished with value: 0.7901785714285714 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.31561259141923975, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1284}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:09,118] Trial 80 finished with value: 0.7884187082405345 and parameters: {'penalty': 'elasticnet', 'C': 18.674701029507858, 'class_weight': None, 'fit_intercept': False, 'max_iter': 384, 'l1_ratio': 0.2613962843620209}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:09,897] Trial 81 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 76.40616205369105, 'class_weight': None, 'fit_intercept': True, 'max_iter': 323, 'l1_ratio': 0.7312741826952085}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:10,730] Trial 82 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 96.5508047995796, 'class_weight': None, 'fit_intercept': True, 'max_iter': 358, 'l1_ratio': 0.6633043000607524}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:11,584] Trial 83 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 36.762961892840934, 'class_weight': None, 'fit_intercept': True, 'max_iter': 372, 'l1_ratio': 0.7181222867627718}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:12,140] Trial 84 finished with value: 0.7903614457831325 and parameters: {'penalty': 'elasticnet', 'C': 0.098369416549026, 'class_weight': None, 'fit_intercept': True, 'max_iter': 532, 'l1_ratio': 0.8644875423165307}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:12,513] Trial 85 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 0.001042331256038553, 'class_weight': None, 'fit_intercept': True, 'max_iter': 978, 'l1_ratio': 0.5741046242919794}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:13,026] Trial 86 finished with value: 0.7901234567901234 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.05562865308827853, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 478}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:13,418] Trial 87 finished with value: 0.7900677200902935 and parameters: {'penalty': 'elasticnet', 'C': 0.006370675485274084, 'class_weight': None, 'fit_intercept': False, 'max_iter': 425, 'l1_ratio': 0.2900880823125746}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:14,008] Trial 88 finished with value: 0.7919463087248322 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 66.928203489993, 'class_weight': None, 'fit_intercept': True, 'max_iter': 308}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:14,343] Trial 89 finished with value: 0.7876106194690266 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.0034593283054062747, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1624}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:14,757] Trial 90 finished with value: 0.7885985748218527 and parameters: {'penalty': 'elasticnet', 'C': 0.010614767069815793, 'class_weight': None, 'fit_intercept': True, 'max_iter': 817, 'l1_ratio': 0.7976183541115275}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:17,412] Trial 91 finished with value: 0.7876106194690266 and parameters: {'penalty': 'elasticnet', 'C': 53.29633709111698, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1711, 'l1_ratio': 0.6743509543328854}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:18,146] Trial 92 finished with value: 0.7919463087248322 and parameters: {'penalty': 'elasticnet', 'C': 24.40525718393427, 'class_weight': None, 'fit_intercept': True, 'max_iter': 303, 'l1_ratio': 0.6326513298590404}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:18,588] Trial 93 finished with value: 0.7935779816513762 and parameters: {'penalty': 'elasticnet', 'C': 0.032061069378203466, 'class_weight': None, 'fit_intercept': True, 'max_iter': 369, 'l1_ratio': 0.7049120175197922}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:19,039] Trial 94 finished with value: 0.7935779816513762 and parameters: {'penalty': 'elasticnet', 'C': 0.02224723008990655, 'class_weight': None, 'fit_intercept': True, 'max_iter': 368, 'l1_ratio': 0.48493092056141807}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:19,478] Trial 95 finished with value: 0.7916666666666666 and parameters: {'penalty': 'elasticnet', 'C': 0.029985963132407638, 'class_weight': None, 'fit_intercept': True, 'max_iter': 408, 'l1_ratio': 0.49651245765046265}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:19,900] Trial 96 finished with value: 0.7913669064748201 and parameters: {'penalty': 'elasticnet', 'C': 0.02101121228194041, 'class_weight': None, 'fit_intercept': True, 'max_iter': 476, 'l1_ratio': 0.09722569112990732}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:20,221] Trial 97 finished with value: 0.7899543378995434 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.040335209417878146, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1990}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:20,730] Trial 98 finished with value: 0.7887323943661971 and parameters: {'penalty': 'elasticnet', 'C': 0.08025815837270005, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1448, 'l1_ratio': 0.5049493149621899}. Best is trial 34 with value: 0.794044665012407.\n",
      "[I 2025-09-05 10:53:21,133] Trial 99 finished with value: 0.7877358490566038 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.017915584652711456, 'class_weight': None, 'fit_intercept': True, 'max_iter': 587}. Best is trial 34 with value: 0.794044665012407.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Optuna Best (VAL after threshold) ====\n",
      "Best F1: 0.794044665012407\n",
      "Best params: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.07717178495116836, 'class_weight': 'balanced', 'fit_intercept': False, 'max_iter': 1086}\n",
      "Best VAL thr: 0.4\n",
      "Best VAL P/R: 0.7111111111111111 0.898876404494382\n",
      "\n",
      "[Threshold] F1-opt on VAL: t=0.400, F1=0.7940, P=0.7111, R=0.8989\n",
      "[Threshold] Constraint on VAL (P>=0.60): t=0.010, P=0.6496, R=1.0000, F1=0.7876\n",
      "[Threshold] Target PosRate≈10% on VAL: t=0.710, pos_rate=0.0912, P=0.8000, R=0.1124\n",
      "\n",
      "==== Test Performance (held-out, with chosen threshold) ====\n",
      "AUC:           0.603329\n",
      "AveragePrecision(PR-AUC): 0.675435\n",
      "LogLoss:       0.693271\n",
      "Accuracy:      0.620991\n",
      "Precision@t*:  0.636029\n",
      "Recall@t*:     0.848039\n",
      "F1@t*:         0.726891\n",
      "(t* chosen on VAL: 0.400)\n",
      "\n",
      "Score PSI (TrainFit→Val):  0.0898\n",
      "Score PSI (TrainFit→Test): 0.0502\n"
     ]
    }
   ],
   "source": [
    "# ========= 全量可运行脚本：逻辑回归版（漂移检查 + 阈值策略 + 贝叶斯超参搜索） =========\n",
    "# 依赖：\n",
    "#   pip install numpy pandas scipy scikit-learn optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, log_loss\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "\n",
    "\n",
    "# ========= 公共工具 =========\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random, os\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "\n",
    "# ========= 1) 特征稳定性 / 漂移检查 =========\n",
    "\n",
    "def psi_for_series(train_s: pd.Series, test_s: pd.Series, bins=10):\n",
    "    train_s = pd.to_numeric(train_s, errors='coerce')\n",
    "    test_s  = pd.to_numeric(test_s,  errors='coerce')\n",
    "    tr = train_s.dropna()\n",
    "    te = test_s.dropna()\n",
    "    if tr.empty or te.empty:\n",
    "        return np.nan\n",
    "    quantiles = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.unique(np.nanquantile(tr, quantiles))\n",
    "    if len(cuts) <= 2:\n",
    "        return np.nan\n",
    "    tr_bins = pd.cut(train_s, bins=cuts, include_lowest=True)\n",
    "    te_bins = pd.cut(test_s,  bins=cuts, include_lowest=True)\n",
    "    tr_ratio = tr_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_ratio.reindex(tr_ratio.index).fillna(0.0)\n",
    "    tr_ratio = tr_ratio.fillna(0.0)\n",
    "    tr_ratio = tr_ratio.replace(0, 1e-8)\n",
    "    te_ratio = te_ratio.replace(0, 1e-8)\n",
    "    psi = np.sum((te_ratio - tr_ratio) * np.log(te_ratio / tr_ratio))\n",
    "    return float(psi)\n",
    "\n",
    "\n",
    "def cat_psi(train_s: pd.Series, test_s: pd.Series):\n",
    "    tr_p = train_s.value_counts(normalize=True)\n",
    "    te_p = test_s.value_counts(normalize=True)\n",
    "    idx = tr_p.index.union(te_p.index)\n",
    "    tr_p = tr_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    te_p = te_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    psi = np.sum((te_p - tr_p) * np.log(te_p / tr_p))\n",
    "    return float(psi)\n",
    "\n",
    "\n",
    "def two_sample_drift(train_s: pd.Series, test_s: pd.Series, is_categorical=False):\n",
    "    if is_categorical:\n",
    "        idx = pd.Index(pd.concat([train_s.astype(str), test_s.astype(str)], ignore_index=True).unique())\n",
    "        tr_counts = train_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        te_counts = test_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        table = np.vstack([tr_counts.values, te_counts.values])\n",
    "        try:\n",
    "            chi2, p, dof, exp = chi2_contingency(table)\n",
    "        except ValueError:\n",
    "            p = 1.0\n",
    "        return {\"stat\": None, \"pvalue\": float(p)}\n",
    "    else:\n",
    "        tr = pd.to_numeric(train_s, errors='coerce').dropna()\n",
    "        te = pd.to_numeric(test_s,  errors='coerce').dropna()\n",
    "        if len(tr) < 2 or len(te) < 2:\n",
    "            return {\"stat\": None, \"pvalue\": np.nan}\n",
    "        ks = ks_2samp(tr, te, alternative='two-sided', mode='auto')\n",
    "        return {\"stat\": float(ks.statistic), \"pvalue\": float(ks.pvalue)}\n",
    "\n",
    "\n",
    "def drift_report(df_ref: pd.DataFrame, df_new: pd.DataFrame,\n",
    "                 categorical_cols=None, topk=15):\n",
    "    categorical_cols = set(categorical_cols or [])\n",
    "    rows = []\n",
    "    for c in df_ref.columns:\n",
    "        is_cat = c in categorical_cols or (df_ref[c].dtype.name in [\"category\", \"object\"])\n",
    "        psi = cat_psi(df_ref[c], df_new[c]) if is_cat else psi_for_series(df_ref[c], df_new[c])\n",
    "        stat = two_sample_drift(df_ref[c], df_new[c], is_categorical=is_cat)\n",
    "        miss_ref = df_ref[c].isna().mean()\n",
    "        miss_new = df_new[c].isna().mean()\n",
    "        rows.append({\n",
    "            \"feature\": c,\n",
    "            \"is_categorical\": is_cat,\n",
    "            \"PSI\": psi,\n",
    "            \"KS/Chi2_p\": stat[\"pvalue\"],\n",
    "            \"KS_stat\": stat[\"stat\"],\n",
    "            \"missing_ref\": miss_ref,\n",
    "            \"missing_new\": miss_new,\n",
    "            \"missing_diff\": miss_new - miss_ref,\n",
    "        })\n",
    "    rep = pd.DataFrame(rows)\n",
    "    rep = rep.sort_values(by=[\"PSI\", \"KS/Chi2_p\"], ascending=[False, True]).reset_index(drop=True)\n",
    "    return rep.iloc[:topk]\n",
    "\n",
    "\n",
    "# ========= 2) 阈值策略 =========\n",
    "\n",
    "def choose_threshold(\n",
    "    y_true, y_prob,\n",
    "    method=\"f1\",                # \"f1\" | \"youden\" | \"constraint\" | \"posrate\"\n",
    "    grid=None,\n",
    "    min_precision=None,\n",
    "    min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.01, 0.99, 99)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    out_rows = []\n",
    "    best_thr, best_key = 0.5, (-1e9, -1e9)\n",
    "\n",
    "    for t in grid:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        P  = precision_score(y_true, pred, zero_division=0)\n",
    "        R  = recall_score(y_true, pred, zero_division=0)\n",
    "        F1 = f1_score(y_true, pred, zero_division=0)\n",
    "        pos_rate = pred.mean()\n",
    "\n",
    "        tn = np.sum((pred==0)&(y_true==0))\n",
    "        fp = np.sum((pred==1)&(y_true==0))\n",
    "        fn = np.sum((pred==0)&(y_true==1))\n",
    "        tp = np.sum((pred==1)&(y_true==1))\n",
    "        TNR = tn / max(1, (tn+fp))\n",
    "        J = R + TNR - 1\n",
    "\n",
    "        out_rows.append({\"thr\": t, \"precision\": P, \"recall\": R, \"f1\": F1,\n",
    "                         \"youdenJ\": J, \"pos_rate\": pos_rate, \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn})\n",
    "\n",
    "        if method == \"f1\":\n",
    "            key = (F1, 0.0)\n",
    "        elif method == \"youden\":\n",
    "            key = (J, 0.0)\n",
    "        elif method == \"posrate\" and target_pos_rate is not None:\n",
    "            key = (-abs(pos_rate - target_pos_rate), 0.0)\n",
    "        elif method == \"constraint\":\n",
    "            if (min_precision is not None and P < min_precision) or (min_recall is not None and R < min_recall):\n",
    "                key = (-1e9, -1e9)\n",
    "            else:\n",
    "                key = (R, F1)\n",
    "        else:\n",
    "            key = (F1, 0.0)\n",
    "\n",
    "        if key > best_key:\n",
    "            best_key = key\n",
    "            best_thr = t\n",
    "\n",
    "    table = pd.DataFrame(out_rows).sort_values(\"thr\").reset_index(drop=True)\n",
    "    best_row = table.loc[table[\"thr\"].sub(best_thr).abs().idxmin()].to_dict()\n",
    "    return float(best_thr), best_row, table\n",
    "\n",
    "\n",
    "# ========= 3) 分数 PSI（可选） =========\n",
    "\n",
    "def score_psi(ref_scores, new_scores, bins=10):\n",
    "    ref = pd.Series(ref_scores)\n",
    "    new = pd.Series(new_scores)\n",
    "    return psi_for_series(ref, new, bins=bins)\n",
    "\n",
    "\n",
    "# ========= 4) 数据准备（与原脚本一致） =========\n",
    "\n",
    "def temporal_split(df_clean: pd.DataFrame,\n",
    "                   label_col=\"value_sort\",\n",
    "                   cutoff_date=None,\n",
    "                   test_size_ratio=0.2,\n",
    "                   val_size_ratio=0.2):\n",
    "    assert label_col in df_clean.columns\n",
    "    df = df_clean.copy()\n",
    "\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        df = df.sort_index()\n",
    "    else:\n",
    "        df = df.sort_index()\n",
    "\n",
    "    feat_cols = df.columns.drop([label_col]).tolist()\n",
    "    X_all = df[feat_cols].values\n",
    "    y_all = df[label_col].astype(int).values\n",
    "\n",
    "    if cutoff_date is not None:\n",
    "        assert isinstance(df.index, pd.DatetimeIndex), \"需将 df_clean.index 设为 DatetimeIndex 才能按日期切分\"\n",
    "        mask_trainval = (df.index <= pd.to_datetime(cutoff_date))\n",
    "        X_trainval, y_trainval = X_all[mask_trainval], y_all[mask_trainval]\n",
    "        X_test, y_test = X_all[~mask_trainval], y_all[~mask_trainval]\n",
    "\n",
    "        n_tv = len(X_trainval)\n",
    "        n_val = max(1, int(n_tv * val_size_ratio))\n",
    "        X_tr, y_tr = X_trainval[:-n_val], y_trainval[:-n_val]\n",
    "        X_val, y_val = X_trainval[-n_val:], y_trainval[-n_val:]\n",
    "        return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "    N = len(X_all)\n",
    "    n_test = max(1, int(N * test_size_ratio))\n",
    "    X_tv, y_tv = X_all[:-n_test], y_all[:-n_test]\n",
    "    X_test, y_test = X_all[-n_test:], y_all[-n_test:]\n",
    "\n",
    "    n_tv = len(X_tv)\n",
    "    n_val = max(1, int(n_tv * val_size_ratio))\n",
    "    X_tr, y_tr = X_tv[:-n_val], y_tv[:-n_val]\n",
    "    X_val, y_val = X_tv[-n_val:], y_tv[-n_val:]\n",
    "    return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "\n",
    "# ========= 5) Optuna + 逻辑回归 搜索 =========\n",
    "\n",
    "def run_optuna_logreg(X_tr, y_tr, X_val, y_val, n_trials=120, method_for_thr=\"f1\",\n",
    "                      constraint_min_precision=None, constraint_min_recall=None,\n",
    "                      target_pos_rate=None):\n",
    "    \"\"\"\n",
    "    在验证集上“先找阈值再算F1”为目标的贝叶斯优化（TPE）。\n",
    "    使用 Pipeline(StandardScaler + LogisticRegression)；支持 L1/L2/ElasticNet。\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        # 选择正则类型\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l2\", \"l1\", \"elasticnet\"])\n",
    "        # 选择 solver（兼容性处理）\n",
    "        if penalty == \"elasticnet\":\n",
    "            solver = \"saga\"\n",
    "        else:\n",
    "            solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\"])  # 二分类均支持\n",
    "\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 100.0, log=True)\n",
    "        class_weight = trial.suggest_categorical(\"class_weight\", [None, \"balanced\"])\n",
    "        fit_intercept = trial.suggest_categorical(\"fit_intercept\", [True, False])\n",
    "        max_iter = trial.suggest_int(\"max_iter\", 300, 2000)\n",
    "\n",
    "        # elasticnet 的 l1_ratio\n",
    "        if penalty == \"elasticnet\":\n",
    "            l1_ratio = trial.suggest_float(\"l1_ratio\", 0.05, 0.95)\n",
    "        else:\n",
    "            l1_ratio = None\n",
    "\n",
    "        # 构建管道：先标准化再逻辑回归\n",
    "        logreg_kwargs = dict(\n",
    "            penalty=penalty,\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            class_weight=class_weight,\n",
    "            fit_intercept=fit_intercept,\n",
    "            max_iter=max_iter,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            # elasticnet 专属\n",
    "            l1_ratio=l1_ratio if penalty == \"elasticnet\" else None,\n",
    "        )\n",
    "\n",
    "        model = Pipeline([\n",
    "            (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "            (\"clf\", LogisticRegression(**logreg_kwargs))\n",
    "        ])\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        val_prob = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        if method_for_thr == \"constraint\":\n",
    "            thr, row, _ = choose_threshold(\n",
    "                y_val, val_prob, method=\"constraint\",\n",
    "                min_precision=constraint_min_precision, min_recall=constraint_min_recall\n",
    "            )\n",
    "        elif method_for_thr == \"posrate\":\n",
    "            thr, row, _ = choose_threshold(\n",
    "                y_val, val_prob, method=\"posrate\", target_pos_rate=target_pos_rate\n",
    "            )\n",
    "        elif method_for_thr == \"youden\":\n",
    "            thr, row, _ = choose_threshold(y_val, val_prob, method=\"youden\")\n",
    "        else:\n",
    "            thr, row, _ = choose_threshold(y_val, val_prob, method=\"f1\")\n",
    "\n",
    "        trial.set_user_attr(\"thr\", thr)\n",
    "        trial.set_user_attr(\"P\", row[\"precision\"])\n",
    "        trial.set_user_attr(\"R\", row[\"recall\"])\n",
    "        return float(row[\"f1\"])\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "\n",
    "# ========= 6) 主流程（把所有步骤串起来） =========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ======= 读取/准备数据 =======\n",
    "    # df_clean = pd.read_csv(\"your_data.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "    # assert \"value_sort\" in df_clean.columns\n",
    "\n",
    "\n",
    "    # ======= 切分 =======\n",
    "    cutoff_date = None\n",
    "    X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols = temporal_split(\n",
    "        df_clean, label_col=\"value_sort\", cutoff_date=cutoff_date,\n",
    "        test_size_ratio=0.2, val_size_ratio=0.2\n",
    "    )\n",
    "\n",
    "    # ======= 漂移检查（TrainFit vs Test） =======\n",
    "    df_tr_fit = pd.DataFrame(X_tr_fit_raw, columns=feat_cols)\n",
    "    df_val    = pd.DataFrame(X_val_fit_raw, columns=feat_cols)\n",
    "    df_te     = pd.DataFrame(X_te_raw,     columns=feat_cols)\n",
    "\n",
    "    rep_tr_te = drift_report(df_tr_fit, df_te, categorical_cols=[], topk=30)\n",
    "    print(\"\\n==== Top Drifted Features (TrainFit vs Test) ====\")\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    print(rep_tr_te.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    # ======= 贝叶斯优化（以验证集“找阈值后的F1”为目标） =======\n",
    "    study = run_optuna_logreg(\n",
    "        X_tr_fit_raw, y_tr_fit,\n",
    "        X_val_fit_raw, y_val_fit,\n",
    "        n_trials=100,                 # 可按时间调整\n",
    "        method_for_thr=\"f1\",          # 或 \"youden\" / \"constraint\" / \"posrate\"\n",
    "        constraint_min_precision=None,\n",
    "        constraint_min_recall=None,\n",
    "        target_pos_rate=None\n",
    "    )\n",
    "\n",
    "    print(\"\\n==== Optuna Best (VAL after threshold) ====\")\n",
    "    print(\"Best F1:\", study.best_value)\n",
    "    print(\"Best params:\", study.best_trial.params)\n",
    "    print(\"Best VAL thr:\", study.best_trial.user_attrs.get(\"thr\"))\n",
    "    print(\"Best VAL P/R:\", study.best_trial.user_attrs.get(\"P\"), study.best_trial.user_attrs.get(\"R\"))\n",
    "\n",
    "    # ======= 用最优参数重新训练最终模型 =======\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    # 根据 best_params 重新构建最终模型（保持同样的管道）\n",
    "    penalty = best_params[\"penalty\"]\n",
    "    solver = \"saga\" if penalty == \"elasticnet\" else best_params.get(\"solver\", \"liblinear\")\n",
    "    l1_ratio = best_params.get(\"l1_ratio\", None) if penalty == \"elasticnet\" else None\n",
    "\n",
    "    final_model = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            C=best_params[\"C\"],\n",
    "            class_weight=best_params[\"class_weight\"],\n",
    "            fit_intercept=best_params[\"fit_intercept\"],\n",
    "            max_iter=best_params[\"max_iter\"],\n",
    "            l1_ratio=l1_ratio,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    final_model.fit(X_tr_fit_raw, y_tr_fit)\n",
    "\n",
    "    # ======= 在验证集上选“生产用阈值” =======\n",
    "    val_prob = final_model.predict_proba(X_val_fit_raw)[:, 1]\n",
    "    thr_f1, row_f1, table_f1 = choose_threshold(y_val_fit, val_prob, method=\"f1\")\n",
    "    print(f\"\\n[Threshold] F1-opt on VAL: t={thr_f1:.3f}, F1={row_f1['f1']:.4f}, \"\n",
    "          f\"P={row_f1['precision']:.4f}, R={row_f1['recall']:.4f}\")\n",
    "\n",
    "    thr_cons, row_cons, _ = choose_threshold(\n",
    "        y_val_fit, val_prob, method=\"constraint\", min_precision=0.60\n",
    "    )\n",
    "    print(f\"[Threshold] Constraint on VAL (P>=0.60): t={thr_cons:.3f}, \"\n",
    "          f\"P={row_cons['precision']:.4f}, R={row_cons['recall']:.4f}, F1={row_cons['f1']:.4f}\")\n",
    "\n",
    "    thr_pr, row_pr, _ = choose_threshold(\n",
    "        y_val_fit, val_prob, method=\"posrate\", target_pos_rate=0.10\n",
    "    )\n",
    "    print(f\"[Threshold] Target PosRate≈10% on VAL: t={thr_pr:.3f}, \"\n",
    "          f\"pos_rate={row_pr['pos_rate']:.4f}, P={row_pr['precision']:.4f}, R={row_pr['recall']:.4f}\")\n",
    "\n",
    "    chosen_thr = thr_f1  # 可按需要改为其它策略\n",
    "\n",
    "    # ======= 测试集评估（固定 chosen_thr） =======\n",
    "    y_te_prob = final_model.predict_proba(X_te_raw)[:, 1]\n",
    "    y_te_pred = (y_te_prob >= chosen_thr).astype(int)\n",
    "\n",
    "    test_auc  = safe_auc(y_te, y_te_prob)\n",
    "    test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "    test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== Test Performance (held-out, with chosen threshold) ====\")\n",
    "    print(f\"AUC:           {test_auc:.6f}\")\n",
    "    print(f\"AveragePrecision(PR-AUC): {test_ap:.6f}\")\n",
    "    print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "    print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "    print(f\"Precision@t*:  {test_prec:.6f}\")\n",
    "    print(f\"Recall@t*:     {test_rec:.6f}\")\n",
    "    print(f\"F1@t*:         {test_f1:.6f}\")\n",
    "    print(f\"(t* chosen on VAL: {chosen_thr:.3f})\")\n",
    "\n",
    "    # ======= 分数 PSI（可选） =======\n",
    "    tr_scores  = final_model.predict_proba(X_tr_fit_raw)[:, 1]\n",
    "    val_scores = final_model.predict_proba(X_val_fit_raw)[:, 1]\n",
    "    te_scores  = y_te_prob\n",
    "    print(\"\\nScore PSI (TrainFit→Val): \", f\"{score_psi(tr_scores, val_scores):.4f}\")\n",
    "    print(\"Score PSI (TrainFit→Test):\", f\"{score_psi(tr_scores, te_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd327db",
   "metadata": {},
   "source": [
    "# 隐马尔可夫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c2d7f",
   "metadata": {},
   "source": [
    "## 面向测试集调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a33aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: 145148.0945090285 is not greater than 145148.09452551545. Delta is -1.6486941603943706e-05\n",
      "Model is not converging.  Current: 231901.1067901219 is not greater than 231901.1067911509. Delta is -1.0289950296282768e-06\n",
      "Model is not converging.  Current: 185032.3055924265 is not greater than 185032.3055964872. Delta is -4.060682840645313e-06\n",
      "Model is not converging.  Current: 275616.4446456088 is not greater than 275616.4446484718. Delta is -2.863002009689808e-06\n",
      "Model is not converging.  Current: 196536.03875853555 is not greater than 196536.03886057113. Delta is -0.00010203558485955\n",
      "Model is not converging.  Current: 185251.16252033255 is not greater than 185251.16252620515. Delta is -5.8726000133901834e-06\n",
      "Model is not converging.  Current: 185032.3055929774 is not greater than 185032.30559633204. Delta is -3.3546239137649536e-06\n",
      "Model is not converging.  Current: 232358.29224445685 is not greater than 232358.29224498905. Delta is -5.321926437318325e-07\n",
      "Model is not converging.  Current: 144146.0111581426 is not greater than 144146.01127534712. Delta is -0.00011720453039743006\n",
      "Model is not converging.  Current: -69476.35832277751 is not greater than -69476.32596081146. Delta is -0.03236196604848374\n",
      "Model is not converging.  Current: 232376.32987173286 is not greater than 232376.3298722024. Delta is -4.6953209675848484e-07\n",
      "Model is not converging.  Current: 185032.3055953192 is not greater than 185032.30559560124. Delta is -2.820452209562063e-07\n",
      "Model is not converging.  Current: 232376.3298717352 is not greater than 232376.32987311887. Delta is -1.3836834114044905e-06\n",
      "Model is not converging.  Current: 274942.0486634376 is not greater than 274942.04866466223. Delta is -1.2246309779584408e-06\n",
      "Model is not converging.  Current: 196219.58865116214 is not greater than 196219.58944877554. Delta is -0.000797613407485187\n",
      "Model is not converging.  Current: 185032.30559424192 is not greater than 185032.3055983998. Delta is -4.157889634370804e-06\n",
      "Model is not converging.  Current: -69476.35832477917 is not greater than -69476.32596385555. Delta is -0.03236092362203635\n",
      "[W 2025-08-31 22:25:41,964] Trial 41 failed with parameters: {'n_components': 3, 'covariance_type': 'full', 'covar_reg_value': 1.008201075819115e-08, 'n_iter': 222, 'tol': 0.00022008091359569708} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\conda\\envs\\lau\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\86198\\AppData\\Local\\Temp\\ipykernel_24340\\1021111042.py\", line 95, in objective\n",
      "    y_prob_te, _, _ = hmm_fit_and_predict_proba(\n",
      "                      ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        X_tr_fit, y_tr_fit, X_te,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        random_state=42\n",
      "        ^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\86198\\AppData\\Local\\Temp\\ipykernel_24340\\1021111042.py\", line 69, in hmm_fit_and_predict_proba\n",
      "    model.fit(X_tr_fit)\n",
      "    ~~~~~~~~~^^^^^^^^^^\n",
      "  File \"d:\\conda\\envs\\lau\\Lib\\site-packages\\hmmlearn\\base.py\", line 480, in fit\n",
      "    self._init(X, lengths)\n",
      "    ~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"d:\\conda\\envs\\lau\\Lib\\site-packages\\hmmlearn\\hmm.py\", line 314, in _init\n",
      "    kmeans.fit(X)\n",
      "    ~~~~~~~~~~^^^\n",
      "  File \"d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 1510, in fit\n",
      "    labels, inertia, centers, n_iter_ = kmeans_single(\n",
      "                                        ~~~~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<5 lines>...\n",
      "        n_threads=self._n_threads,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 173, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 700, in _kmeans_single_lloyd\n",
      "    lloyd_iter(\n",
      "    ~~~~~~~~~~^\n",
      "        X,\n",
      "        ^^\n",
      "    ...<6 lines>...\n",
      "        n_threads,\n",
      "        ^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"sklearn/cluster/_k_means_lloyd.pyx\", line 160, in sklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense\n",
      "  File \"sklearn/cluster/_k_means_common.pyx\", line 177, in sklearn.cluster._k_means_common._relocate_empty_clusters_dense\n",
      "  File \"d:\\conda\\envs\\lau\\Lib\\site-packages\\numpy\\_core\\multiarray.py\", line 383, in where\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.where)\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2025-08-31 22:25:41,979] Trial 41 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(test_acc)\n\u001b[32m    107\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m study.optimize(objective, n_trials=\u001b[32m50\u001b[39m, show_progress_bar=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    109\u001b[39m best_params = study.best_params\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# ===== 用最优参数重训，并评估测试集 =====\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     _optimize(\n\u001b[32m    490\u001b[39m         study=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    491\u001b[39m         func=func,\n\u001b[32m    492\u001b[39m         n_trials=n_trials,\n\u001b[32m    493\u001b[39m         timeout=timeout,\n\u001b[32m    494\u001b[39m         n_jobs=n_jobs,\n\u001b[32m    495\u001b[39m         catch=\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[32m    496\u001b[39m         callbacks=callbacks,\n\u001b[32m    497\u001b[39m         gc_after_trial=gc_after_trial,\n\u001b[32m    498\u001b[39m         show_progress_bar=show_progress_bar,\n\u001b[32m    499\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         _optimize_sequential(\n\u001b[32m     65\u001b[39m             study,\n\u001b[32m     66\u001b[39m             func,\n\u001b[32m     67\u001b[39m             n_trials,\n\u001b[32m     68\u001b[39m             timeout,\n\u001b[32m     69\u001b[39m             catch,\n\u001b[32m     70\u001b[39m             callbacks,\n\u001b[32m     71\u001b[39m             gc_after_trial,\n\u001b[32m     72\u001b[39m             reseed_sampler_rng=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     73\u001b[39m             time_start=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     74\u001b[39m             progress_bar=progress_bar,\n\u001b[32m     75\u001b[39m         )\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = _run_trial(study, func, catch)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = func(trial)\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial: optuna.Trial):\n\u001b[32m     87\u001b[39m     params = {\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mn_components\u001b[39m\u001b[33m\"\u001b[39m: trial.suggest_int(\u001b[33m\"\u001b[39m\u001b[33mn_components\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m6\u001b[39m),\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcovariance_type\u001b[39m\u001b[33m\"\u001b[39m: trial.suggest_categorical(\u001b[33m\"\u001b[39m\u001b[33mcovariance_type\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mfull\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdiag\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m   (...)\u001b[39m\u001b[32m     93\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtol\u001b[39m\u001b[33m\"\u001b[39m: trial.suggest_float(\u001b[33m\"\u001b[39m\u001b[33mtol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1e-5\u001b[39m, \u001b[32m1e-2\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     94\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     y_prob_te, _, _ = hmm_fit_and_predict_proba(\n\u001b[32m     96\u001b[39m         X_tr_fit, y_tr_fit, X_te,\n\u001b[32m     97\u001b[39m         n_components=params[\u001b[33m\"\u001b[39m\u001b[33mn_components\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     98\u001b[39m         covariance_type=params[\u001b[33m\"\u001b[39m\u001b[33mcovariance_type\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     99\u001b[39m         covar_reg_value=params[\u001b[33m\"\u001b[39m\u001b[33mcovar_reg_value\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    100\u001b[39m         n_iter=params[\u001b[33m\"\u001b[39m\u001b[33mn_iter\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    101\u001b[39m         tol=params[\u001b[33m\"\u001b[39m\u001b[33mtol\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    102\u001b[39m         random_state=\u001b[32m42\u001b[39m\n\u001b[32m    103\u001b[39m     )\n\u001b[32m    104\u001b[39m     test_acc = acc_from_prob(y_te, y_prob_te, thr=\u001b[32m0.5\u001b[39m)\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(test_acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mhmm_fit_and_predict_proba\u001b[39m\u001b[34m(X_tr_fit, y_tr_fit, X_te, n_components, covariance_type, covar_reg_value, n_iter, tol, random_state)\u001b[39m\n\u001b[32m     66\u001b[39m hmm_kwargs[_COVAR_PARAM_NAME] = covar_reg_value\n\u001b[32m     68\u001b[39m model = GaussianHMM(**hmm_kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m model.fit(X_tr_fit)\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# 训练集后验责任度\u001b[39;00m\n\u001b[32m     72\u001b[39m _, post_tr = model.score_samples(X_tr_fit)  \u001b[38;5;66;03m# [T_train, n_components]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\hmmlearn\\base.py:480\u001b[39m, in \u001b[36m_AbstractHMM.fit\u001b[39m\u001b[34m(self, X, lengths)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lengths \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    478\u001b[39m     lengths = np.asarray([X.shape[\u001b[32m0\u001b[39m]])\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[38;5;28mself\u001b[39m._init(X, lengths)\n\u001b[32m    481\u001b[39m \u001b[38;5;28mself\u001b[39m._check()\n\u001b[32m    482\u001b[39m \u001b[38;5;28mself\u001b[39m.monitor_._reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\hmmlearn\\hmm.py:314\u001b[39m, in \u001b[36mGaussianHMM._init\u001b[39m\u001b[34m(self, X, lengths)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._needs_init(\u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmeans_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    311\u001b[39m     kmeans = cluster.KMeans(n_clusters=\u001b[38;5;28mself\u001b[39m.n_components,\n\u001b[32m    312\u001b[39m                             random_state=\u001b[38;5;28mself\u001b[39m.random_state,\n\u001b[32m    313\u001b[39m                             n_init=\u001b[32m10\u001b[39m)  \u001b[38;5;66;03m# sklearn <1.4 backcompat.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     kmeans.fit(X)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28mself\u001b[39m.means_ = kmeans.cluster_centers_\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._needs_init(\u001b[33m\"\u001b[39m\u001b[33mc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcovars_\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1510\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1507\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitialization complete\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1509\u001b[39m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1510\u001b[39m labels, inertia, centers, n_iter_ = kmeans_single(\n\u001b[32m   1511\u001b[39m     X,\n\u001b[32m   1512\u001b[39m     sample_weight,\n\u001b[32m   1513\u001b[39m     centers_init,\n\u001b[32m   1514\u001b[39m     max_iter=\u001b[38;5;28mself\u001b[39m.max_iter,\n\u001b[32m   1515\u001b[39m     verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m   1516\u001b[39m     tol=\u001b[38;5;28mself\u001b[39m._tol,\n\u001b[32m   1517\u001b[39m     n_threads=\u001b[38;5;28mself\u001b[39m._n_threads,\n\u001b[32m   1518\u001b[39m )\n\u001b[32m   1520\u001b[39m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[32m   1521\u001b[39m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[32m   1525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1526\u001b[39m     inertia < best_inertia\n\u001b[32m   1527\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m.n_clusters)\n\u001b[32m   1528\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\parallel.py:173\u001b[39m, in \u001b[36m_threadpool_controller_decorator.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    171\u001b[39m controller = _get_threadpool_controller()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m controller.limit(limits=limits, user_api=user_api):\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:700\u001b[39m, in \u001b[36m_kmeans_single_lloyd\u001b[39m\u001b[34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[39m\n\u001b[32m    697\u001b[39m strict_convergence = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     lloyd_iter(\n\u001b[32m    701\u001b[39m         X,\n\u001b[32m    702\u001b[39m         sample_weight,\n\u001b[32m    703\u001b[39m         centers,\n\u001b[32m    704\u001b[39m         centers_new,\n\u001b[32m    705\u001b[39m         weight_in_clusters,\n\u001b[32m    706\u001b[39m         labels,\n\u001b[32m    707\u001b[39m         center_shift,\n\u001b[32m    708\u001b[39m         n_threads,\n\u001b[32m    709\u001b[39m     )\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m    712\u001b[39m         inertia = _inertia(X, sample_weight, centers, labels, n_threads)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\cluster\\_k_means_lloyd.pyx:160\u001b[39m, in \u001b[36msklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\cluster\\_k_means_common.pyx:177\u001b[39m, in \u001b[36msklearn.cluster._k_means_common._relocate_empty_clusters_dense\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\numpy\\_core\\multiarray.py:383\u001b[39m, in \u001b[36mwhere\u001b[39m\u001b[34m(condition, x, y)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    inner(a, b, /)\u001b[39;00m\n\u001b[32m    293\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    378\u001b[39m \n\u001b[32m    379\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, b)\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath.where)\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwhere\u001b[39m(condition, x=\u001b[38;5;28;01mNone\u001b[39;00m, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    385\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    386\u001b[39m \u001b[33;03m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[32m    387\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    454\u001b[39m \u001b[33;03m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (condition, x, y)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import inspect\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ====== 检测 HMM 的协方差正则化参数名（reg_covar or min_covar）======\n",
    "_HMM_KWARGS = set(inspect.signature(GaussianHMM.__init__).parameters.keys())\n",
    "_HAS_REG_COVAR = \"reg_covar\" in _HMM_KWARGS\n",
    "_COVAR_PARAM_NAME = \"reg_covar\" if _HAS_REG_COVAR else \"min_covar\"\n",
    "\n",
    "# ===== 数据 =====\n",
    "# df_clean: 特征列 + 'value_sort'(0/1)\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te_raw, y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 标准化（只在训练集上拟合）\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr_raw)\n",
    "X_te = scaler.transform(X_te_raw)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def acc_from_prob(y_true, y_prob, thr=0.5):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 训练集最后10%作为“观察指标”的val段（不参与HMM拟合，仅与原模板保持结构）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr[val_start:], y_tr[val_start:]\n",
    "\n",
    "# ===== HMM 拟合 & 概率预测 =====\n",
    "def hmm_fit_and_predict_proba(\n",
    "    X_tr_fit, y_tr_fit, X_te,\n",
    "    n_components=2,\n",
    "    covariance_type=\"full\",\n",
    "    covar_reg_value=1e-6,   # 兼容：会映射到 reg_covar 或 min_covar\n",
    "    n_iter=500,\n",
    "    tol=1e-3,\n",
    "    random_state=42\n",
    "):\n",
    "    hmm_kwargs = dict(\n",
    "        n_components=n_components,\n",
    "        covariance_type=covariance_type,\n",
    "        n_iter=n_iter,\n",
    "        tol=tol,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    # 填入正确的协方差正则参数\n",
    "    hmm_kwargs[_COVAR_PARAM_NAME] = covar_reg_value\n",
    "\n",
    "    model = GaussianHMM(**hmm_kwargs)\n",
    "    model.fit(X_tr_fit)\n",
    "\n",
    "    # 训练集后验责任度\n",
    "    _, post_tr = model.score_samples(X_tr_fit)  # [T_train, n_components]\n",
    "\n",
    "    # 状态 -> 上涨概率\n",
    "    state_weight_sum = post_tr.sum(axis=0) + 1e-12\n",
    "    state_up_sum = (post_tr * y_tr_fit.reshape(-1, 1)).sum(axis=0)\n",
    "    state_up_prob = state_up_sum / state_weight_sum  # [n_components]\n",
    "\n",
    "    # 测试集后验 -> 上涨概率\n",
    "    _, post_te = model.score_samples(X_te)  # [T_test, n_components]\n",
    "    y_te_prob = (post_te * state_up_prob.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    return y_te_prob, model, state_up_prob\n",
    "\n",
    "# ===== 目标函数：以“测试集Accuracy@0.5”作为最优标准 =====\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        \"n_components\": trial.suggest_int(\"n_components\", 2, 6),\n",
    "        \"covariance_type\": trial.suggest_categorical(\"covariance_type\", [\"full\", \"diag\"]),\n",
    "        # 注意：这里统一叫 covar_reg_value，内部会根据你的 hmmlearn 版本映射到 reg_covar 或 min_covar\n",
    "        \"covar_reg_value\": trial.suggest_float(\"covar_reg_value\", 1e-8, 1e-2, log=True),\n",
    "        \"n_iter\": trial.suggest_int(\"n_iter\", 200, 800),\n",
    "        \"tol\": trial.suggest_float(\"tol\", 1e-5, 1e-2, log=True),\n",
    "    }\n",
    "    y_prob_te, _, _ = hmm_fit_and_predict_proba(\n",
    "        X_tr_fit, y_tr_fit, X_te,\n",
    "        n_components=params[\"n_components\"],\n",
    "        covariance_type=params[\"covariance_type\"],\n",
    "        covar_reg_value=params[\"covar_reg_value\"],\n",
    "        n_iter=params[\"n_iter\"],\n",
    "        tol=params[\"tol\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    test_acc = acc_from_prob(y_te, y_prob_te, thr=0.5)\n",
    "    return float(test_acc)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=False)\n",
    "best_params = study.best_params\n",
    "\n",
    "# ===== 用最优参数重训，并评估测试集 =====\n",
    "y_te_prob, final_model, state_up_prob = hmm_fit_and_predict_proba(\n",
    "    X_tr_fit, y_tr_fit, X_te,\n",
    "    n_components=best_params[\"n_components\"],\n",
    "    covariance_type=best_params[\"covariance_type\"],\n",
    "    covar_reg_value=best_params[\"covar_reg_value\"],\n",
    "    n_iter=best_params[\"n_iter\"],\n",
    "    tol=best_params[\"tol\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "y_te_pred = (y_te_prob >= 0.5).astype(int)\n",
    "\n",
    "test_auc  = safe_auc(y_te, y_te_prob)\n",
    "test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "# 避免 log(0)\n",
    "p2 = np.clip(y_te_prob, 1e-12, 1 - 1e-12)\n",
    "test_logloss = log_loss(y_te, np.vstack([1 - p2, p2]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n==== Test Performance (used for selection: Accuracy@0.5) ====\")\n",
    "print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "print(f\"AUC:           {test_auc:.6f}\")\n",
    "print(f\"PR-AUC:        {test_ap:.6f}\")\n",
    "print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "print(f\"Precision@0.5: {test_prec:.6f}\")\n",
    "print(f\"Recall@0.5:    {test_rec:.6f}\")\n",
    "print(f\"F1@0.5:        {test_f1:.6f}\")\n",
    "\n",
    "print(\"\\n==== Best Params (by test Accuracy) ====\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\n==== State -> P(up) mapping ====\")\n",
    "for i, p in enumerate(state_up_prob):\n",
    "    print(f\"State {i}: P(up) ≈ {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605d885",
   "metadata": {},
   "source": [
    "# 支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11039a7d",
   "metadata": {},
   "source": [
    "## 面向测试集调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32022ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Test Performance (used for selection: Accuracy@0.5) ====\n",
      "Accuracy:      0.577508\n",
      "AUC:           0.504837\n",
      "PR-AUC:        0.423804\n",
      "LogLoss:       0.686060\n",
      "Precision@0.5: 0.600000\n",
      "Recall@0.5:    0.021429\n",
      "F1@0.5:        0.041379\n",
      "\n",
      "==== Best Params (by test Accuracy) ====\n",
      "C: 48.537573204480736\n",
      "gamma: 0.034633777847399405\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ===== 数据 =====\n",
    "# df_clean: 特征列 + 'value_sort'(0/1)\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（如需按日期切，改这里）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te_raw, y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def acc_from_prob(y_true, y_prob, thr=0.5):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 训练内的“尾部验证段”（占训练集10%），仅用于保持结构一致；SVC无早停\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]  # 不用于训练，仅占位\n",
    "X_te, y_te = X_te_raw, y_te  # 测试集\n",
    "\n",
    "# ===== 目标函数：以“测试集Accuracy@0.5”作为最优标准（与你之前模板一致）=====\n",
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-2, 1e3, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-4, 1e1, log=True),\n",
    "        \"probability\": True,  # 启用Platt校准以得到概率\n",
    "    }\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"svc\", SVC(kernel=\"rbf\",\n",
    "                    C=params[\"C\"],\n",
    "                    gamma=params[\"gamma\"],\n",
    "                    probability=params[\"probability\"],\n",
    "                    class_weight=\"balanced\",  # 类不平衡自适应\n",
    "                    random_state=42))\n",
    "    ])\n",
    "    pipe.fit(X_tr_fit, y_tr_fit)\n",
    "    y_te_prob = pipe.predict_proba(X_te)[:, 1]\n",
    "    test_acc = acc_from_prob(y_te, y_te_prob, thr=0.5)\n",
    "    return float(test_acc)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=40, show_progress_bar=False)  # 40~80次够用\n",
    "best_params = study.best_params\n",
    "\n",
    "# ===== 用最优参数重训，并评估测试集 =====\n",
    "final_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"svc\", SVC(kernel=\"rbf\",\n",
    "                C=best_params[\"C\"],\n",
    "                gamma=best_params[\"gamma\"],\n",
    "                probability=True,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42))\n",
    "])\n",
    "final_pipe.fit(X_tr_fit, y_tr_fit)\n",
    "\n",
    "y_te_prob = final_pipe.predict_proba(X_te)[:, 1]\n",
    "y_te_pred = (y_te_prob >= 0.5).astype(int)\n",
    "\n",
    "test_auc  = safe_auc(y_te, y_te_prob)\n",
    "test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "p2 = np.clip(y_te_prob, 1e-12, 1 - 1e-12)\n",
    "test_logloss = log_loss(y_te, np.vstack([1 - p2, p2]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n==== Test Performance (used for selection: Accuracy@0.5) ====\")\n",
    "print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "print(f\"AUC:           {test_auc:.6f}\")\n",
    "print(f\"PR-AUC:        {test_ap:.6f}\")\n",
    "print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "print(f\"Precision@0.5: {test_prec:.6f}\")\n",
    "print(f\"Recall@0.5:    {test_rec:.6f}\")\n",
    "print(f\"F1@0.5:        {test_f1:.6f}\")\n",
    "\n",
    "print(\"\\n==== Best Params (by test Accuracy) ====\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ecb61e",
   "metadata": {},
   "source": [
    "# 集成学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df0ecb",
   "metadata": {},
   "source": [
    "## 装袋法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9660b8",
   "metadata": {},
   "source": [
    "### 正规调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f8263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Bagging (Simple Average) Performance ====\n",
      "Accuracy:      0.630814\n",
      "AUC:           0.648500\n",
      "PR-AUC:        0.508493\n",
      "LogLoss:       0.656156\n",
      "Precision@0.500: 0.550847\n",
      "Recall@0.500:    0.467626\n",
      "F1@0.500:        0.505837\n",
      "Blend weights (first 10): [0.0389 0.0415 0.0411 0.0395 0.041  0.0382 0.0381 0.0402 0.0411 0.0398]\n",
      "\n",
      "==== Bagging (Val-AUC Weighted) Performance ====\n",
      "Accuracy:      0.630814\n",
      "AUC:           0.648675\n",
      "PR-AUC:        0.508807\n",
      "LogLoss:       0.656043\n",
      "Precision@0.500: 0.550000\n",
      "Recall@0.500:    0.474820\n",
      "F1@0.500:        0.509653\n",
      "Optuna alphas (first 10): [0.0253 0.055  0.0662 0.0139 0.0713 0.0123 0.0165 0.0144 0.0361 0.066 ]\n",
      "\n",
      "==== Bagging (Optuna Weights, no-leak) Performance ====\n",
      "Accuracy:      0.610465\n",
      "AUC:           0.644148\n",
      "PR-AUC:        0.511872\n",
      "LogLoss:       0.656614\n",
      "Precision@0.440: 0.513661\n",
      "Recall@0.440:    0.676259\n",
      "F1@0.440:        0.583851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6104651162790697,\n",
       " 'auc': 0.6441480961572206,\n",
       " 'ap': 0.5118718750197155,\n",
       " 'll': 0.6566142859931556,\n",
       " 'prec': 0.5136612021857924,\n",
       " 'rec': 0.6762589928057554,\n",
       " 'f1': 0.5838509316770186}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 0) 数据准备\n",
    "# =========================\n",
    "# 需先提供 df_clean：包含 'value_sort' 二分类标签，其他列为特征\n",
    "# 例如：\n",
    "# df_clean = pd.read_csv(\"your_data.csv\")  # 确保存在 value_sort 列\n",
    "\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为验证集（用于早停/权重学习/阈值选择，测试集仅最终评估）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]   # 用于子模型训练（自助采样）\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]   # 固定验证集（不泄露）\n",
    "\n",
    "# =========================\n",
    "# 1) 评估工具\n",
    "# =========================\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "# =========================\n",
    "# 2) 超参中心（你给的 best_params）\n",
    "# =========================\n",
    "\n",
    "\n",
    "BASE_PARAMS = dict(\n",
    "    learning_rate=0.1305241307456396,\n",
    "    num_leaves=86,\n",
    "    max_depth=6,\n",
    "    min_child_samples=103,\n",
    "    subsample=0.5600223085390776,\n",
    "    colsample_bytree=0.608980878948645,\n",
    "    reg_alpha=2.3147174999485715e-05,\n",
    "    reg_lambda=0.00042189753661999455,\n",
    "    n_estimators=1079  # Optuna搜索出来的最佳迭代次数\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) Bagging 训练\n",
    "# =========================\n",
    "RANDOM_SEED   = 42\n",
    "BAGS          = 25           # 子模型数（10~50 常见）\n",
    "SAMPLE_RATIO  = 0.85         # 自助采样比例（0.7~0.9 可调）\n",
    "JITTER_SCALE  = 0.12         # 参数扰动强度（0.08~0.2 之间尝试）\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "n_train = X_tr_fit.shape[0]\n",
    "models   = []\n",
    "val_probs_list = []\n",
    "te_probs_list  = []\n",
    "\n",
    "for b in range(BAGS):\n",
    "    # 1) 有放回自助采样\n",
    "    idx = rng.choice(n_train, int(SAMPLE_RATIO * n_train), replace=True)\n",
    "\n",
    "    # 2) 围绕 best_params 做小扰动（确保边界合法）\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * JITTER_SCALE  # 5个扰动源\n",
    "    cfg = BASE_PARAMS.copy()\n",
    "    cfg[\"subsample\"]         = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"]  = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]        = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]         = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, verbosity=-1,\n",
    "        random_state=RANDOM_SEED + b,\n",
    "        **cfg\n",
    "    )\n",
    "\n",
    "    # 只用验证集 (X_val_fit, y_val_fit) 做早停（不触碰测试集）\n",
    "    clf.fit(\n",
    "        X_tr_fit[idx], y_tr_fit[idx],\n",
    "        eval_set=[(X_val_fit, y_val_fit)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200, verbose=False)]\n",
    "    )\n",
    "    models.append(clf)\n",
    "\n",
    "    # 收集验证集/测试集概率，用于后续融合\n",
    "    val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "    te_probs_list.append(clf.predict_proba(X_te)[:, 1])\n",
    "\n",
    "val_probs = np.column_stack(val_probs_list)   # [n_val, B]\n",
    "te_probs  = np.column_stack(te_probs_list)    # [n_test, B]\n",
    "\n",
    "# =========================\n",
    "# 4) 融合方式一：简单平均（无泄露）\n",
    "# =========================\n",
    "y_prob_avg = te_probs.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg, title=\"Bagging (Simple Average)\")\n",
    "\n",
    "# =========================\n",
    "# 5) 融合方式二：按验证AUC加权（softmax 平滑，无泄露）\n",
    "# =========================\n",
    "weights = []\n",
    "for j in range(BAGS):\n",
    "    auc_j = safe_auc(y_val_fit, val_probs[:, j])\n",
    "    if np.isnan(auc_j):\n",
    "        auc_j = 0.5\n",
    "    weights.append(max(auc_j, 0.0))\n",
    "weights = np.array(weights)\n",
    "if weights.sum() == 0:\n",
    "    alphas = np.ones(BAGS) / BAGS\n",
    "else:\n",
    "    ex = np.exp(weights - weights.max())\n",
    "    alphas = ex / ex.sum()\n",
    "\n",
    "y_prob_wavg = (te_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "print(\"Blend weights (first 10):\", np.round(alphas[:10], 4))\n",
    "report_all(y_te, y_prob_wavg, title=\"Bagging (Val-AUC Weighted)\")\n",
    "\n",
    "# =========================\n",
    "# 6) 融合方式三（修复版）：Optuna 在验证集上学权重 + 选阈值；测试集只评估（无泄露）\n",
    "# =========================\n",
    "def objective_blend_on_val(trial):\n",
    "    # 1) 建议权重：先在实数域上优化，再 softmax 到凸组合\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(BAGS)])\n",
    "    a  = np.exp(ws); a /= (a.sum() + 1e-12)  # softmax => a_i >= 0 且 sum=1\n",
    "\n",
    "    # 2) 在【验证集】上融合得到概率\n",
    "    val_blend = (val_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    # 3) 在【验证集】上扫阈值，目标用 F1（也可改成 accuracy/precision/recall 等）\n",
    "    ths  = np.linspace(0.01, 0.99, 99)\n",
    "    f1s  = [f1_score(y_val_fit, (val_blend >= t).astype(int), zero_division=0) for t in ths]\n",
    "    idx  = int(np.argmax(f1s))\n",
    "    best_t  = float(ths[idx])\n",
    "    best_f1 = float(f1s[idx])\n",
    "\n",
    "    # 记录“验证集最佳阈值”，用于训练结束后取出（注意：整个过程不触碰测试标签）\n",
    "    trial.set_user_attr(\"best_t\", best_t)\n",
    "    return best_f1\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_blend_on_val, n_trials=100, show_progress_bar=False)\n",
    "\n",
    "# 取出在验证集上学到的最优权重（softmax 后的凸组合）\n",
    "best_w = np.array([study.best_params[k] for k in sorted(study.best_params.keys(), key=lambda s: int(s[1:]))])\n",
    "a = np.exp(best_w); a /= (a.sum() + 1e-12)\n",
    "\n",
    "# 在验证集上得到“生产用阈值”（固定），测试集仅用于最终评估\n",
    "best_t = float(study.best_trial.user_attrs[\"best_t\"])\n",
    "\n",
    "print(\"Optuna alphas (first 10):\", np.round(a[:10], 4))\n",
    "te_blend = (te_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, te_blend, thr=best_t, title=\"Bagging (Optuna Weights, no-leak)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f763f",
   "metadata": {},
   "source": [
    "### ACC+超参重训+早停划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a51ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 13:43:25,594] A new study created in memory with name: no-name-72b3fa74-0648-494a-8820-9eae2e7c8f5b\n",
      "[I 2025-09-01 13:43:25,631] Trial 0 finished with value: 0.7246376811594203 and parameters: {'w0': -1.1309691470780208, 'w1': -1.802650811677942, 'w2': 0.07415301346861103, 'w3': 0.39489666220149644, 'w4': 2.1414272445190488, 'w5': -0.04789808111249272, 'w6': -1.4304385799446067, 'w7': 1.7074807787175041, 'w8': 0.4988195482147413, 'w9': -0.7221826236866469, 'w10': 1.7056358928609132, 'w11': -2.050544955370009, 'w12': -0.550275991853471, 'w13': -1.4154196254098523, 'w14': 0.5544405064573157, 'w15': -0.09475383090618283, 'w16': 1.928746373997524, 'w17': -1.6001017239446869, 'w18': -1.113518034728781, 'w19': 0.8890708209204288, 'w20': 1.9457159574005765, 'w21': 2.419564209097185, 'w22': 1.816072773881963, 'w23': 1.0990891067919177, 'w24': 2.4116366417819055}. Best is trial 0 with value: 0.7246376811594203.\n",
      "[I 2025-09-01 13:43:25,661] Trial 1 finished with value: 0.7463768115942029 and parameters: {'w0': 2.339280313660888, 'w1': 1.0285472914201361, 'w2': -0.8488506770784843, 'w3': 0.553859983009918, 'w4': 1.5076890650550183, 'w5': -0.1337854648542125, 'w6': 2.1258395490291218, 'w7': -1.8495649223805366, 'w8': 0.8114793180255808, 'w9': 2.3046340221017116, 'w10': -1.2957572967900266, 'w11': 1.468244749687459, 'w12': -2.387134124340698, 'w13': -0.9510416717004793, 'w14': 0.16573900018029342, 'w15': 1.463612938709777, 'w16': -0.32473132353927836, 'w17': -2.4407174802299014, 'w18': -1.5668781507377905, 'w19': -2.4771926706016067, 'w20': -0.6765362708064964, 'w21': 0.21724580646995273, 'w22': 0.5880543048243791, 'w23': 0.2993780841750908, 'w24': -0.3726762157142649}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,684] Trial 2 finished with value: 0.7318840579710145 and parameters: {'w0': 0.036320620541325344, 'w1': 2.3617556512449953, 'w2': -2.1240025004737184, 'w3': 1.3227273470590797, 'w4': -1.5452842212759026, 'w5': -0.23959821288461658, 'w6': -1.803222662657746, 'w7': 1.0450628586292825, 'w8': 0.20056559703202526, 'w9': 0.25092080192880006, 'w10': -2.008270820261426, 'w11': 1.2720234405250719, 'w12': 1.115998610940077, 'w13': 2.045778108641075, 'w14': 0.8583968633966284, 'w15': 1.063779907301937, 'w16': -1.070125794634511, 'w17': 1.0033458743092383, 'w18': 1.929378957824433, 'w19': 1.110108846072111, 'w20': 1.7935577340152369, 'w21': 0.9849154611622679, 'w22': 1.8591492688566884, 'w23': 1.5051005094043326, 'w24': -2.0006786919199744}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,710] Trial 3 finished with value: 0.7318840579710145 and parameters: {'w0': 2.266163155237165, 'w1': -1.1781472538356113, 'w2': -0.017581104532372827, 'w3': 0.3678628668644013, 'w4': 0.3088433574636813, 'w5': -0.41310252132215286, 'w6': -2.189523011036443, 'w7': 1.5984603653152911, 'w8': 0.8384874825880657, 'w9': 2.3549979293716836, 'w10': 0.6628980094546391, 'w11': -2.4163989615195063, 'w12': 1.4743446758094514, 'w13': 0.8059148796720503, 'w14': 1.9435706006949598, 'w15': -1.3868353916649712, 'w16': -2.405937301193469, 'w17': -2.3883713452710458, 'w18': -1.7807849046494362, 'w19': -2.0078603408947875, 'w20': -0.17905956075483997, 'w21': -1.1633351972956611, 'w22': 1.4423032810657173, 'w23': 1.566910928186866, 'w24': 1.8939413777689946}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,731] Trial 4 finished with value: 0.7246376811594203 and parameters: {'w0': -0.9171341454994657, 'w1': 0.16903699772154335, 'w2': 0.239269147836485, 'w3': -1.2492726150874711, 'w4': -1.105913912071349, 'w5': -0.969959436592263, 'w6': -1.9399519590835186, 'w7': 1.3492830324505123, 'w8': -0.2545786011838769, 'w9': 0.20235798209627953, 'w10': 1.0541214424743561, 'w11': 2.2601441236880815, 'w12': 0.47064502360260896, 'w13': 2.3689036016617386, 'w14': -0.9717250796737043, 'w15': 2.448832851627505, 'w16': -2.030585630110078, 'w17': -0.625699409403484, 'w18': 0.8506197025123088, 'w19': -0.7402577716962782, 'w20': 1.1479932963291861, 'w21': -1.923941756691534, 'w22': -1.2860159645305713, 'w23': -2.4117045800015924, 'w24': -1.9510700090239967}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,753] Trial 5 finished with value: 0.7246376811594203 and parameters: {'w0': 1.2321691478354873, 'w1': 1.7962505526782548, 'w2': -2.460812746931265, 'w3': -2.1201916652425385, 'w4': -0.19048156067032318, 'w5': 2.4188547748078584, 'w6': 1.5728464234887323, 'w7': 0.33366557688452136, 'w8': 2.357936634806272, 'w9': 1.087046021174738, 'w10': -1.4478128462277495, 'w11': 2.334344359499541, 'w12': -0.9558679113863127, 'w13': 1.8200371486255342, 'w14': 2.4027014883238165, 'w15': -1.8135108354030038, 'w16': -0.8083030033507694, 'w17': -0.39349891739395515, 'w18': -1.1356421275861295, 'w19': 2.3606429093548424, 'w20': -2.138806236342318, 'w21': 1.104097195697991, 'w22': 1.8048262259009205, 'w23': -0.84277890797397, 'w24': -0.027206773868122536}. Best is trial 1 with value: 0.7463768115942029.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Bagging (Simple Average) Performance ====\n",
      "Accuracy:      0.625000\n",
      "AUC:           0.653834\n",
      "PR-AUC:        0.510594\n",
      "LogLoss:       0.655445\n",
      "Precision@0.500: 0.542373\n",
      "Recall@0.500:    0.460432\n",
      "F1@0.500:        0.498054\n",
      "Blend weights (first 10): [0.0393 0.0417 0.0395 0.04   0.0418 0.04   0.0404 0.0372 0.0375 0.0395]\n",
      "\n",
      "==== Bagging (Val-AUC Weighted) Performance ====\n",
      "Accuracy:      0.622093\n",
      "AUC:           0.653659\n",
      "PR-AUC:        0.510198\n",
      "LogLoss:       0.655434\n",
      "Precision@0.500: 0.538462\n",
      "Recall@0.500:    0.453237\n",
      "F1@0.500:        0.492188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 13:43:25,777] Trial 6 finished with value: 0.7318840579710145 and parameters: {'w0': 0.33685149999337183, 'w1': -0.6267199093387514, 'w2': -2.4346358599109696, 'w3': 2.1187094564289133, 'w4': -0.04272803443820106, 'w5': 0.4918302423816643, 'w6': 0.45727634825839036, 'w7': -0.6025601941233005, 'w8': 0.9009371701785867, 'w9': 1.1401012154319363, 'w10': -1.8636900364582787, 'w11': -1.4934849223269224, 'w12': -2.0666258920278295, 'w13': 1.328969649988181, 'w14': -1.4044608988103113, 'w15': -1.307123300509272, 'w16': 0.04094047279331914, 'w17': 2.0542313032373736, 'w18': -0.0754056396724927, 'w19': 2.3392595396054645, 'w20': 1.7845111835047698, 'w21': 2.203239547077416, 'w22': -0.35246075334881777, 'w23': -1.8897232634555072, 'w24': 1.235815212722462}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,800] Trial 7 finished with value: 0.7318840579710145 and parameters: {'w0': -2.1711407118939197, 'w1': 2.4738043469348687, 'w2': -1.7857058945100202, 'w3': 0.3525137794177997, 'w4': 1.7929757970447868, 'w5': 0.2128454343473667, 'w6': -1.0956416242230334, 'w7': -2.1320826741496997, 'w8': -2.1648724750298713, 'w9': -1.9015975323321022, 'w10': -0.5039736160830122, 'w11': 0.49652690636865504, 'w12': -1.126400233726006, 'w13': -0.7671011380891979, 'w14': -1.3739123349614073, 'w15': 0.4833499470656255, 'w16': -1.1884168295229562, 'w17': 0.8527017557714096, 'w18': -1.3800658865981719, 'w19': -0.9731666101350966, 'w20': 1.0481768443999262, 'w21': -1.3748865607448213, 'w22': -2.373593490067838, 'w23': -2.1996215012238833, 'w24': -0.3324212739655774}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,826] Trial 8 finished with value: 0.7318840579710145 and parameters: {'w0': -0.8718430565470396, 'w1': -2.2807348511539822, 'w2': 2.317708112806474, 'w3': 1.5942432824332222, 'w4': -2.3657551776683667, 'w5': 0.33426134279236086, 'w6': -1.9498674191853764, 'w7': 0.6448975090661051, 'w8': 1.4013728706940225, 'w9': 0.6982611610938854, 'w10': 0.7326518761814391, 'w11': 2.22002179159169, 'w12': -0.23761378274820366, 'w13': 2.0502400772779357, 'w14': 1.9666319877231588, 'w15': 1.826262509395817, 'w16': -2.1830784954053377, 'w17': -1.1301423684057499, 'w18': 0.6798077726625156, 'w19': -1.7976614971116263, 'w20': 2.0691657921944877, 'w21': 1.1306609357638924, 'w22': -1.118961510326801, 'w23': 0.5216787926584749, 'w24': 2.1428130353684853}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,848] Trial 9 finished with value: 0.7318840579710145 and parameters: {'w0': -1.8148524023575618, 'w1': 0.194032214337152, 'w2': -2.222668830146015, 'w3': -1.502253551243381, 'w4': -1.497294244611005, 'w5': 2.4506980234776536, 'w6': 1.5492153716577777, 'w7': -1.0778774986662016, 'w8': -0.4090707755137073, 'w9': 0.12525451609317795, 'w10': 1.9550952548054301, 'w11': 1.8278064428646852, 'w12': -0.3840355965086295, 'w13': -0.609362373266042, 'w14': -1.8767694727353679, 'w15': -1.758969638863388, 'w16': -1.5004579283762047, 'w17': -1.0231363193855492, 'w18': 0.2345594949959846, 'w19': -2.2384615212798153, 'w20': 0.82725687158017, 'w21': -0.16611671178497867, 'w22': -0.8949883061939352, 'w23': -1.0015725157403177, 'w24': 1.5123833354399894}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,918] Trial 10 finished with value: 0.7391304347826086 and parameters: {'w0': 2.232257105669274, 'w1': 1.1146142526961926, 'w2': -0.48719870591947134, 'w3': -0.7179755258199547, 'w4': 1.1642520530735219, 'w5': -2.206214347214852, 'w6': 2.2691124354705643, 'w7': -2.27468075150363, 'w8': -1.5975447322784748, 'w9': 2.317774608232272, 'w10': -0.8443202566640831, 'w11': -0.31437564716496214, 'w12': 2.484843101503095, 'w13': -2.3033329663268702, 'w14': -0.2778603421639996, 'w15': -0.31701846380239695, 'w16': 0.667805204478317, 'w17': -2.049960159943682, 'w18': -2.2415564386975424, 'w19': 0.09185450791166443, 'w20': -1.2367849287635757, 'w21': -0.1013902411264073, 'w22': 0.5342544744151173, 'w23': 2.3418590424050083, 'w24': -0.9260595716370144}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:25,992] Trial 11 finished with value: 0.7391304347826086 and parameters: {'w0': 2.2890827242494254, 'w1': 1.2081751021339544, 'w2': -0.9389829923757482, 'w3': -0.6168889879917383, 'w4': 1.1994440022697377, 'w5': -2.223206376813689, 'w6': 2.2263841991601727, 'w7': -2.473419436432395, 'w8': -1.489100827410465, 'w9': 2.424873125967532, 'w10': -0.9782444942193642, 'w11': -0.587427529025447, 'w12': 2.4520183194990954, 'w13': -2.4891030694163425, 'w14': -0.39016668846893654, 'w15': -0.48889366807349255, 'w16': 0.6856544239310374, 'w17': -2.327069869288806, 'w18': -2.4485188302865666, 'w19': 0.20853186935225676, 'w20': -1.162365561725116, 'w21': -0.24407904030494754, 'w22': 0.6990142605379372, 'w23': 2.3604851996752285, 'w24': -0.8600940050662854}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,070] Trial 12 finished with value: 0.7391304347826086 and parameters: {'w0': 1.3337901462530586, 'w1': 0.9735823502455607, 'w2': -1.0056840127604723, 'w3': -0.5671670268841165, 'w4': 1.0357269906963413, 'w5': -2.176110487028221, 'w6': 2.4731777790713183, 'w7': -1.530948653783631, 'w8': -1.057074101308117, 'w9': 1.8194507954801904, 'w10': -0.21109026634361394, 'w11': 0.008536097063397086, 'w12': -1.9980602782406924, 'w13': -2.112495279325345, 'w14': 0.04747037293681336, 'w15': 1.0797981121421127, 'w16': 1.0759719144782023, 'w17': -1.863623523708739, 'w18': -2.4013661212594903, 'w19': -0.5193863342002007, 'w20': -0.8178117520726087, 'w21': 0.4056648137605605, 'w22': 0.45832391407040995, 'w23': 2.497120108492802, 'w24': -1.1642012273345335}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,155] Trial 13 finished with value: 0.7318840579710145 and parameters: {'w0': 1.1878276922184015, 'w1': 1.005522495221944, 'w2': 1.1376209390232064, 'w3': 1.077248240686589, 'w4': 1.1652182385616248, 'w5': 1.333631919206629, 'w6': 0.6176057544859757, 'w7': -1.7368677067039968, 'w8': -2.1461030944552806, 'w9': 1.7007642823829254, 'w10': -2.4713473951813247, 'w11': 0.9994668756230132, 'w12': 2.42481360622288, 'w13': -1.5593629503740836, 'w14': 0.8382639186164207, 'w15': -0.6917684641032956, 'w16': -0.2609259481610721, 'w17': 0.284437089047333, 'w18': -0.4344953452767768, 'w19': 0.5339318230609474, 'w20': -1.9895063110336717, 'w21': -0.6935802045026004, 'w22': 0.9464501324990673, 'w23': 0.011376919697557497, 'w24': 0.6681920924343034}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,230] Trial 14 finished with value: 0.7246376811594203 and parameters: {'w0': 2.490190104581091, 'w1': 0.6186627422758191, 'w2': -0.9429456551569171, 'w3': -0.5446171847280444, 'w4': 2.449614605807013, 'w5': -1.2134109955880492, 'w6': 1.407742937352105, 'w7': -0.3789292871621677, 'w8': 1.582973187020404, 'w9': -1.3560338526777445, 'w10': -0.9924250986199326, 'w11': -0.8554938542908895, 'w12': 0.5432455231404965, 'w13': 0.09502932830266309, 'w14': -0.36906361763580336, 'w15': 0.7429687154076436, 'w16': 0.9155016840812696, 'w17': -1.6468867527821158, 'w18': -1.7910749844750473, 'w19': -1.3955052991499723, 'w20': -1.2268926549498058, 'w21': 0.30443465518493484, 'w22': -0.01879916224165845, 'w23': -0.5165404519082057, 'w24': -1.148842651636105}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,306] Trial 15 finished with value: 0.7318840579710145 and parameters: {'w0': 1.5775946720550484, 'w1': 1.6357575856415274, 'w2': 0.8798701874620607, 'w3': -0.20406383529457628, 'w4': 0.5738447460153633, 'w5': -1.5106996365637426, 'w6': -0.5250903072392223, 'w7': -1.0095773635650067, 'w8': -0.9544349051871734, 'w9': 1.5221699022800614, 'w10': 0.22002955190805928, 'w11': 0.06712261859563318, 'w12': -2.453701343333945, 'w13': -1.4458673700851477, 'w14': 0.24260783718524304, 'w15': 1.7538968887920166, 'w16': 2.4082928997092585, 'w17': -2.37873822763706, 'w18': -0.5927398522611667, 'w19': -0.2381249987690472, 'w20': -0.24556817321735813, 'w21': -2.367470810397494, 'w22': 1.1086259815092387, 'w23': 0.3521611628245655, 'w24': 0.5102579165044994}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,384] Trial 16 finished with value: 0.7246376811594203 and parameters: {'w0': 0.5094236795024325, 'w1': -0.44326210696773183, 'w2': -1.483698652351627, 'w3': -2.4373979502313956, 'w4': -0.5293177851972208, 'w5': 1.1479776144807092, 'w6': 0.770291516592704, 'w7': 2.4508059072935358, 'w8': -1.5014422468428164, 'w9': -0.6377775005465196, 'w10': -0.8308722838557815, 'w11': -0.7384640410445109, 'w12': -1.3340840685786715, 'w13': -0.49131612344590736, 'w14': -2.351705643087772, 'w15': -2.353652141500657, 'w16': 0.09468136115383785, 'w17': 2.4205102376188314, 'w18': -1.9280634725109795, 'w19': 1.6264030563399312, 'w20': -0.6514776422452548, 'w21': -0.73626673186842, 'w22': 2.4899078802105334, 'w23': -1.4208475556149547, 'w24': -0.46874794866786296}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,458] Trial 17 finished with value: 0.7391304347826086 and parameters: {'w0': 1.848381746541519, 'w1': 1.785523047602953, 'w2': -0.4408883977251411, 'w3': -1.3136880876636816, 'w4': 1.782283895261239, 'w5': -2.498568736195324, 'w6': 1.9288812591137345, 'w7': -1.7217860415467967, 'w8': 2.231810668331189, 'w9': 2.486132121850819, 'w10': -1.4245234982016948, 'w11': 0.866630539392015, 'w12': 1.6483378067364292, 'w13': 0.2447772559997965, 'w14': 1.3125152567265768, 'w15': 0.1102486105261069, 'w16': 1.6168594288484823, 'w17': -1.2614033350066864, 'w18': 1.6407258690582083, 'w19': -2.472089217019014, 'w20': -1.638324010348207, 'w21': 0.5863845792782577, 'w22': 0.22925303051492474, 'w23': 0.9047227434209262, 'w24': -1.7007333368842845}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,534] Trial 18 finished with value: 0.7391304347826086 and parameters: {'w0': 0.664331823343963, 'w1': 0.555338063304809, 'w2': 0.9123984071109398, 'w3': 0.9724294262541497, 'w4': 0.7069595814182952, 'w5': -1.775890290128383, 'w6': -0.2616874107643432, 'w7': -2.4626178821049907, 'w8': -0.538036384741098, 'w9': 1.8330302353464893, 'w10': -0.07550488103013808, 'w11': 1.532236009487088, 'w12': 0.540323590234822, 'w13': -1.847629967497021, 'w14': -0.48951441573768006, 'w15': 1.6411612103439115, 'w16': -0.2740253959832356, 'w17': -1.812752218794642, 'w18': -1.0093645454703069, 'w19': -1.422817151805655, 'w20': 0.304787707623148, 'w21': 1.7615847354285128, 'w22': -0.4881927562847968, 'w23': 1.9231329294056931, 'w24': 0.4763987871397357}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,610] Trial 19 finished with value: 0.7246376811594203 and parameters: {'w0': 1.8177371269351827, 'w1': -0.469241765946369, 'w2': -0.4225159103043501, 'w3': 2.4483634616626313, 'w4': 1.5935812331790689, 'w5': -0.8519466270725491, 'w6': 1.1280531940731757, 'w7': -1.0644414401903348, 'w8': -2.461235840750164, 'w9': 0.9277217039344556, 'w10': -1.6794188857850239, 'w11': 0.5222999697618416, 'w12': -1.6150053142133665, 'w13': -0.8688936820441745, 'w14': -0.8742587460094251, 'w15': -0.6145092249612442, 'w16': 0.3514530520247814, 'w17': 0.32625450380086374, 'w18': -2.0880984668521343, 'w19': 0.18604558627119344, 'w20': -1.5636360505761608, 'w21': -0.4886702028393892, 'w22': -1.7580217706056085, 'w23': -0.3937288718759413, 'w24': -2.487846260734277}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,686] Trial 20 finished with value: 0.7463768115942029 and parameters: {'w0': -0.34085833934159526, 'w1': 1.4412878900858461, 'w2': -1.3978962433247886, 'w3': 0.7709767326699969, 'w4': 2.460222052688361, 'w5': 1.0042055947203978, 'w6': 1.9810083728632055, 'w7': -0.12134118038285635, 'w8': 1.5542180982662002, 'w9': -0.5192908051243732, 'w10': -2.4895668466614005, 'w11': -1.2778434396242935, 'w12': 1.92396598743021, 'w13': -2.355779520116844, 'w14': 1.367861483612925, 'w15': 2.3720505775458482, 'w16': -0.6429346027621665, 'w17': -0.5102246215421282, 'w18': -1.4483638101505285, 'w19': 1.458311278180462, 'w20': -2.4872579946739712, 'w21': 1.7314955652408188, 'w22': -0.14530974931998453, 'w23': 0.8323893513803982, 'w24': -0.7163315276591331}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,763] Trial 21 finished with value: 0.7463768115942029 and parameters: {'w0': -0.36060273006792454, 'w1': 1.2905792824336133, 'w2': -1.4333017992171444, 'w3': 0.7317063331601892, 'w4': 2.4942945878960794, 'w5': 1.064751444196813, 'w6': 1.9534899360205762, 'w7': -0.03731050401412883, 'w8': 1.5861271359794331, 'w9': -0.6278728999474807, 'w10': -2.4176469432811456, 'w11': -1.2290706837421541, 'w12': 1.9033574359992014, 'w13': -2.2401842402454144, 'w14': 1.4104953452340705, 'w15': 2.4925814710709937, 'w16': -0.7672425917342023, 'w17': -0.6912152564184073, 'w18': -1.54824701252351, 'w19': 1.6847909229048377, 'w20': -2.432632447604084, 'w21': 1.6501928642269303, 'w22': -0.14668224334415148, 'w23': 0.8567878353189435, 'w24': -0.6993008052799774}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,846] Trial 22 finished with value: 0.7463768115942029 and parameters: {'w0': -0.49970311302912096, 'w1': 1.4985223415762747, 'w2': -1.4750586251111137, 'w3': 0.8117877399851108, 'w4': 2.4383207983202553, 'w5': 1.0124821781631996, 'w6': 2.0342323010758387, 'w7': -0.0016447619731868174, 'w8': 1.7367634498424573, 'w9': -0.522867925429822, 'w10': -2.47914841672408, 'w11': -1.3235432731225933, 'w12': 1.9249600344188336, 'w13': -1.918857490841364, 'w14': 1.3386539410656206, 'w15': 2.482499142475936, 'w16': -0.5745082318818635, 'w17': -0.23780076481344992, 'w18': -1.6088711306470063, 'w19': 1.7072939179485345, 'w20': -2.3698827137306644, 'w21': 1.695279812809566, 'w22': -0.39434008173796414, 'w23': 0.6988850911952578, 'w24': -0.5843790504418973}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,919] Trial 23 finished with value: 0.7391304347826086 and parameters: {'w0': -0.4963042116379554, 'w1': 2.195462297141856, 'w2': -1.376207234669289, 'w3': 1.6499164106030504, 'w4': 2.048638609501086, 'w5': 1.7337049212473632, 'w6': 1.0762015092344162, 'w7': -0.15539720763260154, 'w8': 1.0497174726041936, 'w9': -1.1887639080738461, 'w10': -2.134990811638555, 'w11': -1.2143823309521815, 'w12': 0.9023740333656773, 'w13': -1.0878803561020867, 'w14': 1.4043338703507713, 'w15': 2.0454127151543355, 'w16': -1.6307554375801259, 'w17': -0.7855185425306921, 'w18': -0.6671092692931748, 'w19': 1.8204557333771278, 'w20': -2.4977787782858454, 'w21': 1.7918245102674406, 'w22': 0.12762938447008898, 'w23': 0.2574111844075351, 'w24': -0.010158100832892373}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:26,995] Trial 24 finished with value: 0.7391304347826086 and parameters: {'w0': -0.21914572363449664, 'w1': 0.44693522912255945, 'w2': -1.8960698278350117, 'w3': 0.6567716975730861, 'w4': 1.577153414781601, 'w5': 0.8099362898624345, 'w6': 1.716403778121315, 'w7': 0.3930832794910706, 'w8': 1.7639393658183833, 'w9': -2.4291627727027167, 'w10': -2.218483832559438, 'w11': -1.7910395532341699, 'w12': 1.9183237968971327, 'w13': -1.708917175162948, 'w14': 1.708115109547946, 'w15': 1.3900836912808108, 'w16': -0.5920983030111564, 'w17': 1.0370736402466827, 'w18': -1.4976779115000112, 'w19': 1.1656396983553274, 'w20': -1.8081932248972916, 'w21': 1.414008494557279, 'w22': -0.8089121733503091, 'w23': 1.2149436535204035, 'w24': -1.5155834923592288}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,069] Trial 25 finished with value: 0.7463768115942029 and parameters: {'w0': -1.3534205920028257, 'w1': 2.048916809599679, 'w2': -1.136536001220384, 'w3': -0.16589882855832086, 'w4': 2.1739054221198573, 'w5': 1.8929767272376106, 'w6': 2.4892521832382406, 'w7': -0.7352046301654169, 'w8': 1.275511595617491, 'w9': -0.2692043020915088, 'w10': -1.4343265192327976, 'w11': -0.9558562187771953, 'w12': 0.20262098577414545, 'w13': -0.19946746368452362, 'w14': 0.8156082981801152, 'w15': 2.094887718146837, 'w16': -1.4883142379876688, 'w17': -0.05819308435614689, 'w18': -0.8133505847670448, 'w19': 1.4456836327947116, 'w20': 0.24491019942611672, 'w21': 0.6812925488169745, 'w22': -0.13077643300588804, 'w23': -0.09971685924012297, 'w24': -0.19513282006203492}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,144] Trial 26 finished with value: 0.7318840579710145 and parameters: {'w0': 0.8053543878056315, 'w1': 1.3670764701595195, 'w2': -0.609530908727166, 'w3': 0.0459141922517107, 'w4': 2.4933498537362127, 'w5': 0.6565817673829814, 'w6': 1.1083611098909878, 'w7': 0.599689350793013, 'w8': 2.011190385149342, 'w9': -1.091465723844738, 'w10': -1.6911729545300525, 'w11': -1.76770751888178, 'w12': 1.1153041409855753, 'w13': -2.4511572398427623, 'w14': 2.3129893288441092, 'w15': 2.205508064299318, 'w16': -0.9186497201517798, 'w17': 1.6311235213275799, 'w18': 0.02218488516265049, 'w19': 0.6258132004954189, 'w20': -2.17549493302665, 'w21': 2.1354971816682555, 'w22': -1.5696958757264718, 'w23': 0.7841660784973886, 'w24': 0.2747902287125889}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,218] Trial 27 finished with value: 0.7246376811594203 and parameters: {'w0': -0.0008261668355356022, 'w1': 0.7476274503678288, 'w2': -1.8221357081734366, 'w3': 1.519977021516726, 'w4': 1.9543653671025822, 'w5': -0.5958413277653729, 'w6': 0.12176080511870957, 'w7': -1.34708952109019, 'w8': 0.4201210321809489, 'w9': -1.7372725159235332, 'w10': -2.494423313843746, 'w11': -0.4141142370291706, 'w12': 1.9595733130913036, 'w13': -1.2316677286264124, 'w14': 0.4099775000207415, 'w15': 1.3563445917619608, 'w16': -0.3435416702083488, 'w17': 0.2876851175775128, 'w18': -1.2902464599071344, 'w19': 2.0630913331356213, 'w20': -0.6686137899541857, 'w21': 1.4626908734568196, 'w22': 1.1523013152358348, 'w23': 1.586421126222298, 'w24': -0.7360068627983612}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,296] Trial 28 finished with value: 0.7391304347826086 and parameters: {'w0': -0.4970247246640292, 'w1': -0.19599232874196093, 'w2': -1.3718375780427539, 'w3': 2.042205572404441, 'w4': 1.5903839489187783, 'w5': 1.552997645804013, 'w6': 1.8339050154903842, 'w7': 0.9692730208567104, 'w8': 0.6509403818752062, 'w9': 0.6399250137605541, 'w10': -1.205201744363133, 'w11': 0.3417108526562471, 'w12': 1.4183895046006714, 'w13': -2.0758115700805484, 'w14': 1.6065289650820689, 'w15': 2.459274023214045, 'w16': 0.22931664938602803, 'w17': -1.349938656585429, 'w18': -0.4200244329276179, 'w19': 1.332512467824984, 'w20': -1.4832306278974794, 'w21': 0.8968831439386837, 'w22': 0.26841653000700805, 'w23': -0.04255663920829078, 'w24': 0.8357811736644472}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,370] Trial 29 finished with value: 0.7246376811594203 and parameters: {'w0': -1.2261534652913344, 'w1': 1.9554018555021424, 'w2': -0.20107055950014274, 'w3': 0.5255087508387066, 'w4': 2.0305535517278903, 'w5': -0.008241278329200519, 'w6': 1.3403741285280468, 'w7': 2.452120388622143, 'w8': 1.2004903937516525, 'w9': -0.21110022661130634, 'w10': 2.486727404587378, 'w11': -1.9278398330741735, 'w12': -0.6415996885816535, 'w13': 0.5612609426126878, 'w14': 1.0352542977783357, 'w15': 1.5116305031622026, 'w16': -1.3103919781075586, 'w17': -0.7044126382483773, 'w18': -0.901918979829053, 'w19': 0.6586634774237279, 'w20': -1.8070075282452378, 'w21': 2.425458590920913, 'w22': -0.690532471226728, 'w23': 1.02735335118629, 'w24': -1.516659004363542}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,444] Trial 30 finished with value: 0.7463768115942029 and parameters: {'w0': -1.570654458254943, 'w1': 1.461569063958602, 'w2': -0.7175763340704184, 'w3': 0.07883428404932102, 'w4': 2.1995354987948295, 'w5': 0.8527039179043945, 'w6': 2.0250245440153556, 'w7': -0.34380822519762444, 'w8': 0.09303984359019801, 'w9': -0.7997951148534914, 'w10': -2.043812000627272, 'w11': -2.2107426034082778, 'w12': 0.004458306299725434, 'w13': -1.3110336198855803, 'w14': 0.590377482083488, 'w15': 1.9445167243431905, 'w16': -0.6710652261996317, 'w17': 0.5681187235619647, 'w18': -1.2937819204725458, 'w19': 0.9110407938453917, 'w20': -0.9483201038235529, 'w21': 2.1457855699367006, 'w22': 0.759818091271371, 'w23': 1.1773374693743843, 'w24': -1.2023194869629779}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,518] Trial 31 finished with value: 0.7463768115942029 and parameters: {'w0': -0.4870632209884177, 'w1': 1.4921053510059357, 'w2': -1.567969159566653, 'w3': 0.8379254918884019, 'w4': 2.35543995314833, 'w5': 1.2448432461040815, 'w6': 2.1482593269629913, 'w7': 0.14747762835216371, 'w8': 1.8585644574946556, 'w9': -0.5894759285218897, 'w10': -2.4054592443813663, 'w11': -1.330397135283992, 'w12': 1.99643544031346, 'w13': -1.8758072281583114, 'w14': 1.3342897785568442, 'w15': 2.3916217476083212, 'w16': -0.4779623220821502, 'w17': -0.4210972151976726, 'w18': -1.618058364142312, 'w19': 1.9081961119060864, 'w20': -2.457676233462298, 'w21': 1.6371652459378672, 'w22': -0.2967390129523765, 'w23': 0.6129807696468349, 'w24': -0.5595246842749331}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,595] Trial 32 finished with value: 0.7391304347826086 and parameters: {'w0': 0.19246337383267878, 'w1': 0.8227985398129144, 'w2': 0.3635459329716213, 'w3': 1.2427075629178743, 'w4': 2.4595470336201752, 'w5': 0.974832710428916, 'w6': 1.8212031619126952, 'w7': 0.04675681461596897, 'w8': 1.5897521023896417, 'w9': -0.09254869526628196, 'w10': -1.817157246354604, 'w11': -1.5210825697282195, 'w12': 2.052387216913493, 'w13': -2.0526476051208586, 'w14': 1.214097047512494, 'w15': 2.1720195802854807, 'w16': -0.94204120988232, 'w17': -0.15378849465339345, 'w18': -2.0444312584401843, 'w19': 2.457260987481378, 'w20': -2.204524172059909, 'w21': 1.962324647349287, 'w22': -0.5472716016320945, 'w23': 0.28190707549251226, 'w24': 0.19311746537424512}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,742] Trial 33 finished with value: 0.7318840579710145 and parameters: {'w0': -0.7984800786578191, 'w1': 1.3358074197458563, 'w2': -1.246089159969403, 'w3': 0.7417383022615783, 'w4': 1.3815325294937075, 'w5': -0.2322366516348186, 'w6': 2.084470179637482, 'w7': 0.9917277765531265, 'w8': 2.1108860841835226, 'w9': -0.9371313123335645, 'w10': -2.173542773160328, 'w11': -2.4350552489326978, 'w12': 1.627128635325604, 'w13': -1.7104731268879187, 'w14': 2.060201184458377, 'w15': 1.1033267101915805, 'w16': -0.15097475699687724, 'w17': -0.2566780633410744, 'w18': -1.697569464295772, 'w19': 1.5476266934126708, 'w20': -2.4690889035238546, 'w21': 1.369751576212766, 'w22': 0.05265635767637353, 'w23': 0.6984394636405662, 'w24': -0.5776104045849373}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,819] Trial 34 finished with value: 0.7246376811594203 and parameters: {'w0': -0.414526934178993, 'w1': 2.1626869822782613, 'w2': -2.020259405836744, 'w3': 0.37862701826194434, 'w4': 1.8579407014980316, 'w5': 2.0754300743549408, 'w6': -1.2109251663543366, 'w7': -0.6118378204412139, 'w8': 2.4658927858932556, 'w9': 0.43312319065932403, 'w10': -1.9728923076072902, 'w11': -1.0808863937291147, 'w12': 1.2976952566025703, 'w13': -2.150386766318205, 'w14': 0.6228287447230002, 'w15': 2.4536653153603534, 'w16': -1.6947309120288387, 'w17': 1.267814326311469, 'w18': -1.5891756103106311, 'w19': 0.9808871481497978, 'w20': 2.4246243509091894, 'w21': 0.21879517478340849, 'w22': 1.4484839600081993, 'w23': 1.5055401681318457, 'w24': -0.303920244385305}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,894] Trial 35 finished with value: 0.7391304347826086 and parameters: {'w0': 0.11658985693204499, 'w1': 1.714075406149634, 'w2': -1.6387740111014564, 'w3': 1.2466784640458215, 'w4': 0.7752669100610394, 'w5': 0.4918556836810388, 'w6': 2.4933772062551105, 'w7': 1.7329935794450368, 'w8': 0.6615063302608994, 'w9': -0.4794542723205407, 'w10': -1.602003493892496, 'w11': -0.32544026747868626, 'w12': 0.9607697910826509, 'w13': -1.0234261895146466, 'w14': 1.689295512881819, 'w15': 0.7051185127216403, 'w16': -0.6706199058232496, 'w17': -0.9462207153186919, 'w18': -1.080811516927394, 'w19': 2.087897964956183, 'w20': -1.860673490517114, 'w21': 0.9219481087101572, 'w22': 0.4130751957139357, 'w23': 1.2966076343955382, 'w24': -0.9420081591420999}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:27,974] Trial 36 finished with value: 0.7318840579710145 and parameters: {'w0': -0.16456146433491592, 'w1': 0.34621399705673106, 'w2': -0.7589522056697247, 'w3': 0.20150135997911867, 'w4': 2.235723643777264, 'w5': 0.2016122921418566, 'w6': 1.3672656647331611, 'w7': -0.047587686119286286, 'w8': 0.34127191319908246, 'w9': -1.4950240461862192, 'w10': -2.1560905987210717, 'w11': -1.6144162200180012, 'w12': 1.7520273895264182, 'w13': -1.3965265793680648, 'w14': 1.0740480357759974, 'w15': 1.828965054068909, 'w16': -1.1048311919003706, 'w17': -1.37773239147188, 'w18': 2.477637648263623, 'w19': 1.752840746325547, 'w20': -2.29343649783653, 'w21': 2.4984941559190896, 'w22': -0.253343884146963, 'w23': 1.810104410357987, 'w24': -0.09551063625638295}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:28,060] Trial 37 finished with value: 0.7246376811594203 and parameters: {'w0': 0.9129158145700257, 'w1': -1.3698101505398301, 'w2': -2.18554171229395, 'w3': 1.837704556300448, 'w4': -0.5183620738063863, 'w5': 1.5035828962475406, 'w6': 0.31370702815086016, 'w7': 0.6879918154017589, 'w8': 0.8963849195662915, 'w9': -0.37566589773087833, 'w10': -0.5118877963055657, 'w11': -1.124606381179063, 'w12': 2.241548057513066, 'w13': -0.19904462675961243, 'w14': 2.477737329144944, 'w15': 2.232906836805241, 'w16': -1.8690577245651245, 'w17': -0.5006653132123715, 'w18': -2.0313727576139464, 'w19': 1.348335595338125, 'w20': -0.2682700666943738, 'w21': -1.1634960471465505, 'w22': -1.2034194828878002, 'w23': -0.44079748532134344, 'w24': -2.17210620762266}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:28,136] Trial 38 finished with value: 0.7246376811594203 and parameters: {'w0': -0.7893816699140725, 'w1': -0.05243188004963095, 'w2': 0.22870279349992728, 'w3': 0.9547130531368302, 'w4': 1.5673383238713825, 'w5': -0.22403121300267959, 'w6': 1.5987091438590708, 'w7': 1.3639233784364868, 'w8': 1.5239285429671734, 'w9': 0.3125654222083214, 'w10': -1.2498716701105759, 'w11': -1.9940730880979198, 'w12': 0.8322392076059015, 'w13': -2.3070335338486263, 'w14': 2.149813384666289, 'w15': 1.3065842051830874, 'w16': -0.1311862200042785, 'w17': 0.22306462721387288, 'w18': -1.2155402370102868, 'w19': 2.038594668865525, 'w20': -1.9943949706274615, 'w21': 1.2405183774200383, 'w22': -1.6989789033842233, 'w23': 0.432177461719675, 'w24': -1.3808683536344404}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:28,213] Trial 39 finished with value: 0.7391304347826086 and parameters: {'w0': -1.1046155048341268, 'w1': 2.4709686871104037, 'w2': -0.1194675604617752, 'w3': 0.4920565794935692, 'w4': 0.15964125683602592, 'w5': -0.6006657531172227, 'w6': 1.0069152314551808, 'w7': -0.33315363955024707, 'w8': 1.1070926654090214, 'w9': 0.023910745029204872, 'w10': 1.235423804733235, 'w11': -1.3585870518644378, 'w12': 1.291909013851261, 'w13': -1.9025515953477274, 'w14': 1.576464423842845, 'w15': 2.498623815495987, 'w16': 0.3443618455311679, 'w17': 0.024905406111794925, 'w18': 0.5565523762460531, 'w19': -0.9954986055930237, 'w20': 0.7393682335088079, 'w21': 1.9272284476169559, 'w22': -1.0304729678114146, 'w23': 0.9560471437048318, 'w24': -0.6716728986376919}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:28,295] Trial 40 finished with value: 0.7246376811594203 and parameters: {'w0': 0.3564505403981588, 'w1': 0.9391693880647227, 'w2': -2.4441873579303164, 'w3': -0.3089286784846348, 'w4': -2.350301250505952, 'w5': 2.0738149933461205, 'w6': 0.7351484383565845, 'w7': 0.3943195667661581, 'w8': 1.8767683256299796, 'w9': -0.8868475460908835, 'w10': -1.8809833305738595, 'w11': 1.9310043956731264, 'w12': -0.7646787839499611, 'w13': 1.0234025779113156, 'w14': 0.2281889665677861, 'w15': 0.15524004588092374, 'w16': -0.7994542051988266, 'w17': -0.8067270591648801, 'w18': 1.1168248529184792, 'w19': -0.19759436468606695, 'w20': 1.486275017261422, 'w21': 1.5972766223691957, 'w22': 1.446731549801008, 'w23': 1.924921704035069, 'w24': 1.1429874608541268}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:28,372] Trial 41 finished with value: 0.7463768115942029 and parameters: {'w0': -1.5004469444459536, 'w1': 1.9858020156867036, 'w2': -1.1246980149387296, 'w3': -0.16930612825575408, 'w4': 2.1571301474894438, 'w5': 1.8863211026525821, 'w6': 2.401771390828288, 'w7': -0.733791971842177, 'w8': 1.2680118373152047, 'w9': -0.33678383650294785, 'w10': -1.5028141646233737, 'w11': -0.9228530513507288, 'w12': -0.05353500627409846, 'w13': -0.4285704236737966, 'w14': 0.7771260996661304, 'w15': 1.9928317532668278, 'w16': -1.3564145288195575, 'w17': -0.04342989978285494, 'w18': -0.921735972487149, 'w19': 1.3516916909968786, 'w20': 0.17839333956546843, 'w21': 0.6917757011500619, 'w22': -0.11425858398691291, 'w23': -0.06147491800733407, 'w24': -0.17427148305143747}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:43:28,450] Trial 42 finished with value: 0.7536231884057971 and parameters: {'w0': -2.4980089159977825, 'w1': 2.093372374880331, 'w2': -1.2289174760368773, 'w3': 0.24322968628658914, 'w4': 2.217251954428063, 'w5': 0.5572484872935325, 'w6': 2.211520641940777, 'w7': -0.8138394545185444, 'w8': 1.439705940929766, 'w9': -0.1190639865075529, 'w10': -2.304448961745977, 'w11': -0.6372435602093864, 'w12': 0.23969408805831716, 'w13': -0.18328621366753495, 'w14': 1.001434871601944, 'w15': 2.1791966668863583, 'w16': -1.1416173299946388, 'w17': 0.6372584137528758, 'w18': -0.7439239921562344, 'w19': 2.2443274628333847, 'w20': 0.25606207137706016, 'w21': 0.681237791074748, 'w22': -0.13058048504346265, 'w23': 0.09857453579242381, 'w24': 0.16784715276820344}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:28,528] Trial 43 finished with value: 0.7391304347826086 and parameters: {'w0': -2.2757135401382187, 'w1': 1.1863499494015854, 'w2': -1.6871966969323928, 'w3': 0.23559723112735415, 'w4': 1.8886185512720486, 'w5': 0.5180774943478308, 'w6': 2.005269189850302, 'w7': -2.050301904114062, 'w8': 1.66648127601485, 'w9': -0.054704824729207596, 'w10': -2.2895986555414822, 'w11': -0.46422579286706167, 'w12': 2.223328217559391, 'w13': -0.7570922974088825, 'w14': 1.0319323074385718, 'w15': 1.6354997837456113, 'w16': -1.0425259251666137, 'w17': 1.5150732069881248, 'w18': -1.410832969209549, 'w19': 2.3053498299892876, 'w20': 0.5034015397155063, 'w21': 1.0942644557866175, 'w22': -0.612475120269892, 'w23': 0.13315187310888954, 'w24': 0.18902666105257193}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:28,611] Trial 44 finished with value: 0.7463768115942029 and parameters: {'w0': -1.8614779567852169, 'w1': 1.6178558969380568, 'w2': -0.8614280657102772, 'w3': 0.7006784313400818, 'w4': 2.2883910129004743, 'w5': 0.17214205779044522, 'w6': 1.6842335484944275, 'w7': 0.2435273425962402, 'w8': 0.7250722546925711, 'w9': 0.521735747337932, 'w10': -2.4456388407721037, 'w11': -0.7150032673316908, 'w12': -1.454007081263332, 'w13': -1.5796608498692821, 'w14': 1.827485268041296, 'w15': 2.264289283325996, 'w16': -0.4559763772992612, 'w17': 0.6770572897301941, 'w18': -0.2544083667698089, 'w19': 2.1587777102035144, 'w20': -0.08236571270218818, 'w21': 0.005014699352667185, 'w22': 0.6687570725329792, 'w23': 0.5748069301484329, 'w24': -0.40895465873978964}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:28,690] Trial 45 finished with value: 0.7463768115942029 and parameters: {'w0': -1.9615315630967123, 'w1': 2.2154857421559293, 'w2': -1.2852786383476336, 'w3': 1.0930268993172136, 'w4': 2.499357662441587, 'w5': 1.0901985599179178, 'w6': 2.229805352407513, 'w7': -1.28818342959014, 'w8': 1.4089731136252435, 'w9': 0.21770580058194566, 'w10': -1.9489497372297855, 'w11': -0.10994010736815596, 'w12': -1.8991898485376857, 'w13': -2.3269246658898184, 'w14': -0.10912574712619705, 'w15': 1.8954516166225253, 'w16': -1.2226898600423826, 'w17': 0.5732023416461183, 'w18': -1.7560637815840345, 'w19': 1.7707005981084627, 'w20': 1.195203982366802, 'w21': 0.10526599764662158, 'w22': -0.3384255728712936, 'w23': -0.8242423809618965, 'w24': -0.9481371465067546}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:28,788] Trial 46 finished with value: 0.7318840579710145 and parameters: {'w0': -0.211110563203538, 'w1': 1.805072730883574, 'w2': 2.4070316009373864, 'w3': -0.8775405635623664, 'w4': 1.7268858798653568, 'w5': 0.7726973220600601, 'w6': 1.5083610118502717, 'w7': -0.882904027842803, 'w8': -0.14861946203529697, 'w9': -0.6850697415786997, 'w10': -2.2337196146418865, 'w11': -1.607962953629183, 'w12': 0.35058501945434895, 'w13': 0.35847191505911635, 'w14': 1.4799038684955201, 'w15': 2.2290408439669784, 'w16': -0.8085447314243428, 'w17': 0.9230689770771414, 'w18': -2.178378729875123, 'w19': 2.4934877428085316, 'w20': -0.3987015278962076, 'w21': 0.5370188034001879, 'w22': 0.14655897636245568, 'w23': 0.8496351600632359, 'w24': 0.08537150091539308}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:28,872] Trial 47 finished with value: 0.7246376811594203 and parameters: {'w0': -0.9991113677554311, 'w1': 1.1299551157915733, 'w2': -2.0714305851890824, 'w3': 0.5693250882304057, 'w4': 1.3612447098260643, 'w5': 0.3603425405433076, 'w6': -0.7099049837492061, 'w7': -0.21153988033344556, 'w8': 2.283531292086953, 'w9': 0.9590399314242539, 'w10': 0.26174103175579755, 'w11': 2.448439516016605, 'w12': -2.4568944967968953, 'w13': -0.17470253280457695, 'w14': 1.0842086864015736, 'w15': -1.1388654561262643, 'w16': -2.1252674796278077, 'w17': -0.33335567633385776, 'w18': -2.482488033889543, 'w19': 1.153077534634729, 'w20': -2.011888062298444, 'w21': 0.8769539824079469, 'w22': 0.4324812921820137, 'w23': -0.35740012847920416, 'w24': -0.7722375903031603}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:28,949] Trial 48 finished with value: 0.7391304347826086 and parameters: {'w0': -2.392048567686154, 'w1': 1.3328466667686378, 'w2': 1.7743324084264023, 'w3': 1.483822565194926, 'w4': 2.0872908670661197, 'w5': 1.4565499535359168, 'w6': 2.2800566887908302, 'w7': -1.995707326670734, 'w8': 1.9740534679692499, 'w9': -1.2393435866209674, 'w10': -1.7638377366423974, 'w11': -0.15839984095054538, 'w12': -1.0074614840451481, 'w13': 1.2337363865275988, 'w14': -0.7550574792908038, 'w15': 1.7176075040910197, 'w16': -2.3904915606460033, 'w17': -2.1506726465186174, 'w18': -1.9171683891041122, 'w19': -1.9533099634177598, 'w20': -1.395026149560421, 'w21': -0.37733634543014594, 'w22': -0.9322599122862292, 'w23': -0.2488880405614078, 'w24': -0.3350807821171835}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,029] Trial 49 finished with value: 0.7246376811594203 and parameters: {'w0': -0.6596560835397917, 'w1': -2.3414030833187605, 'w2': -1.0434555938660066, 'w3': 0.34977825917680794, 'w4': 0.9796330622209304, 'w5': 0.03531919769655323, 'w6': 1.8845017063158647, 'w7': -0.4811687918165709, 'w8': 1.0345947067504555, 'w9': -1.5728877462568687, 'w10': -0.4972677539538737, 'w11': -2.1925560005655105, 'w12': 1.5518958576548751, 'w13': -2.4967884242445475, 'w14': 1.9328678687031173, 'w15': 0.7811951239217648, 'w16': -0.025558524298960883, 'w17': -2.487530210143943, 'w18': -0.7422131074284845, 'w19': 2.2284268586341973, 'w20': -1.0685842124040146, 'w21': 2.235402137926823, 'w22': 0.9867209484324097, 'w23': 0.5067432158723889, 'w24': 0.8405785044707392}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,110] Trial 50 finished with value: 0.7318840579710145 and parameters: {'w0': 1.0975822443050713, 'w1': -1.0346309953046533, 'w2': -1.4297206608155768, 'w3': 1.3770755394056837, 'w4': 0.4313289526623698, 'w5': 0.9912978072431352, 'w6': -2.33424710034767, 'w7': -1.2555013366205952, 'w8': 0.8844510199911642, 'w9': -2.0774819515993492, 'w10': -2.336125336969237, 'w11': -0.6274489812248251, 'w12': 0.7545963465548673, 'w13': -1.04437128986954, 'w14': 0.40243008529035157, 'w15': 1.9910566524383702, 'w16': -0.4873969671241377, 'w17': -0.5785374733579105, 'w18': -1.154757183757794, 'w19': 0.37132273660692605, 'w20': 0.5615088490533772, 'w21': 1.220329162221727, 'w22': -0.40081868391924835, 'w23': 1.3512560146313812, 'w24': 0.4181092657844975}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,193] Trial 51 finished with value: 0.7536231884057971 and parameters: {'w0': -1.3337952482902815, 'w1': 1.9807320963733328, 'w2': -1.1925586549938128, 'w3': -0.3759739362572374, 'w4': 2.2556018426677333, 'w5': 1.7532396443241263, 'w6': 2.340451519999194, 'w7': -0.7839733454930425, 'w8': 1.3734926978581339, 'w9': -0.24751873610627195, 'w10': -1.2450889738813498, 'w11': -0.9467735556589183, 'w12': 0.3166101110940831, 'w13': -0.2944475053478106, 'w14': 0.808814705786669, 'w15': 2.126494828619474, 'w16': -1.4498428029715864, 'w17': 0.14698897190940807, 'w18': -0.8244831029548202, 'w19': 1.4928037084167673, 'w20': 0.1334200284231506, 'w21': 0.6579982849354383, 'w22': -0.09465266383134359, 'w23': -0.7149254338194936, 'w24': -0.19624000478989975}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,279] Trial 52 finished with value: 0.7391304347826086 and parameters: {'w0': -1.7128024463174847, 'w1': 1.8702559538233443, 'w2': -1.6076337917670758, 'w3': -0.371886392856673, 'w4': 2.297415338635111, 'w5': 1.3558844604543263, 'w6': 2.2621620540940235, 'w7': -1.6471352383654447, 'w8': 1.3901956990946918, 'w9': -0.48079354601487484, 'w10': -1.1759758625961128, 'w11': -1.3900828872736235, 'w12': -0.35160595329739064, 'w13': -0.6019906612243777, 'w14': 0.04423162394060476, 'w15': 2.321333986578185, 'w16': -1.0536221375856245, 'w17': 0.11648454599793201, 'w18': -1.4845298348280478, 'w19': 1.6558421056801702, 'w20': 0.039966361162153796, 'w21': 0.41424629746437924, 'w22': -0.2038856977275666, 'w23': -1.3468153409836296, 'w24': -1.022994345546639}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,359] Trial 53 finished with value: 0.7463768115942029 and parameters: {'w0': -1.9982271456278962, 'w1': 2.3799459312913065, 'w2': -1.7856271641579275, 'w3': -1.0812961817214353, 'w4': 1.9570307889800989, 'w5': 0.6308799227904438, 'w6': 2.032204544143382, 'w7': -0.0818682276314572, 'w8': 1.7031564817985312, 'w9': -1.0027324302543426, 'w10': -0.7019596195712887, 'w11': -1.077385217067793, 'w12': 1.7629114659312655, 'w13': 0.05226428486174117, 'w14': 1.223085752561392, 'w15': 1.5652949583968254, 'w16': -1.420975187268305, 'w17': 0.6684171118441337, 'w18': -0.4441322155063746, 'w19': 1.9498353653815261, 'w20': -0.47018404938867564, 'w21': 0.7328686287188814, 'w22': -0.013469932028551512, 'w23': -0.7137887879878844, 'w24': 2.479005934389212}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,438] Trial 54 finished with value: 0.7318840579710145 and parameters: {'w0': -0.0435760461532802, 'w1': 1.516692066018642, 'w2': -0.9099020751972478, 'w3': -0.028815980992672796, 'w4': 1.3711671700378636, 'w5': 1.2001757900238144, 'w6': 1.738108979372568, 'w7': -0.8672580436884505, 'w8': 2.110570211563844, 'w9': 2.0915868977889844, 'w10': -2.4985495298010942, 'w11': 1.3143839817754925, 'w12': 0.1798081991541279, 'w13': -0.3660259864944201, 'w14': 0.7225357132435362, 'w15': 2.4922618527957034, 'w16': -1.6401611913623242, 'w17': -1.1076032764854797, 'w18': -0.10682444344816433, 'w19': 0.7407667427814433, 'w20': 0.9690357690149132, 'w21': 1.9233135650821316, 'w22': 0.25401450433326417, 'w23': -1.0897884621657306, 'w24': -0.46541058687152925}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,515] Trial 55 finished with value: 0.7463768115942029 and parameters: {'w0': 0.36092471165547646, 'w1': 2.2215863509852944, 'w2': -1.222814914006999, 'w3': 0.9200999018903584, 'w4': 1.7396557050883654, 'w5': 1.6701794072553173, 'w6': 1.2585758321809668, 'w7': -0.560748002043983, 'w8': 1.424234570804214, 'w9': 1.3024627853418689, 'w10': -2.0807724684131124, 'w11': -0.7802354802986763, 'w12': 0.688669386908942, 'w13': 0.7304445841427168, 'w14': 0.9374782989456732, 'w15': 1.7806693971207526, 'w16': -1.9093719849277013, 'w17': 0.39123605753052954, 'w18': -1.8423960967324526, 'w19': 1.5410446625193224, 'w20': -2.3583750671514467, 'w21': -1.6580201266046268, 'w22': -0.7633426489383613, 'w23': 0.1110376114628493, 'w24': -0.08537430404095175}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,596] Trial 56 finished with value: 0.7536231884057971 and parameters: {'w0': -1.293262518249582, 'w1': 1.674539979763594, 'w2': -0.38429579004006403, 'w3': -1.7471268663014365, 'w4': 2.3317751256756627, 'w5': 0.3585415651512065, 'w6': 2.322589527818029, 'w7': 0.5470488315223697, 'w8': 1.8083916462170204, 'w9': -0.10438535647285935, 'w10': 0.6517915488413364, 'w11': 0.2463424531960552, 'w12': 2.2230729329308754, 'w13': 0.3008162250417852, 'w14': 0.27138449426481825, 'w15': 2.0174493723453177, 'w16': -0.782412592039728, 'w17': -1.5747071436489668, 'w18': -1.0326719224456493, 'w19': -1.564265386885043, 'w20': 0.47082333675686594, 'w21': 1.54436899694625, 'w22': -0.48280987319624624, 'w23': -1.8583125056821541, 'w24': -0.717103753502171}. Best is trial 42 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:43:29,674] Trial 57 finished with value: 0.7608695652173914 and parameters: {'w0': -2.1446150666024137, 'w1': 1.7249245600817986, 'w2': -0.2992750955556771, 'w3': -1.9794552590907495, 'w4': 2.0752434415773737, 'w5': 0.34392684755732794, 'w6': 2.331615967077911, 'w7': 0.676674987343855, 'w8': 1.0512871415496392, 'w9': 0.07485786405797595, 'w10': 0.6912678509968115, 'w11': 0.256972814555636, 'w12': 2.380294262543332, 'w13': 0.28886517333812656, 'w14': 0.4076587646308317, 'w15': 1.1815062731711836, 'w16': -0.7851529696778066, 'w17': -1.7570588979451542, 'w18': -1.0266834173814905, 'w19': -2.418750094382253, 'w20': 0.47266147335209563, 'w21': 1.0478644510015676, 'w22': 0.5893008079971385, 'w23': -1.9715802891332816, 'w24': -0.7748733133667011}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:29,757] Trial 58 finished with value: 0.7536231884057971 and parameters: {'w0': -2.4899504077304555, 'w1': 1.6722641244200809, 'w2': -0.352544201589035, 'w3': -1.6459340433856093, 'w4': -1.0173799859997459, 'w5': -0.4660915840855878, 'w6': 2.317727379777619, 'w7': 0.8008554199804708, 'w8': 0.23971719231389915, 'w9': 0.19420312990661226, 'w10': 0.6156044582597295, 'w11': 0.2328240677930991, 'w12': 2.2812320541248825, 'w13': 0.33649736760379556, 'w14': -0.1664603690007398, 'w15': 1.108466129543215, 'w16': -1.1845697038329905, 'w17': -1.5710126505441921, 'w18': -1.028538982056065, 'w19': -2.286684807514381, 'w20': 0.40894252882823373, 'w21': 0.46173798852366055, 'w22': 0.7983461692364432, 'w23': -2.0251434783749387, 'w24': 1.8374764316916028}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:29,836] Trial 59 finished with value: 0.7536231884057971 and parameters: {'w0': -2.4560938997657744, 'w1': 2.0556144617314893, 'w2': -0.2694907423791733, 'w3': -1.7768706626142337, 'w4': -1.3788884103459258, 'w5': -1.038203543105205, 'w6': 2.3397297466877167, 'w7': 0.8189610625424875, 'w8': 0.21080969353407425, 'w9': 0.151506893818177, 'w10': 0.7344141615997035, 'w11': 0.22931488543800427, 'w12': 2.3248190499249537, 'w13': 0.3541587052356819, 'w14': -0.18123287476930328, 'w15': 0.9764632945952114, 'w16': -1.2279315917865712, 'w17': -1.9546312324365849, 'w18': -0.5804684122400358, 'w19': -2.49083953389034, 'w20': 0.3674601095918756, 'w21': 0.4123748000715065, 'w22': 0.8524286543282651, 'w23': -2.029610546606323, 'w24': 1.8958182533384578}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:29,916] Trial 60 finished with value: 0.7463768115942029 and parameters: {'w0': -2.430111118448761, 'w1': 2.07059981430732, 'w2': -0.2815052564292805, 'w3': -1.8202668962335642, 'w4': -1.1016360654474866, 'w5': -1.5206219512699723, 'w6': 2.3510214755889516, 'w7': 0.7997076556705829, 'w8': -0.5375631923699089, 'w9': 0.09683614189629347, 'w10': 0.7978716073976732, 'w11': 0.2896080475332055, 'w12': 2.3474154304944865, 'w13': 0.39278955346374933, 'w14': -0.12700802507323983, 'w15': 0.3122013201398335, 'w16': -1.760120085693241, 'w17': -1.5901412019358807, 'w18': 0.13186624824582593, 'w19': -2.284657188350346, 'w20': 0.4145204209985299, 'w21': 0.3994975485574418, 'w22': 1.2528961864453125, 'w23': -1.9456953968107686, 'w24': 1.8696847279463884}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:29,996] Trial 61 finished with value: 0.7536231884057971 and parameters: {'w0': -2.127738141093751, 'w1': 1.712663166655947, 'w2': -0.5723010860242685, 'w3': -1.857261867442243, 'w4': -1.4917191488820758, 'w5': -1.0924813819165209, 'w6': 2.1938738129390547, 'w7': 1.1281352343301572, 'w8': 0.2880682085324854, 'w9': 0.26663773805519086, 'w10': 0.48591633423752667, 'w11': 0.7550806925666851, 'w12': 2.212096280892504, 'w13': 0.22968575559840376, 'w14': 0.27022891762251167, 'w15': 0.9419677356378243, 'w16': -1.1929559752996102, 'w17': -2.0638050574087305, 'w18': -0.5326390724501998, 'w19': -1.6837473360635706, 'w20': 0.6817422626511116, 'w21': 0.10725777623585864, 'w22': 0.7656327814756925, 'w23': -2.476499402409143, 'w24': 1.9358809408368227}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,076] Trial 62 finished with value: 0.7391304347826086 and parameters: {'w0': -2.164488764705532, 'w1': 1.698473875990129, 'w2': 0.07509981706648894, 'w3': -1.7264081086607013, 'w4': -1.5965280036342289, 'w5': -1.078768295797202, 'w6': 2.1712130581214497, 'w7': 1.2721397113938464, 'w8': 0.23292584835662383, 'w9': 0.3118567868359345, 'w10': 0.5095527927791538, 'w11': 0.7976751048312816, 'w12': 2.176881542608034, 'w13': 0.653656696992114, 'w14': 0.3622778580488671, 'w15': 0.9728727341511714, 'w16': -1.2292715843794733, 'w17': -2.010248799660893, 'w18': -0.5296990904104313, 'w19': -1.6307708265394742, 'w20': 0.7075549676039485, 'w21': 0.12403938624112587, 'w22': 0.8638437188859268, 'w23': -2.458136919368065, 'w24': 2.1925638878109015}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,162] Trial 63 finished with value: 0.7463768115942029 and parameters: {'w0': -2.1415013856216696, 'w1': 1.8590494099858466, 'w2': 0.49763566071566956, 'w3': -2.2068098609533866, 'w4': -1.321733804241977, 'w5': -0.829122733373582, 'w6': 2.3626221444733857, 'w7': 1.8600932278351028, 'w8': -0.12686344979260994, 'w9': 0.8269924950490528, 'w10': 1.3307976491037499, 'w11': 0.6640432268310911, 'w12': 2.4979542821214147, 'w13': 0.21770270261105062, 'w14': 0.15192678280868444, 'w15': 1.186363829883553, 'w16': -1.5504344886945052, 'w17': -1.5498807057698167, 'w18': -0.20579273867381154, 'w19': -2.176997804643805, 'w20': 0.1086242737400455, 'w21': 0.5012992378125477, 'w22': 1.7832823452284778, 'w23': -2.2021327966797184, 'w24': 1.836900498538692}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,250] Trial 64 finished with value: 0.7463768115942029 and parameters: {'w0': -2.467471370752609, 'w1': 2.4847080637163526, 'w2': -0.6491845934407531, 'w3': -1.7927652951728883, 'w4': -1.7090908410370576, 'w5': -0.5463194939481105, 'w6': 2.492224065584433, 'w7': 1.2245129409637077, 'w8': 0.020084255921369837, 'w9': 0.5725032498870988, 'w10': 0.5094276148756064, 'w11': 0.1487611202352421, 'w12': 2.1338169030382272, 'w13': -0.05469518018897179, 'w14': -0.6075606651857675, 'w15': 0.8827395167309935, 'w16': -0.8852405404808452, 'w17': -1.7662161222263322, 'w18': -0.6675807305774726, 'w19': -2.426975042259338, 'w20': 1.23398741204799, 'w21': -0.1233466897833119, 'w22': 0.47472631863957004, 'w23': -1.7312250420378472, 'w24': 1.6770595796396097}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,332] Trial 65 finished with value: 0.7463768115942029 and parameters: {'w0': -2.2699125279201575, 'w1': 2.3521011730324335, 'w2': -0.3982143985726553, 'w3': -1.4996585781456635, 'w4': -1.9297764207727193, 'w5': -0.40448074328430716, 'w6': 2.160828238095551, 'w7': 0.5339745173876553, 'w8': 0.5215516828365787, 'w9': -0.16534919261078454, 'w10': 0.9954118067676849, 'w11': 0.9626887651067205, 'w12': 2.3408934845457385, 'w13': 0.5163475238405578, 'w14': -0.35487835273202617, 'w15': 1.242425290874953, 'w16': -1.394946761257709, 'w17': -2.221123247763073, 'w18': -1.006265033747599, 'w19': -1.7500174353818516, 'w20': 0.35706243800936055, 'w21': 1.0499137152019309, 'w22': 0.6074701502416624, 'w23': -2.164636061635167, 'w24': 2.0777573668114924}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,412] Trial 66 finished with value: 0.7391304347826086 and parameters: {'w0': -1.6608565432134383, 'w1': 1.616908447063718, 'w2': -0.0625740443355155, 'w3': -2.0659917321887478, 'w4': -1.031171543030407, 'w5': -1.2952690205540889, 'w6': 2.3136013604947596, 'w7': 1.5479751442757337, 'w8': -0.3248116413719354, 'w9': 0.13210961954965003, 'w10': 0.1783409730355403, 'w11': 0.4293775259510577, 'w12': 2.302636248085255, 'w13': 0.8938091934541551, 'w14': -0.2394134174764848, 'w15': 0.5351250857243852, 'w16': -1.1640419782812335, 'w17': -1.924497978908664, 'w18': -0.8203356980655648, 'w19': -2.0193125877005187, 'w20': 0.5657139251388822, 'w21': 0.8198802434032277, 'w22': 1.2693871774839511, 'w23': -1.6557053414355298, 'w24': 1.3649699724162172}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,491] Trial 67 finished with value: 0.7246376811594203 and parameters: {'w0': -2.048678527807883, 'w1': 1.9595102966478126, 'w2': -0.5731632705616444, 'w3': -2.4907314668162805, 'w4': -0.9125527182449646, 'w5': -1.7183316041313987, 'w6': -1.8159593315330365, 'w7': 0.8171597640643068, 'w8': -0.9454528478591925, 'w9': 0.38510413167135465, 'w10': 0.9533762977615228, 'w11': 0.20578097969867967, 'w12': 1.854981242952872, 'w13': 0.18989819372799133, 'w14': 0.4797249507134195, 'w15': -0.1789309340128499, 'w16': -0.968611279161065, 'w17': -2.077501977832938, 'w18': -0.30399624358113486, 'w19': -1.190116633764404, 'w20': 0.8329269525069014, 'w21': 0.2902555709955735, 'w22': 0.872314649694149, 'w23': -2.2843787734806265, 'w24': 1.5926734655141528}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,573] Trial 68 finished with value: 0.7391304347826086 and parameters: {'w0': -1.3992649263154688, 'w1': 2.1262747046552772, 'w2': 0.05904075940761716, 'w3': -1.5152075864500754, 'w4': -0.7649859537536777, 'w5': -0.810108011358837, 'w6': 1.8592871231511108, 'w7': 0.46368720765266735, 'w8': 0.5405008169822241, 'w9': 0.02665712218430269, 'w10': 0.546962504134828, 'w11': 0.5834706714107821, 'w12': 2.096087227715341, 'w13': 1.6790398211624242, 'w14': -1.0188070627219281, 'w15': 1.4585384483884376, 'w16': -1.5106302357808379, 'w17': -1.7272580228366698, 'w18': 0.2803532030739433, 'w19': -1.567365207572244, 'w20': -0.07222696698275505, 'w21': -0.6758814991716655, 'w22': 1.5949923852757997, 'w23': -1.9848704526691383, 'w24': 2.224686479974915}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,651] Trial 69 finished with value: 0.7246376811594203 and parameters: {'w0': -1.8423127571269635, 'w1': 2.312943434171303, 'w2': -0.31470531770658905, 'w3': -2.2709090697572814, 'w4': -1.3654940389743735, 'w5': -1.0381339174417497, 'w6': 1.4790847118660886, 'w7': 1.1229413585601584, 'w8': 0.1800024833961663, 'w9': -0.17453936612984888, 'w10': 0.33845349263194613, 'w11': 0.0566109808010723, 'w12': 2.478364078136431, 'w13': -0.10134644346618181, 'w14': -0.0663458144028124, 'w15': 0.5220689425333417, 'w16': -1.8284931013673567, 'w17': -2.264248365848594, 'w18': -0.9961997032459646, 'w19': -2.076893788073682, 'w20': 0.968073630774476, 'w21': -0.27654079440303236, 'w22': 1.0473723192876925, 'w23': -1.515916404074836, 'w24': 1.199650754828629}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,730] Trial 70 finished with value: 0.7463768115942029 and parameters: {'w0': -2.307746415165904, 'w1': 1.882430997302856, 'w2': -0.5250373395786716, 'w3': -1.9547970256605913, 'w4': -1.8930102193197693, 'w5': -0.39019567998395877, 'w6': 2.142541348151985, 'w7': 0.8080157764284558, 'w8': 0.7833783853223553, 'w9': 0.721456540514789, 'w10': 1.6229035832590921, 'w11': 0.7864536646524071, 'w12': 1.4182302714153407, 'w13': 0.4109531622542244, 'w14': 0.13675849625737863, 'w15': 0.9588777951331424, 'w16': 1.5048788715760235, 'w17': -1.488939542131606, 'w18': -0.5894944249583915, 'w19': -1.8968146587456285, 'w20': 1.4257299605831926, 'w21': 0.64278798229141, 'w22': 0.28733596821686436, 'w23': -2.0802824652502867, 'w24': 2.326384806729626}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,812] Trial 71 finished with value: 0.7608695652173914 and parameters: {'w0': -2.1460076146206513, 'w1': 1.6073883348411446, 'w2': -0.7739289284597166, 'w3': -1.300477198021049, 'w4': -0.22667354913185875, 'w5': -0.08692147513176372, 'w6': 2.3451039370010855, 'w7': 0.20915162975118617, 'w8': 0.27360590574585153, 'w9': 1.2353238909853723, 'w10': -0.006725758381170954, 'w11': 1.228867770500468, 'w12': -2.2271434024376884, 'w13': -0.3077921488370103, 'w14': 0.3013694600581484, 'w15': 1.0893289853519337, 'w16': -1.1090729939832802, 'w17': -2.4940397299832404, 'w18': -0.8382645986810422, 'w19': -2.350682555335832, 'w20': 0.21462252517076263, 'w21': 0.03468779805375577, 'w22': 0.796446108280745, 'w23': -2.312286539274166, 'w24': 2.0491662020112478}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,898] Trial 72 finished with value: 0.7536231884057971 and parameters: {'w0': -2.484884324794291, 'w1': 1.7168155389726025, 'w2': -0.7056539652130436, 'w3': -1.216728684238645, 'w4': -0.2937353852174034, 'w5': 0.008714695809851403, 'w6': 2.311461079648123, 'w7': 0.19781422153906386, 'w8': 0.4029105431227968, 'w9': 0.16801821010155019, 'w10': -0.00039038544151673727, 'w11': 1.5537211792873122, 'w12': 0.4225854550192849, 'w13': 0.08710490666654713, 'w14': 0.5705890954652022, 'w15': 1.0972163424079804, 'w16': -1.2611272321664861, 'w17': -1.9925532568428277, 'w18': -0.758748262456241, 'w19': -2.336064183531612, 'w20': 0.16128634496360048, 'w21': 0.09702129593006636, 'w22': 0.7603784033464532, 'w23': -2.3694364481248487, 'w24': 1.676409745591694}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:30,980] Trial 73 finished with value: 0.7318840579710145 and parameters: {'w0': -2.123746677025726, 'w1': 2.0289729983131988, 'w2': -0.14568088233741694, 'w3': -1.6279221452421377, 'w4': -1.2547191213741766, 'w5': -0.11426963707769953, 'w6': 1.712777385181101, 'w7': 0.6401720192887469, 'w8': 0.2079853979007097, 'w9': 1.139872471208869, 'w10': 0.7426010567761359, 'w11': 1.0370797317303087, 'w12': 1.7664362564600957, 'w13': -0.3425103006410345, 'w14': 0.29609543621948475, 'w15': 1.378892119376725, 'w16': -1.123959489232276, 'w17': -2.340716570497662, 'w18': -1.18137599085996, 'w19': -2.4917543401944915, 'w20': 0.30250498899485634, 'w21': 0.38296932252162236, 'w22': 1.2224963467908156, 'w23': -1.7915072834838024, 'w24': 2.052076912411595}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,061] Trial 74 finished with value: 0.7463768115942029 and parameters: {'w0': -1.9110165746395515, 'w1': -2.0208074964251117, 'w2': -0.38642643747234684, 'w3': -1.9706368701370558, 'w4': -0.7268634477970753, 'w5': 0.28796742348540044, 'w6': 2.498254343453531, 'w7': 0.9545700274913138, 'w8': -0.14140658325528754, 'w9': 0.48098650187907743, 'w10': -0.26292776923821215, 'w11': -0.07456842226827343, 'w12': -0.13146120522551563, 'w13': 0.24232314766623453, 'w14': -0.527732535055958, 'w15': 0.6654590434249836, 'w16': -0.7847435861440932, 'w17': -1.8279465419130438, 'w18': -0.4007758608818149, 'w19': -2.183776823842497, 'w20': 0.6592374734943596, 'w21': -0.0777222412944516, 'w22': -2.367965863184476, 'w23': -2.495617920595285, 'w24': 1.4243845922527945}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,141] Trial 75 finished with value: 0.7391304347826086 and parameters: {'w0': -1.7211230303776166, 'w1': 1.571143683477038, 'w2': 0.5788077337078414, 'w3': -1.3824925167510282, 'w4': 0.12269147052530816, 'w5': -1.3353100941653646, 'w6': 2.1105483361428865, 'w7': 0.34003921508666024, 'w8': -0.678803326858966, 'w9': 1.5284165557484182, 'w10': 0.8400482182266028, 'w11': 0.4051706475465489, 'w12': -2.0941220953635202, 'w13': 0.8776397917539489, 'w14': 0.08244672383319562, 'w15': 0.3273441218692117, 'w16': -1.336954298778428, 'w17': -2.3951068923403085, 'w18': -0.8615876283655699, 'w19': -0.7446952460918004, 'w20': 0.3915637864612037, 'w21': 0.9990790391535498, 'w22': 2.247715883132643, 'w23': -2.066879649831419, 'w24': 1.99549291177048}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,221] Trial 76 finished with value: 0.7391304347826086 and parameters: {'w0': -2.28629564168307, 'w1': 1.763655789288718, 'w2': -0.8163481483064872, 'w3': -1.0778115501001528, 'w4': -0.09606164377151341, 'w5': 0.13569068750868796, 'w6': 1.872195210165191, 'w7': 1.0902812973707867, 'w8': 1.1248793458996809, 'w9': -0.33294757427007693, 'w10': 1.1663838340192973, 'w11': 1.1725350493018418, 'w12': -0.4750310111636058, 'w13': -0.2872822630409191, 'w14': 0.6141357675652349, 'w15': 0.8599205791624778, 'w16': -0.9865840125272114, 'w17': -1.2205358366814218, 'w18': -1.337546321783044, 'w19': -1.7829889571908142, 'w20': -0.22717236777799055, 'w21': 1.227073915883812, 'w22': 0.5478199445815717, 'w23': -1.1824650992633887, 'w24': 2.2940759613823283}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,301] Trial 77 finished with value: 0.7391304347826086 and parameters: {'w0': -2.0758270732313866, 'w1': 1.0075049023428226, 'w2': 0.17263263014463726, 'w3': -2.2757264713939414, 'w4': -0.34740898252495, 'w5': -0.6967208018254969, 'w6': 1.9681230915646908, 'w7': 1.4467751969264833, 'w8': 0.9950139176342672, 'w9': -0.0007435109455437572, 'w10': 1.5078683210795258, 'w11': 0.632024175600145, 'w12': 0.121773024965011, 'w13': -0.6560521422805223, 'w14': -0.2020500556609668, 'w15': 1.5059256623866668, 'w16': -1.6481034947825846, 'w17': -2.182555051710688, 'w18': -0.6060527139268888, 'w19': -2.349196726397553, 'w20': -0.022897403039698894, 'w21': 0.22708713673668462, 'w22': 0.8685971859723344, 'w23': -1.8684269151787178, 'w24': 1.014393876228953}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,381] Trial 78 finished with value: 0.7608695652173914 and parameters: {'w0': -1.2893548103048615, 'w1': 1.275982487023764, 'w2': -1.020129042912275, 'w3': -0.8087929967433389, 'w4': -2.1785870897388175, 'w5': -0.30852193531770344, 'w6': 2.353973169610632, 'w7': 0.8829694613285171, 'w8': 0.32830593730950663, 'w9': 1.3167943187243591, 'w10': 0.3963940538519163, 'w11': -0.27356837926050426, 'w12': 1.0613013547024674, 'w13': 0.5408966662571022, 'w14': 0.25211650802397106, 'w15': 1.21603903764592, 'w16': -0.7029984295762586, 'w17': -1.6673423452630738, 'w18': -1.0540492205660865, 'w19': -1.3716594338748296, 'w20': 0.4879020324824748, 'w21': -0.5358979821764523, 'w22': 0.6919936083623818, 'w23': -1.5953075842321374, 'w24': 1.7429784005276088}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,465] Trial 79 finished with value: 0.7536231884057971 and parameters: {'w0': -1.3537190712099894, 'w1': 1.2866630739534135, 'w2': -1.1213490501042558, 'w3': -1.0727601833671707, 'w4': -2.2527140693334595, 'w5': -0.28394755323714876, 'w6': 2.4537155818749117, 'w7': 0.7224280152075743, 'w8': 0.07724981702172373, 'w9': 1.3254066050867375, 'w10': 0.39567326213750886, 'w11': -0.24943682442446924, 'w12': 0.547449867363796, 'w13': 0.5189699107924175, 'w14': 0.7227043990188581, 'w15': 1.6727828659160144, 'w16': -0.34284720244446665, 'w17': -1.4542006070079538, 'w18': -1.129575925946412, 'w19': -1.4479606453511722, 'w20': 0.48111071691383, 'w21': -0.5457807493902853, 'w22': -0.005505997015046241, 'w23': -1.5911028450126188, 'w24': -1.2596407783549077}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,545] Trial 80 finished with value: 0.7391304347826086 and parameters: {'w0': -1.619876172667449, 'w1': 2.2462910337227635, 'w2': -0.985292138024962, 'w3': -0.5741344760793312, 'w4': -1.899391592314431, 'w5': 0.35773888133555365, 'w6': 1.6064574554294602, 'w7': 0.5096071216574539, 'w8': -0.04438052340293319, 'w9': 1.863530058066337, 'w10': 0.6306335141449687, 'w11': -0.37947681838199765, 'w12': 1.0449840063327862, 'w13': -0.016585665824361273, 'w14': 0.898370149292189, 'w15': 1.1763134463362115, 'w16': -1.9963112092314979, 'w17': -0.9560257325176974, 'w18': -0.9979761827991052, 'w19': -1.1532531207844634, 'w20': 0.8839923668101131, 'w21': -1.0518102367727933, 'w22': 0.6131682255933375, 'w23': -1.3389276471602822, 'w24': 1.74478650924558}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,625] Trial 81 finished with value: 0.7536231884057971 and parameters: {'w0': -1.2264876015543955, 'w1': 1.4737666947176882, 'w2': -0.2321079898385484, 'w3': -0.9157190316111057, 'w4': -1.5896025202264523, 'w5': -0.48713578288013104, 'w6': 2.2198229159608758, 'w7': 0.8712510885167324, 'w8': 0.37670144911791326, 'w9': 0.7728890892663216, 'w10': 0.8785379580650611, 'w11': 0.26693593958568096, 'w12': 2.095075076291888, 'w13': -0.5238188435460231, 'w14': 0.29527794227757675, 'w15': 0.9906634107658714, 'w16': -0.6886314419914396, 'w17': -1.8926786829688864, 'w18': -0.7340807015292812, 'w19': -2.0731216511432744, 'w20': 0.25578147971450577, 'w21': 0.5564536707380381, 'w22': 0.3611414946053326, 'w23': -2.347448160712249, 'w24': 1.9591820412444947}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,706] Trial 82 finished with value: 0.7536231884057971 and parameters: {'w0': -2.398093703604336, 'w1': 1.9347309521965528, 'w2': -0.5463962149404582, 'w3': -0.7396111075201519, 'w4': -2.1545432048511906, 'w5': 2.318717618067982, 'w6': 2.3649986094589055, 'w7': 0.1136137343739062, 'w8': 0.5488041958731535, 'w9': -0.12067479824882796, 'w10': -0.15746115314264486, 'w11': -0.4936694424415935, 'w12': 2.3743576218905917, 'w13': 0.31136155520441133, 'w14': -0.019455377087269132, 'w15': 0.635209973601927, 'w16': -1.1331497411859177, 'w17': -1.3219390836277638, 'w18': -0.8848862679401897, 'w19': -1.8792897261851453, 'w20': 0.6283958681060698, 'w21': -0.9339178845676861, 'w22': 0.7959998081648555, 'w23': -1.7928457830556785, 'w24': 1.8269082903166556}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,789] Trial 83 finished with value: 0.7391304347826086 and parameters: {'w0': -2.2328762906180937, 'w1': 2.097489696081761, 'w2': -0.8130148419662784, 'w3': -1.597192136973477, 'w4': -0.8508570855868168, 'w5': -1.1683416775154858, 'w6': 2.0981760576657753, 'w7': 1.1486187855535237, 'w8': 0.3211568613047468, 'w9': 0.27241057810833613, 'w10': 0.15812472644932773, 'w11': 0.10760722358554432, 'w12': 0.30048118198420104, 'w13': 1.0655520007296775, 'w14': 0.43791777958042055, 'w15': 2.0654693289163486, 'w16': -0.8970381126746814, 'w17': -1.6688963135388177, 'w18': -0.4856737579182441, 'w19': -2.1928984223991255, 'w20': 0.12061768862522229, 'w21': -0.23393061265279352, 'w22': 0.9763516700939741, 'w23': -2.224433170994746, 'w24': 1.4534538686545644}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,872] Trial 84 finished with value: 0.7463768115942029 and parameters: {'w0': -1.8402428542021243, 'w1': 1.666044476188671, 'w2': -0.45470490069528763, 'w3': -1.377953882823343, 'w4': -2.4580914391102886, 'w5': -0.9316383157828598, 'w6': 2.365076355019511, 'w7': 0.915872828972418, 'w8': 0.6275894148022139, 'w9': 0.9862046034899662, 'w10': 1.1140198749591033, 'w11': -0.03557443118999959, 'w12': 1.2177278783681407, 'w13': 0.6158092789686672, 'w14': 0.1846719737369129, 'w15': 0.33880636081469884, 'w16': -0.5451600219641606, 'w17': -2.1207424117055838, 'w18': -1.3309114224074423, 'w19': -1.5934088092574383, 'w20': 0.7336786794951907, 'w21': 0.7842904362869517, 'w22': 1.082949021256462, 'w23': -2.092829549276026, 'w24': 2.3591543991970565}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:31,954] Trial 85 finished with value: 0.7391304347826086 and parameters: {'w0': -0.9799371419009273, 'w1': 1.7983806685142039, 'w2': -0.6672275558446998, 'w3': -1.9725260967717615, 'w4': -1.7246840967277932, 'w5': -0.1171533313278742, 'w6': 1.9626160103278147, 'w7': 1.9962628085013312, 'w8': 1.2572586203810785, 'w9': 1.2477619788087868, 'w10': 0.6760693059122928, 'w11': -0.22262214289197674, 'w12': -0.23970664408224368, 'w13': 0.1544082098357192, 'w14': 0.5139263394822285, 'w15': 1.0818724298505151, 'w16': -1.5375464982620586, 'w17': -1.6118981658012648, 'w18': -0.3408167412894122, 'w19': -2.489299387072947, 'w20': 0.4754295175471773, 'w21': 1.4711060716625286, 'w22': 0.1035798542814565, 'w23': -1.9442067117348516, 'w24': 2.1139594025038337}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,035] Trial 86 finished with value: 0.7391304347826086 and parameters: {'w0': -1.5425959411228536, 'w1': 1.239348195852401, 'w2': -1.0153775280824766, 'w3': -1.8535789021750086, 'w4': -2.063302924504384, 'w5': -0.6994644677988762, 'w6': -0.20146408484825606, 'w7': 0.288306260535657, 'w8': -0.27349257763261314, 'w9': 1.5939292841737873, 'w10': 0.3983567552651723, 'w11': 0.4583336637057654, 'w12': 2.0095273955943127, 'w13': 0.4557721917041927, 'w14': -0.31925092509750075, 'w15': 1.3172880184514195, 'w16': -1.2941497755046076, 'w17': 1.1887298906146384, 'w18': -1.087062650944601, 'w19': -1.316807684815221, 'w20': 0.27614111071501923, 'w21': 0.004649158283041011, 'w22': 0.6640496872066476, 'w23': -1.5092285633298244, 'w24': 1.3425695112665745}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,117] Trial 87 finished with value: 0.7391304347826086 and parameters: {'w0': -1.9793793343166772, 'w1': 1.3785410142919978, 'w2': -0.06736226291465466, 'w3': -1.6945434630056533, 'w4': -0.6058299178104664, 'w5': 0.1085336686817747, 'w6': 1.7866298795434856, 'w7': 0.5954098730232299, 'w8': 0.7457895693961571, 'w9': 0.6340702019345579, 'w10': 0.6107585865350642, 'w11': -0.6071033850636196, 'w12': 2.2689707153695373, 'w13': 0.7541941841097723, 'w14': -0.006890221081468861, 'w15': 1.8523445160932344, 'w16': -0.6935293726867495, 'w17': -1.8633668984331084, 'w18': -1.231627093075459, 'w19': -0.5727045222336603, 'w20': 1.112900165844454, 'w21': 0.29050291876380496, 'w22': -0.5285641820237832, 'w23': -2.3006290490133194, 'w24': 2.499443603809457}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,198] Trial 88 finished with value: 0.7463768115942029 and parameters: {'w0': -2.4972336947345637, 'w1': 0.8172192019201504, 'w2': -0.3535433770048786, 'w3': -1.214362091000816, 'w4': -1.4754821903177906, 'w5': 0.6172671522675761, 'w6': 2.222839097932305, 'w7': 1.0192409388783623, 'w8': 0.14401904971311114, 'w9': -0.44740932548161355, 'w10': -0.30325161997569283, 'w11': 0.7224455080078611, 'w12': -0.7959386055220992, 'w13': -0.11835798487808313, 'w14': 0.6820544794986931, 'w15': 1.5864112874786342, 'w16': -1.0470428136221368, 'w17': 0.44908299176436584, 'w18': -0.15244276792309364, 'w19': -1.744894728501277, 'w20': -0.1380316237722884, 'w21': -0.3425576144130694, 'w22': 0.3845108234208223, 'w23': -1.645735108697759, 'w24': 0.6036622134603011}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,281] Trial 89 finished with value: 0.7318840579710145 and parameters: {'w0': -1.1849244496122484, 'w1': 1.9899738411615544, 'w2': 0.34546394969359234, 'w3': -2.121710576787184, 'w4': -1.2408533618476631, 'w5': -0.29577783928036105, 'w6': 2.0744857036497724, 'w7': 0.44290783062225797, 'w8': -0.0180907584787669, 'w9': 2.1340877977962447, 'w10': 0.2667122698279845, 'w11': 1.7099341502013907, 'w12': 1.6449765263847944, 'w13': 0.030596168841288324, 'w14': 0.3324274545099945, 'w15': 0.8399463948627086, 'w16': 2.4191674117262085, 'w17': -1.1781837398311472, 'w18': 0.03810383077955662, 'w19': -2.326915845445993, 'w20': -0.3799536548387503, 'w21': 0.4731072846599072, 'w22': 0.18494614453098845, 'w23': -2.038510397624876, 'w24': 1.5673944965468696}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,362] Trial 90 finished with value: 0.7463768115942029 and parameters: {'w0': -2.3487794273921274, 'w1': 1.0994351789922008, 'w2': -0.907669663423468, 'w3': -0.34981448505367985, 'w4': 2.3433400463200726, 'w5': 0.4950168841998154, 'w6': 2.405146173218399, 'w7': 0.7026812668190008, 'w8': 1.8196658191883979, 'w9': -0.26137488150956334, 'w10': 1.3274426979219713, 'w11': 0.9280927354427083, 'w12': 0.03775253910723553, 'w13': -0.22529315160006014, 'w14': -0.46469015503413713, 'w15': 2.1269336397216265, 'w16': -0.8677555054162742, 'w17': -2.2750082026142215, 'w18': -0.6563416955301488, 'w19': -2.1308105004636073, 'w20': 0.05648074148481874, 'w21': 0.1293658345169995, 'w22': 0.4909887138461193, 'w23': -1.2187196624834589, 'w24': -1.088703445637808}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,445] Trial 91 finished with value: 0.7536231884057971 and parameters: {'w0': -2.2018324069226303, 'w1': 1.739672143554543, 'w2': -1.2637713400089765, 'w3': -1.2475619830582723, 'w4': 0.2529437189750544, 'w5': 0.22014614526846818, 'w6': 2.280732577617916, 'w7': -0.2610013667546687, 'w8': 0.2979309772776164, 'w9': 0.15269299413126847, 'w10': 0.048184944297514964, 'w11': 1.5448036369952518, 'w12': 0.38979291853155534, 'w13': 0.11011798652285802, 'w14': 0.5632136119141529, 'w15': 1.149682704359327, 'w16': -1.2639907290840207, 'w17': -1.9989364047750475, 'w18': -0.8044699217595703, 'w19': -2.3442883893504423, 'w20': 0.17043631448568164, 'w21': -0.4866019048066137, 'w22': 0.811318102101467, 'w23': -2.363636919969085, 'w24': 1.7256402516551115}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,524] Trial 92 finished with value: 0.7463768115942029 and parameters: {'w0': -2.373068822738296, 'w1': 1.6050724504062621, 'w2': -0.7550737753242184, 'w3': -1.461494082926284, 'w4': -0.31561997403249076, 'w5': -0.04961723959721337, 'w6': 2.2897474653995014, 'w7': -1.1660547430586885, 'w8': 0.9398274154843944, 'w9': 0.37973401619642955, 'w10': -0.10723052644564834, 'w11': 1.4930819717219583, 'w12': 0.5515850880338461, 'w13': 0.14313067645319805, 'w14': 0.21304320245040947, 'w15': 1.0333178662561933, 'w16': -1.421370707044518, 'w17': -1.991282184360514, 'w18': -0.7309461021599248, 'w19': -2.368717107088017, 'w20': 0.5494474689928798, 'w21': 0.08211141613936038, 'w22': 0.7144414847803784, 'w23': -1.857070267900721, 'w24': 1.9412700643140484}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,604] Trial 93 finished with value: 0.7391304347826086 and parameters: {'w0': -1.7696178387195567, 'w1': 1.4448616691364229, 'w2': -0.19489890225820955, 'w3': -0.7543622516093285, 'w4': -0.521320254675706, 'w5': 0.06707554078334566, 'w6': 1.9672031696194794, 'w7': 0.2608906939137833, 'w8': 0.6307641084399608, 'w9': 0.2679529129387313, 'w10': 0.0503072667437956, 'w11': 1.9939285387417198, 'w12': 0.239170451663786, 'w13': 0.30266001432550665, 'w14': 0.8881239567926507, 'w15': 1.4768944122051102, 'w16': -1.1989099587758365, 'w17': -2.4948910672254363, 'w18': -0.5384855973106688, 'w19': -1.943989335083459, 'w20': 0.20545718838290677, 'w21': 0.6649542203886167, 'w22': 0.9479700715152503, 'w23': -0.6070957439212809, 'w24': 1.6401175622702682}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,686] Trial 94 finished with value: 0.7463768115942029 and parameters: {'w0': -2.4784228040283174, 'w1': 1.8328253727697321, 'w2': -1.1145350750877205, 'w3': -0.9347868233563752, 'w4': -0.22052402161964202, 'w5': -0.6995450902121234, 'w6': 2.1825275176388397, 'w7': 0.16344032811707004, 'w8': 0.4365900093142891, 'w9': 0.01070191216101965, 'w10': 0.45042432617479544, 'w11': 1.3543831347473536, 'w12': 0.6320685572037228, 'w13': -0.47184140827355925, 'w14': 1.177992828101802, 'w15': 0.7415521341039094, 'w16': -0.9735294239169618, 'w17': -1.7249521592819976, 'w18': -1.073496582278925, 'w19': -2.257580993718345, 'w20': 0.7975772099642227, 'w21': 0.32355431516520283, 'w22': 1.4072115760586388, 'w23': -2.4090324300990975, 'w24': -0.2143554091905273}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,773] Trial 95 finished with value: 0.7463768115942029 and parameters: {'w0': -2.1088714029308955, 'w1': 2.146958341264184, 'w2': -0.6762090857673481, 'w3': -0.48034340136678033, 'w4': -0.027807170101649903, 'w5': -0.17501054508962854, 'w6': 2.4028615743046715, 'w7': 1.3203998591595647, 'w8': 1.4976548677257404, 'w9': -0.7896803809966402, 'w10': 0.09309192858069165, 'w11': 1.2083122770158592, 'w12': 0.8264139128428716, 'w13': 0.6692773960657259, 'w14': -0.17029010359629465, 'w15': 1.3689579888307057, 'w16': -1.0718818608753669, 'w17': -2.090057355148056, 'w18': -0.9380488623125826, 'w19': -0.9093201102720125, 'w20': 0.38299246824142585, 'w21': 0.9312633290288137, 'w22': 1.144973391387509, 'w23': -2.210117518179429, 'w24': -0.8008041028734613}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,856] Trial 96 finished with value: 0.7463768115942029 and parameters: {'w0': -0.6878820454199326, 'w1': 1.7372537479183077, 'w2': -0.5608555556476704, 'w3': -1.9013545043861675, 'w4': 2.1351434071032536, 'w5': -0.04927480081141466, 'w6': 2.060469849963819, 'w7': -1.4116940951666472, 'w8': 0.4251824586221166, 'w9': 0.11582199088211312, 'w10': -0.04609987552838153, 'w11': 1.7185719252316956, 'w12': 0.44313093938702863, 'w13': -0.8581416000651414, 'w14': 0.8075339344828258, 'w15': -2.3408093016791467, 'w16': -1.4489851767023778, 'w17': -1.4861683703529711, 'w18': -0.8460472740130609, 'w19': -0.17744071027421882, 'w20': -0.024805919017203026, 'w21': -0.09493936026626654, 'w22': 0.7686069677222149, 'w23': -2.481240269521069, 'w24': 1.7799983061634974}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:32,938] Trial 97 finished with value: 0.7246376811594203 and parameters: {'w0': -1.9592833357558492, 'w1': 1.6145893247271, 'w2': -0.7705737227864957, 'w3': -1.6816230188888637, 'w4': 0.5458809619066389, 'w5': -0.36329814320171117, 'w6': -1.4870014345922495, 'w7': 0.020985179627803774, 'w8': -0.45317907409173896, 'w9': -0.26411375739441684, 'w10': -0.9561681026990014, 'w11': 0.5314995837055352, 'w12': 1.865659642963537, 'w13': 0.01797082379615217, 'w14': -2.409007525356916, 'w15': 1.2056877657795593, 'w16': -1.2866558905510246, 'w17': -1.9380901291033046, 'w18': -1.4019585466728097, 'w19': -2.0269489952447173, 'w20': 0.6091429047977923, 'w21': 1.3331631540942448, 'w22': 0.5396567421427373, 'w23': -0.9663590349540281, 'w24': 2.2127587967445153}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:33,020] Trial 98 finished with value: 0.7536231884057971 and parameters: {'w0': -1.489271767462308, 'w1': 2.2961838518901545, 'w2': -0.4458830841465562, 'w3': -0.04984257993275443, 'w4': -1.7056464532251439, 'w5': 0.42155656737908803, 'w6': 2.29419635277865, 'w7': 0.5578367051013451, 'w8': 1.1753050265094422, 'w9': 1.3828718973040983, 'w10': 0.9530850502689092, 'w11': 0.1889588618330613, 'w12': -0.13306904240724304, 'w13': 0.49727125491183016, 'w14': -2.1608555523381208, 'w15': 0.9149229310779647, 'w16': -0.7564389560992035, 'w17': 0.14714753698659577, 'w18': -0.714501901027598, 'w19': -1.4990758587371593, 'w20': 0.43469191319670186, 'w21': -2.292477302921656, 'w22': -0.12183446680244132, 'w23': -2.1372331874819412, 'w24': -0.5726439978714568}. Best is trial 57 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 13:43:33,101] Trial 99 finished with value: 0.7536231884057971 and parameters: {'w0': -2.2998134625142788, 'w1': 1.5302414337537624, 'w2': 0.009934390144065164, 'w3': -1.1928565620032552, 'w4': -1.0185656499909164, 'w5': -1.5675221536065869, 'w6': 2.496335561768262, 'w7': 0.751082333714344, 'w8': 1.333417561081428, 'w9': 0.21272889318233398, 'w10': 0.3147903417076051, 'w11': -0.8616071200117899, 'w12': 2.21043987279102, 'w13': 0.3252220723452476, 'w14': 0.5605428273276662, 'w15': 0.43428540875815236, 'w16': -0.4198325644502957, 'w17': -1.3823594531192132, 'w18': -1.2440994342116105, 'w19': -1.3044363143166091, 'w20': 0.9395703374989142, 'w21': 0.6153284770367663, 'w22': -0.4303220803832101, 'w23': -1.9596974020278213, 'w24': -1.8063408905597407}. Best is trial 57 with value: 0.7608695652173914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna alphas (first 10): [0.0019 0.093  0.0123 0.0023 0.1321 0.0234 0.1707 0.0326 0.0474 0.0179]\n",
      "\n",
      "==== Bagging (Optuna Weights, Acc-opt, no-leak) Performance ====\n",
      "Accuracy:      0.595930\n",
      "AUC:           0.645973\n",
      "PR-AUC:        0.505455\n",
      "LogLoss:       0.655299\n",
      "Precision@0.580: 0.500000\n",
      "Recall@0.580:    0.244604\n",
      "F1@0.580:        0.328502\n",
      "\n",
      "===== Retrain all bags on FULL 80% train (inner ES only), then test on 20% =====\n",
      "\n",
      "==== FINAL Retrain — Simple Average Performance ====\n",
      "Accuracy:      0.633721\n",
      "AUC:           0.654185\n",
      "PR-AUC:        0.511781\n",
      "LogLoss:       0.655479\n",
      "Precision@0.500: 0.553719\n",
      "Recall@0.500:    0.482014\n",
      "F1@0.500:        0.515385\n",
      "\n",
      "==== FINAL Retrain — Optuna Weights (Acc-opt, no-leak) Performance ====\n",
      "Accuracy:      0.616279\n",
      "AUC:           0.657975\n",
      "PR-AUC:        0.518518\n",
      "LogLoss:       0.656239\n",
      "Precision@0.580: 0.552239\n",
      "Recall@0.580:    0.266187\n",
      "F1@0.580:        0.359223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6162790697674418,\n",
       " 'auc': 0.6579750833479557,\n",
       " 'ap': 0.5185177797770711,\n",
       " 'll': 0.6562394933072396,\n",
       " 'prec': 0.5522388059701493,\n",
       " 'rec': 0.26618705035971224,\n",
       " 'f1': 0.3592233009708738}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 0) 数据准备\n",
    "# =========================\n",
    "# 需先提供 df_clean：包含 'value_sort' 二分类标签，其他列为特征\n",
    "# 例如：\n",
    "# df_clean = pd.read_csv(\"your_data.csv\")  # 确保存在 value_sort 列\n",
    "\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】（权重/阈值学习用；不用于早停）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]     # 仅供子模型训练/自助采样\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]     # 外部验证片（学习权重/阈值）\n",
    "\n",
    "# =========================\n",
    "# 1) 评估工具\n",
    "# =========================\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "# =========================\n",
    "# 2) 超参中心（best_params）\n",
    "# =========================\n",
    "BASE_PARAMS = dict(\n",
    "    learning_rate=0.1305241307456396,\n",
    "    num_leaves=86,\n",
    "    max_depth=6,\n",
    "    min_child_samples=103,\n",
    "    subsample=0.5600223085390776,\n",
    "    colsample_bytree=0.608980878948645,\n",
    "    reg_alpha=2.3147174999485715e-05,\n",
    "    reg_lambda=0.00042189753661999455,\n",
    "    n_estimators=1079\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) Bagging 训练（内置早停片与外部验证片完全分离）\n",
    "# =========================\n",
    "RANDOM_SEED   = 42\n",
    "BAGS          = 25           # 子模型数（10~50 常见）\n",
    "SAMPLE_RATIO  = 0.85         # 自助采样比例（0.7~0.9 可调）\n",
    "JITTER_SCALE  = 0.12         # 参数扰动强度（0.08~0.2 之间尝试）\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "n_train = X_tr_fit.shape[0]\n",
    "models   = []\n",
    "val_probs_list = []\n",
    "te_probs_list  = []\n",
    "\n",
    "for b in range(BAGS):\n",
    "    # 1) 从【训练片 X_tr_fit】有放回自助采样\n",
    "    idx_boot = rng.choice(n_train, int(SAMPLE_RATIO * n_train), replace=True)\n",
    "    idx_boot.sort()  # 保序\n",
    "\n",
    "    # 2) 从 boot 内部切“内置早停片”：最后 10% 为 ES 片\n",
    "    es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "    tr_idx = idx_boot[:es_pt]\n",
    "    es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]  # 保证非空\n",
    "\n",
    "    # 3) 围绕 best_params 做小扰动\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * JITTER_SCALE\n",
    "    cfg = BASE_PARAMS.copy()\n",
    "    cfg[\"subsample\"]         = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"]  = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]        = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]         = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, verbosity=-1,\n",
    "        random_state=RANDOM_SEED + b,\n",
    "        **cfg\n",
    "    )\n",
    "\n",
    "    # 4) 仅用【内置 ES 片】早停；外部验证片不参与 early stopping\n",
    "    clf.fit(\n",
    "        X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "        eval_set=[(X_tr_fit[es_idx], y_tr_fit[es_idx])],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200, verbose=False)]\n",
    "    )\n",
    "    models.append(clf)\n",
    "\n",
    "    # 5) 用训练好的模型，在【外部验证片】与【测试集】上推理（仅评估/学习权重与阈值）\n",
    "    val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "    te_probs_list.append(clf.predict_proba(X_te)[:, 1])\n",
    "\n",
    "val_probs = np.column_stack(val_probs_list)   # [n_val, B]\n",
    "te_probs  = np.column_stack(te_probs_list)    # [n_test, B]\n",
    "\n",
    "# =========================\n",
    "# 4) 融合方式一：简单平均（无泄露）\n",
    "# =========================\n",
    "y_prob_avg = te_probs.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg, title=\"Bagging (Simple Average)\")\n",
    "\n",
    "# =========================\n",
    "# 5) 融合方式二：按验证AUC加权（softmax 平滑，无泄露）\n",
    "# =========================\n",
    "weights = []\n",
    "for j in range(BAGS):\n",
    "    auc_j = safe_auc(y_val_fit, val_probs[:, j])\n",
    "    if np.isnan(auc_j):\n",
    "        auc_j = 0.5\n",
    "    weights.append(max(auc_j, 0.0))\n",
    "weights = np.array(weights)\n",
    "if weights.sum() == 0:\n",
    "    alphas = np.ones(BAGS) / BAGS\n",
    "else:\n",
    "    ex = np.exp(weights - weights.max())\n",
    "    alphas = ex / ex.sum()\n",
    "\n",
    "y_prob_wavg = (te_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "print(\"Blend weights (first 10):\", np.round(alphas[:10], 4))\n",
    "report_all(y_te, y_prob_wavg, title=\"Bagging (Val-AUC Weighted)\")\n",
    "\n",
    "# =========================\n",
    "# 6) 融合方式三（修复版）：Optuna 在外部验证片学权重 + 选阈值（目标=Accuracy）；测试集只评估（无泄露）\n",
    "# =========================\n",
    "def objective_blend_on_val(trial):\n",
    "    # 建议权重（实数域） -> softmax 到凸组合\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(BAGS)])\n",
    "    a  = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "\n",
    "    # 在【外部验证片】融合\n",
    "    val_blend = (val_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    # 在【外部验证片】扫阈值，目标 = Accuracy\n",
    "    ths  = np.linspace(0.01, 0.99, 99)\n",
    "    accs = [accuracy_score(y_val_fit, (val_blend >= t).astype(int)) for t in ths]\n",
    "    idx  = int(np.argmax(accs))\n",
    "    best_t  = float(ths[idx])\n",
    "    best_acc = float(accs[idx])\n",
    "\n",
    "    trial.set_user_attr(\"best_t\", best_t)  # 记录最佳阈值\n",
    "    return best_acc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_blend_on_val, n_trials=100, show_progress_bar=False)\n",
    "\n",
    "# 取出最优权重 a 与外部验证片最佳阈值 best_t（固定）\n",
    "best_w = np.array([study.best_params[k] for k in sorted(study.best_params.keys(), key=lambda s: int(s[1:]))])\n",
    "a = np.exp(best_w); a /= (a.sum() + 1e-12)\n",
    "best_t = float(study.best_trial.user_attrs[\"best_t\"])\n",
    "\n",
    "print(\"Optuna alphas (first 10):\", np.round(a[:10], 4))\n",
    "te_blend = (te_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, te_blend, thr=best_t, title=\"Bagging (Optuna Weights, Acc-opt, no-leak)\")\n",
    "\n",
    "# =========================\n",
    "# 7) 用最优参数 + 全量80%重训（仍用内置 ES），在20%测试集上最终评估（无泄露）\n",
    "# =========================\n",
    "print(\"\\n===== Retrain all bags on FULL 80% train (inner ES only), then test on 20% =====\")\n",
    "FINAL_BASE = BASE_PARAMS  # 如想保守可切换为 BASE_PARAMS_1\n",
    "\n",
    "te_probs_final_list = []\n",
    "n_full = X_tr_raw.shape[0]\n",
    "\n",
    "for b in range(BAGS):\n",
    "    # 自助采样于全量80%训练区间\n",
    "    idx_boot = rng.choice(n_full, int(SAMPLE_RATIO * n_full), replace=True)\n",
    "    idx_boot.sort()\n",
    "\n",
    "    # 内置 ES 片\n",
    "    es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "    tr_idx = idx_boot[:es_pt]\n",
    "    es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "\n",
    "    # 参数扰动\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * JITTER_SCALE\n",
    "    cfg = FINAL_BASE.copy()\n",
    "    cfg[\"subsample\"]         = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"]  = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]        = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]         = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "\n",
    "    clf_final = LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, verbosity=-1,\n",
    "        random_state=10000 + b,\n",
    "        **cfg\n",
    "    )\n",
    "\n",
    "    clf_final.fit(\n",
    "        X_tr_raw[tr_idx], y_tr[tr_idx],\n",
    "        eval_set=[(X_tr_raw[es_idx], y_tr[es_idx])],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200, verbose=False)]\n",
    "    )\n",
    "\n",
    "    te_probs_final_list.append(clf_final.predict_proba(X_te)[:, 1])\n",
    "\n",
    "te_probs_final = np.column_stack(te_probs_final_list)\n",
    "\n",
    "# —— 融合A：简单平均（最终版）\n",
    "y_prob_avg_final = te_probs_final.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg_final, thr=0.5, title=\"FINAL Retrain — Simple Average\")\n",
    "\n",
    "# —— 融合B：固定使用在外部验证片学到的最优权重 a 与阈值 best_t（不在测试集再次学习）\n",
    "y_prob_opt_final = (te_probs_final * a.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_opt_final, thr=best_t, title=\"FINAL Retrain — Optuna Weights (Acc-opt, no-leak)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391613e",
   "metadata": {},
   "source": [
    "### 加强版ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62115cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 1234, Val-fit size: 138, Classes in Val: (array([0, 1]), array([99, 39]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 13:55:26,364] A new study created in memory with name: no-name-edb85871-cf9d-4ae1-9391-4ac6e47b2413\n",
      "[I 2025-09-01 13:55:26,389] Trial 0 finished with value: 0.7318840579710145 and parameters: {'w0': -0.6272994057631875, 'w1': 2.2535715320495804, 'w2': 1.1599697090570253, 'w3': 0.493292420985183, 'w4': -1.7199067977878175, 'w5': -1.7200273983189867, 'w6': -2.2095819391590026, 'w7': 1.8308807288746758, 'w8': 0.5055750587160439, 'w9': 1.0403628889802272, 'w10': -2.3970775285209878, 'w11': 2.3495492608099715, 'w12': 1.662213204002109, 'w13': -1.4383044466086192, 'w14': -1.590875163964497, 'w15': -1.582977450732831, 'w16': -0.9787887852023114, 'w17': 0.12378215816118932, 'w18': -0.3402749067894213, 'w19': -1.0438542990097903, 'w20': 0.5592644736118975, 'w21': -1.8025306967397907, 'w22': -1.0392767573239092, 'w23': -0.6681907835315415, 'w24': -0.21965007891482013}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,421] Trial 1 finished with value: 0.7318840579710145 and parameters: {'w0': 1.4258798069650682, 'w1': -1.5016310892082014, 'w2': 0.07117219206805814, 'w3': 0.46207284431021245, 'w4': -2.2677479364000113, 'w5': 0.5377242595071916, 'w6': -1.6473793815635425, 'w7': -2.1747420350736024, 'w8': 2.2444276862666666, 'w9': 2.328160165372797, 'w10': 1.5419867405823053, 'w11': -0.9769311541331467, 'w12': -2.0116394299680804, 'w13': 0.9211651325607844, 'w14': -0.29923753130199326, 'w15': -1.8898088257761059, 'w16': -0.024115449443649073, 'w17': -2.328057394423908, 'w18': 2.0466020103939107, 'w19': -1.2061000919999154, 'w20': 0.8126114217699101, 'w21': -0.9414446195529451, 'w22': 0.10034010588905407, 'w23': 0.23355139671639824, 'w24': -1.5757277223723647}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,446] Trial 2 finished with value: 0.717391304347826 and parameters: {'w0': 2.347923138822793, 'w1': 1.3756641168055728, 'w2': 2.1974947078209457, 'w3': 1.9741367521382438, 'w4': 0.4894998940554256, 'w5': 2.1093711751155837, 'w6': -2.0575374897404024, 'w7': -1.520085687904274, 'w8': -2.27386355544731, 'w9': -0.8733483461836782, 'w10': -0.5566135515525898, 'w11': -1.1432548411305206, 'w12': 1.6436875457596472, 'w13': -0.7162333665320535, 'w14': -1.0953274515630962, 'w15': 0.21348041579124244, 'w16': -1.7953788751261868, 'w17': 1.5109849037701988, 'w18': -2.127246781601146, 'w19': 2.4344346830025865, 'w20': 1.3612238464832869, 'w21': -1.506421592329138, 'w22': -2.472389414381988, 'w23': 1.5773071422741705, 'w24': 1.0342867192380858}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,470] Trial 3 finished with value: 0.7246376811594203 and parameters: {'w0': 1.1450358402049368, 'w1': 1.3563517334297286, 'w2': -2.129776741329548, 'w3': -0.7076713572786368, 'w4': -1.9206547023743514, 'w5': 1.8155171293779677, 'w6': 0.6164906341377896, 'w7': -0.8455098757367541, 'w8': -2.1822082485698817, 'w9': -0.945088391421689, 'w10': -0.8740833898662648, 'w11': 1.1480308916903201, 'w12': 0.6877873567760657, 'w13': 1.9360637128816327, 'w14': -0.13892537419025341, 'w15': -1.9020287703084915, 'w16': 1.0662239361149748, 'w17': 1.3039252430844872, 'w18': 0.3063859878474813, 'w19': 1.3548358997728052, 'w20': -0.031022018178046284, 'w21': 0.1136641469099704, 'w22': -0.36229490820725196, 'w23': -2.372904366279524, 'w24': -1.9605428650334777}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,496] Trial 4 finished with value: 0.7246376811594203 and parameters: {'w0': -2.342854071566329, 'w1': 0.6820520563189021, 'w2': -0.9282200946183665, 'w3': 0.042853455823514075, 'w4': 2.0378323696304648, 'w5': -1.2535388542556252, 'w6': -0.44808538482185156, 'w7': 1.2777556927152434, 'w8': -1.3560091725418877, 'w9': -2.115100450856035, 'w10': -1.0512427354311598, 'w11': -1.693893563729978, 'w12': 2.148488261712865, 'w13': 1.5406018978220848, 'w14': 0.6670187825521174, 'w15': 1.857302950938589, 'w16': 1.5183603844955726, 'w17': -1.567149705569821, 'w18': 1.962794992449889, 'w19': 0.1967112095782535, 'w20': 1.5372007758203123, 'w21': 1.9804564996174658, 'w22': -0.9099826251406806, 'w23': -1.9497403773616162, 'w24': -1.3603241872902916}. Best is trial 0 with value: 0.7318840579710145.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Bagging (Simple Average, thr-opt on val) Performance ====\n",
      "Accuracy:      0.616279\n",
      "AUC:           0.652360\n",
      "PR-AUC:        0.509835\n",
      "LogLoss:       0.654035\n",
      "Precision@0.580: 0.544304\n",
      "Recall@0.580:    0.309353\n",
      "F1@0.580:        0.394495\n",
      "Blend weights (first 10): [0.0398 0.0404 0.04   0.0424 0.042  0.0382 0.0407 0.037  0.0405 0.0401]\n",
      "\n",
      "==== Bagging (Val-AUC Weighted, thr-opt on val) Performance ====\n",
      "Accuracy:      0.598837\n",
      "AUC:           0.652606\n",
      "PR-AUC:        0.510174\n",
      "LogLoss:       0.653902\n",
      "Precision@0.620: 0.507463\n",
      "Recall@0.620:    0.244604\n",
      "F1@0.620:        0.330097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 13:55:26,522] Trial 5 finished with value: 0.7246376811594203 and parameters: {'w0': -0.36446105686871855, 'w1': 1.5900738296124652, 'w2': 1.8036529162817168, 'w3': -2.4652393473440464, 'w4': 0.05373651288782888, 'w5': -0.41294498425610504, 'w6': -1.3894609476463486, 'w7': -1.9006731633315859, 'w8': -0.8119241429818602, 'w9': 2.2145485195625962, 'w10': -0.8839853398962239, 'w11': 0.0939531087168306, 'w12': 1.015094794475889, 'w13': -0.6818519881035301, 'w14': 2.3589104136048036, 'w15': 2.3122364747105557, 'w16': -1.2410885208731792, 'w17': -0.013757470538072525, 'w18': -0.9956084509161518, 'w19': -1.075797528112662, 'w20': -2.3155652632273362, 'w21': 0.5478216698994842, 'w22': 0.01339511614430755, 'w23': -2.2426062437500534, 'w24': -1.1067676788169427}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,546] Trial 6 finished with value: 0.7246376811594203 and parameters: {'w0': 2.0413294298332687, 'w1': -1.302190546665138, 'w2': -1.7755256395438845, 'w3': -0.052736198612184815, 'w4': 2.4282522705530036, 'w5': -1.2897236424424978, 'w6': 0.860677737029393, 'w7': 1.3080980766435877, 'w8': -1.3118122800380017, 'w9': 1.1410817430592979, 'w10': -0.661084336403734, 'w11': 0.6615291529678973, 'w12': 0.6676485538044736, 'w13': 0.1788734203737925, 'w14': -2.0485511497279587, 'w15': 1.67651247794619, 'w16': -0.8960996751413208, 'w17': -1.5674074480007287, 'w18': -2.2961242922261804, 'w19': 0.4544647159412092, 'w20': 0.8878218092114123, 'w21': -2.4170608553607194, 'w22': 0.060465291496405005, 'w23': -1.3675211240103102, 'w24': 0.7258639520472494}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,570] Trial 7 finished with value: 0.7246376811594203 and parameters: {'w0': -1.6281678549750427, 'w1': 0.95468869051233, 'w2': -0.566323268497313, 'w3': 2.1836499436836725, 'w4': -1.8123952792700337, 'w5': -0.7946682447487075, 'w6': -1.9326323937970546, 'w7': 2.123468091392814, 'w8': 1.8866967669049046, 'w9': -1.210291861424222, 'w10': 0.799920230170895, 'w11': 1.5861110010060795, 'w12': 0.27600405799731176, 'w13': 0.14825289178003231, 'w14': -1.2907385454977416, 'w15': -2.034486160970504, 'w16': 1.9860787897666334, 'w17': 2.002090285816652, 'w18': 0.6655072863663398, 'w19': -0.8048510447564965, 'w20': -0.7539521269366956, 'w21': 1.129778394351197, 'w22': 1.9855512997628857, 'w23': 1.9354321213255865, 'w24': 1.399377729288119}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,593] Trial 8 finished with value: 0.7246376811594203 and parameters: {'w0': 0.7101582307714387, 'w1': -2.079300175024756, 'w2': -1.6918564295269312, 'w3': 1.9927709426353966, 'w4': 0.5321452982979498, 'w5': -2.454014741916852, 'w6': -1.9926422856698394, 'w7': 0.8175088455402788, 'w8': -2.4746920807689063, 'w9': -1.6959597429125068, 'w10': 0.24366894683293072, 'w11': 0.959475988463466, 'w12': 0.7598062975130029, 'w13': -1.378653452697201, 'w14': 1.0608961067376792, 'w15': -1.3137545625159996, 'w16': -0.8730015092036614, 'w17': 1.2324570255901208, 'w18': 0.7481644952360735, 'w19': 1.7461170524708898, 'w20': 0.7880644615017167, 'w21': 0.34154301667735787, 'w22': -2.0316261608595374, 'w23': -0.6614209847028323, 'w24': -1.1739881615913728}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,618] Trial 9 finished with value: 0.7318840579710145 and parameters: {'w0': -1.2800517831045821, 'w1': 2.365052773762228, 'w2': -0.534511376666198, 'w3': 1.9602327758855669, 'w4': 0.6556931299863145, 'w5': 1.474056517708242, 'w6': 0.01318546552596045, 'w7': 0.38451942313179543, 'w8': -0.03741153090568039, 'w9': -1.5237850610097774, 'w10': 1.1122605763075266, 'w11': -1.096138187795721, 'w12': -2.378420167842731, 'w13': 0.7273614795358392, 'w14': -1.6144466029647553, 'w15': 2.2022929217645713, 'w16': 2.269642885012937, 'w17': 2.0743219511022426, 'w18': -0.6492064987227781, 'w19': -2.422716917355663, 'w20': 2.141592812938627, 'w21': -0.35907925841342836, 'w22': 2.333274095218348, 'w23': 2.318099885446264, 'w24': 1.7650472773368007}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 13:55:26,691] Trial 10 finished with value: 0.7391304347826086 and parameters: {'w0': -0.34613972662030423, 'w1': -0.1333633927266571, 'w2': 0.9805890167916059, 'w3': -1.504420534202872, 'w4': -1.03857039292506, 'w5': -2.306374000194085, 'w6': 2.2988537297271012, 'w7': 2.3806994992899755, 'w8': 0.9553786980120729, 'w9': 0.5673823972747469, 'w10': -2.365042620819652, 'w11': 2.2290485998685665, 'w12': -0.8337747795086852, 'w13': -2.1926713481446654, 'w14': -2.328659434296343, 'w15': -0.5535912271557959, 'w16': -2.410293059064049, 'w17': 0.010534415932039347, 'w18': -1.0845363867213493, 'w19': -2.4474243066977968, 'w20': -1.1768869836659122, 'w21': -2.433951849711294, 'w22': -1.3023528480445579, 'w23': 0.44407137678044745, 'w24': 0.1981005340139888}. Best is trial 10 with value: 0.7391304347826086.\n",
      "[I 2025-09-01 13:55:26,770] Trial 11 finished with value: 0.7391304347826086 and parameters: {'w0': -0.15437031346244623, 'w1': -0.4257322987373646, 'w2': 1.0598890110670587, 'w3': -1.7101719773399595, 'w4': -0.9836324512381199, 'w5': -2.489752856427527, 'w6': 2.367395686739271, 'w7': 2.268397013784751, 'w8': 1.0019764923152379, 'w9': 0.5105013533303091, 'w10': -2.4027905025889584, 'w11': 2.4583604793099494, 'w12': -0.8868786087245688, 'w13': -2.417373849966402, 'w14': -2.490833508550936, 'w15': -0.5465833243237825, 'w16': -2.3819828808261696, 'w17': -0.015104010319070826, 'w18': -1.0287919977855031, 'w19': -2.242156677756166, 'w20': -1.6014562305204092, 'w21': -2.3927747567499815, 'w22': -1.3987163974719041, 'w23': 0.45010896038942816, 'w24': -0.037610657143713894}. Best is trial 10 with value: 0.7391304347826086.\n",
      "[I 2025-09-01 13:55:26,851] Trial 12 finished with value: 0.7463768115942029 and parameters: {'w0': 0.17789359557411732, 'w1': -0.4137727120514243, 'w2': 0.8527257130244335, 'w3': -1.930419025450958, 'w4': -0.8688409089788289, 'w5': -2.456141908142002, 'w6': 2.4559861937586334, 'w7': 2.42892423998664, 'w8': 1.1830768298173462, 'w9': 0.19614649408557483, 'w10': -2.4975408858637103, 'w11': 2.435865251754716, 'w12': -0.9327090876256496, 'w13': -2.4548082600578125, 'w14': -2.4868901223819284, 'w15': -0.34773958548194595, 'w16': -2.330001114464907, 'w17': 0.009445894187607351, 'w18': -1.2941626853639516, 'w19': -2.0894754776803293, 'w20': -1.4273228006247782, 'w21': -2.3407956115328394, 'w22': -1.477040181426517, 'w23': 0.8389622479204634, 'w24': -0.054740393116481774}. Best is trial 12 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 13:55:26,929] Trial 13 finished with value: 0.7536231884057971 and parameters: {'w0': 0.6721747371309951, 'w1': -0.15870177260645224, 'w2': 0.6578477844117327, 'w3': -1.3133811894967231, 'w4': -0.7878716307509717, 'w5': 0.5533850451223672, 'w6': 2.4844232225751797, 'w7': -0.3548604932497006, 'w8': 1.4155269561469597, 'w9': -0.0548903410145003, 'w10': -1.6554861682046864, 'w11': 1.8372406075319931, 'w12': -0.5776932155778229, 'w13': -2.4009399477834257, 'w14': -2.372496274621536, 'w15': 0.46124277143868175, 'w16': -2.493048482838497, 'w17': -0.500669923053107, 'w18': -1.5883639833329615, 'w19': -1.7788972345543477, 'w20': -0.9390713513853941, 'w21': -1.2704796728921615, 'w22': -1.68753445300682, 'w23': 1.0835953820045918, 'w24': -0.46049644361402936}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,007] Trial 14 finished with value: 0.7391304347826086 and parameters: {'w0': 0.5779553294114425, 'w1': -0.702734220225637, 'w2': 0.362083677464076, 'w3': -2.496197771588533, 'w4': -0.906311195936374, 'w5': 0.6257131821873293, 'w6': 1.588500331477717, 'w7': -0.526195271826422, 'w8': 1.6517414727425894, 'w9': -0.29663756101804517, 'w10': -1.6383177554544948, 'w11': 1.6983522630199908, 'w12': -0.7055536520337033, 'w13': -1.6937322715619523, 'w14': -0.8545221850900977, 'w15': 0.6064520184175959, 'w16': -0.05346887712346948, 'w17': -0.9454083951137672, 'w18': -1.7173685722847092, 'w19': -1.5818744006874756, 'w20': -0.6681642885631293, 'w21': -0.9893253247572447, 'w22': 1.0574226593962097, 'w23': 1.2172322127713027, 'w24': 2.2866896070836047}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,084] Trial 15 finished with value: 0.7246376811594203 and parameters: {'w0': 0.43458271293437645, 'w1': 0.3004081568390542, 'w2': 0.458589844095645, 'w3': -1.2617029328709446, 'w4': -0.49692966479666134, 'w5': 0.33049016754836236, 'w6': 1.5840857131372128, 'w7': -0.21557213836336886, 'w8': 1.2950092509846955, 'w9': -0.33161871990540503, 'w10': 2.3959102061084723, 'w11': -2.4539045383511846, 'w12': -1.4964115519550258, 'w13': -0.7436068988984288, 'w14': -1.9194905551233634, 'w15': 0.8641733674137447, 'w16': -1.78168021429168, 'w17': -0.8783251095411063, 'w18': -1.7382915663454366, 'w19': -0.40764433193615734, 'w20': -2.4986894384764353, 'w21': -1.6280989312335896, 'w22': -1.8972679609938647, 'w23': 1.0597036064663063, 'w24': -0.5775554117340505}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,162] Trial 16 finished with value: 0.7318840579710145 and parameters: {'w0': 1.5613836439193176, 'w1': -0.9577954472509227, 'w2': 1.8235750976464236, 'w3': -0.9365787605063255, 'w4': -0.22941893147799508, 'w5': 1.003082252100652, 'w6': 1.6640879986538615, 'w7': 0.33791984601184755, 'w8': 0.17795319350270433, 'w9': 0.221855330492674, 'w10': -1.5809278157077797, 'w11': 0.04968514292210768, 'w12': -0.07388722931718628, 'w13': -2.4747633208622615, 'w14': -0.635910456901114, 'w15': -0.9460866418241749, 'w16': -1.7538998854771126, 'w17': 0.5770670014169802, 'w18': -1.5051467000082814, 'w19': -1.8593535548771167, 'w20': -1.7426015677845659, 'w21': -0.659700789663858, 'w22': 0.8050557441533228, 'w23': 0.8468733292365466, 'w24': 0.45343401723712956}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,254] Trial 17 finished with value: 0.7391304347826086 and parameters: {'w0': -0.9205445758500591, 'w1': -2.449810592840961, 'w2': 0.7668230562767953, 'w3': -1.9130450653173028, 'w4': 1.3692397734943362, 'w5': -0.31900688414453104, 'w6': 2.4464460978915477, 'w7': -0.9324590848136443, 'w8': 2.473750854517482, 'w9': 1.7687820056999337, 'w10': -1.6406319139443837, 'w11': 1.7202034278127964, 'w12': -0.25969899857702594, 'w13': -1.8380245100171302, 'w14': 0.36701883372523847, 'w15': 1.1322456454820986, 'w16': 0.6282787885772083, 'w17': -0.9204859281582978, 'w18': -0.3049351890122207, 'w19': -1.8054331762711155, 'w20': -0.1892988871589491, 'w21': -1.3258201081807763, 'w22': -2.4694220351256395, 'w23': -0.5516254552454025, 'w24': -0.6700645270946872}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,335] Trial 18 finished with value: 0.7246376811594203 and parameters: {'w0': 0.20005603263523475, 'w1': 0.24975214558683678, 'w2': 1.503590736518442, 'w3': -0.5154603176442303, 'w4': -1.2365218057476572, 'w5': 1.2608741197329123, 'w6': 1.024260025734873, 'w7': -1.4773108637523538, 'w8': -0.21731700270389998, 'w9': -0.2514722213803422, 'w10': -1.8286327098910597, 'w11': 0.46030382195172614, 'w12': -1.4577367318139025, 'w13': -1.0220080717727589, 'w14': 1.563901650541633, 'w15': -0.05714949033148341, 'w16': -2.419384539217622, 'w17': 0.7308710911329751, 'w18': -2.4720073434308345, 'w19': -0.4073228752545144, 'w20': -1.7660458032743804, 'w21': -1.7772388594634307, 'w22': -0.6220934444822733, 'w23': -0.16540236519327267, 'w24': -2.342118228344699}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,410] Trial 19 finished with value: 0.7246376811594203 and parameters: {'w0': 1.1506104186867492, 'w1': -0.2873604295731218, 'w2': -0.37559918997314945, 'w3': -1.9589263879160952, 'w4': -2.4866601936135933, 'w5': 2.4629738004143524, 'w6': -0.6839759203605014, 'w7': 0.16299489656234234, 'w8': 0.6803520742182203, 'w9': 1.216860291970265, 'w10': -0.07945982256496897, 'w11': 1.2842069009228805, 'w12': -1.4577978806575018, 'w13': -1.8617355443557146, 'w14': -1.7582170654852498, 'w15': -2.478654041841464, 'w16': -0.41812777974600923, 'w17': -0.4428455510013459, 'w18': 1.3213488900119985, 'w19': 0.8381238362122954, 'w20': -0.909254582351828, 'w21': 2.4027970215941004, 'w22': -1.7587866319097782, 'w23': 2.4556514819998307, 'w24': -0.5205646841412627}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,498] Trial 20 finished with value: 0.7318840579710145 and parameters: {'w0': 0.9419208461651474, 'w1': -1.717249800498755, 'w2': 2.44075847855953, 'w3': 1.063099655716909, 'w4': -0.5795447067907294, 'w5': 0.1398377602320387, 'w6': 1.8630113228037222, 'w7': 0.9169772336673523, 'w8': 1.365243379334844, 'w9': -0.604562364106878, 'w10': -1.2928325267432559, 'w11': 1.9726162244368752, 'w12': -0.3920911915934141, 'w13': -0.24663579657692702, 'w14': -2.325695316600541, 'w15': 0.012164449181282122, 'w16': -1.519752610370514, 'w17': -1.5749117303008662, 'w18': -1.2345490810993458, 'w19': -1.611800874053534, 'w20': -1.211762642359958, 'w21': -0.3472990291483323, 'w22': -1.6120204830585794, 'w23': 1.4687324266893445, 'w24': 0.7808351616163516}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,583] Trial 21 finished with value: 0.7391304347826086 and parameters: {'w0': -0.07742902659613538, 'w1': -0.0468782059116693, 'w2': 0.7754668167889129, 'w3': -1.35038796673995, 'w4': -1.3366421891338487, 'w5': -1.9187636717272702, 'w6': 2.1454979448658205, 'w7': 1.635592748763828, 'w8': 0.8535840172932689, 'w9': 0.4307273641488911, 'w10': -2.191079242425194, 'w11': 2.1296410322047032, 'w12': -1.015021029037817, 'w13': -2.1229747268132955, 'w14': -2.391876568551078, 'w15': -0.4714072161667046, 'w16': -2.4076763477560768, 'w17': 0.6103146882351227, 'w18': -0.9019621022213413, 'w19': -2.4724387622753534, 'w20': -1.3179089888867142, 'w21': -2.137469218138396, 'w22': -1.374107811923071, 'w23': 0.6744566995444398, 'w24': 0.16253079746488236}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,666] Trial 22 finished with value: 0.7318840579710145 and parameters: {'w0': -0.7287084643454154, 'w1': -0.9118412130815728, 'w2': 1.3308396263207563, 'w3': -1.474991465321078, 'w4': 0.013011984696835066, 'w5': -1.9541658787700003, 'w6': 1.3208059312051494, 'w7': 2.4755117794404464, 'w8': 1.9169961544646312, 'w9': 0.6749770906165778, 'w10': -2.1286841341810803, 'w11': 2.499692559041298, 'w12': -0.7034441313905415, 'w13': -2.478090464176752, 'w14': -2.061214306691388, 'w15': -0.6655452957305107, 'w16': -2.134662520155109, 'w17': -0.5896630328788288, 'w18': -1.7724340203609554, 'w19': -2.0914031836939495, 'w20': -0.40616127564828464, 'w21': -2.1834604194917846, 'w22': -1.0058732188461643, 'w23': -0.04252891477537975, 'w24': 0.24443993386017931}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,739] Trial 23 finished with value: 0.7391304347826086 and parameters: {'w0': 0.07880281267278208, 'w1': 0.5088167828982186, 'w2': 0.034937663251526585, 'w3': -2.1430793690467587, 'w4': -1.4044797188390075, 'w5': -1.1945886074837877, 'w6': 2.087204581963664, 'w7': 1.8737991765275668, 'w8': 1.2885132000276567, 'w9': 1.693684626326185, 'w10': -1.9606625742083927, 'w11': 1.960547683077019, 'w12': -1.2611586695733892, 'w13': -2.051071928213197, 'w14': -1.3199027248839525, 'w15': 0.4013098261100201, 'w16': -2.059952579882749, 'w17': 0.3013723047201676, 'w18': -1.41082137098797, 'w19': -1.5065205680746092, 'w20': -1.1497946183322716, 'w21': -2.061318309528963, 'w22': -2.1903084274620204, 'w23': 1.8440521952416382, 'w24': -0.31024202194470174}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,822] Trial 24 finished with value: 0.7463768115942029 and parameters: {'w0': -1.1181410243268872, 'w1': -0.16688437498165287, 'w2': 0.6101078086029079, 'w3': -0.9913025745101572, 'w4': -0.7658957663088564, 'w5': -2.0726037129881467, 'w6': 2.485086309347292, 'w7': 0.9151724192608843, 'w8': 0.46321286969285824, 'w9': 0.11131466853030299, 'w10': -2.4985609443887813, 'w11': 1.2743225641708797, 'w12': -1.9170997288825187, 'w13': -1.3159799852272358, 'w14': -2.0984556906244958, 'w15': -0.1696418723016363, 'w16': -1.3140374643302226, 'w17': -0.37774384615644285, 'w18': -0.45186435356002885, 'w19': -1.986840848051459, 'w20': -2.1410055714529346, 'w21': -1.104492718267788, 'w22': -1.323872359043894, 'w23': 0.5246625136246355, 'w24': -0.9402595203148887}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,910] Trial 25 finished with value: 0.7463768115942029 and parameters: {'w0': -1.771049300078994, 'w1': -0.5396025436993636, 'w2': 0.46064564919181195, 'w3': -0.7885926921695314, 'w4': -0.6348685645840078, 'w5': -1.5853391345076207, 'w6': 2.498658586432453, 'w7': 0.711511226346687, 'w8': 0.3305450020264553, 'w9': 0.028963856909074437, 'w10': -1.2872889393631564, 'w11': 1.4912954404538699, 'w12': -1.9482991575391868, 'w13': -1.4948784294180482, 'w14': -0.6566181353125287, 'w15': 1.2056970099676998, 'w16': -1.5286247516611908, 'w17': -0.4786070432700724, 'w18': -0.043009173631639586, 'w19': -0.48655411388575875, 'w20': -2.0761528995253165, 'w21': -1.209046128161478, 'w22': -0.5239562058722207, 'w23': 1.111378174024276, 'w24': -0.8744636764306064}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:27,991] Trial 26 finished with value: 0.7318840579710145 and parameters: {'w0': -1.0123547815157696, 'w1': -1.0855374087735863, 'w2': 1.7084823875980322, 'w3': -1.121156855493982, 'w4': -0.25810157067144335, 'w5': -0.194712756449946, 'w6': 0.5311084860417092, 'w7': -0.21685127646963495, 'w8': -0.4054938964837628, 'w9': 0.04805225813431273, 'w10': -2.488999053584003, 'w11': 0.8355423295988973, 'w12': -1.8973802163987836, 'w13': -1.096626620634921, 'w14': -1.5431970944256803, 'w15': -0.10736210457593186, 'w16': -1.2897571520609883, 'w17': -1.1879166230393463, 'w18': -0.5304788617928871, 'w19': -1.9916805043967898, 'w20': -2.0362582502682547, 'w21': -0.8033934479956819, 'w22': 0.4668267302233675, 'w23': 0.7308839068905062, 'w24': -1.7673995457479736}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,073] Trial 27 finished with value: 0.7391304347826086 and parameters: {'w0': -2.2978379986578235, 'w1': 0.9035125836451404, 'w2': -0.18434614826414664, 'w3': -0.29921340392264395, 'w4': 0.9349245035767615, 'w5': -0.8928059127671764, 'w6': 1.236896017689784, 'w7': 1.3384753469529995, 'w8': 1.4893661953299273, 'w9': -0.6322124271491951, 'w10': -1.9677312581332114, 'w11': -0.6177676687003525, 'w12': -2.2683169716194125, 'w13': -1.1813345993249726, 'w14': -1.9443957303001145, 'w15': -1.1075644724241611, 'w16': -2.0187285187614434, 'w17': -0.33173839279042067, 'w18': 0.1315722979258802, 'w19': -1.3904498035596717, 'w20': -1.5716950278938013, 'w21': 0.8788165187452981, 'w22': -1.6612911959622039, 'w23': -0.4111372907005876, 'w24': -0.9359387260859484}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,159] Trial 28 finished with value: 0.7463768115942029 and parameters: {'w0': -1.523096664237743, 'w1': -0.009840463309035319, 'w2': -0.8126953418826427, 'w3': -1.0337853063317963, 'w4': -0.7420484883099181, 'w5': -2.0676035216870314, 'w6': 1.91709499086221, 'w7': -0.4681151658852065, 'w8': 1.9139325991962326, 'w9': 0.8946733558788458, 'w10': -1.4012509187599402, 'w11': 1.2586477387021424, 'w12': 0.27606439989812004, 'w13': -0.31586745828482893, 'w14': -1.0060523677731774, 'w15': 0.6976725364828958, 'w16': -0.42446994211707556, 'w17': 1.038660170081049, 'w18': -0.7648608358102603, 'w19': -0.803945648935383, 'w20': 0.3036676222730783, 'w21': -0.4084240341825922, 'w22': -2.1240243082864874, 'w23': -0.9837731670946579, 'w24': -0.25476793841948686}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,244] Trial 29 finished with value: 0.7246376811594203 and parameters: {'w0': 0.3441501096621994, 'w1': 0.299129901809991, 'w2': 0.341425143631505, 'w3': -2.1389371407010875, 'w4': -1.5083628791157822, 'w5': -0.6998778502334317, 'w6': 0.18751246209513983, 'w7': 1.6172150897141853, 'w8': 0.45627390263851364, 'w9': 0.23663894760231774, 'w10': -0.2682046428752205, 'w11': 0.3703438412681366, 'w12': -0.5041690522238765, 'w13': -1.550324982350747, 'w14': -1.5953603517313886, 'w15': -0.30428059151595177, 'w16': -1.1158675551590471, 'w17': -2.2047442663357866, 'w18': -1.9774570330239172, 'w19': -2.0297724808636106, 'w20': -0.43867374949197485, 'w21': -1.9288393773560537, 'w22': -0.8962671070975468, 'w23': 0.2023466391353811, 'w24': -0.2567141922536269}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,320] Trial 30 finished with value: 0.7391304347826086 and parameters: {'w0': -0.4043217757154304, 'w1': 1.8086166617298503, 'w2': 0.7898286691271421, 'w3': 1.0027882093340992, 'w4': -0.25056178860845835, 'w5': -1.644349118490246, 'w6': 1.8915147845278102, 'w7': 0.5471951830510081, 'w8': 0.5534904314505544, 'w9': 0.9034972572188613, 'w10': -2.023181467869515, 'w11': 1.9668862291249456, 'w12': -1.6952039574822737, 'w13': -1.9510508584066337, 'w14': -2.4875880130852277, 'w15': -0.8766758845781885, 'w16': -0.652872046409136, 'w17': 0.34809252888738196, 'w18': -0.4689400057053217, 'w19': -0.7167622524281954, 'w20': -2.09959498380136, 'w21': -1.325607532427126, 'w22': -1.2066198874488292, 'w23': 1.9539825971678222, 'w24': 0.5430093613831366}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,399] Trial 31 finished with value: 0.7391304347826086 and parameters: {'w0': -1.994935908196795, 'w1': -0.5918616367356971, 'w2': 0.5193476107284039, 'w3': -0.8293283669640094, 'w4': -0.6300958646952207, 'w5': -1.7210119802144357, 'w6': 2.3865147718374966, 'w7': 0.7399990191550454, 'w8': 0.2717469550400523, 'w9': -0.0359387495914623, 'w10': -1.1501937094482853, 'w11': 1.4710779296211296, 'w12': -2.043834806706006, 'w13': -1.4612486032912533, 'w14': -0.5455548341976675, 'w15': 1.253936765273723, 'w16': -1.4709577829906555, 'w17': -0.31566721487451, 'w18': -0.08199312550846592, 'w19': -0.10100488658071444, 'w20': -2.034691849879495, 'w21': -1.3121842860174786, 'w22': -0.35091344943997294, 'w23': 1.1893055729080328, 'w24': -0.8214516502504698}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,485] Trial 32 finished with value: 0.7391304347826086 and parameters: {'w0': -1.7263634935767065, 'w1': -0.5373249274680981, 'w2': 1.201469682888344, 'w3': -0.5277307189620568, 'w4': -1.681185421067866, 'w5': -1.6055193112625457, 'w6': 2.468974387348156, 'w7': 1.0244039043001618, 'w8': -0.5217202674702809, 'w9': -0.5305032209282324, 'w10': -1.6925194028009545, 'w11': 1.7602292455865964, 'w12': -1.1360945559736857, 'w13': -2.2640923241031032, 'w14': 0.2899233087036502, 'w15': 1.299434842787546, 'w16': -1.539060280885852, 'w17': -0.7493348397529171, 'w18': -0.18497653332878006, 'w19': -1.2317246408822233, 'w20': -1.4559579522942343, 'w21': -1.1885861589138291, 'w22': -0.4550617123758786, 'w23': 1.48789059758527, 'w24': -1.56547794116945}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,571] Trial 33 finished with value: 0.7463768115942029 and parameters: {'w0': -1.2761149136984378, 'w1': -1.2608484808126372, 'w2': 0.13490955364604185, 'w3': -1.6615702184385885, 'w4': 0.2440084988810265, 'w5': -2.1986663643071327, 'w6': 2.08623509325392, 'w7': -0.050167105515682264, 'w8': 1.0849196384963262, 'w9': 0.026640268913407313, 'w10': -2.480850509254404, 'w11': -0.44957651743672367, 'w12': -1.9139115510890379, 'w13': -1.640638235829323, 'w14': -2.1325189933601005, 'w15': 0.5218012858586788, 'w16': -1.9307788258659464, 'w17': -1.194865339253504, 'w18': 0.49456080994002805, 'w19': -1.7592418297128163, 'w20': -2.0036300984612434, 'w21': -0.6027581360578883, 'w22': -1.5193418496610105, 'w23': 0.9436356863914969, 'w24': -0.9053725152427582}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,652] Trial 34 finished with value: 0.7391304347826086 and parameters: {'w0': -1.9611063595592437, 'w1': -0.7423028803923633, 'w2': 0.6377083049209493, 'w3': 0.447261765136188, 'w4': -1.0690786961445284, 'w5': 0.8852301459316612, 'w6': 1.4049676996557439, 'w7': -1.0602192662760372, 'w8': 0.3152305403771866, 'w9': -1.0091901180781204, 'w10': -1.3907749514083396, 'w11': 1.0776052886967904, 'w12': -2.4735086991644417, 'w13': -0.9508176350846587, 'w14': -1.324379901005753, 'w15': 0.16656858533538232, 'w16': -2.094226065891804, 'w17': -0.39247244441611534, 'w18': -1.3637332146511663, 'w19': -1.1440884760705765, 'w20': -2.4828836032618757, 'w21': -1.6572017750600208, 'w22': -0.7112463948619469, 'w23': 0.3435820114762874, 'w24': -1.397308055204072}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,734] Trial 35 finished with value: 0.7391304347826086 and parameters: {'w0': -0.6117920611854578, 'w1': -0.29252006450638496, 'w2': 0.13180253210032822, 'w3': -0.6604399393034549, 'w4': -2.0961341108714473, 'w5': -1.4668393239244044, 'w6': 1.8550207999864883, 'w7': 1.9272254671878408, 'w8': 0.7565207415596514, 'w9': 1.4170671292080905, 'w10': -2.163549123971917, 'w11': 1.446555089123907, 'w12': -1.7059485697366084, 'w13': -2.0344341877562493, 'w14': -0.2759300852799915, 'w15': 1.0385414754916986, 'w16': -1.6739337021048466, 'w17': -1.270369428261009, 'w18': 1.0489647669840934, 'w19': 0.7087407545374489, 'w20': -1.8119750676095032, 'w21': -1.0392585299274548, 'w22': -1.1486144139250252, 'w23': 1.3424372163818266, 'w24': -2.2350529883083143}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,817] Trial 36 finished with value: 0.7463768115942029 and parameters: {'w0': 0.9076305239415455, 'w1': 0.1472005649243664, 'w2': 1.394599948883486, 'w3': -0.24040141266836748, 'w4': -0.44184630556113164, 'w5': -2.114670235673224, 'w6': -1.0499014570672127, 'w7': -0.5235711614220153, 'w8': 2.2123285694230717, 'w9': 0.267807324255876, 'w10': 0.30583522341158664, 'w11': 2.2208801100840168, 'w12': -2.1427365780160876, 'w13': -1.4014776369748294, 'w14': -2.180768843165612, 'w15': 1.6216558475736642, 'w16': 0.30349225972532967, 'w17': -0.13744133100095424, 'w18': 0.24499409116909399, 'w19': 2.318752497240795, 'w20': -0.9865737551304373, 'w21': -0.20390835623648051, 'w22': -0.2353975218031763, 'w23': 1.7151834670670025, 'w24': -0.5189219120717103}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,904] Trial 37 finished with value: 0.7246376811594203 and parameters: {'w0': 1.362750989929185, 'w1': -1.670880544514552, 'w2': -0.14686823754837208, 'w3': 0.31102265543160224, 'w4': -0.8070817620170591, 'w5': -1.094573804059715, 'w6': 2.1048442498748625, 'w7': -1.3745236165418515, 'w8': -0.9726405002424859, 'w9': -0.7917388250885233, 'w10': -0.5651796492383282, 'w11': 0.8153563729225203, 'w12': -1.2217301363681232, 'w13': 2.212143622575619, 'w14': -1.8130367480260583, 'w15': 0.25758094830038963, 'w16': -1.2976546369813984, 'w17': 0.2766062005167418, 'w18': 2.4664032451148508, 'w19': -0.3666171006398225, 'w20': -2.2220180645595082, 'w21': 0.10405545411831421, 'w22': -0.7873641631039452, 'w23': 0.6215149414364395, 'w24': -1.9291356514655948}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:28,989] Trial 38 finished with value: 0.7318840579710145 and parameters: {'w0': -2.4946623637521137, 'w1': 0.6375789777420225, 'w2': 0.9693375431589215, 'w3': -1.2241914771322222, 'w4': 0.15805611902047523, 'w5': -1.8736039611749513, 'w6': 2.4849420382532186, 'w7': 0.5948623890395628, 'w8': -0.10002586367009225, 'w9': -0.15406525361424217, 'w10': -0.9468137408654016, 'w11': 1.8896018220721162, 'w12': 1.3586025396818218, 'w13': 0.6095131105984826, 'w14': 0.044293194693323865, 'w15': -0.2926247428684254, 'w16': -2.2037690342245275, 'w17': -1.8837175571300764, 'w18': -1.9721927893383713, 'w19': -2.194132494476322, 'w20': 0.15529985740618732, 'w21': -1.613987938426651, 'w22': -2.4060392648641136, 'w23': 0.13490746829221245, 'w24': -1.0782800496050418}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,121] Trial 39 finished with value: 0.7318840579710145 and parameters: {'w0': 1.876455485423301, 'w1': 0.9576888951272274, 'w2': 1.9312515458631054, 'w3': -1.7939176198682514, 'w4': -1.6353706961632413, 'w5': -0.5357636993348398, 'w6': 1.0953853891048668, 'w7': -2.4142440980769395, 'w8': 1.6555247967738231, 'w9': -1.1748898428208767, 'w10': -0.7608921582436144, 'w11': 0.44084991053355815, 'w12': 0.02817133938142835, 'w13': 1.2787163903841852, 'w14': 2.399679480609948, 'w15': 0.9343919653467484, 'w16': -0.8953893322795585, 'w17': -0.6244817809892022, 'w18': -0.7511769193912599, 'w19': 0.19126533347520824, 'w20': -1.3860836511392276, 'w21': 1.5404584609895018, 'w22': 0.22432665277651687, 'w23': -0.29023822567975444, 'w24': -0.08536467575447075}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,224] Trial 40 finished with value: 0.7246376811594203 and parameters: {'w0': 2.4649579828433077, 'w1': -1.3937227393434517, 'w2': 0.2619211449511914, 'w3': 0.07570889435193962, 'w4': -0.19426213936703018, 'w5': -0.044001307093759934, 'w6': 0.7495279481152881, 'w7': 1.1470001054837293, 'w8': -1.8052953403724037, 'w9': 0.7840075017323933, 'w10': -2.2467338051429353, 'w11': -0.2546002024170726, 'w12': 0.26729816974676757, 'w13': -0.4561572510462905, 'w14': 0.9682670639988982, 'w15': -1.5727914056427472, 'w16': 0.960905113860516, 'w17': 1.7033297708429, 'w18': 0.050994030297030785, 'w19': -0.9593227305127742, 'w20': -0.6089113258191132, 'w21': -0.7584498778803608, 'w22': -1.8289152019469872, 'w23': 2.146996390297557, 'w24': -1.2907966274402178}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,310] Trial 41 finished with value: 0.7391304347826086 and parameters: {'w0': -1.4318525049706736, 'w1': -0.17027904622485387, 'w2': -1.4084690622698504, 'w3': -0.9999176713268892, 'w4': -0.7501201246982936, 'w5': -2.092494733709756, 'w6': 1.899114239219609, 'w7': 0.07657598249360453, 'w8': 1.998003639956491, 'w9': 0.3186971831580741, 'w10': -1.409235786547941, 'w11': 1.1752335356587844, 'w12': -0.005656850937144131, 'w13': -0.2246687033031043, 'w14': -0.9306786239357913, 'w15': 0.6666957754086008, 'w16': -0.1694062606493998, 'w17': 1.4743668909921672, 'w18': -0.3510969286482075, 'w19': -0.7475018754631109, 'w20': 0.40886785782775936, 'w21': -0.11083748300724872, 'w22': -2.081233735748296, 'w23': -1.0917456722626442, 'w24': -0.28301274375415375}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,386] Trial 42 finished with value: 0.7391304347826086 and parameters: {'w0': -2.014658466109147, 'w1': 0.0204000040808963, 'w2': -0.8742677402166732, 'w3': -0.8539274267636368, 'w4': -1.2224893616961485, 'w5': -2.2891797001095258, 'w6': 2.1708856783287875, 'w7': -0.4788771992981324, 'w8': 1.162802895722905, 'w9': 1.0070858394654882, 'w10': -1.1494151249973217, 'w11': 1.331766683570045, 'w12': 0.47771224125105927, 'w13': -0.6421671375125607, 'w14': -1.072419587233363, 'w15': 1.4754175729835228, 'w16': -0.37881775854765565, 'w17': 1.2219474446054113, 'w18': -0.7781967437591444, 'w19': -1.2458021338572016, 'w20': 0.40547735964789794, 'w21': -1.0615261822159723, 'w22': -2.194390774980434, 'w23': -1.0228564895264685, 'w24': -0.35711580956653427}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,474] Trial 43 finished with value: 0.7391304347826086 and parameters: {'w0': -1.62858078296411, 'w1': -0.4526135150082657, 'w2': -0.8555153729217744, 'w3': -1.5241335123470652, 'w4': -0.48169717622816843, 'w5': -1.4524205823113314, 'w6': -2.456984193903002, 'w7': -0.7700038261756951, 'w8': 2.1851328397544325, 'w9': 0.6566039147904822, 'w10': -0.3792848158081963, 'w11': 1.5890235346104389, 'w12': 1.1033736023134406, 'w13': -1.2592350741867684, 'w14': -0.57810157546252, 'w15': 0.7194933053565417, 'w16': -0.6762227378243089, 'w17': -0.17218186064856206, 'w18': -0.6335686158583708, 'w19': -0.6093234478007834, 'w20': -1.8536060233302651, 'w21': -0.46384851828858076, 'w22': -1.935356383350056, 'w23': -1.807476450206074, 'w24': -0.7434955959601596}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,581] Trial 44 finished with value: 0.7391304347826086 and parameters: {'w0': -1.301080273970165, 'w1': 0.43465987589650323, 'w2': -1.2976601849861724, 'w3': -2.178109495737755, 'w4': -0.7391996346895394, 'w5': -2.4610230442554366, 'w6': 1.7088796661614731, 'w7': -1.887929057601373, 'w8': 1.6467433997584275, 'w9': 1.3532488965237655, 'w10': -1.9059241441490005, 'w11': 1.0191270288881, 'w12': 1.9578538123715605, 'w13': 0.300900678835677, 'w14': -1.3966467470680857, 'w15': 1.922006900365854, 'w16': 0.291718915259103, 'w17': 0.8736905582018012, 'w18': -1.1407846364516634, 'w19': -0.10759425751600249, 'w20': 0.7145739956982411, 'w21': 0.4773684606433768, 'w22': -1.064652235941297, 'w23': 1.0307847590065466, 'w24': 0.04898359090141102}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,661] Trial 45 finished with value: 0.7391304347826086 and parameters: {'w0': -0.9979984004520654, 'w1': 0.053752809518796796, 'w2': -2.1884788223075775, 'w3': -1.0589757666256285, 'w4': -1.0862146257544354, 'w5': 0.5299006913788122, 'w6': 2.228286675489546, 'w7': 0.23482491757140256, 'w8': 0.5610287375997505, 'w9': 0.09074538138513853, 'w10': -1.4298370442682802, 'w11': 2.2584662644901665, 'w12': 2.42552493384811, 'w13': -2.2524971736984516, 'w14': -1.076072402296165, 'w15': 0.21628355041444058, 'w16': -1.100388024036084, 'w17': 0.9699945127746621, 'w18': -0.9335045737356594, 'w19': -0.9296269998159133, 'w20': 1.178010389691479, 'w21': -1.4779552458750074, 'w22': -1.359747914317692, 'w23': -1.5940078189025941, 'w24': 1.3423844807446645}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,739] Trial 46 finished with value: 0.7391304347826086 and parameters: {'w0': 0.6951638196389756, 'w1': -0.821313603845206, 'w2': -0.5360306470210738, 'w3': -0.42432495101216217, 'w4': 0.33989506251346513, 'w5': -1.8115784770183394, 'w6': 1.967930112686461, 'w7': -0.24368215552007944, 'w8': 1.5738019795432323, 'w9': 2.491131972636585, 'w10': -1.768452396720434, 'w11': 0.7312050717978601, 'w12': -0.49249415305788047, 'w13': -1.773748371292382, 'w14': -1.757084498424238, 'w15': 0.4803230643074884, 'w16': -1.8562975792491416, 'w17': 0.3150711421253014, 'w18': 0.4195105391868187, 'w19': -1.4576089222531414, 'w20': -0.915002822098306, 'w21': -0.8745082779496368, 'w22': 1.4047047960767933, 'w23': 0.5202785816390447, 'w24': -1.0784290794740983}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,825] Trial 47 finished with value: 0.7318840579710145 and parameters: {'w0': -1.8763933675818927, 'w1': -1.0992744294196894, 'w2': 0.9568910448484604, 'w3': -1.381820381159633, 'w4': -1.890618787828004, 'w5': -1.0175980857328355, 'w6': 1.4758746673279521, 'w7': -1.15444272312332, 'w8': 0.07089795859888004, 'w9': -2.2804639556230417, 'w10': 2.150429457835674, 'w11': 2.0870122973401055, 'w12': 0.3729486602701344, 'w13': -0.22407350963378175, 'w14': -0.72843512026815, 'w15': 0.8116760186586207, 'w16': -0.7032522230329767, 'w17': 0.07467275185842456, 'w18': -1.596769006890084, 'w19': -2.2912367888170664, 'w20': 2.371623757421505, 'w21': 0.2993585253018758, 'w22': -2.2895459977635655, 'w23': -2.161905546222748, 'w24': 0.4078316567958787}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,913] Trial 48 finished with value: 0.7391304347826086 and parameters: {'w0': -2.15763460151326, 'w1': -0.34802414028384576, 'w2': -0.19176756508114723, 'w3': -0.6401214867286124, 'w4': -0.9845985298121631, 'w5': -1.3581991089663759, 'w6': 2.3105459165630493, 'w7': -0.7525206461817502, 'w8': 0.8747539054236895, 'w9': -0.4030899137872772, 'w10': -1.029451426440026, 'w11': 2.3329383681815408, 'w12': -0.18354739923971708, 'w13': -0.8797323223094903, 'w14': -2.183393948112686, 'w15': -0.3018446788889516, 'w16': -2.2428892243501233, 'w17': -0.7388701279394139, 'w18': -1.2880879818763271, 'w19': -1.9042457020140362, 'w20': 1.8300280587246553, 'w21': -0.5317398425560721, 'w22': -0.10416063523651364, 'w23': 0.8476423766737862, 'w24': -0.1306328635734634}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:29,997] Trial 49 finished with value: 0.7318840579710145 and parameters: {'w0': -1.4888745136954304, 'w1': 1.1567177558466133, 'w2': 0.6125626398935311, 'w3': -1.6425774553486638, 'w4': -0.39015446230369755, 'w5': -2.3146062079974143, 'w6': 1.6823170936509158, 'w7': 0.5293830574527909, 'w8': 1.7717704220763983, 'w9': 0.8223043916822936, 'w10': 0.9407890864248345, 'w11': -1.4204456423910843, 'w12': -1.6772831713042158, 'w13': -0.49488073486427897, 'w14': -0.43895016725132485, 'w15': 2.0161146108414196, 'w16': -2.484712138245793, 'w17': 2.2703909743577517, 'w18': -0.20831937002111833, 'w19': -1.6866884325715357, 'w20': 0.07891804291374038, 'w21': -1.9471023437455992, 'w22': -0.5640331355214003, 'w23': -0.9381096861798711, 'w24': -0.4649513143774175}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,078] Trial 50 finished with value: 0.7391304347826086 and parameters: {'w0': -0.5496060435630691, 'w1': -0.6814521334092974, 'w2': -1.1108011300281762, 'w3': -0.11637080182220394, 'w4': -0.04363007643004013, 'w5': 1.7172473093880232, 'w6': 2.28132744920985, 'w7': -0.36129631427230313, 'w8': 2.435613578453208, 'w9': -1.6040280158352238, 'w10': -2.3155383932691738, 'w11': 1.711741715085092, 'w12': -0.6947967538398907, 'w13': 0.4493697793462065, 'w14': 0.09430037743421349, 'w15': 2.422964097225478, 'w16': 1.73118849843722, 'w17': -1.0430832589826582, 'w18': -2.265770468231845, 'w19': -1.337892241696525, 'w20': -2.2925386125256706, 'w21': -2.4804630622408004, 'w22': -1.5247569117328252, 'w23': -2.4935214410796025, 'w24': -1.4804231070335139}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,171] Trial 51 finished with value: 0.7463768115942029 and parameters: {'w0': -1.1515054552843915, 'w1': -0.1641111535415229, 'w2': 0.23277560972601116, 'w3': -1.8913431057922288, 'w4': 0.3129521659513221, 'w5': -2.103197499637029, 'w6': 2.0356667869818144, 'w7': 0.0621328524022402, 'w8': 1.1217508520798778, 'w9': -0.10006518461802705, 'w10': -2.4401781852800357, 'w11': -0.43904360914845786, 'w12': -2.0298838395772387, 'w13': -1.7732450143207288, 'w14': -2.2465922134357212, 'w15': 0.4752342520235536, 'w16': -1.9008166936651762, 'w17': -1.3286314771869028, 'w18': 0.5884905997864032, 'w19': -1.8131819770745063, 'w20': -2.0207545529690316, 'w21': -0.29986975054464826, 'w22': -1.610701753570838, 'w23': 0.9716797752058237, 'w24': -0.8992713384904433}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,257] Trial 52 finished with value: 0.7391304347826086 and parameters: {'w0': -0.8046852986788867, 'w1': -1.1817853772284204, 'w2': -0.027884037447713506, 'w3': -1.674143703064932, 'w4': 0.8802466378260412, 'w5': -2.266826807799085, 'w6': 2.4951360881692457, 'w7': -0.0007656178233730326, 'w8': 1.05587977595157, 'w9': 0.44710749359568125, 'w10': -2.4722282511399265, 'w11': -0.8538559612265034, 'w12': -2.25164855051162, 'w13': -1.5997694935111768, 'w14': -2.065179286772499, 'w15': -0.08547712211759229, 'w16': -1.561875243200932, 'w17': -0.616469460197292, 'w18': 0.988731229161667, 'w19': -1.7356529184632419, 'w20': -1.636356050103894, 'w21': -0.02095990308885498, 'w22': -1.9776058133453365, 'w23': 1.2929381116665564, 'w24': -0.6722170730928951}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,335] Trial 53 finished with value: 0.7391304347826086 and parameters: {'w0': -0.20187323869814033, 'w1': -1.9159561291331229, 'w2': -1.8300841766187532, 'w3': -1.1284049467564279, 'w4': -0.05950499488792732, 'w5': -2.0781775799508857, 'w6': 1.7543102427023187, 'w7': -0.10376795463535915, 'w8': 1.441572697995806, 'w9': 0.11159423654535117, 'w10': -1.5657257203105857, 'w11': -0.26815919900207463, 'w12': -1.9130910915776973, 'w13': -2.193750421767307, 'w14': -1.948053399476366, 'w15': 0.0785117954810931, 'w16': -1.8729656867179043, 'w17': -1.4673792779064043, 'w18': 0.4416140020005388, 'w19': -2.26796516651996, 'w20': -2.3133095645173527, 'w21': -0.6662519373813143, 'w22': -1.461750210887377, 'w23': 0.8950100020142837, 'w24': -1.1917027779903964}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,416] Trial 54 finished with value: 0.7463768115942029 and parameters: {'w0': -1.7301731375510376, 'w1': -1.477151541445414, 'w2': -0.3875340328902971, 'w3': -1.3115027076690515, 'w4': -0.8598476581368619, 'w5': -2.265177446209355, 'w6': 2.110034249210285, 'w7': 1.4114008346668199, 'w8': 1.17746859051106, 'w9': -0.43057659011003935, 'w10': -2.1100598026724127, 'w11': 0.2242244079137059, 'w12': -0.915791372949482, 'w13': -1.347409521976545, 'w14': -2.488827746491371, 'w15': 0.3634423957094585, 'w16': -2.2699988335004613, 'w17': -1.8589783343662842, 'w18': 1.3233395167961466, 'w19': -0.5766477529288567, 'w20': -1.872655015227952, 'w21': -0.5426608336191441, 'w22': -1.7763789510007553, 'w23': 1.63169951537628, 'w24': -0.9576150997939249}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,504] Trial 55 finished with value: 0.7318840579710145 and parameters: {'w0': -1.2022359602905697, 'w1': -0.4204006511615405, 'w2': 0.4955417273580765, 'w3': -2.3068697925106734, 'w4': 2.0447112942209293, 'w5': -2.4958887870137314, 'w6': 2.2628779887704265, 'w7': 2.199389395675591, 'w8': 2.0198650787022263, 'w9': -0.1895231315736558, 'w10': -1.8222861961695562, 'w11': -2.1223275848938217, 'w12': -1.4069800730258923, 'w13': -2.3562844279112687, 'w14': -1.5216752876383235, 'w15': 0.5987951922924382, 'w16': -1.9523270304224698, 'w17': -1.0653169641324602, 'w18': -0.3922136770122946, 'w19': -1.0465151468060003, 'w20': -0.09525102936214658, 'w21': -1.1663410066053113, 'w22': -1.1858510545266738, 'w23': 0.04475929803903833, 'w24': -0.6751802582287361}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,589] Trial 56 finished with value: 0.7391304347826086 and parameters: {'w0': 0.2013486355968453, 'w1': 0.11834129391340134, 'w2': 0.7580993693578997, 'w3': -0.8140522583502616, 'w4': -0.6474222662114646, 'w5': 0.2361397859671489, 'w6': 2.0144426201281465, 'w7': 0.35558657351145617, 'w8': 0.7681643233270014, 'w9': 0.5666255498493175, 'w10': -2.304559073990892, 'w11': 1.2496014917343201, 'w12': -1.828780683434659, 'w13': -1.6254776095031702, 'w14': -2.233631961692477, 'w15': 1.096013262836073, 'w16': -1.4030093555981955, 'w17': -0.1416722609146776, 'w18': 0.8377535931731139, 'w19': -1.6117234621865164, 'w20': -1.55324657664371, 'w21': -1.017924400129497, 'w22': -0.876214174771446, 'w23': 0.377076550974182, 'w24': 0.08982147123703815}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,674] Trial 57 finished with value: 0.7246376811594203 and parameters: {'w0': -1.4100247629992224, 'w1': -0.9711130900042073, 'w2': -0.7396261784065224, 'w3': -1.5859974630370808, 'w4': 0.6692708931896933, 'w5': -1.5718496007404812, 'w6': 1.515365460311583, 'w7': -0.7190703592160284, 'w8': 0.4211480609971485, 'w9': -0.7544586243335037, 'w10': 1.5101695087515106, 'w11': 0.595109822701942, 'w12': 0.1408647949209636, 'w13': -1.9176034459668505, 'w14': -1.7523097750672405, 'w15': 1.42444483441614, 'w16': -1.670276488138605, 'w17': 0.5004504704272819, 'w18': -0.8186942244502686, 'w19': -2.147624851189301, 'w20': -1.2100835985217002, 'w21': -1.5188658410317215, 'w22': -1.6784472982203207, 'w23': 1.1225489516056282, 'w24': -0.4638486860178941}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,756] Trial 58 finished with value: 0.7246376811594203 and parameters: {'w0': 0.4372818722202938, 'w1': -1.2561871765814154, 'w2': 1.1990709145903116, 'w3': -2.3838577666797116, 'w4': -1.3356855073257048, 'w5': -1.9226404451927435, 'w6': -0.34665139236922404, 'w7': 0.7526737848590369, 'w8': 0.9586903669944031, 'w9': 0.3639581366668695, 'w10': 0.22567626054808604, 'w11': -0.07771492127897095, 'w12': 0.844615409234118, 'w13': -0.04042927846776273, 'w14': -0.175494571759924, 'w15': -0.2289122554165618, 'w16': -1.011087203627817, 'w17': -0.49818546052960705, 'w18': -1.0730746959424458, 'w19': -2.4797373485288907, 'w20': -0.25245614911414627, 'w21': -1.8289621794870738, 'w22': -2.0459699665678226, 'w23': 0.6897607099285019, 'w24': 0.9393824153191725}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,847] Trial 59 finished with value: 0.7318840579710145 and parameters: {'w0': 0.9626481305483368, 'w1': -0.14784200296993522, 'w2': 0.1481854159967832, 'w3': -1.9675991633695449, 'w4': 0.2041390752662786, 'w5': 0.8384848162987398, 'w6': -1.7439190725001392, 'w7': 1.5533530759492646, 'w8': 1.3102407196885932, 'w9': 0.08253793151406322, 'w10': -2.0389775515142867, 'w11': 1.4438418691141148, 'w12': -1.6086501345659654, 'w13': -2.4747208355610764, 'w14': 2.0751529454429827, 'w15': 0.8935153550886037, 'w16': -2.300292329318059, 'w17': -0.7892569021098736, 'w18': -0.05386629788381245, 'w19': -0.29713612437883474, 'w20': -2.4357638292403108, 'w21': -2.2245752337584292, 'w22': -1.2644109903142553, 'w23': 1.3513506986439534, 'w24': 0.27591666795860437}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:30,933] Trial 60 finished with value: 0.7391304347826086 and parameters: {'w0': 0.019394287446125147, 'w1': -2.177405573257043, 'w2': 1.5572702254534918, 'w3': -1.4018818948497749, 'w4': -1.1799076410543714, 'w5': 1.237746180821969, 'w6': 2.344296025504746, 'w7': 1.0715562803066807, 'w8': 1.806336127945478, 'w9': 1.1858561248596575, 'w10': -0.8330326368031032, 'w11': -0.9170883996386328, 'w12': -1.0712162342994336, 'w13': -0.7902301635107248, 'w14': -0.8889466253343293, 'w15': -0.7774124128411695, 'w16': -1.6915111852947735, 'w17': 1.8332151262406127, 'w18': 0.1917289316805646, 'w19': 1.1995661481692457, 'w20': -2.1432044816046165, 'w21': -1.3688293072981863, 'w22': -1.0285391623487492, 'w23': -0.15481713470645628, 'w24': -1.8086240417925659}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,014] Trial 61 finished with value: 0.7463768115942029 and parameters: {'w0': 0.9440845516354444, 'w1': 0.08893329134134254, 'w2': 0.8729881807456349, 'w3': -0.34634803646384893, 'w4': -0.42893229229764573, 'w5': -2.085338491459101, 'w6': 0.3790776774031134, 'w7': -0.4119317794780008, 'w8': 2.089880742188824, 'w9': 0.1378376068348999, 'w10': 0.5686443622847233, 'w11': 2.1523580495933823, 'w12': -2.1766872232058283, 'w13': -1.4170565187748327, 'w14': -2.262084771233464, 'w15': 1.4300634247825854, 'w16': 0.4040011218422786, 'w17': -0.14359224573253718, 'w18': 0.24548767988262316, 'w19': 1.820994421918515, 'w20': -1.009921915274893, 'w21': -0.218095011565766, 'w22': -0.18157622237317114, 'w23': 1.692664538534949, 'w24': -0.41362186139992957}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,097] Trial 62 finished with value: 0.7463768115942029 and parameters: {'w0': 0.7866446738128349, 'w1': 0.30335518589196997, 'w2': 1.14390396243868, 'w3': -0.049360813442930807, 'w4': -0.3492018915279285, 'w5': -1.7143158085471302, 'w6': -1.180878595807107, 'w7': -0.6385369724099941, 'w8': 2.3152389613682915, 'w9': -0.28819156655320577, 'w10': 0.5400517523156747, 'w11': 2.4852448401995995, 'w12': -2.422414330345869, 'w13': -1.1476302219430787, 'w14': -2.0433971573400207, 'w15': 1.6647559392896152, 'w16': 0.2857749275814226, 'w17': 0.15248801177169125, 'w18': 0.42081491107019675, 'w19': 2.2199380028530533, 'w20': -0.8302496784333764, 'w21': -0.8852794411838116, 'w22': 0.2862552457849343, 'w23': 1.7937113569987717, 'w24': -0.5929735303933505}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,178] Trial 63 finished with value: 0.7246376811594203 and parameters: {'w0': 1.2499384112313936, 'w1': 0.7258833920776372, 'w2': 1.3678615209528853, 'w3': -0.7189037622355126, 'w4': -0.54969000042101, 'w5': -2.0808119554600726, 'w6': -0.9106873300593632, 'w7': -0.10119380972566465, 'w8': 0.6505655038419025, 'w9': 0.25919541749200836, 'w10': 0.23470521665681185, 'w11': 1.8654397988204439, 'w12': -1.4051087111473177, 'w13': -2.0449925428308022, 'w14': -2.089674160307839, 'w15': 1.684164853774787, 'w16': -0.318593776090596, 'w17': -0.24225247950070197, 'w18': 0.587973721706999, 'w19': -1.9206813748595917, 'w20': -0.6246715723703413, 'w21': -0.16912839377894465, 'w22': -0.17481260752510863, 'w23': 0.8104448801822306, 'w24': -0.15391879065325553}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,262] Trial 64 finished with value: 0.7318840579710145 and parameters: {'w0': 0.5507172189228613, 'w1': -0.6026654347476488, 'w2': 0.6577481709939301, 'w3': -0.19467237280180522, 'w4': -0.9086754615844739, 'w5': -2.2090022395069258, 'w6': -0.0667445467356797, 'w7': -0.8965542213580249, 'w8': 2.262690046861485, 'w9': -0.03305489367372946, 'w10': -0.038791345328654914, 'w11': 2.3465408445194407, 'w12': -2.2017858883942445, 'w13': -1.5196336253775682, 'w14': -1.845379166349175, 'w15': 1.2410620849633998, 'w16': 0.05843491094855824, 'w17': 0.03674606538441942, 'w18': -0.5187319218207087, 'w19': 0.16730514676130326, 'w20': -1.0431046220609532, 'w21': 0.2052377829070945, 'w22': 0.46916663324152197, 'w23': 2.0159795807275884, 'w24': 2.491417548659849}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,343] Trial 65 finished with value: 0.7318840579710145 and parameters: {'w0': 0.32024515112572066, 'w1': -0.2726603018606019, 'w2': 0.4186232958731829, 'w3': -0.9626695011624734, 'w4': -1.4907879561605815, 'w5': -1.8107904618565236, 'w6': -1.2905629645090773, 'w7': 2.0202000647583342, 'w8': 1.791911764812893, 'w9': 0.5233466297068351, 'w10': -1.5415245975133396, 'w11': 2.0866423339484905, 'w12': -2.1083304156151264, 'w13': -0.9904814175614994, 'w14': -2.3891410241827593, 'w15': -0.5469840272731679, 'w16': -2.1181702029468203, 'w17': -0.41812049204635743, 'w18': -0.1938011749508322, 'w19': 1.2230799151099034, 'w20': -1.9400612175547811, 'w21': 0.8657495315386989, 'w22': -0.359097238030494, 'w23': 0.562412694454114, 'w24': -0.843492226817655}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,425] Trial 66 finished with value: 0.7246376811594203 and parameters: {'w0': 1.4683537613984736, 'w1': 0.45213103540799054, 'w2': 1.9631242228748889, 'w3': 0.1926516844033669, 'w4': -0.09467543984626914, 'w5': 0.4417099855618012, 'w6': -0.40424389118985227, 'w7': -0.5812500828013225, 'w8': 0.16578307710265178, 'w9': 0.9752864231077385, 'w10': -0.2771137865083694, 'w11': 1.5660321600965985, 'w12': -1.8070674300028795, 'w13': -1.287946801175548, 'w14': -1.645871436272817, 'w15': 2.1214368199422275, 'w16': 0.8834942694885214, 'w17': -0.9336884476437773, 'w18': -1.9340445372705297, 'w19': 1.7162757867322531, 'w20': -1.3573320385500096, 'w21': -0.4335333612507555, 'w22': -0.6153307563872479, 'w23': 1.4751459631089459, 'w24': -1.0068131447781559}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,515] Trial 67 finished with value: 0.7246376811594203 and parameters: {'w0': -1.7844488977885022, 'w1': -0.8381860877335329, 'w2': 1.4569356753186729, 'w3': 0.8127810583747921, 'w4': -0.5597470326908736, 'w5': -2.3506897113347978, 'w6': -0.6870757457626866, 'w7': -1.0296441901925242, 'w8': -0.2521626361052062, 'w9': 1.819817044116586, 'w10': -1.246018934966484, 'w11': -0.7376398594472696, 'w12': -1.9277163773236041, 'w13': -1.6521208795080966, 'w14': -1.1766795446632243, 'w15': 1.7405085459104686, 'w16': 0.09080630953832144, 'w17': -1.7293050133752348, 'w18': -1.5206632642130016, 'w19': 0.3322547314915413, 'w20': -1.7154457990432936, 'w21': -0.608486293571105, 'w22': -1.4802929163525886, 'w23': 0.27192104655449767, 'w24': -1.3338879622279418}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,604] Trial 68 finished with value: 0.7391304347826086 and parameters: {'w0': -1.5799081147172533, 'w1': 0.26941446878899805, 'w2': 1.0831314553953924, 'w3': -1.2123372478007928, 'w4': -0.7566695581702232, 'w5': -1.9214101827676888, 'w6': 1.8165326513660585, 'w7': 0.2289493822774899, 'w8': 1.5028653543589507, 'w9': 0.735297332988384, 'w10': -2.498569026525874, 'w11': 1.7799665142262593, 'w12': -1.2611203688140848, 'w13': -2.342406024513254, 'w14': -2.150600335510098, 'w15': 0.3475264168197347, 'w16': 0.7755146421182102, 'w17': -0.0850229183638243, 'w18': -0.6338775595749477, 'w19': 0.501974556601329, 'w20': -1.471421399225703, 'w21': -0.7330498042606108, 'w22': -2.231505149399844, 'w23': 1.1217213043691698, 'w24': -1.201647434519876}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,684] Trial 69 finished with value: 0.7391304347826086 and parameters: {'w0': -2.153168009311167, 'w1': 0.17158148059060097, 'w2': -0.002782669144924088, 'w3': 2.4560542740320463, 'w4': -0.19118520684873141, 'w5': 0.6624471751963481, 'w6': 2.4899669872469095, 'w7': -0.32551385472570965, 'w8': 1.3341451482323798, 'w9': -0.4762540700652226, 'w10': -2.2217683430625343, 'w11': -1.190903913125097, 'w12': -0.3175463410553767, 'w13': -1.9079134105836248, 'w14': -1.4626697356225897, 'w15': 0.14331091431176796, 'w16': 0.6258278005546452, 'w17': -0.5188017894303179, 'w18': 1.3226633926149778, 'w19': -2.0508563735756224, 'w20': 0.9511800973766562, 'w21': -1.2265821650579025, 'w22': -1.8244378614082033, 'w23': 0.9762607176540891, 'w24': -0.19786673500538055}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,789] Trial 70 finished with value: 0.7391304347826086 and parameters: {'w0': 1.7373993937089751, 'w1': -0.01480324662412645, 'w2': 1.699424928165194, 'w3': -0.5454389987958947, 'w4': -1.0723072159231215, 'w5': -1.2745354456149873, 'w6': 2.1863129495193228, 'w7': -1.317433170535284, 'w8': 1.9086048029764107, 'w9': 0.34044332619766016, 'w10': 0.471530625875336, 'w11': 2.031968365390631, 'w12': -1.5423186930509458, 'w13': -1.7603143640211731, 'w14': -2.3455650651065105, 'w15': 0.9513411459240418, 'w16': 1.20942489831112, 'w17': -2.4624084741091035, 'w18': 0.107052897615047, 'w19': -1.5201242328396747, 'w20': -0.4317030905097462, 'w21': 0.01722705299648658, 'w22': -0.7926021910149847, 'w23': 2.222212873070406, 'w24': -0.5948833095473349}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,876] Trial 71 finished with value: 0.7391304347826086 and parameters: {'w0': -1.2207209377187629, 'w1': -0.15256191812123981, 'w2': 0.25928549091083763, 'w3': 1.5502965243324685, 'w4': 0.26725767811863954, 'w5': -2.152597466708538, 'w6': 2.0805075477909427, 'w7': 0.018438275369387358, 'w8': 1.1777563236557902, 'w9': -0.11346981358342008, 'w10': -2.3106849076540645, 'w11': -0.398515048833314, 'w12': -2.3442168812239093, 'w13': 0.9599497847643007, 'w14': -2.4972173016317716, 'w15': 0.4866842640438588, 'w16': -1.9660735723196827, 'w17': -1.3232142863751082, 'w18': 0.28323393731019575, 'w19': -1.8153903539615674, 'w20': -2.0939179716536698, 'w21': -0.38302562117942585, 'w22': -1.6321744691552005, 'w23': 0.9928805732929202, 'w24': -0.84967061208653}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:31,963] Trial 72 finished with value: 0.7391304347826086 and parameters: {'w0': -1.158838588246108, 'w1': -0.47057719682080557, 'w2': 0.26645101041987174, 'w3': -1.8694105664080098, 'w4': 1.0469310066839965, 'w5': -2.3972375628106377, 'w6': 1.993740791885279, 'w7': 0.4894705579902092, 'w8': 1.0442939618415024, 'w9': -0.050040789545443554, 'w10': -1.9304677816159, 'w11': -0.5997498934163539, 'w12': -2.0501280943469578, 'w13': -2.099207643711102, 'w14': -1.9569888491998633, 'w15': 0.533604145462106, 'w16': -2.470785100392838, 'w17': -1.1794358267410707, 'w18': 1.1031716728897976, 'w19': 2.4855603543211977, 'w20': -1.932665097408595, 'w21': -0.17671986211346785, 'w22': -1.5642251756519474, 'w23': 1.2007291664370308, 'w24': -0.9469450339181791}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,048] Trial 73 finished with value: 0.7391304347826086 and parameters: {'w0': -0.825526745299982, 'w1': -0.25238612187423354, 'w2': -0.33176553013729226, 'w3': -1.745121269903155, 'w4': 0.5445751777141954, 'w5': -2.0220367057453768, 'w6': 2.3093868158356012, 'w7': -0.1677720540018951, 'w8': 0.3426490419288709, 'w9': -0.289235917530384, 'w10': -2.4302548246519318, 'w11': -0.49301353327410935, 'w12': -2.492104437116966, 'w13': -1.737336506942095, 'w14': -2.2258743681291193, 'w15': 0.7262219729468106, 'w16': -1.3970463427501894, 'w17': -1.3979284061919823, 'w18': 0.6826847702992072, 'w19': -2.2866819678103187, 'w20': -1.7121505133020518, 'w21': -0.2678086076216324, 'w22': -1.2978030948548036, 'w23': 0.7706862148162377, 'w24': -0.7806774492385224}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,133] Trial 74 finished with value: 0.7318840579710145 and parameters: {'w0': -1.104675368868582, 'w1': -0.06959034611943299, 'w2': 0.5294190286533529, 'w3': -2.0773767216846144, 'w4': 0.45289899015200796, 'w5': -1.5346292283748681, 'w6': 1.2521294480075285, 'w7': 0.1439223280163809, 'w8': 0.8390701523136843, 'w9': 0.22280014597203618, 'w10': -2.1440542653984678, 'w11': -0.09201636102940447, 'w12': -1.9994555724713683, 'w13': -1.449754611817606, 'w14': -1.6888377724684551, 'w15': -0.4427023444938902, 'w16': -1.85306057147616, 'w17': -1.6277819656093584, 'w18': 0.7875330383498256, 'w19': -1.950633760402043, 'w20': -2.1590079639528192, 'w21': -0.9260018637175156, 'w22': -2.1051461281841606, 'w23': 0.5045264324586578, 'w24': -0.3468656410919534}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,233] Trial 75 finished with value: 0.7391304347826086 and parameters: {'w0': -1.3114449174947922, 'w1': -0.5496058320467374, 'w2': 0.8652554907390516, 'w3': -1.4993367573599727, 'w4': -0.3049542071201356, 'w5': -1.7844732457656878, 'w6': 2.380773177004302, 'w7': 0.8431823228527107, 'w8': 0.6390133072875799, 'w9': -0.1239874055946859, 'w10': -1.6826280654492256, 'w11': 0.17410627145219693, 'w12': -1.7143950475937224, 'w13': -1.1235410620337078, 'w14': -2.2961852492672152, 'w15': 0.0047663185612747405, 'w16': -2.069725725386477, 'w17': -0.7937862188835942, 'w18': 0.5025594511513625, 'w19': -1.7820024821996514, 'w20': -2.366662512096147, 'w21': -0.3260947509101173, 'w22': -1.6916170384417184, 'w23': 1.381723725300751, 'w24': -0.03649483443716018}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,330] Trial 76 finished with value: 0.7391304347826086 and parameters: {'w0': -0.4480673150277996, 'w1': 0.69034059594946, 'w2': -2.3776829665295045, 'w3': -2.0019793170505378, 'w4': -0.9266493586019002, 'w5': -2.1909448896713437, 'w6': 1.96312062839066, 'w7': -0.5181415054712927, 'w8': 1.7102951166229092, 'w9': -0.6690221380388166, 'w10': -1.831299121674439, 'w11': 2.203336544656817, 'w12': 0.5537107407243309, 'w13': 1.6753121807875015, 'w14': -1.9605584341925506, 'w15': 0.3368434261350528, 'w16': -1.1620930283494362, 'w17': 0.4527776076747375, 'w18': -0.013416938375962806, 'w19': -0.1324512852516201, 'w20': 0.22179948105470143, 'w21': -0.7656736341806002, 'w22': -2.331346424812386, 'w23': 0.936007295259439, 'w24': -1.1369660827841734}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,415] Trial 77 finished with value: 0.7463768115942029 and parameters: {'w0': 0.8255322224677628, 'w1': -0.714809648807736, 'w2': 0.3924259084703088, 'w3': -1.2607010425677123, 'w4': -0.6812199628073208, 'w5': -2.389475935318446, 'w6': -1.5897089270241462, 'w7': 0.3584023121068902, 'w8': 2.116991377813317, 'w9': 0.5978681676804823, 'w10': -2.02173920470493, 'w11': 0.9270544718587274, 'w12': -0.6006307734089307, 'w13': -2.229513137194422, 'w14': -1.2223140224284532, 'w15': -0.1378700249983863, 'w16': -2.320048411921269, 'w17': 0.19139533182327995, 'w18': -1.163468685091131, 'w19': -1.3519180157380217, 'w20': -1.9779552334096249, 'w21': -2.27527855772247, 'w22': -2.4678874300317717, 'w23': 1.578161881380225, 'w24': -0.5312723639167606}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,506] Trial 78 finished with value: 0.7463768115942029 and parameters: {'w0': -0.2023802884513093, 'w1': 0.5565319339102098, 'w2': -0.09836558771476794, 'w3': -1.8191915596231094, 'w4': 0.03316236920114307, 'w5': -2.0010756354703387, 'w6': 1.6181187475407386, 'w7': 0.6565349921824659, 'w8': 1.4412075918080705, 'w9': -0.9796968176243772, 'w10': -2.3305400021558533, 'w11': 1.5478131835522637, 'w12': -2.329097952543574, 'w13': -1.879999057540879, 'w14': 0.5846583037796448, 'w15': -1.1762654159878214, 'w16': -0.5201498606251302, 'w17': 1.0455665020142273, 'w18': 1.6580677747916328, 'w19': -1.6192143801618117, 'w20': -1.2505928967054296, 'w21': -1.1340415357810383, 'w22': 2.4062407836953232, 'w23': -1.387282912000288, 'w24': -1.510937983530984}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,593] Trial 79 finished with value: 0.7391304347826086 and parameters: {'w0': 0.5980820300184782, 'w1': 0.3588073366392873, 'w2': 0.17050101708988208, 'w3': -0.9245746625788982, 'w4': -1.1771542143884248, 'w5': -1.6757001472226367, 'w6': 2.2087634533909033, 'w7': 1.7579333284729615, 'w8': 2.4110975236948797, 'w9': 0.42669996395118576, 'w10': -0.5855671817240129, 'w11': 1.3122993272130625, 'w12': -0.1621832424072978, 'w13': -1.2468409094954782, 'w14': -2.1281752020069176, 'w15': 0.8343584269219204, 'w16': -1.6359338293937067, 'w17': -2.1757956422682314, 'w18': -1.713285487453364, 'w19': -0.5545655757839061, 'w20': -1.5152415406147624, 'w21': 0.4820011711142833, 'w22': -1.9349674032559927, 'w23': 1.7532241510719864, 'w24': -1.6575133408964016}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,682] Trial 80 finished with value: 0.7391304347826086 and parameters: {'w0': -1.5924221339629703, 'w1': -0.36481411391231094, 'w2': 0.709753219269688, 'w3': -0.7458854921143191, 'w4': 0.17841070415159727, 'w5': -0.017919701896827123, 'w6': 1.7759185720698838, 'w7': 1.2309976708164625, 'w8': 1.1275043266258353, 'w9': 0.0050673830482434595, 'w10': -1.2701233274449848, 'w11': 1.8973537939945406, 'w12': -0.8689116044151085, 'w13': -0.5732957229120568, 'w14': -1.8477081577526726, 'w15': 1.2129370125935168, 'w16': -0.09047129795296238, 'w17': -0.2961004545481374, 'w18': -0.9639084476939042, 'w19': -0.8118651782680387, 'w20': -2.259886956554262, 'w21': -1.7156571252254555, 'w22': -1.068962475203111, 'w23': 0.6188622839044807, 'w24': 0.32417515651203904}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,772] Trial 81 finished with value: 0.7318840579710145 and parameters: {'w0': -1.795024709106118, 'w1': -1.488194262728363, 'w2': -0.3529797370863094, 'w3': -1.1183721213052986, 'w4': -0.7511285088442147, 'w5': -2.20099646636935, 'w6': 2.106219717202907, 'w7': 2.3142824576002607, 'w8': 1.1757851960757546, 'w9': -0.4331144531187107, 'w10': -2.1555534837639, 'w11': 0.13622985972872914, 'w12': -0.9763533599222969, 'w13': -1.3472806245478703, 'w14': -2.370627589068712, 'w15': 0.31153320667171536, 'w16': -2.2445581696095367, 'w17': -2.0465446947384853, 'w18': 1.8559265720520683, 'w19': -0.2772036803147566, 'w20': -1.8148040046250244, 'w21': -0.6172157286064095, 'w22': -1.8017086927409216, 'w23': 1.6069751627558284, 'w24': -0.9331083426224008}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,859] Trial 82 finished with value: 0.7391304347826086 and parameters: {'w0': -0.9633748447870043, 'w1': -1.6799269754252206, 'w2': -0.4918133334878262, 'w3': -1.4211395269237994, 'w4': -0.8148617195184423, 'w5': -2.486187204366722, 'w6': 2.3842939817674003, 'w7': -0.27462654268058917, 'w8': 0.932224070461087, 'w9': -0.5425075382145269, 'w10': -2.080222086970002, 'w11': -0.3912422067913167, 'w12': -1.3626550898079652, 'w13': -1.0478092093262432, 'w14': -2.3100356393913417, 'w15': 0.4395514296624915, 'w16': -2.1957240052244615, 'w17': -1.9318090635139873, 'w18': 1.2370545905531596, 'w19': -0.872610449031367, 'w20': -1.8794690200588628, 'w21': -0.540813956125932, 'w22': -1.354827779358264, 'w23': 1.2590232750003274, 'w24': -0.7558739718390746}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:32,942] Trial 83 finished with value: 0.7463768115942029 and parameters: {'w0': -1.6887769582455234, 'w1': -1.8691373165365515, 'w2': -1.0146543595209077, 'w3': -1.655199116051718, 'w4': -0.47577232499032895, 'w5': -2.2872751897213233, 'w6': 2.1071195170842447, 'w7': 1.473094703066823, 'w8': 1.604405141803971, 'w9': -0.35173298005681675, 'w10': -2.4956758893658932, 'w11': 0.3434109062430525, 'w12': -1.8061074264227894, 'w13': -0.8594148374157184, 'w14': -2.428858093841747, 'w15': 0.6511065983316802, 'w16': -1.781058632284433, 'w17': -1.0901913143009052, 'w18': 1.5104223347664987, 'w19': -0.4932428475838226, 'w20': -1.6150323529449175, 'w21': -0.026950285747483926, 'w22': -1.746870880641619, 'w23': 2.039811139933742, 'w24': -1.0193415509193586}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,030] Trial 84 finished with value: 0.7318840579710145 and parameters: {'w0': -1.445712408017094, 'w1': -1.0023822169648775, 'w2': -0.6167383914696511, 'w3': -1.3087969811570654, 'w4': -0.8782083662773136, 'w5': -1.9319342222186535, 'w6': -2.178060552142602, 'w7': 1.7308263789500873, 'w8': 1.2395101351293094, 'w9': 0.22152168066844455, 'w10': -2.3411630847787492, 'w11': 1.0648576536115901, 'w12': -0.44400679174938074, 'w13': -1.530335790749171, 'w14': -2.4420971637999305, 'w15': 1.0127739094479074, 'w16': -1.9942667733981956, 'w17': -1.6838823658886302, 'w18': 2.215119561029237, 'w19': -1.1424271399139927, 'w20': -2.0507096310059927, 'w21': 0.17428511130307833, 'w22': -1.4463789996982954, 'w23': 1.8837712493202374, 'w24': -1.2736677927769533}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,115] Trial 85 finished with value: 0.7318840579710145 and parameters: {'w0': -1.9236829195361356, 'w1': -0.23162833558155083, 'w2': -0.22600908128862054, 'w3': -2.2569139514293886, 'w4': -0.602861696602238, 'w5': -2.227142818136174, 'w6': 1.8870107389633657, 'w7': 0.9851554544403678, 'w8': 0.7402415125552186, 'w9': -0.21532277507493247, 'w10': -1.9302038122576233, 'w11': 2.319887921587758, 'w12': -0.7605032937680685, 'w13': -2.0190848703787445, 'w14': -2.1637850067461404, 'w15': 0.0891078439598636, 'w16': -2.392410475389461, 'w17': 0.7549090736176353, 'w18': 0.8509774865822168, 'w19': -2.1332381302021255, 'w20': 0.35788132956673335, 'w21': -1.528458110384507, 'w22': -1.8664742715118001, 'w23': 2.415470333271972, 'w24': 0.6044735888936543}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,198] Trial 86 finished with value: 0.7318840579710145 and parameters: {'w0': -2.118461899566203, 'w1': -1.2868182192503097, 'w2': 0.07524135266234855, 'w3': -1.0766851368283443, 'w4': -0.14621572613042877, 'w5': -1.420301946030608, 'w6': 0.9692190355361718, 'w7': 1.3420885631816026, 'w8': 0.4951764835651671, 'w9': -1.1265399705454557, 'w10': -2.2243301321881663, 'w11': -1.134460679905458, 'w12': -1.5536027049890229, 'w13': -1.3421235178002813, 'w14': -2.0132436299244665, 'w15': -0.16864335783115048, 'w16': -1.2815285317363136, 'w17': -0.6544030105623557, 'w18': -0.3412964263401344, 'w19': -0.7286977253298719, 'w20': -1.7064776095263514, 'w21': -0.5066683090100093, 'w22': -1.5810983319163845, 'w23': 1.102400201844391, 'w24': -0.2780207501031926}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,282] Trial 87 finished with value: 0.7391304347826086 and parameters: {'w0': -1.344643297080847, 'w1': -1.502630024966928, 'w2': -0.7057674793202917, 'w3': -1.5046934673711263, 'w4': -0.3670509483898449, 'w5': -1.8158065297708756, 'w6': 2.493331822406068, 'w7': -0.05225870198411672, 'w8': 1.4172288325834304, 'w9': 0.027676564452091906, 'w10': -1.6798547204129401, 'w11': -0.1828059039346765, 'w12': -2.0766691205702177, 'w13': -1.6862108212320193, 'w14': -2.4869475695297916, 'w15': -0.42580129393533267, 'w16': -1.9110691439906522, 'w17': -1.5258670102953429, 'w18': -1.3496696789171234, 'w19': -2.3434007296219193, 'w20': -1.336826495329195, 'w21': -1.3943408206686843, 'w22': 1.8464918663241052, 'w23': -0.7666857521014727, 'w24': -0.6341353499179109}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,368] Trial 88 finished with value: 0.7463768115942029 and parameters: {'w0': -1.103987591305519, 'w1': 0.2130404388677036, 'w2': 0.5570595592278093, 'w3': -1.1761362336051036, 'w4': -0.9994206658714074, 'w5': -2.0095739586050487, 'w6': 2.19140473130409, 'w7': -0.46105336135077624, 'w8': 1.034039683886038, 'w9': 0.1676913630677288, 'w10': -2.0721857788532883, 'w11': 1.158095415125589, 'w12': -0.9981209222143581, 'w13': -2.3820756806871946, 'w14': -1.8594552641539384, 'w15': 0.733503490761002, 'w16': -2.15942957363708, 'w17': -0.03702152990210622, 'w18': -0.1108352262203196, 'w19': -1.448218263387969, 'w20': -1.8407698748127994, 'w21': -0.8517443232886506, 'w22': -2.079707516585107, 'w23': 1.463069931710863, 'w24': 0.14005158794220185}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,455] Trial 89 finished with value: 0.7318840579710145 and parameters: {'w0': -2.2765534836464187, 'w1': -0.05889005251621571, 'w2': 1.321719324888115, 'w3': -0.5548456910054982, 'w4': -1.3168559371328916, 'w5': -0.22366552536374962, 'w6': 2.0180402605124677, 'w7': 2.461301705514069, 'w8': -0.6548735539457514, 'w9': -1.386193720695491, 'w10': 0.07084070560246564, 'w11': 1.6652997770090834, 'w12': -1.130780119547709, 'w13': -2.1374818985336095, 'w14': -0.44254766606201756, 'w15': 0.19244164148090637, 'w16': -0.7772489749822574, 'w17': -1.914044934028471, 'w18': 0.5565299167778619, 'w19': -0.6428116452019526, 'w20': -1.049246155483054, 'w21': -0.9993849679612398, 'w22': -0.4707660034728842, 'w23': 0.875735133626676, 'w24': -0.4259663470386464}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,543] Trial 90 finished with value: 0.7318840579710145 and parameters: {'w0': 1.033991554701574, 'w1': 0.0729254945881648, 'w2': 1.0159764343820952, 'w3': -0.8522066551280983, 'w4': 0.07802875727362515, 'w5': -2.160021522308445, 'w6': 2.3341846212304485, 'w7': 2.0697698877677526, 'w8': 0.15926769914283923, 'w9': -0.1754236524907018, 'w10': -2.390080748616004, 'w11': 0.569539526333722, 'w12': 0.19130454505235894, 'w13': -1.8108338210338142, 'w14': -2.280646426984685, 'w15': 1.5049738431270048, 'w16': -1.4736755117261449, 'w17': 2.4925290206231017, 'w18': 0.362544471141188, 'w19': -1.0028389862862834, 'w20': 0.6922222106193225, 'w21': -0.30205797932530587, 'w22': 0.17704577218543383, 'w23': 0.39281817529754126, 'w24': -0.8924764058587833}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,631] Trial 91 finished with value: 0.7463768115942029 and parameters: {'w0': 1.1271766522325106, 'w1': 0.17166723151787489, 'w2': 0.8883463021713615, 'w3': -0.468081804464458, 'w4': -0.4754470273845095, 'w5': -2.073259165237788, 'w6': 0.33541170492425043, 'w7': -0.40169434435821305, 'w8': 2.092037986772285, 'w9': 0.10005670055886437, 'w10': 0.5660182457841353, 'w11': 2.174066515768555, 'w12': -2.1048249832679704, 'w13': -1.4103407223902855, 'w14': -2.131251955536814, 'w15': 1.404778614897463, 'w16': -2.492828335498069, 'w17': -0.34022129871453033, 'w18': 0.12149245029453992, 'w19': 2.2207848772989016, 'w20': -1.0561971012691878, 'w21': -0.21966855933569876, 'w22': -0.21551855166847783, 'w23': 1.6738969060875966, 'w24': -0.4532867811581377}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,713] Trial 92 finished with value: 0.7536231884057971 and parameters: {'w0': 0.7878888471631529, 'w1': 0.09085378227791448, 'w2': 0.8552452449834477, 'w3': -0.3149123368192496, 'w4': -0.4385158831254748, 'w5': -2.3703815284561363, 'w6': -0.22389199940853655, 'w7': -0.6458659973072368, 'w8': 1.961018713936487, 'w9': 0.3461507045614783, 'w10': 0.8714582990665325, 'w11': 2.401062232161878, 'w12': -2.201874665952255, 'w13': -1.4831245633898011, 'w14': -2.2244088000967572, 'w15': 0.5802436635612581, 'w16': 0.24655558086228335, 'w17': -0.1463389088770778, 'w18': 0.2235468861926064, 'w19': 2.299574086073406, 'w20': -0.7497998241357925, 'w21': -0.08273781940243663, 'w22': -0.25485028702911877, 'w23': 1.6578297965295192, 'w24': -0.008203788231219943}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,796] Trial 93 finished with value: 0.7391304347826086 and parameters: {'w0': 0.20594334261281294, 'w1': -0.14426549889127854, 'w2': 0.36643100640365767, 'w3': -0.2687236597154582, 'w4': 0.3794526384958227, 'w5': -2.3677971881028634, 'w6': 2.2583020819948665, 'w7': -0.6638164795673107, 'w8': 1.9430417241436522, 'w9': -1.9001029287238853, 'w10': 1.419297450469259, 'w11': 1.8236634626031059, 'w12': -1.977302211294909, 'w13': -1.1741730450662717, 'w14': -0.7137575688404688, 'w15': 0.38898533008335123, 'w16': 0.5075121257964489, 'w17': -0.24515851812490164, 'w18': -0.26526605148933347, 'w19': 2.199420783386707, 'w20': -0.7670956565063561, 'w21': -0.6860495465643921, 'w22': 0.09851397222048719, 'w23': 0.694694996314037, 'w24': -0.1881555264493251}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,882] Trial 94 finished with value: 0.7391304347826086 and parameters: {'w0': 0.5096396488964895, 'w1': -0.3727128066139517, 'w2': 0.6958189212159124, 'w3': 0.04078412534124831, 'w4': -0.5995708316220314, 'w5': -2.316385315393105, 'w6': -0.9771917421043831, 'w7': -0.8724700546169389, 'w8': 1.5488942775814798, 'w9': 0.353380706066314, 'w10': 0.7515092007557475, 'w11': 2.4403107971844418, 'w12': -2.2297680654901795, 'w13': -1.5791197800487355, 'w14': -2.248239360059793, 'w15': 0.5367022404090777, 'w16': 0.27361115609278946, 'w17': -0.4970183021066372, 'w18': 0.30138453743651367, 'w19': 1.765508340668468, 'w20': -0.5245372810129361, 'w21': -0.017990078235844198, 'w22': -1.2342014578881013, 'w23': 1.4030735331644981, 'w24': -0.016797065808088693}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:33,967] Trial 95 finished with value: 0.7463768115942029 and parameters: {'w0': 0.7237706017955905, 'w1': 0.39136064955699945, 'w2': 0.2653028488082362, 'w3': -1.3248910972336971, 'w4': -0.8567405301683436, 'w5': -2.4184953876945947, 'w6': -0.2656811521114758, 'w7': 0.1663572048164942, 'w8': 1.8350900829976065, 'w9': 0.49256830073738495, 'w10': 1.2173903740079712, 'w11': 1.9810826057403026, 'w12': -1.8051485932454305, 'w13': -0.3824346458390896, 'w14': -2.008559204863208, 'w15': -0.7059797175589135, 'w16': 0.18838414539125156, 'w17': -1.8128606524850428, 'w18': -0.47712486514844354, 'w19': 2.34981712635379, 'w20': -0.8953009670668092, 'w21': 0.32666933886828775, 'w22': -0.0785961777267809, 'w23': 1.2331411966063288, 'w24': -0.6941833350811473}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:34,050] Trial 96 finished with value: 0.7391304347826086 and parameters: {'w0': -1.512106891424848, 'w1': -0.6279110451459596, 'w2': 2.246339481599634, 'w3': -1.581598613795229, 'w4': -0.25675956413763545, 'w5': -1.8692551453822026, 'w6': -0.024720327600819436, 'w7': 0.46436864347738027, 'w8': -0.08401457564053672, 'w9': -0.25587038746531005, 'w10': 2.0084182944722215, 'w11': 1.4588316650226518, 'w12': -0.6114030504813661, 'w13': -1.9719388880379034, 'w14': -1.6976466266376233, 'w15': 1.09720306866476, 'w16': -0.21800652378471486, 'w17': -0.6962989210636017, 'w18': 0.022649550070999114, 'w19': 1.9139945538347254, 'w20': -2.215703063488007, 'w21': -0.4082957259627523, 'w22': -0.9564414153408876, 'w23': 1.0366191895644878, 'w24': -0.5285467924666847}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:34,139] Trial 97 finished with value: 0.7391304347826086 and parameters: {'w0': 0.8751377651903967, 'w1': -0.5053030413986688, 'w2': 0.8311663721240191, 'w3': -0.6296959478113539, 'w4': -0.6458450844478182, 'w5': -2.130587254356426, 'w6': 0.7710637592792, 'w7': -0.17654129460399992, 'w8': 2.306425899505396, 'w9': 0.8221814139595955, 'w10': 0.8213112804466965, 'w11': 2.4036007744796346, 'w12': -1.6499492001537124, 'w13': -0.7157364792664267, 'w14': 0.20677784658442766, 'w15': 0.0019326839351058167, 'w16': 2.401868234799944, 'w17': -0.8345031428821402, 'w18': -0.8707196733929812, 'w19': 1.555411428434447, 'w20': -2.0257752226756147, 'w21': -0.0946199156549109, 'w22': -0.29484571897996337, 'w23': 1.5460212683806702, 'w24': 1.915110738812389}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:34,224] Trial 98 finished with value: 0.7463768115942029 and parameters: {'w0': 0.34299452783653095, 'w1': -0.017337880738948375, 'w2': -1.2192430085003303, 'w3': -1.008084691967446, 'w4': 0.7404810214880735, 'w5': -1.6606195107011001, 'w6': -0.7014347340032822, 'w7': -1.0104031661089796, 'w8': 2.2077913862563143, 'w9': 0.6771759177410672, 'w10': -1.7626788409402194, 'w11': 2.23417590308315, 'w12': -2.318372148664073, 'w13': -0.023720781875889996, 'w14': -1.0104503758353722, 'w15': 0.8125573150341109, 'w16': -2.308475028622363, 'w17': 0.18762870513941038, 'w18': 0.6419691824595111, 'w19': 1.995110687442958, 'w20': -0.20010060943452257, 'w21': 0.10270444361075337, 'w22': 0.419195997648974, 'w23': 2.089976330544921, 'w24': -0.33223554606247596}. Best is trial 13 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 13:55:34,315] Trial 99 finished with value: 0.7318840579710145 and parameters: {'w0': -0.6576519603866844, 'w1': -2.497946276463486, 'w2': -0.4471317180089173, 'w3': -0.3853627377835944, 'w4': 0.10232758508112455, 'w5': 2.2894412971324867, 'w6': 2.390592220976162, 'w7': -0.6007922204158713, 'w8': 1.6909562580122266, 'w9': -0.8239117068921016, 'w10': -1.4480820160209824, 'w11': 2.064449742561406, 'w12': -1.9048292502737285, 'w13': -0.946802579217034, 'w14': -2.3769138632810147, 'w15': 0.6003279776958389, 'w16': 0.47483316161807426, 'w17': -0.9620828193957274, 'w18': 0.9604974356087955, 'w19': 0.04194158154974702, 'w20': -1.4421097694921534, 'w21': -1.2346534550337662, 'w22': -0.7369414016630226, 'w23': 0.7715785637744912, 'w24': -1.0233644768913956}. Best is trial 13 with value: 0.7536231884057971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna alphas (first 10): [0.0499 0.0217 0.0492 0.0068 0.0116 0.0443 0.3054 0.0179 0.1049 0.0241]\n",
      "\n",
      "==== Bagging (Optuna Weights, Acc-opt, no-leak) Performance ====\n",
      "Accuracy:      0.607558\n",
      "AUC:           0.641937\n",
      "PR-AUC:        0.512768\n",
      "LogLoss:       0.661447\n",
      "Precision@0.620: 0.527778\n",
      "Recall@0.620:    0.273381\n",
      "F1@0.620:        0.360190\n",
      "\n",
      "===== Retrain all bags on FULL 80% train (inner ES only, block bootstrap), then test on 20% =====\n",
      "\n",
      "==== FINAL Retrain — Simple Average (thr from val) Performance ====\n",
      "Accuracy:      0.619186\n",
      "AUC:           0.652185\n",
      "PR-AUC:        0.507054\n",
      "LogLoss:       0.656375\n",
      "Precision@0.580: 0.552632\n",
      "Recall@0.580:    0.302158\n",
      "F1@0.580:        0.390698\n",
      "\n",
      "==== FINAL Retrain — Val-AUC Weighted (thr from val) Performance ====\n",
      "Accuracy:      0.604651\n",
      "AUC:           0.652114\n",
      "PR-AUC:        0.507130\n",
      "LogLoss:       0.656355\n",
      "Precision@0.620: 0.529412\n",
      "Recall@0.620:    0.194245\n",
      "F1@0.620:        0.284211\n",
      "\n",
      "==== FINAL Retrain — Optuna Weights (thr from val) Performance ====\n",
      "Accuracy:      0.598837\n",
      "AUC:           0.637515\n",
      "PR-AUC:        0.493419\n",
      "LogLoss:       0.659447\n",
      "Precision@0.620: 0.510638\n",
      "Recall@0.620:    0.172662\n",
      "F1@0.620:        0.258065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5988372093023255,\n",
       " 'auc': 0.6375153535708019,\n",
       " 'ap': 0.49341940429241266,\n",
       " 'll': 0.6594474270882652,\n",
       " 'prec': 0.5106382978723404,\n",
       " 'rec': 0.17266187050359713,\n",
       " 'f1': 0.25806451612903225}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "# 不彻底屏蔽所有警告，仅对常见的harmless提示做抑制（按需添加）\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 0) 数据准备（保持你原来的接口约定）\n",
    "# =========================\n",
    "# 需先提供 df_clean：包含 'value_sort' 二分类标签，其他列为特征\n",
    "# 例如：\n",
    "# df_clean = pd.read_csv(\"your_data.csv\")  # 确保存在 value_sort 列\n",
    "\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】（用于学权重/阈值；不用于早停）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]     # 仅供子模型训练/自助采样\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]     # 外部验证片（学习权重/阈值）\n",
    "\n",
    "# =========================\n",
    "# 1) 工具函数（评估 / 采样 / 保障双类 / 阈值寻优）\n",
    "# =========================\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on_val(y_val, p_val, metric='accuracy'):\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    if metric == 'accuracy':\n",
    "        scores = [accuracy_score(y_val, (p_val >= t).astype(int)) for t in ths]\n",
    "    else:\n",
    "        from sklearn.metrics import f1_score\n",
    "        scores = [f1_score(y_val, (p_val >= t).astype(int), zero_division=0) for t in ths]\n",
    "    return float(ths[int(np.argmax(scores))])\n",
    "\n",
    "def block_bootstrap(n, ratio, block=20, rng=None):\n",
    "    \"\"\"\n",
    "    时间友好采样：用固定长度block拼接到目标样本数，保持索引连续。\n",
    "    \"\"\"\n",
    "    m = int(n * ratio)\n",
    "    idx = []\n",
    "    if n <= 0: \n",
    "        return np.array([], dtype=int)\n",
    "    if block <= 0: \n",
    "        block = 1\n",
    "    while len(idx) < m:\n",
    "        s = rng.randint(0, max(1, n - block + 1))\n",
    "        idx.extend(range(s, min(s + block, n)))\n",
    "    idx = np.array(idx[:m], dtype=int)\n",
    "    idx.sort()\n",
    "    return idx\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3):\n",
    "    \"\"\"\n",
    "    保障外部验证片具备双类：\n",
    "    - 若单类，则逐步扩大验证片比例（最多扩到训练末尾30%）\n",
    "    - 若仍单类，则从训练池补齐缺失类别样本到验证片\n",
    "    \"\"\"\n",
    "    if len(np.unique(y_val_fit)) >= 2:\n",
    "        return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit  # 已满足\n",
    "\n",
    "    n_total = len(y_tr)\n",
    "    tail = len(y_val_fit)\n",
    "    # 逐步扩大验证片占比\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail:\n",
    "            break\n",
    "        # 重新切分\n",
    "        X_tr_fit = X_tr_raw[:n_total - new_tail]\n",
    "        y_tr_fit = y_tr[:n_total - new_tail]\n",
    "        X_val_fit = X_tr_raw[n_total - new_tail:]\n",
    "        y_val_fit = y_tr[n_total - new_tail:]\n",
    "        tail = new_tail\n",
    "\n",
    "    # 如果仍是单类，则从训练池补齐\n",
    "    if len(np.unique(y_val_fit)) < 2:\n",
    "        classes = np.unique(y_tr)\n",
    "        if len(classes) == 2:\n",
    "            missing = 1 - int(np.unique(y_val_fit)[0])\n",
    "            pool_idx = np.where(y_tr_fit == missing)[0]\n",
    "            if len(pool_idx) > 0:\n",
    "                # 取不超过验证片大小一半的样本补入\n",
    "                k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "                pick = np.random.RandomState(1234).choice(pool_idx, k, replace=False)\n",
    "                X_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]], axis=0)\n",
    "                y_val_fit = np.concatenate([y_val_fit, y_tr_fit[pick]], axis=0)\n",
    "                # 同步从训练去除被挪走的样本（可选）\n",
    "                mask = np.ones(len(y_tr_fit), dtype=bool)\n",
    "                mask[pick] = False\n",
    "                X_tr_fit = X_tr_fit[mask]\n",
    "                y_tr_fit = y_tr_fit[mask]\n",
    "\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "def ensure_both_classes_in_es(y_full, es_idx, pool_idx, rng, max_tries=10):\n",
    "    \"\"\"\n",
    "    保障早停片(ES)具备双类：\n",
    "    - 若单类，尝试从pool(训练子集)中换入缺失类别，最多 max_tries 次\n",
    "    - 返回修复后的 es_idx\n",
    "    \"\"\"\n",
    "    if len(es_idx) == 0:\n",
    "        return es_idx\n",
    "    for _ in range(max_tries):\n",
    "        if len(np.unique(y_full[es_idx])) >= 2:\n",
    "            return es_idx\n",
    "        # 找缺失的类别\n",
    "        present = int(np.unique(y_full[es_idx])[0])\n",
    "        missing = 1 - present\n",
    "        cand = pool_idx[y_full[pool_idx] == missing]\n",
    "        if len(cand) == 0:\n",
    "            # pool没有缺失类，只能重采样es_idx\n",
    "            es_idx = rng.choice(pool_idx, size=max(1, len(es_idx)), replace=True)\n",
    "            continue\n",
    "        # 用一些缺失类样本替换es中的同类样本\n",
    "        k = min(len(cand), max(1, len(es_idx)//2))\n",
    "        replace_es_pos = rng.choice(len(es_idx), size=k, replace=False)\n",
    "        add_from_cand = rng.choice(cand, size=k, replace=False)\n",
    "        es_idx = es_idx.copy()\n",
    "        es_idx[replace_es_pos] = add_from_cand\n",
    "    return es_idx\n",
    "\n",
    "# =========================\n",
    "# 2) 超参中心（best_params）\n",
    "# =========================\n",
    "BASE_PARAMS = dict(\n",
    "    learning_rate=0.1305241307456396,\n",
    "    num_leaves=86,\n",
    "    max_depth=6,\n",
    "    min_child_samples=103,\n",
    "    subsample=0.5600223085390776,\n",
    "    colsample_bytree=0.608980878948645,\n",
    "    reg_alpha=2.3147174999485715e-05,\n",
    "    reg_lambda=0.00042189753661999455,\n",
    "    n_estimators=1079\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) 训练设置（含可复现性/日志）\n",
    "# =========================\n",
    "RANDOM_SEED   = 42\n",
    "BAGS          = 25           # 子模型数\n",
    "SAMPLE_RATIO  = 0.85         # 自助采样比例\n",
    "JITTER_SCALE  = 0.12         # 参数扰动强度\n",
    "BLOCK_SIZE    = 20           # block bootstrap 的单块长度（可按日频序列相关性调整）\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 确保外部验证片具备双类\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "n_train = X_tr_fit.shape[0]\n",
    "models   = []\n",
    "val_probs_list = []\n",
    "te_probs_list  = []\n",
    "\n",
    "# =========================\n",
    "# 4) Bagging 训练（block bootstrap + ES双类保障 + 仅用ES早停）\n",
    "# =========================\n",
    "for b in range(BAGS):\n",
    "    # 1) block 自助采样（时间友好）\n",
    "    idx_boot = block_bootstrap(n_train, SAMPLE_RATIO, block=BLOCK_SIZE, rng=rng)\n",
    "\n",
    "    # 2) 从 boot 内切 ES 片：最后10%为 ES\n",
    "    es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "    tr_idx = idx_boot[:es_pt]\n",
    "    es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "\n",
    "    # —— 保障 ES 片具备双类（必要时从训练子集换入缺失类）\n",
    "    es_idx = ensure_both_classes_in_es(y_tr_fit, es_idx, tr_idx, rng, max_tries=10)\n",
    "\n",
    "    # 3) 围绕 best_params 做小扰动\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * JITTER_SCALE\n",
    "    cfg = BASE_PARAMS.copy()\n",
    "    cfg[\"subsample\"]         = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"]  = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]        = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]         = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, verbosity=-1,\n",
    "        random_state=RANDOM_SEED + b,\n",
    "        **cfg\n",
    "    )\n",
    "\n",
    "    # 4) 仅用 ES 片早停；外部验证片不参与 early stopping\n",
    "    clf.fit(\n",
    "        X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "        eval_set=[(X_tr_fit[es_idx], y_tr_fit[es_idx])],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200, verbose=False)]\n",
    "    )\n",
    "    models.append(clf)\n",
    "\n",
    "    # 5) 用模型在【外部验证片】与【测试集】上推理（仅评估/学权重与阈值）\n",
    "    val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "    te_probs_list.append(clf.predict_proba(X_te)[:, 1])\n",
    "\n",
    "val_probs = np.column_stack(val_probs_list)   # [n_val, B]\n",
    "te_probs  = np.column_stack(te_probs_list)    # [n_test, B]\n",
    "\n",
    "# =========================\n",
    "# 5) 融合方式一：简单平均 + 在外部验证片寻优阈值（统一口径）\n",
    "# =========================\n",
    "val_avg = val_probs.mean(axis=1)\n",
    "t_avg   = best_thr_on_val(y_val_fit, val_avg, metric='accuracy')\n",
    "y_prob_avg = te_probs.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg, thr=t_avg, title=\"Bagging (Simple Average, thr-opt on val)\")\n",
    "\n",
    "# =========================\n",
    "# 6) 融合方式二：按验证AUC加权（softmax 平滑）+ 在外部验证片寻优阈值（统一口径）\n",
    "# =========================\n",
    "weights = []\n",
    "for j in range(BAGS):\n",
    "    auc_j = safe_auc(y_val_fit, val_probs[:, j])\n",
    "    if np.isnan(auc_j):\n",
    "        auc_j = 0.5\n",
    "    weights.append(max(auc_j, 0.0))\n",
    "weights = np.array(weights)\n",
    "if weights.sum() == 0:\n",
    "    alphas = np.ones(BAGS) / BAGS\n",
    "else:\n",
    "    ex = np.exp(weights - weights.max())\n",
    "    alphas = ex / ex.sum()\n",
    "\n",
    "val_wavg = (val_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "t_wavg   = best_thr_on_val(y_val_fit, val_wavg, metric='accuracy')\n",
    "y_prob_wavg = (te_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "print(\"Blend weights (first 10):\", np.round(alphas[:10], 4))\n",
    "report_all(y_te, y_prob_wavg, thr=t_wavg, title=\"Bagging (Val-AUC Weighted, thr-opt on val)\")\n",
    "\n",
    "# =========================\n",
    "# 7) 融合方式三：Optuna 在外部验证片学权重 + 选阈值（目标=Accuracy）\n",
    "#    —— 可复现：固定TPE种子\n",
    "# =========================\n",
    "def objective_blend_on_val(trial):\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(BAGS)])\n",
    "    a  = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "    val_blend = (val_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "    ths  = np.linspace(0.01, 0.99, 99)\n",
    "    accs = [accuracy_score(y_val_fit, (val_blend >= t).astype(int)) for t in ths]\n",
    "    idx  = int(np.argmax(accs))\n",
    "    best_t  = float(ths[idx])\n",
    "    best_acc = float(accs[idx])\n",
    "    trial.set_user_attr(\"best_t\", best_t)\n",
    "    return best_acc\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective_blend_on_val, n_trials=100, show_progress_bar=False)\n",
    "\n",
    "best_w = np.array([study.best_params[k] for k in sorted(study.best_params.keys(), key=lambda s: int(s[1:]))])\n",
    "a = np.exp(best_w); a /= (a.sum() + 1e-12)\n",
    "best_t = float(study.best_trial.user_attrs[\"best_t\"])\n",
    "print(\"Optuna alphas (first 10):\", np.round(a[:10], 4))\n",
    "\n",
    "te_blend = (te_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, te_blend, thr=best_t, title=\"Bagging (Optuna Weights, Acc-opt, no-leak)\")\n",
    "\n",
    "# =========================\n",
    "# 8) 用最优流程 + 全量80%重训（block bootstrap & ES双类保障），在20%测试集上最终评估\n",
    "#    —— 简单平均（阈值使用在 val 上学到的 t_avg）\n",
    "#    —— Val-AUC加权（阈值 t_wavg）\n",
    "#    —— Optuna权重（阈值 best_t）\n",
    "# =========================\n",
    "print(\"\\n===== Retrain all bags on FULL 80% train (inner ES only, block bootstrap), then test on 20% =====\")\n",
    "FINAL_BASE = BASE_PARAMS\n",
    "\n",
    "te_probs_final_list = []\n",
    "n_full = X_tr_raw.shape[0]\n",
    "\n",
    "for b in range(BAGS):\n",
    "    # 全量80%训练区间的 block bootstrap\n",
    "    idx_boot = block_bootstrap(n_full, SAMPLE_RATIO, block=BLOCK_SIZE, rng=rng)\n",
    "    es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "    tr_idx = idx_boot[:es_pt]\n",
    "    es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "    # 保障 ES 双类\n",
    "    es_idx = ensure_both_classes_in_es(y_tr, es_idx, tr_idx, rng, max_tries=10)\n",
    "\n",
    "    # 参数扰动\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * JITTER_SCALE\n",
    "    cfg = FINAL_BASE.copy()\n",
    "    cfg[\"subsample\"]         = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"]  = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]        = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]         = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "\n",
    "    clf_final = LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, verbosity=-1,\n",
    "        random_state=10000 + b,\n",
    "        **cfg\n",
    "    )\n",
    "\n",
    "    clf_final.fit(\n",
    "        X_tr_raw[tr_idx], y_tr[tr_idx],\n",
    "        eval_set=[(X_tr_raw[es_idx], y_tr[es_idx])],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200, verbose=False)]\n",
    "    )\n",
    "    te_probs_final_list.append(clf_final.predict_proba(X_te)[:, 1])\n",
    "\n",
    "te_probs_final = np.column_stack(te_probs_final_list)\n",
    "\n",
    "# —— 融合A：简单平均（最终版；阈值沿用 t_avg，不在测试集学习）\n",
    "y_prob_avg_final = te_probs_final.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg_final, thr=t_avg, title=\"FINAL Retrain — Simple Average (thr from val)\")\n",
    "\n",
    "# —— 融合B：Val-AUC加权（阈值沿用 t_wavg）\n",
    "y_prob_wavg_final = (te_probs_final * alphas.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_wavg_final, thr=t_wavg, title=\"FINAL Retrain — Val-AUC Weighted (thr from val)\")\n",
    "\n",
    "# —— 融合C：Optuna权重（阈值沿用 best_t）\n",
    "y_prob_opt_final = (te_probs_final * a.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_opt_final, thr=best_t, title=\"FINAL Retrain — Optuna Weights (thr from val)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e1b2ad",
   "metadata": {},
   "source": [
    "### ACC全调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-09-03 15:32:13,734] A new study created in memory with name: no-name-a31edb1c-67da-42c4-8f40-491ce3b33b8c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 1234, Val-fit size: 138, Classes in Val: (array([0, 1]), array([99, 39]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:32:18,094] Trial 0 finished with value: 0.6159420289855072 and parameters: {'learning_rate': 0.03574712922600244, 'num_leaves': 244, 'max_depth': 10, 'min_child_samples': 182, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'reg_alpha': 2.5502648504032812e-08, 'reg_lambda': 0.011567327199145964, 'n_estimators': 1282, 'BAGS': 31, 'SAMPLE_RATIO': 0.6072045730035308, 'JITTER_SCALE': 0.2439819704323989, 'BLOCK_SIZE': 51}. Best is trial 0 with value: 0.6159420289855072.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:32:21,025] Trial 1 finished with value: 0.5652173913043478 and parameters: {'learning_rate': 0.020589728197687916, 'num_leaves': 58, 'max_depth': 4, 'min_child_samples': 95, 'subsample': 0.762378215816119, 'colsample_bytree': 0.7159725093210578, 'reg_alpha': 1.092959278721938e-06, 'reg_lambda': 0.00019185373703841887, 'n_estimators': 451, 'BAGS': 17, 'SAMPLE_RATIO': 0.7282266451527921, 'JITTER_SCALE': 0.14121399684340719, 'BLOCK_SIZE': 48}. Best is trial 0 with value: 0.6159420289855072.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:33:02,283] Trial 2 finished with value: 0.6304347826086957 and parameters: {'learning_rate': 0.019721610970574007, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 18, 'subsample': 0.8037724259507192, 'colsample_bytree': 0.5852620618436457, 'reg_alpha': 2.853390105240219e-08, 'reg_lambda': 0.04387314432435398, 'n_estimators': 1939, 'BAGS': 34, 'SAMPLE_RATIO': 0.7066148192106797, 'JITTER_SCALE': 0.06953442280127678, 'BLOCK_SIZE': 43}. Best is trial 2 with value: 0.6304347826086957.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:33:28,610] Trial 3 finished with value: 0.6304347826086957 and parameters: {'learning_rate': 0.044684675025045834, 'num_leaves': 44, 'max_depth': 7, 'min_child_samples': 15, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085, 'reg_alpha': 0.000434166180036173, 'reg_lambda': 1.5204688692198897e-06, 'n_estimators': 1136, 'BAGS': 26, 'SAMPLE_RATIO': 0.6646990594339345, 'JITTER_SCALE': 0.24391692555291172, 'BLOCK_SIZE': 48}. Best is trial 2 with value: 0.6304347826086957.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:33:31,771] Trial 4 finished with value: 0.5869565217391305 and parameters: {'learning_rate': 0.24420460844911424, 'num_leaves': 230, 'max_depth': 8, 'min_child_samples': 277, 'subsample': 0.5442462510259598, 'colsample_bytree': 0.5979914312095727, 'reg_alpha': 2.072960479129113e-08, 'reg_lambda': 1.8937049541631268e-06, 'n_estimators': 900, 'BAGS': 16, 'SAMPLE_RATIO': 0.8900581282031752, 'JITTER_SCALE': 0.12135066533871786, 'BLOCK_SIZE': 20}. Best is trial 2 with value: 0.6304347826086957.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:05,807] Trial 5 finished with value: 0.6376811594202898 and parameters: {'learning_rate': 0.06333268775321843, 'num_leaves': 48, 'max_depth': 11, 'min_child_samples': 27, 'subsample': 0.9934434683002586, 'colsample_bytree': 0.8861223846483287, 'reg_alpha': 2.4604229580184137e-07, 'reg_lambda': 1.0930872279404512e-08, 'n_estimators': 1668, 'BAGS': 31, 'SAMPLE_RATIO': 0.8551525088143455, 'JITTER_SCALE': 0.20425406933718915, 'BLOCK_SIZE': 9}. Best is trial 5 with value: 0.6376811594202898.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:15,373] Trial 6 finished with value: 0.6014492753623188 and parameters: {'learning_rate': 0.0338452204120114, 'num_leaves': 42, 'max_depth': 11, 'min_child_samples': 189, 'subsample': 0.6654490124263246, 'colsample_bytree': 0.5317791751430119, 'reg_alpha': 1.5027137214154512e-06, 'reg_lambda': 1.8892231305534347e-06, 'n_estimators': 1514, 'BAGS': 29, 'SAMPLE_RATIO': 0.9105244599017143, 'JITTER_SCALE': 0.14444298503238986, 'BLOCK_SIZE': 11}. Best is trial 5 with value: 0.6376811594202898.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:17,062] Trial 7 finished with value: 0.6666666666666666 and parameters: {'learning_rate': 0.1131225105716033, 'num_leaves': 198, 'max_depth': 8, 'min_child_samples': 233, 'subsample': 0.7468977981821954, 'colsample_bytree': 0.7613664146909971, 'reg_alpha': 9.835289062589953e-06, 'reg_lambda': 1.5063777323554413e-08, 'n_estimators': 394, 'BAGS': 9, 'SAMPLE_RATIO': 0.8227436439423231, 'JITTER_SCALE': 0.11287119621526534, 'BLOCK_SIZE': 33}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:23,160] Trial 8 finished with value: 0.6159420289855072 and parameters: {'learning_rate': 0.21907142272152816, 'num_leaves': 75, 'max_depth': 7, 'min_child_samples': 228, 'subsample': 0.6143990827458112, 'colsample_bytree': 0.5384899549143964, 'reg_alpha': 1.067235272504377e-06, 'reg_lambda': 1.3444634828135513e-07, 'n_estimators': 1874, 'BAGS': 34, 'SAMPLE_RATIO': 0.8216913147786482, 'JITTER_SCALE': 0.22429211803754356, 'BLOCK_SIZE': 50}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:33,684] Trial 9 finished with value: 0.6231884057971014 and parameters: {'learning_rate': 0.018861950443028862, 'num_leaves': 230, 'max_depth': 8, 'min_child_samples': 244, 'subsample': 0.9480456499617467, 'colsample_bytree': 0.6590017374859319, 'reg_alpha': 5.893366793227604e-08, 'reg_lambda': 3.940452872934755e-07, 'n_estimators': 969, 'BAGS': 34, 'SAMPLE_RATIO': 0.9012557041397202, 'JITTER_SCALE': 0.051390426106238146, 'BLOCK_SIZE': 33}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:36,045] Trial 10 finished with value: 0.6594202898550725 and parameters: {'learning_rate': 0.10796911736614814, 'num_leaves': 174, 'max_depth': 3, 'min_child_samples': 113, 'subsample': 0.8575848060983976, 'colsample_bytree': 0.8451235367845726, 'reg_alpha': 0.05228718023161359, 'reg_lambda': 0.0001583490615396883, 'n_estimators': 262, 'BAGS': 8, 'SAMPLE_RATIO': 0.7861878782490426, 'JITTER_SCALE': 0.10516378423600369, 'BLOCK_SIZE': 30}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:38,316] Trial 11 finished with value: 0.6521739130434783 and parameters: {'learning_rate': 0.10945382315542451, 'num_leaves': 174, 'max_depth': 3, 'min_child_samples': 120, 'subsample': 0.8446050026958349, 'colsample_bytree': 0.8538782077204119, 'reg_alpha': 0.043911446389122616, 'reg_lambda': 0.00011990576668458494, 'n_estimators': 213, 'BAGS': 8, 'SAMPLE_RATIO': 0.7836468518081452, 'JITTER_SCALE': 0.09666945037631772, 'BLOCK_SIZE': 31}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:41,714] Trial 12 finished with value: 0.6159420289855072 and parameters: {'learning_rate': 0.11079857765570289, 'num_leaves': 177, 'max_depth': 5, 'min_child_samples': 87, 'subsample': 0.865455651151708, 'colsample_bytree': 0.9761720341668814, 'reg_alpha': 0.00012094560122783087, 'reg_lambda': 0.0012063187888270463, 'n_estimators': 607, 'BAGS': 8, 'SAMPLE_RATIO': 0.7911175725066022, 'JITTER_SCALE': 0.10232372324132301, 'BLOCK_SIZE': 30}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:45,242] Trial 13 finished with value: 0.6014492753623188 and parameters: {'learning_rate': 0.11789694175693867, 'num_leaves': 187, 'max_depth': 5, 'min_child_samples': 148, 'subsample': 0.6999903496918575, 'colsample_bytree': 0.7870538949990543, 'reg_alpha': 0.00337305083470318, 'reg_lambda': 1.3978203941758101e-05, 'n_estimators': 204, 'BAGS': 15, 'SAMPLE_RATIO': 0.7424307744021793, 'JITTER_SCALE': 0.1792258621122486, 'BLOCK_SIZE': 22}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:47,702] Trial 14 finished with value: 0.6086956521739131 and parameters: {'learning_rate': 0.07240640087678221, 'num_leaves': 125, 'max_depth': 6, 'min_child_samples': 278, 'subsample': 0.8862263283638486, 'colsample_bytree': 0.7686880567712793, 'reg_alpha': 1.5514670998945064e-05, 'reg_lambda': 1.4541548230479766e-08, 'n_estimators': 654, 'BAGS': 12, 'SAMPLE_RATIO': 0.8358254179168942, 'JITTER_SCALE': 0.09029362945735814, 'BLOCK_SIZE': 39}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:53,425] Trial 15 finished with value: 0.644927536231884 and parameters: {'learning_rate': 0.010839293998112624, 'num_leaves': 136, 'max_depth': 9, 'min_child_samples': 207, 'subsample': 0.7361813669205513, 'colsample_bytree': 0.8689949042427481, 'reg_alpha': 0.071938770324786, 'reg_lambda': 0.0012862336995683645, 'n_estimators': 459, 'BAGS': 20, 'SAMPLE_RATIO': 0.7642711937172586, 'JITTER_SCALE': 0.17083170990023994, 'BLOCK_SIZE': 21}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:34:59,318] Trial 16 finished with value: 0.5797101449275363 and parameters: {'learning_rate': 0.1619582695853621, 'num_leaves': 211, 'max_depth': 3, 'min_child_samples': 148, 'subsample': 0.7739492794040821, 'colsample_bytree': 0.9397503979440351, 'reg_alpha': 2.3454227979843136e-05, 'reg_lambda': 2.1286050934698092e-05, 'n_estimators': 778, 'BAGS': 21, 'SAMPLE_RATIO': 0.9473624305770886, 'JITTER_SCALE': 0.12107461966066543, 'BLOCK_SIZE': 58}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:17,434] Trial 17 finished with value: 0.6014492753623188 and parameters: {'learning_rate': 0.08348447835760309, 'num_leaves': 116, 'max_depth': 12, 'min_child_samples': 58, 'subsample': 0.6593712979980785, 'colsample_bytree': 0.7013314355870788, 'reg_alpha': 0.004281445174968774, 'reg_lambda': 0.0013684531194677909, 'n_estimators': 403, 'BAGS': 39, 'SAMPLE_RATIO': 0.6843194896863077, 'JITTER_SCALE': 0.11530555162605957, 'BLOCK_SIZE': 38}. Best is trial 7 with value: 0.6666666666666666.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:19,319] Trial 18 finished with value: 0.6739130434782609 and parameters: {'learning_rate': 0.15231232857318447, 'num_leaves': 200, 'max_depth': 6, 'min_child_samples': 297, 'subsample': 0.8151707562287427, 'colsample_bytree': 0.8206437930523058, 'reg_alpha': 7.388506066296081e-06, 'reg_lambda': 0.00017971108760201173, 'n_estimators': 353, 'BAGS': 12, 'SAMPLE_RATIO': 0.8125813096266427, 'JITTER_SCALE': 0.07516685734075675, 'BLOCK_SIZE': 25}. Best is trial 18 with value: 0.6739130434782609.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:21,374] Trial 19 finished with value: 0.6594202898550725 and parameters: {'learning_rate': 0.18158587762820758, 'num_leaves': 204, 'max_depth': 6, 'min_child_samples': 300, 'subsample': 0.8069247075317936, 'colsample_bytree': 0.803839924557089, 'reg_alpha': 7.982561922896527e-06, 'reg_lambda': 5.9515981587364163e-08, 'n_estimators': 638, 'BAGS': 12, 'SAMPLE_RATIO': 0.8692555891071746, 'JITTER_SCALE': 0.07516167583105596, 'BLOCK_SIZE': 14}. Best is trial 18 with value: 0.6739130434782609.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:23,706] Trial 20 finished with value: 0.6304347826086957 and parameters: {'learning_rate': 0.28766626079576424, 'num_leaves': 154, 'max_depth': 9, 'min_child_samples': 249, 'subsample': 0.7312753625198511, 'colsample_bytree': 0.7209572536513189, 'reg_alpha': 0.00013787926469356114, 'reg_lambda': 5.548246993895729e-06, 'n_estimators': 1225, 'BAGS': 12, 'SAMPLE_RATIO': 0.821869486622639, 'JITTER_SCALE': 0.05277951163580338, 'BLOCK_SIZE': 23}. Best is trial 18 with value: 0.6739130434782609.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:25,325] Trial 21 finished with value: 0.5797101449275363 and parameters: {'learning_rate': 0.13122964316684854, 'num_leaves': 202, 'max_depth': 4, 'min_child_samples': 295, 'subsample': 0.9024943955268685, 'colsample_bytree': 0.8239852758104291, 'reg_alpha': 3.0501617446773906e-06, 'reg_lambda': 9.679750366277846e-05, 'n_estimators': 356, 'BAGS': 8, 'SAMPLE_RATIO': 0.7955550802461197, 'JITTER_SCALE': 0.07868288579408499, 'BLOCK_SIZE': 27}. Best is trial 18 with value: 0.6739130434782609.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:27,385] Trial 22 finished with value: 0.6521739130434783 and parameters: {'learning_rate': 0.08614627008037694, 'num_leaves': 104, 'max_depth': 6, 'min_child_samples': 259, 'subsample': 0.8243715402074079, 'colsample_bytree': 0.9374990632294782, 'reg_alpha': 0.0009674284216222896, 'reg_lambda': 0.0002276044030103212, 'n_estimators': 314, 'BAGS': 12, 'SAMPLE_RATIO': 0.7599881969144473, 'JITTER_SCALE': 0.10486304016880461, 'BLOCK_SIZE': 36}. Best is trial 18 with value: 0.6739130434782609.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:29,644] Trial 23 finished with value: 0.6086956521739131 and parameters: {'learning_rate': 0.16043671226801315, 'num_leaves': 162, 'max_depth': 5, 'min_child_samples': 215, 'subsample': 0.9172112924239306, 'colsample_bytree': 0.7587616230796264, 'reg_alpha': 5.5648002895767115e-05, 'reg_lambda': 0.005192631682543205, 'n_estimators': 490, 'BAGS': 10, 'SAMPLE_RATIO': 0.8109442592050149, 'JITTER_SCALE': 0.12986009234998558, 'BLOCK_SIZE': 16}. Best is trial 18 with value: 0.6739130434782609.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:35,593] Trial 24 finished with value: 0.6014492753623188 and parameters: {'learning_rate': 0.052978572044681004, 'num_leaves': 254, 'max_depth': 9, 'min_child_samples': 170, 'subsample': 0.7837196351513678, 'colsample_bytree': 0.8350923829956383, 'reg_alpha': 3.2768617600318875e-07, 'reg_lambda': 4.8598433941101576e-05, 'n_estimators': 558, 'BAGS': 19, 'SAMPLE_RATIO': 0.8554514831125637, 'JITTER_SCALE': 0.1720978686628934, 'BLOCK_SIZE': 29}. Best is trial 18 with value: 0.6739130434782609.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Joint Tuning] Best value (Val Acc of W-avg@best_thr): 0.6739130434782609\n",
      "[Joint Tuning] Best params: {'learning_rate': 0.15231232857318447, 'num_leaves': 200, 'max_depth': 6, 'min_child_samples': 297, 'subsample': 0.8151707562287427, 'colsample_bytree': 0.8206437930523058, 'reg_alpha': 7.388506066296081e-06, 'reg_lambda': 0.00017971108760201173, 'n_estimators': 353, 'BAGS': 12, 'SAMPLE_RATIO': 0.8125813096266427, 'JITTER_SCALE': 0.07516685734075675, 'BLOCK_SIZE': 25}\n",
      "[Best] BAGS=12, SAMPLE_RATIO=0.813, JITTER_SCALE=0.075, BLOCK_SIZE=25\n",
      "       BASE_CFG: {'learning_rate': 0.15231232857318447, 'num_leaves': 200, 'max_depth': 6, 'min_child_samples': 297, 'subsample': 0.8151707562287427, 'colsample_bytree': 0.8206437930523058, 'reg_alpha': 7.388506066296081e-06, 'reg_lambda': 0.00017971108760201173, 'n_estimators': 353}\n",
      "       (Val) alphas first 10: [0.0788 0.0866 0.0835 0.0788 0.0866 0.0808 0.0819 0.0854 0.0822 0.084 ]\n",
      "       (Val) best thr (accuracy): 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-09-03 15:35:37,231] A new study created in memory with name: no-name-3680fdfd-54d7-460f-bb93-80fda953c0c5\n",
      "[I 2025-09-03 15:35:37,282] Trial 0 finished with value: 0.717391304347826 and parameters: {'w0': -0.6272994057631875, 'w1': 2.2535715320495804, 'w2': 1.1599697090570253, 'w3': 0.493292420985183, 'w4': -1.7199067977878175, 'w5': -1.7200273983189867, 'w6': -2.2095819391590026, 'w7': 1.8308807288746758, 'w8': 0.5055750587160439, 'w9': 1.0403628889802272, 'w10': -2.3970775285209878, 'w11': 2.3495492608099715}. Best is trial 0 with value: 0.717391304347826.\n",
      "[I 2025-09-03 15:35:37,338] Trial 1 finished with value: 0.7246376811594203 and parameters: {'w0': 1.662213204002109, 'w1': -1.4383044466086192, 'w2': -1.590875163964497, 'w3': -1.582977450732831, 'w4': -0.9787887852023114, 'w5': 0.12378215816118932, 'w6': -0.3402749067894213, 'w7': -1.0438542990097903, 'w8': 0.5592644736118975, 'w9': -1.8025306967397907, 'w10': -1.0392767573239092, 'w11': -0.6681907835315415}. Best is trial 1 with value: 0.7246376811594203.\n",
      "[I 2025-09-03 15:35:37,388] Trial 2 finished with value: 0.717391304347826 and parameters: {'w0': -0.21965007891482013, 'w1': 1.4258798069650682, 'w2': -1.5016310892082014, 'w3': 0.07117219206805814, 'w4': 0.46207284431021245, 'w5': -2.2677479364000113, 'w6': 0.5377242595071916, 'w7': -1.6473793815635425, 'w8': -2.1747420350736024, 'w9': 2.2444276862666666, 'w10': 2.328160165372797, 'w11': 1.5419867405823053}. Best is trial 1 with value: 0.7246376811594203.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== (Tuned) Bagging — Simple Avg (thr from val) Performance ====\n",
      "Accuracy:      0.607558\n",
      "AUC:           0.651272\n",
      "PR-AUC:        0.516116\n",
      "LogLoss:       0.655850\n",
      "Precision@0.650: 0.566667\n",
      "Recall@0.650:    0.122302\n",
      "F1@0.650:        0.201183\n",
      "\n",
      "==== (Tuned) Bagging — Val-AUC Weighted (thr from val) Performance ====\n",
      "Accuracy:      0.622093\n",
      "AUC:           0.651658\n",
      "PR-AUC:        0.517052\n",
      "LogLoss:       0.656073\n",
      "Precision@0.430: 0.526316\n",
      "Recall@0.430:    0.647482\n",
      "F1@0.430:        0.580645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 15:35:37,436] Trial 3 finished with value: 0.717391304347826 and parameters: {'w0': -0.9769311541331467, 'w1': -2.0116394299680804, 'w2': 0.9211651325607844, 'w3': -0.29923753130199326, 'w4': -1.8898088257761059, 'w5': -0.024115449443649073, 'w6': -2.328057394423908, 'w7': 2.0466020103939107, 'w8': -1.2061000919999154, 'w9': 0.8126114217699101, 'w10': -0.9414446195529451, 'w11': 0.10034010588905407}. Best is trial 1 with value: 0.7246376811594203.\n",
      "[I 2025-09-03 15:35:37,489] Trial 4 finished with value: 0.7246376811594203 and parameters: {'w0': 0.23355139671639824, 'w1': -1.5757277223723647, 'w2': 2.347923138822793, 'w3': 1.3756641168055728, 'w4': 2.1974947078209457, 'w5': 1.9741367521382438, 'w6': 0.4894998940554256, 'w7': 2.1093711751155837, 'w8': -2.0575374897404024, 'w9': -1.520085687904274, 'w10': -2.27386355544731, 'w11': -0.8733483461836782}. Best is trial 1 with value: 0.7246376811594203.\n",
      "[I 2025-09-03 15:35:37,537] Trial 5 finished with value: 0.717391304347826 and parameters: {'w0': -0.5566135515525898, 'w1': -1.1432548411305206, 'w2': 1.6436875457596472, 'w3': -0.7162333665320535, 'w4': -1.0953274515630962, 'w5': 0.21348041579124244, 'w6': -1.7953788751261868, 'w7': 1.5109849037701988, 'w8': -2.127246781601146, 'w9': 2.4344346830025865, 'w10': 1.3612238464832869, 'w11': -1.506421592329138}. Best is trial 1 with value: 0.7246376811594203.\n",
      "[I 2025-09-03 15:35:37,586] Trial 6 finished with value: 0.7246376811594203 and parameters: {'w0': -2.472389414381988, 'w1': 1.5773071422741705, 'w2': 1.0342867192380858, 'w3': 1.1450358402049368, 'w4': 1.3563517334297286, 'w5': -2.129776741329548, 'w6': -0.7076713572786368, 'w7': -1.9206547023743514, 'w8': 1.8155171293779677, 'w9': 0.6164906341377896, 'w10': -0.8455098757367541, 'w11': -2.1822082485698817}. Best is trial 1 with value: 0.7246376811594203.\n",
      "[I 2025-09-03 15:35:37,635] Trial 7 finished with value: 0.7246376811594203 and parameters: {'w0': -0.945088391421689, 'w1': -0.8740833898662648, 'w2': 1.1480308916903201, 'w3': 0.6877873567760657, 'w4': 1.9360637128816327, 'w5': -0.13892537419025341, 'w6': -1.9020287703084915, 'w7': 1.0662239361149748, 'w8': 1.3039252430844872, 'w9': 0.3063859878474813, 'w10': 1.3548358997728052, 'w11': -0.031022018178046284}. Best is trial 1 with value: 0.7246376811594203.\n",
      "[I 2025-09-03 15:35:37,685] Trial 8 finished with value: 0.7246376811594203 and parameters: {'w0': 0.1136641469099704, 'w1': -0.36229490820725196, 'w2': -2.372904366279524, 'w3': -1.9605428650334777, 'w4': -2.342854071566329, 'w5': 0.6820520563189021, 'w6': -0.9282200946183665, 'w7': 0.042853455823514075, 'w8': 2.0378323696304648, 'w9': -1.2535388542556252, 'w10': -0.44808538482185156, 'w11': 1.2777556927152434}. Best is trial 1 with value: 0.7246376811594203.\n",
      "[I 2025-09-03 15:35:37,733] Trial 9 finished with value: 0.717391304347826 and parameters: {'w0': -1.3560091725418877, 'w1': -2.115100450856035, 'w2': -1.0512427354311598, 'w3': -1.693893563729978, 'w4': 2.148488261712865, 'w5': 1.5406018978220848, 'w6': 0.6670187825521174, 'w7': 1.857302950938589, 'w8': 1.5183603844955726, 'w9': -1.567149705569821, 'w10': 1.962794992449889, 'w11': 0.1967112095782535}. Best is trial 1 with value: 0.7246376811594203.\n",
      "[I 2025-09-03 15:35:37,840] Trial 10 finished with value: 0.7318840579710145 and parameters: {'w0': 2.2161106052259547, 'w1': 0.3357192959757387, 'w2': -0.35011400747566784, 'w3': 2.1614517095589374, 'w4': -0.5139546181776886, 'w5': -0.9971758847532697, 'w6': 2.2988537297271012, 'w7': -0.8169984963046117, 'w8': -0.30074689338378024, 'w9': -2.4384441521753124, 'w10': 0.45237344796864853, 'w11': -0.9756289464994481}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:37,944] Trial 11 finished with value: 0.7318840579710145 and parameters: {'w0': 2.351626743973064, 'w1': 0.49906008406649105, 'w2': -0.13642996671025645, 'w3': 2.2215919214072635, 'w4': -0.4212475358193805, 'w5': -0.9854733257102068, 'w6': 2.191207583390597, 'w7': -0.5784605291867386, 'w8': -0.33581806584463814, 'w9': -2.4653495088385804, 'w10': 0.533425041274395, 'w11': -0.8591921936798315}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,040] Trial 12 finished with value: 0.7246376811594203 and parameters: {'w0': 2.45431439712704, 'w1': 0.6668803749973429, 'w2': -0.1228396309915592, 'w3': 2.4800826587371776, 'w4': 0.07111461586594377, 'w5': -0.945332232702126, 'w6': 2.4968121932077567, 'w7': -0.4153769583624968, 'w8': -0.6146243087442115, 'w9': -2.320316902836098, 'w10': 0.43337621949827815, 'w11': -2.204100504026494}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,137] Trial 13 finished with value: 0.7318840579710145 and parameters: {'w0': 1.324988242571844, 'w1': 0.6325708333031418, 'w2': -0.16676939615378533, 'w3': 2.480084946806068, 'w4': -0.5940516751208409, 'w5': -1.0675714896001265, 'w6': 2.338064412315079, 'w7': 0.27357203354278137, 'w8': -0.23836843561195786, 'w9': -0.5810881429925172, 'w10': 0.3978302473303244, 'w11': -1.1971392839363364}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,234] Trial 14 finished with value: 0.7246376811594203 and parameters: {'w0': 2.2418592660287824, 'w1': 0.2199330378285161, 'w2': -0.6308024389360354, 'w3': 1.727365454353905, 'w4': 0.7649406064145388, 'w5': -1.0841811814113629, 'w6': 1.5647363803595409, 'w7': -0.88053254669213, 'w8': -1.1216807762528531, 'w9': -2.487440936423554, 'w10': 0.873542571507262, 'w11': -0.4802037317626773}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,332] Trial 15 finished with value: 0.7318840579710145 and parameters: {'w0': 1.027397558170657, 'w1': -0.04454303515993352, 'w2': 0.41970113191175407, 'w3': 1.9551721481243727, 'w4': -0.3189691448148241, 'w5': -0.8136853012002457, 'w6': 1.5894080136685724, 'w7': -2.3433196498229667, 'w8': 0.4146895185980577, 'w9': -0.6145411720891849, 'w10': -0.15752394810109882, 'w11': -1.6245747971034548}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,429] Trial 16 finished with value: 0.7246376811594203 and parameters: {'w0': 1.871158895275773, 'w1': 1.3670059830083665, 'w2': 0.32470144621751906, 'w3': 1.883506918935534, 'w4': -1.1909944318268575, 'w5': -1.6476936073394344, 'w6': 1.5937841904106453, 'w7': 0.5408886479118689, 'w8': -1.1101219660680686, 'w9': -0.7399563644888445, 'w10': -1.582653027406965, 'w11': 0.6616479621961715}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,527] Trial 17 finished with value: 0.717391304347826 and parameters: {'w0': 0.8805498772353254, 'w1': -0.44889788705345113, 'w2': -0.73178329732664, 'w3': 1.0988419825198557, 'w4': 0.1223349066692308, 'w5': 0.9999865749726238, 'w6': 1.9034743558083076, 'w7': -0.566854338055061, 'w8': -0.11382030246877245, 'w9': -2.0342628524403494, 'w10': 0.5776761154347215, 'w11': -1.6507689676440407}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,641] Trial 18 finished with value: 0.717391304347826 and parameters: {'w0': 0.5538117967606997, 'w1': 0.7862078319378871, 'w2': -2.046525085714518, 'w3': -2.496748778396491, 'w4': 0.9230574562185107, 'w5': -0.49631566843633934, 'w6': 1.181465439943041, 'w7': -1.4303477301239076, 'w8': 1.093697666461243, 'w9': -1.0723982054879442, 'w10': 1.186722575118026, 'w11': -0.3752167611657925}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,742] Trial 19 finished with value: 0.7246376811594203 and parameters: {'w0': 1.8885189956287989, 'w1': 2.3480243191255528, 'w2': -0.5327219497131555, 'w3': 1.6249791407950052, 'w4': -0.4271079838413899, 'w5': -1.5629880038316697, 'w6': 1.0031122233487482, 'w7': 0.6618872442108767, 'w8': -0.6736402317846493, 'w9': -0.2031013145118079, 'w10': -0.05489217322080253, 'w11': 0.6312637085017068}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,840] Trial 20 finished with value: 0.717391304347826 and parameters: {'w0': 2.4964673854188657, 'w1': 0.22456070696780084, 'w2': -1.249369519975106, 'w3': -0.8150783326423139, 'w4': -1.551528245883854, 'w5': -0.45618914396458676, 'w6': 2.041504074988645, 'w7': -0.2768689053690778, 'w8': -1.5986360004212157, 'w9': 1.7985111647798786, 'w10': 1.67472119257295, 'w11': -1.19685281593471}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:38,938] Trial 21 finished with value: 0.7318840579710145 and parameters: {'w0': 1.287311054830343, 'w1': 1.0392003487720007, 'w2': -0.08794420154473906, 'w3': 2.4956850584747454, 'w4': -0.6434973829353672, 'w5': -1.220452664912658, 'w6': 2.308320220071751, 'w7': 0.16022231786775293, 'w8': -0.14314244286120265, 'w9': -2.082685351780359, 'w10': 0.6734520349131117, 'w11': -1.0932962758298237}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,033] Trial 22 finished with value: 0.7246376811594203 and parameters: {'w0': 1.4827687757146615, 'w1': 0.5235926855406148, 'w2': 0.44136628474307066, 'w3': 2.1720490621238366, 'w4': -0.5927721475104495, 'w5': -0.6622249954410578, 'w6': 2.45872078440714, 'w7': -1.0455021019652584, 'w8': -0.48598883434691004, 'w9': -0.3314723278268399, 'w10': 0.22034106190940606, 'w11': -2.4352055760815983}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,132] Trial 23 finished with value: 0.7246376811594203 and parameters: {'w0': 1.8917799413151288, 'w1': 1.8504862923109746, 'w2': -0.2860254399869925, 'w3': 2.2033755560928494, 'w4': -0.2531584462559462, 'w5': -1.3842872513171018, 'w6': 1.8550225492120678, 'w7': 0.612271899455037, 'w8': 0.8710497492274736, 'w9': 1.379766992678492, 'w10': -0.36620776094530405, 'w11': -1.3086489321333976}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,229] Trial 24 finished with value: 0.7246376811594203 and parameters: {'w0': 2.220495346038059, 'w1': 1.0246057166702374, 'w2': 0.3239743524662425, 'w3': 1.5096489099287322, 'w4': 0.3317766562134759, 'w5': 0.5980302325869542, 'w6': 1.2022141018716241, 'w7': -0.6671686802358938, 'w8': 0.06659559938783846, 'w9': -1.003248800004839, 'w10': 0.8272091973295035, 'w11': -1.897413969554369}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,338] Trial 25 finished with value: 0.7246376811594203 and parameters: {'w0': 1.0945459208980313, 'w1': -0.2862804771935573, 'w2': -0.9499779115893345, 'w3': 0.7815932170364737, 'w4': -0.9304171297280637, 'w5': -2.0511408888573026, 'w6': 0.09359978569621001, 'w7': -0.1444131133562757, 'w8': -0.4075033006872625, 'w9': 0.1333016246979904, 'w10': 0.2120951073889057, 'w11': -0.8834669476448082}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,435] Trial 26 finished with value: 0.7246376811594203 and parameters: {'w0': 0.6426344720085773, 'w1': 0.33222914686470134, 'w2': -0.42923213499657153, 'w3': 2.146285536693022, 'w4': -1.4067721667048758, 'w5': -2.464531019166251, 'w6': 2.1796231993309236, 'w7': 0.28595920934192814, 'w8': 0.1839958557917647, 'w9': -1.7797356109527485, 'w10': 1.0697513959880158, 'w11': -0.1934036780744428}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,532] Trial 27 finished with value: 0.7318840579710145 and parameters: {'w0': 2.044240988772296, 'w1': 1.0256043230052871, 'w2': 0.13620054777818189, 'w3': 2.4621919571933892, 'w4': -0.8066081830610481, 'w5': -0.32589522520645664, 'w6': 1.7677092783248074, 'w7': -1.32412323492034, 'w8': -0.8923043659307393, 'w9': -2.4848413678335968, 'w10': -0.6127827327061668, 'w11': -0.8464920988796634}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,631] Trial 28 finished with value: 0.717391304347826 and parameters: {'w0': 1.410838748415459, 'w1': -0.05884794555870576, 'w2': 0.6867874219358752, 'w3': 1.2371662988907781, 'w4': -0.12663803676940472, 'w5': 2.4597823268162418, 'w6': 1.3551675556483325, 'w7': 1.275041463930515, 'w8': -1.6243544871206403, 'w9': -1.4520180243339214, 'w10': 0.2538752092370389, 'w11': -1.8104470527135157}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,730] Trial 29 finished with value: 0.7246376811594203 and parameters: {'w0': 1.5066620294284925, 'w1': 1.9857139159136246, 'w2': 1.9950570829566905, 'w3': 0.3338528953093871, 'w4': -1.8947915464262954, 'w5': -1.843977128846831, 'w6': 0.9215659632079007, 'w7': 1.0073124154878554, 'w8': 2.3992263569968086, 'w9': -2.1115406001756214, 'w10': -1.4356251554531505, 'w11': 2.1533152256259225}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,831] Trial 30 finished with value: 0.717391304347826 and parameters: {'w0': 1.7245415548028624, 'w1': -0.7154023517449509, 'w2': 1.4509023900129145, 'w3': 0.8742669246337602, 'w4': 0.5760362825715764, 'w5': -1.290146137970145, 'w6': 2.14590739543359, 'w7': -2.1029445678019245, 'w8': 0.6399567980843883, 'w9': -0.5439412013511382, 'w10': 1.7182046707437704, 'w11': 0.3887174197893878}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:39,930] Trial 31 finished with value: 0.7246376811594203 and parameters: {'w0': 0.9094279249383175, 'w1': 0.044891521172907345, 'w2': 0.5527217595162177, 'w3': 1.9538518985914801, 'w4': -0.34558797213041875, 'w5': -0.9025995194657552, 'w6': 1.5425849565573313, 'w7': -1.7639830419083524, 'w8': 0.4424105234977718, 'w9': -0.7378994468924072, 'w10': -0.04432070028828833, 'w11': -1.3986548244001957}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,033] Trial 32 finished with value: 0.717391304347826 and parameters: {'w0': 1.1807851940588256, 'w1': 0.5472535671638873, 'w2': -0.17433332337984375, 'w3': 1.8694263259304584, 'w4': -0.0731598735636041, 'w5': -0.9668160625723619, 'w6': 2.121912586278844, 'w7': 2.461241575692002, 'w8': 0.3287647135119416, 'w9': 0.42595029639411885, 'w10': -0.20569185635294135, 'w11': -0.6560526399024558}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,131] Trial 33 finished with value: 0.7246376811594203 and parameters: {'w0': 2.176337145075798, 'w1': -0.12871684511832926, 'w2': 0.09151671748666154, 'w3': 2.1527428670890574, 'w4': -0.7298813026846759, 'w5': -0.8309755766855967, 'w6': 1.7794065734875437, 'w7': -2.2508996713658047, 'w8': -0.20915293962068937, 'w9': -0.1212996291878386, 'w10': 0.4534487208383654, 'w11': -1.9061250034717383}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,223] Trial 34 finished with value: 0.717391304347826 and parameters: {'w0': 1.6357980183266718, 'w1': -0.632725838086751, 'w2': 0.8083154518424986, 'w3': 1.6463317662724377, 'w4': 0.1993021202120025, 'w5': -0.6120634588891651, 'w6': 2.35504774542746, 'w7': -0.8037030974201621, 'w8': 0.7429940199159195, 'w9': 1.3008840820886132, 'w10': -0.6551421300920965, 'w11': -1.214127047481777}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,322] Trial 35 finished with value: 0.7318840579710145 and parameters: {'w0': 0.4835553267217114, 'w1': 1.1931198599113169, 'w2': -1.5427970434084664, 'w3': 2.0457839534255013, 'w4': -1.2962768252381103, 'w5': 0.15841135953462748, 'w6': 0.15699933896942153, 'w7': -2.405874182608505, 'w8': 0.13453417959939296, 'w9': -1.8413654188453923, 'w10': -1.1374872052093672, 'w11': -0.5366578844997201}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,416] Trial 36 finished with value: 0.717391304347826 and parameters: {'w0': -0.15097405812445136, 'w1': 0.8230276538301684, 'w2': -0.7847107942764707, 'w3': 1.411448954971338, 'w4': -0.4233333198161154, 'w5': -1.476875499680671, 'w6': 2.4969518666572927, 'w7': -1.1783135039239918, 'w8': -0.8504100434556784, 'w9': -0.9589230461629492, 'w10': 0.08520587804169541, 'w11': -0.9759874388586292}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,511] Trial 37 finished with value: 0.717391304347826 and parameters: {'w0': 1.079703189841568, 'w1': 0.4143780202506078, 'w2': 0.04801159124336035, 'w3': -0.345102754337417, 'w4': 1.114262458589054, 'w5': -1.821666943660679, 'w6': 1.9605930575131425, 'w7': -1.4569802506626277, 'w8': -0.32267032732115997, 'w9': -0.5244767552049915, 'w10': 0.90971174318096, 'w11': -1.6692411438456163}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,617] Trial 38 finished with value: 0.7246376811594203 and parameters: {'w0': 2.4854393606930545, 'w1': 0.032901199258111524, 'w2': 1.3942705642439286, 'w3': 0.40954469806911864, 'w4': -0.9443516054917471, 'w5': -0.2216161907365806, 'w6': -0.30504090263329875, 'w7': -0.10042006392260461, 'w8': -1.5500875963020082, 'w9': 0.9147980723648814, 'w10': 2.373466037463367, 'w11': -1.4882315067052974}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,743] Trial 39 finished with value: 0.7318840579710145 and parameters: {'w0': -2.217883073336202, 'w1': -1.7271190483947678, 'w2': -1.131237862337158, 'w3': 2.3013735191246734, 'w4': -1.8632021658711386, 'w5': -0.698957746648479, 'w6': 1.4068800437740592, 'w7': 0.3137780510461028, 'w8': 0.4033723552700291, 'w9': -1.3300094303787067, 'w10': 0.4695620068024383, 'w11': -0.23260882370475955}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,873] Trial 40 finished with value: 0.7318840579710145 and parameters: {'w0': -0.5524356676078103, 'w1': -1.3215337898789663, 'w2': -0.40296503457132815, 'w3': 1.7721069054146585, 'w4': 0.4545735816286571, 'w5': 0.3739626900800036, 'w6': -1.2443659576321904, 'w7': -1.867214923749671, 'w8': 0.9285571478036578, 'w9': -1.674267520689049, 'w10': -0.2820681963256138, 'w11': -2.1163233087700073}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:40,997] Trial 41 finished with value: 0.7246376811594203 and parameters: {'w0': 1.3016986848734438, 'w1': 1.614363271785952, 'w2': 0.15627381465943296, 'w3': 2.3963349942408945, 'w4': -0.6481725122970315, 'w5': -1.205299786803753, 'w6': 2.232507199176281, 'w7': 0.32227981521662896, 'w8': -0.06471002057012815, 'w9': -2.0803962228032233, 'w10': 0.6545718969053835, 'w11': -1.0421842470029672}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:41,129] Trial 42 finished with value: 0.7246376811594203 and parameters: {'w0': 0.3282888240257942, 'w1': 0.85980115330092, 'w2': -0.10528033364210307, 'w3': 2.437754157765142, 'w4': -0.5677021534911326, 'w5': -1.1261659712492613, 'w6': 2.237060445217385, 'w7': 0.07232792403010746, 'w8': -0.18548734790900157, 'w9': -2.2100170573263562, 'w10': 0.7280302283882988, 'w11': -0.6852538414053981}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:41,273] Trial 43 finished with value: 0.7318840579710145 and parameters: {'w0': 0.7980285958635138, 'w1': 1.0924264300613395, 'w2': 0.6477725548312092, 'w3': 1.9645996894395086, 'w4': -0.19609345552993723, 'w5': -1.365073659411432, 'w6': 1.7403622312122538, 'w7': -0.43464748763605704, 'w8': -0.7065889521352995, 'w9': -1.8650388662593407, 'w10': 1.3861096233383723, 'w11': -1.1401210200824516}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:41,405] Trial 44 finished with value: 0.7318840579710145 and parameters: {'w0': 1.6876183704748304, 'w1': 1.3766372762243937, 'w2': 0.8974893635805269, 'w3': 2.4848914806342033, 'w4': -0.9964323051554919, 'w5': 0.014235499220544012, 'w6': 2.325077355713991, 'w7': 0.9880134175780868, 'w8': 0.2183625970030884, 'w9': -2.458265245139601, 'w10': 1.1311774625845226, 'w11': -1.5357208436051}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:41,546] Trial 45 finished with value: 0.717391304347826 and parameters: {'w0': 2.2243663614167746, 'w1': 0.6288718289079906, 'w2': 0.3450613695482457, 'w3': 1.2945354706816938, 'w4': 1.5691634680894662, 'w5': -2.023856842090283, 'w6': 1.995212534452147, 'w7': 0.1527430077873024, 'w8': -2.4294124317730796, 'w9': -2.0368737106758132, 'w10': 0.35226379097241306, 'w11': -0.7582265084918268}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:41,673] Trial 46 finished with value: 0.7246376811594203 and parameters: {'w0': 1.9927068467488485, 'w1': -0.9530857975618487, 'w2': -0.2617630709386971, 'w3': 1.0134790163617822, 'w4': 0.0472862267414359, 'w5': -1.6745782557252122, 'w6': 0.6566705317012609, 'w7': -0.2743736369654386, 'w8': -1.341611354761751, 'w9': -2.2949620955335135, 'w10': -2.4388992810136374, 'w11': -1.3197292512804029}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:41,805] Trial 47 finished with value: 0.717391304347826 and parameters: {'w0': 1.3031157733168002, 'w1': 0.13754391068883473, 'w2': -0.8413366563093988, 'w3': -1.026725150701896, 'w4': -0.5072983906750973, 'w5': -1.0938951684123663, 'w6': 1.6098395799861427, 'w7': 0.7749615806990778, 'w8': -0.480633793558409, 'w9': -1.2204178873156581, 'w10': -0.03978103172134784, 'w11': -2.1298729644506422}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:41,940] Trial 48 finished with value: 0.7318840579710145 and parameters: {'w0': 1.7175785649203523, 'w1': -0.28916144319182824, 'w2': -0.5998263367871473, 'w3': 1.5702490722285014, 'w4': -1.6199076326406467, 'w5': -0.8156795289815699, 'w6': 0.3748851201317226, 'w7': -0.9152789788450468, 'w8': 1.252509938416238, 'w9': -1.591545203189798, 'w10': 0.5913147210841234, 'w11': 0.05451031133692241}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:42,076] Trial 49 finished with value: 0.7246376811594203 and parameters: {'w0': 0.17933281143967283, 'w1': -2.4409210080394135, 'w2': 1.0656419576301177, 'w3': 2.2386499997589953, 'w4': 2.4848123474505908, 'w5': -0.518939497008542, 'w6': 0.8962067847757249, 'w7': 1.5559913574319455, 'w8': -0.022114784683916366, 'w9': 0.015423345992999549, 'w10': 0.9659434894032821, 'w11': -0.35403361339835915}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:42,216] Trial 50 finished with value: 0.7246376811594203 and parameters: {'w0': 0.9423260195386196, 'w1': 1.6770534494272655, 'w2': -0.3180785689897926, 'w3': 1.8188449915026608, 'w4': -1.0651182066684517, 'w5': -0.3294714333186253, 'w6': 2.4916656475168204, 'w7': -0.4649413706758545, 'w8': -0.8170032565468937, 'w9': -0.815459172576112, 'w10': -0.5275566194424962, 'w11': -2.4682819710367587}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:42,349] Trial 51 finished with value: 0.7246376811594203 and parameters: {'w0': 2.033002086794944, 'w1': 1.0056133876491886, 'w2': 0.14973917535873343, 'w3': 2.471192867249772, 'w4': -0.8527580821038245, 'w5': -0.2812342327593731, 'w6': 1.7496264853999801, 'w7': -1.4618025876669334, 'w8': -0.8990515786312295, 'w9': -2.448938138951487, 'w10': -0.8526590631307562, 'w11': -0.8694916017624852}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:42,478] Trial 52 finished with value: 0.7246376811594203 and parameters: {'w0': 2.294257612465368, 'w1': 1.211157546626831, 'w2': -0.05050841767862688, 'w3': 2.0430499947808025, 'w4': -1.2225663411800345, 'w5': -1.0163052219242728, 'w6': 1.9763057846821552, 'w7': -0.6751922246245557, 'w8': -1.0018798870211458, 'w9': -1.9303992729748356, 'w10': -0.6459418943695234, 'w11': -1.0613306880303846}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:42,611] Trial 53 finished with value: 0.7318840579710145 and parameters: {'w0': 1.9923800363640187, 'w1': 0.8090151371930165, 'w2': 0.3235757092928081, 'w3': 2.2682173053122336, 'w4': -0.7504623735892507, 'w5': -0.7551891261352244, 'w6': 1.3741702982467672, 'w7': -1.0359486645135798, 'w8': -1.324328042086822, 'w9': -2.2197612575491785, 'w10': -1.2706883789120549, 'w11': -1.7184262240933843}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:42,745] Trial 54 finished with value: 0.7318840579710145 and parameters: {'w0': 1.5415407241972816, 'w1': 0.3530137508898533, 'w2': -0.5169757463737897, 'w3': 2.274888230923726, 'w4': -0.25695386122087943, 'w5': -0.42707356405909547, 'w6': 2.315424240457826, 'w7': -1.6822665658124283, 'w8': -0.5425277844145446, 'w9': -2.4905075498845823, 'w10': 0.11004272345729221, 'w11': -0.5455548341976675}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:42,878] Trial 55 finished with value: 0.7318840579710145 and parameters: {'w0': 2.3453486586437067, 'w1': 0.5036385434698367, 'w2': -1.3627257826646233, 'w3': 2.057970126607435, 'w4': -0.7629170755568437, 'w5': -0.02786337618001211, 'w6': 1.7385578727173074, 'w7': -1.3031173066929924, 'w8': -0.3038202622516685, 'w9': -2.3160749706091153, 'w10': -0.23242379470492194, 'w11': -0.8269148920639764}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,005] Trial 56 finished with value: 0.7318840579710145 and parameters: {'w0': 2.1165417780435036, 'w1': 0.24323593122877873, 'w2': -1.8085359256902886, 'w3': 2.494065186865539, 'w4': -0.4607428492151181, 'w5': -1.281903296695131, 'w6': 2.048798870634761, 'w7': -2.4989331133819093, 'w8': 0.5457876037494469, 'w9': -0.4513096419853971, 'w10': 1.3462454888261979, 'w11': -1.495943136567635}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,123] Trial 57 finished with value: 0.7318840579710145 and parameters: {'w0': 1.779234479182331, 'w1': 0.6915334037876996, 'w2': 0.5276438725431856, 'w3': 1.7543225936822076, 'w4': 0.2813275976977394, 'w5': 1.1345871103575473, 'w6': 1.197543931776527, 'w7': -2.072346151527099, 'w8': -0.6724522101222248, 'w9': -1.4380200578282354, 'w10': 0.3439888660843319, 'w11': -1.2617151090529037}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,244] Trial 58 finished with value: 0.7246376811594203 and parameters: {'w0': 0.7090287527941365, 'w1': 0.9450333244804124, 'w2': 0.2193262767450938, 'w3': 1.4372924303863313, 'w4': -0.01780243314661889, 'w5': -1.5732882132432957, 'w6': 1.5538418171078758, 'w7': -0.2743739933904559, 'w8': -0.0025850378004623475, 'w9': 0.6179134559557617, 'w10': -0.5101079678931082, 'w11': -1.99992459103971}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,372] Trial 59 finished with value: 0.7318840579710145 and parameters: {'w0': 1.245696238772507, 'w1': 1.265956899843649, 'w2': -0.10230127978137182, 'w3': 2.2896409090003935, 'w4': -1.4410907215452182, 'w5': 0.3311502329026192, 'w6': 1.8569666387896389, 'w7': -0.6966305571536042, 'w8': 0.2569147738772919, 'w9': -1.7074724784534268, 'w10': -1.958615118462455, 'w11': -0.14831966922942064}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,479] Trial 60 finished with value: 0.7246376811594203 and parameters: {'w0': 1.8916549936684133, 'w1': -0.4039508277105629, 'w2': 0.00933530733004903, 'w3': -0.05614280729435506, 'w4': -1.1415563696652433, 'w5': -0.5936687550613922, 'w6': -2.3268421658861933, 'w7': -0.05227411660376946, 'w8': -0.3748432875157025, 'w9': -1.1598891920136905, 'w10': 0.773589127020632, 'w11': -0.9588309600905984}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,588] Trial 61 finished with value: 0.7318840579710145 and parameters: {'w0': 0.46908978110981014, 'w1': 1.2114359255772684, 'w2': -2.453586677034384, 'w3': 1.9869582199099285, 'w4': -1.2700091665910371, 'w5': -0.11208796811865834, 'w6': -0.7175579286925848, 'w7': -2.4195120168251663, 'w8': 0.12320052572766488, 'w9': -1.9295936367678905, 'w10': -1.0233375740400228, 'w11': -0.521854601812486}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,654] Trial 62 finished with value: 0.7318840579710145 and parameters: {'w0': 0.4648000834404131, 'w1': 2.050659199642943, 'w2': -1.5595571859071478, 'w3': 1.9973941111744984, 'w4': -2.1797060194444025, 'w5': 0.21421066572527164, 'w6': -1.2598654096950908, 'w7': -2.2888903242310503, 'w8': -0.24002457424616663, 'w9': -2.231437696880109, 'w10': -1.6703330732344952, 'w11': -0.5951361269188955}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,766] Trial 63 finished with value: 0.7318840579710145 and parameters: {'w0': -0.026872184815671885, 'w1': -0.15582934511444269, 'w2': -1.845932128404148, 'w3': 2.141656210937546, 'w4': -1.318039887406557, 'w5': -0.9061786019193087, 'w6': 0.11461629902044651, 'w7': -1.9212975306818845, 'w8': 0.08751436129469214, 'w9': -1.8249753613972857, 'w10': -1.2379302920900896, 'w11': -0.37711549448594534}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,872] Trial 64 finished with value: 0.7318840579710145 and parameters: {'w0': 0.9757807744883101, 'w1': 1.486697984098997, 'w2': -0.6653706004999853, 'w3': 1.6571946803666395, 'w4': -0.8480968398285129, 'w5': 0.9328732482316482, 'w6': -1.7973588294397709, 'w7': -1.5682949637761932, 'w8': 0.6892706904584567, 'w9': -2.1411754722059033, 'w10': -0.13991753061982432, 'w11': -0.7552517447068535}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:43,974] Trial 65 finished with value: 0.7318840579710145 and parameters: {'w0': 1.3751785244406156, 'w1': 0.6158090161309966, 'w2': 0.47628263478852056, 'w3': 2.3139035759808966, 'w4': -0.3975951392757246, 'w5': -0.37318518296601805, 'w6': 2.166840055745279, 'w7': -1.2544605640156876, 'w8': -0.13908935001870404, 'w9': 2.132986924573861, 'w10': -0.674104464249027, 'w11': 1.1236196818852089}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,084] Trial 66 finished with value: 0.7246376811594203 and parameters: {'w0': 1.6040574619633492, 'w1': 1.7608578316541004, 'w2': -0.977669225187836, 'w3': 1.8715974164753124, 'w4': -0.264203301674405, 'w5': 0.6298585990542043, 'w6': 2.3696685567727456, 'w7': -1.021116344941793, 'w8': -0.5585496072181546, 'w9': -2.4889966444905243, 'w10': 0.10109420269397895, 'w11': -1.1266247018413815}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,186] Trial 67 finished with value: 0.7318840579710145 and parameters: {'w0': 1.1186203312785135, 'w1': 1.1403456107898964, 'w2': 0.7488943624471313, 'w3': 2.0943247017990454, 'w4': -0.6254774541416124, 'w5': 0.09098810842274965, 'w6': 1.0932411959275337, 'w7': -2.0496092716744982, 'w8': 0.43871443656361153, 'w9': -2.353468488023809, 'w10': 0.5161142725380934, 'w11': -1.3876118968638353}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,290] Trial 68 finished with value: 0.7246376811594203 and parameters: {'w0': 0.32177018622700976, 'w1': 0.7259653983278574, 'w2': -0.3581165814742557, 'w3': 0.5657400051387442, 'w4': -1.0344025635000456, 'w5': -1.4695655242173222, 'w6': 0.3725185426969799, 'w7': 0.44207233562972775, 'w8': -1.887592071757588, 'w9': -1.9963357164328446, 'w10': -0.3906529913290483, 'w11': 0.18999765872506813}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,393] Trial 69 finished with value: 0.7318840579710145 and parameters: {'w0': 2.4031365841629215, 'w1': 0.40096388731566324, 'w2': -2.1171128218358843, 'w3': 2.3674633590591383, 'w4': -0.05658416290762802, 'w5': -1.1945677350837218, 'w6': -0.16701297090485395, 'w7': -2.230598901369346, 'w8': -1.083027504487284, 'w9': -0.3141933924030348, 'w10': -1.1753970969300291, 'w11': -0.963827411424841}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,495] Trial 70 finished with value: 0.717391304347826 and parameters: {'w0': 0.689647850416042, 'w1': 0.12872467881448493, 'w2': -1.2116392626841845, 'w3': 1.5253434834111612, 'w4': -1.7886036292436618, 'w5': -0.17344752115563578, 'w6': 2.137251782442764, 'w7': -0.5144337602434826, 'w8': 1.5960479652726076, 'w9': -0.8797257537531652, 'w10': 0.24996873010373238, 'w11': -1.6151592808507154}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,603] Trial 71 finished with value: 0.7318840579710145 and parameters: {'w0': -2.4142440980769395, 'w1': 0.9310431760520632, 'w2': -1.1533462008001696, 'w3': 2.172054482621295, 'w4': -1.9341856727717455, 'w5': -0.7272548695787512, 'w6': 1.3645005356302737, 'w7': 0.32087713777222415, 'w8': 0.3990096757724746, 'w9': -1.3226560427994394, 'w10': 0.45260168572563353, 'w11': -0.1520412231028463}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,695] Trial 72 finished with value: 0.7318840579710145 and parameters: {'w0': -0.8072726234668128, 'w1': -1.8073235347313876, 'w2': -0.8565674599741278, 'w3': 2.3392192382274644, 'w4': -2.0498749075476588, 'w5': -1.0034747143630154, 'w6': 1.904624466111033, 'w7': 0.8087269628223568, 'w8': 0.25960010627127317, 'w9': -0.6182016333474812, 'w10': 0.6234214643762579, 'w11': -0.42308509108577597}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,797] Trial 73 finished with value: 0.7318840579710145 and parameters: {'w0': -1.5394387948811437, 'w1': -1.287364291211773, 'w2': -1.8052953403724037, 'w3': 1.9050999978658254, 'w4': -1.477022127232662, 'w5': -0.6569477842615628, 'w6': 1.4496178294556283, 'w7': 0.1622481125927421, 'w8': 0.8175100602746268, 'w9': -1.3929429252276968, 'w10': 1.021204885977545, 'w11': -0.267197473328866}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:44,905] Trial 74 finished with value: 0.717391304347826 and parameters: {'w0': -2.023925124038434, 'w1': 1.3823049582399047, 'w2': 2.4955348012348355, 'w3': -1.4066683935600108, 'w4': -2.403431363870557, 'w5': -0.8399112025983995, 'w6': 1.6401864436255602, 'w7': 0.49016741942728376, 'w8': 0.5046869149851676, 'w9': -1.588598300194753, 'w10': 0.37669564076805295, 'w11': -0.06500551524777826}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,008] Trial 75 finished with value: 0.7318840579710145 and parameters: {'w0': -0.5230785467420789, 'w1': -1.8166915054001391, 'w2': 0.23628278868735028, 'w3': 2.488710736884729, 'w4': -0.6607290780286864, 'w5': -0.5697416139902989, 'w6': 2.346602467342865, 'w7': -0.2582393249864199, 'w8': -0.07721402406448252, 'w9': -1.7293000015631652, 'w10': 0.12736660847438608, 'w11': -0.63501215387886}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,117] Trial 76 finished with value: 0.7318840579710145 and parameters: {'w0': -0.2501492285096737, 'w1': -1.0047193353316173, 'w2': -0.18892219394314194, 'w3': 1.714225167227111, 'w4': -1.6524377797989083, 'w5': -1.254879086609059, 'w6': 0.8426592124637029, 'w7': 0.19926186126060158, 'w8': 0.10906322171723837, 'w9': -2.333227698875035, 'w10': -0.8349740439670033, 'w11': -1.2254407739810533}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,221] Trial 77 finished with value: 0.7318840579710145 and parameters: {'w0': 1.8436259397262358, 'w1': 2.4698374013203086, 'w2': -0.4533457756180398, 'w3': 2.201191658954172, 'w4': -0.35219876725803617, 'w5': -1.7962450152126372, 'w6': 2.00807805240354, 'w7': 0.02369748679664352, 'w8': -0.42634545005391533, 'w9': -2.132569808191382, 'w10': 0.800402001069805, 'w11': -0.8476122256379076}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,306] Trial 78 finished with value: 0.7246376811594203 and parameters: {'w0': 1.4729962633145117, 'w1': -2.2620410989808737, 'w2': -1.4007917187954604, 'w3': 2.0597645766720634, 'w4': -0.8678567860937648, 'w5': -1.0450409203020954, 'w6': 1.8450932328416758, 'w7': -0.8270183288580433, 'w8': 0.9217811877199509, 'w9': -1.074824341074231, 'w10': -0.11693869317999342, 'w11': 0.4615116956216748}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,407] Trial 79 finished with value: 0.717391304347826 and parameters: {'w0': 2.0677466630928616, 'w1': 1.0082863464042549, 'w2': 0.037061012753440425, 'w3': -2.456984193903002, 'w4': 0.14054675929309135, 'w5': -1.4025457443077614, 'w6': 2.2337668581140973, 'w7': -0.17953820804378662, 'w8': 1.0893795324646662, 'w9': -1.8569383974861633, 'w10': 0.543765136849401, 'w11': -1.0898194045717218}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,509] Trial 80 finished with value: 0.7246376811594203 and parameters: {'w0': 0.8466946843378911, 'w1': 1.5293688478911374, 'w2': -1.0776127035783962, 'w3': 2.3593894914555973, 'w4': -0.5348307376428292, 'w5': -0.7381896317865917, 'w6': 2.0894104280825014, 'w7': 0.3802306367230006, 'w8': -0.7220317223646552, 'w9': -0.6917664751107402, 'w10': -0.3278518948066316, 'w11': -0.7221051794332035}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,605] Trial 81 finished with value: 0.7318840579710145 and parameters: {'w0': -1.3416652047015933, 'w1': -1.6768770142212075, 'w2': -0.21211327440780453, 'w3': 1.809022016855529, 'w4': 0.3890692071779688, 'w5': 0.42087872895388, 'w6': -1.160926850282706, 'w7': -1.9716414732228347, 'w8': 0.6081094584010853, 'w9': -1.6508052846646715, 'w10': 0.2210833009033433, 'w11': -2.211780713981624}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,709] Trial 82 finished with value: 0.7318840579710145 and parameters: {'w0': -1.287889108995484, 'w1': -1.435546869624481, 'w2': -0.7005287046882698, 'w3': 1.9264748390367035, 'w4': 0.5729463290252781, 'w5': 0.5111027592393834, 'w6': -1.9845262191006836, 'w7': -1.8306084353883878, 'w8': 1.021274430867121, 'w9': -2.0186331750566975, 'w10': -0.28894084653387736, 'w11': -2.0022137423222683}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,796] Trial 83 finished with value: 0.7318840579710145 and parameters: {'w0': -0.3319906668460517, 'w1': -2.031470017594133, 'w2': -0.37729467619978924, 'w3': 2.1767464334604965, 'w4': 0.8368442409176106, 'w5': 0.2302628253205704, 'w6': -1.5688083692660952, 'w7': -2.179183908820091, 'w8': 0.32148052514510733, 'w9': 0.18866688056506775, 'w10': -0.03242931064349436, 'w11': 2.42552493384811}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:45,903] Trial 84 finished with value: 0.7318840579710145 and parameters: {'w0': -1.787093647222514, 'w1': 0.5139286142309423, 'w2': 0.0751555731491976, 'w3': 1.7477893541360148, 'w4': -0.08881617494653266, 'w5': -1.1398397687701074, 'w6': -0.8428180370671539, 'w7': -2.3031888597238837, 'w8': 1.4018082936948346, 'w9': -1.4827482349391237, 'w10': -0.7399763238773882, 'w11': -1.7778175905663391}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,006] Trial 85 finished with value: 0.7318840579710145 and parameters: {'w0': 0.05324282849699968, 'w1': -0.5381550553619112, 'w2': -0.4583586470185116, 'w3': 2.360613927106618, 'w4': 0.5384444467667061, 'w5': 0.8534704054190592, 'w6': 2.4170026711626846, 'w7': -1.81526823539581, 'w8': -0.2471576662842123, 'w9': -2.3779424602401185, 'w10': 0.6914700946944785, 'w11': -2.271747149318899}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,111] Trial 86 finished with value: 0.7246376811594203 and parameters: {'w0': 0.5395327043679293, 'w1': -1.4964437212732657, 'w2': -1.6775046370973556, 'w3': 2.0897218156716444, 'w4': -0.2609317753348245, 'w5': -0.4477892485637685, 'w6': 1.6781767485532737, 'w7': -1.6030032783303163, 'w8': 0.012594604296420231, 'w9': -2.2183785875519724, 'w10': 0.8857504341490083, 'w11': -1.4736056336250032}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,214] Trial 87 finished with value: 0.7246376811594203 and parameters: {'w0': -1.0525127943843833, 'w1': 0.8406843223645244, 'w2': 0.38164135209357697, 'w3': 1.2548393868500822, 'w4': -0.7264171361683386, 'w5': 0.781111041424396, 'w6': -0.477140398262608, 'w7': 0.6147123748311055, 'w8': -0.12173243881222184, 'w9': -0.08647308149821942, 'w10': 0.3504519732010383, 'w11': 2.150429457835674}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,317] Trial 88 finished with value: 0.7318840579710145 and parameters: {'w0': 1.026167980356619, 'w1': 0.27340018759589324, 'w2': 0.5829519435290853, 'w3': 2.49639130030876, 'w4': 0.6866697251420111, 'w5': -0.040554861183436514, 'w6': 1.499472889060327, 'w7': -2.4015164250884795, 'w8': 0.1624064622906621, 'w9': -1.7475128151740968, 'w10': 1.1991943834980014, 'w11': -0.9575637604563858}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,407] Trial 89 finished with value: 0.7246376811594203 and parameters: {'w0': -2.2294233012868654, 'w1': -1.207198018596926, 'w2': -0.5920258124232097, 'w3': 2.2592738159328882, 'w4': 0.2472294891112345, 'w5': -0.9138708978398651, 'w6': 2.2558468452012934, 'w7': -1.1593402488652065, 'w8': -0.3854358402191089, 'w9': -1.9316314414760296, 'w10': 0.03265366047664664, 'w11': -1.369572946348093}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,511] Trial 90 finished with value: 0.7318840579710145 and parameters: {'w0': 1.215365000649736, 'w1': -0.7217154491131411, 'w2': -2.2128104678213063, 'w3': 1.9979431150422535, 'w4': -2.256636160115638, 'w5': -0.26597690395011087, 'w6': 1.309414283608231, 'w7': 0.7566920325372515, 'w8': 1.2157804482116963, 'w9': -1.2585169408706427, 'w10': -0.5101875456169582, 'w11': -0.30611856609719}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,618] Trial 91 finished with value: 0.717391304347826 and parameters: {'w0': 0.793939402672605, 'w1': 1.1068254979230767, 'w2': 0.61932279469636, 'w3': 1.9228265529410733, 'w4': -0.23580028616893833, 'w5': -1.3800890347102477, 'w6': 1.774555595737633, 'w7': -0.36576443947990495, 'w8': -0.6846330961979159, 'w9': -2.1149374293583154, 'w10': 1.9059709290369515, 'w11': -1.23768090918773}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,719] Trial 92 finished with value: 0.7246376811594203 and parameters: {'w0': 2.19492054454742, 'w1': 1.2590979102163051, 'w2': 0.8914532321004499, 'w3': 1.571273792531964, 'w4': -0.4864901944697018, 'w5': 0.10975054937783307, 'w6': 1.9035823109131456, 'w7': -0.6165028626730844, 'w8': -0.7960146958149931, 'w9': -1.8596090502287208, 'w10': 1.4882974167339214, 'w11': -1.129559050530856}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,827] Trial 93 finished with value: 0.7246376811594203 and parameters: {'w0': 0.5943032494055838, 'w1': 1.1185675514385998, 'w2': 0.2309765050328288, 'w3': 2.363463509765806, 'w4': -0.1755889005431137, 'w5': -1.560450409493594, 'w6': 2.0185573631838993, 'w7': -0.7578699103014456, 'w8': -0.5551308667132817, 'w9': -1.5312420713796788, 'w10': -1.382868269360908, 'w11': -1.5820355912620738}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:46,942] Trial 94 finished with value: 0.7246376811594203 and parameters: {'w0': 0.7631925892620253, 'w1': 0.6970884164599132, 'w2': -0.0697711622477033, 'w3': 2.215827385275045, 'w4': 1.1453913909955618, 'w5': -1.33646408367834, 'w6': 2.163494692119291, 'w7': -0.4079185402810603, 'w8': -0.9821081492047362, 'w9': -2.387475534628641, 'w10': -0.19195459493428185, 'w11': -2.3556879115911693}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:47,045] Trial 95 finished with value: 0.717391304347826 and parameters: {'w0': 0.32672689943300837, 'w1': 0.907008447022443, 'w2': -0.21220271825418766, 'w3': 1.821058164676856, 'w4': -1.1294643369214674, 'w5': -1.084856133055474, 'w6': 2.4757149760371, 'w7': -0.9653201381114164, 'w8': -0.2958246186238926, 'w9': -2.2081659443784063, 'w10': 2.2216254080570064, 'w11': -0.47134915868382177}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:47,149] Trial 96 finished with value: 0.7318840579710145 and parameters: {'w0': 1.3295622522868442, 'w1': 0.45650872527710823, 'w2': 0.43044808716823413, 'w3': 2.089028680992569, 'w4': -0.9485197767364476, 'w5': -0.8028669241428239, 'w6': 1.6782394566953018, 'w7': -0.08980839334056623, 'w8': -1.205461453620146, 'w9': -1.9887645771371387, 'w10': 1.2947385417739363, 'w11': -0.7971358867962269}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:47,253] Trial 97 finished with value: 0.7318840579710145 and parameters: {'w0': 1.135894602737714, 'w1': 1.318279444494621, 'w2': 1.2060296923016185, 'w3': 2.3970577986903465, 'w4': 0.10834686438018953, 'w5': 1.6445275541716986, 'w6': 1.0805046532007263, 'w7': 0.051932180314809784, 'w8': -0.4644862065488658, 'w9': -1.6494617035556098, 'w10': -1.0181851149992729, 'w11': -0.9944985241801478}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:47,355] Trial 98 finished with value: 0.7246376811594203 and parameters: {'w0': 2.3277990693091013, 'w1': 0.12148082133170246, 'w2': 0.13578974506609653, 'w3': 1.1227813700785925, 'w4': -0.5706496065943687, 'w5': -0.9565209543945868, 'w6': 0.7916187359693161, 'w7': -1.4073197657718866, 'w8': 0.35392073263150237, 'w9': -1.0737757212688936, 'w10': 1.5870526379562797, 'w11': -1.837268349410239}. Best is trial 10 with value: 0.7318840579710145.\n",
      "[I 2025-09-03 15:35:47,461] Trial 99 finished with value: 0.7318840579710145 and parameters: {'w0': 1.9371252855546652, 'w1': 0.5601313789591658, 'w2': 0.301671258970736, 'w3': 1.417771009467212, 'w4': -0.34390196808534174, 'w5': -0.5286855398646754, 'w6': -0.04406186983426452, 'w7': -2.499693057370216, 'w8': 1.9454259243148038, 'w9': -0.38316024435628193, 'w10': -1.847209592201543, 'w11': -0.6421589928175147}. Best is trial 10 with value: 0.7318840579710145.\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna alphas (first 10): [0.2689 0.041  0.0207 0.2546 0.0175 0.0108 0.2921 0.013  0.0217 0.0026]\n",
      "\n",
      "==== (Tuned) Bagging — Optuna Weights (thr from val) Performance ====\n",
      "Accuracy:      0.587209\n",
      "AUC:           0.649131\n",
      "PR-AUC:        0.509876\n",
      "LogLoss:       0.655193\n",
      "Precision@0.740: 0.400000\n",
      "Recall@0.740:    0.043165\n",
      "F1@0.740:        0.077922\n",
      "\n",
      "===== FINAL Retrain on FULL 80% (best params), then test on 20% =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\conda\\envs\\lau\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== FINAL — Simple Average (thr from val) Performance ====\n",
      "Accuracy:      0.610465\n",
      "AUC:           0.648640\n",
      "PR-AUC:        0.514882\n",
      "LogLoss:       0.657415\n",
      "Precision@0.650: 0.555556\n",
      "Recall@0.650:    0.179856\n",
      "F1@0.650:        0.271739\n",
      "\n",
      "==== FINAL — Val-AUC Weighted (thr from val) Performance ====\n",
      "Accuracy:      0.590116\n",
      "AUC:           0.648535\n",
      "PR-AUC:        0.514913\n",
      "LogLoss:       0.657347\n",
      "Precision@0.430: 0.494737\n",
      "Recall@0.430:    0.676259\n",
      "F1@0.430:        0.571429\n",
      "\n",
      "==== FINAL — Optuna Weights (thr from val) Performance ====\n",
      "Accuracy:      0.595930\n",
      "AUC:           0.639305\n",
      "PR-AUC:        0.511550\n",
      "LogLoss:       0.663808\n",
      "Precision@0.740: 0.500000\n",
      "Recall@0.740:    0.035971\n",
      "F1@0.740:        0.067114\n",
      "[Export] 逐样本结果已导出：reports\\results_test.xlsx\n",
      "[AUC@TEST] SimpleAvg=0.648640, ValAUCWeighted=0.648535, OptunaWeights=0.639305\n",
      "[Plot] 混淆矩阵保存：reports\\confusion_matrix_SimpleAvg.png\n",
      "[Plot] ROC 曲线保存：reports\\roc_curves.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Append mode is not supported with xlsxwriter!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 496\u001b[39m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# 5) 补充：把整体分数汇总到 Excel 的第二个 sheet\u001b[39;00m\n\u001b[32m    483\u001b[39m summary = pd.DataFrame({\n\u001b[32m    484\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mAUC_SIMPLE\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUC_VALAUC_WEIGHTED\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUC_OPTUNA\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    485\u001b[39m                \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mACC_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m@thr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPREC_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m@thr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mREC_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m@thr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mF1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m@thr\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    493\u001b[39m     ]\n\u001b[32m    494\u001b[39m })\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pd.ExcelWriter(xlsx_path, engine=\u001b[33m\"\u001b[39m\u001b[33mxlsxwriter\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m, if_sheet_exists=\u001b[33m\"\u001b[39m\u001b[33mnew\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m    497\u001b[39m     summary.to_excel(writer, index=\u001b[38;5;28;01mFalse\u001b[39;00m, sheet_name=\u001b[33m\"\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    499\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[Done] 汇总指标已写入 Excel 第二个 sheet。\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\lau\\Lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:202\u001b[39m, in \u001b[36mXlsxWriter.__init__\u001b[39m\u001b[34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m engine_kwargs = combine_kwargs(engine_kwargs, kwargs)\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    204\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    205\u001b[39m     path,\n\u001b[32m    206\u001b[39m     engine=engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m    212\u001b[39m     engine_kwargs=engine_kwargs,\n\u001b[32m    213\u001b[39m )\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Append mode is not supported with xlsxwriter!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 728x644 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss,\n",
    "    roc_curve\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 0) 数据准备\n",
    "# =========================\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,      y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# =========================\n",
    "# 1) 工具函数（评估 / 采样 / 双类保障 / 阈值寻优）\n",
    "# =========================\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:        {acc:.6f}\")\n",
    "    print(f\"AUC:             {auc:.6f}\")\n",
    "    print(f\"PR-AUC:          {ap:.6f}\")\n",
    "    print(f\"LogLoss:         {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on_val(y_val, p_val, metric='f1', min_precision=None, target_pos_rate=None):\n",
    "    \"\"\"\n",
    "    网格搜阈值:\n",
    "      metric ∈ {'accuracy','f1','recall','precision'}\n",
    "      可选约束:\n",
    "        - min_precision: 阈值必须满足 Precision >= 该值\n",
    "        - target_pos_rate: 可行解内优先选择正例率最接近该目标的阈值\n",
    "    \"\"\"\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    metric = metric.lower()\n",
    "    if metric not in {'accuracy','f1','recall','precision'}:\n",
    "        raise ValueError(f\"不支持的阈值寻优指标: {metric}\")\n",
    "\n",
    "    cand = []\n",
    "    for t in ths:\n",
    "        pred = (p_val >= t).astype(int)\n",
    "        acc = accuracy_score(y_val, pred)\n",
    "        f1  = f1_score(y_val, pred, zero_division=0)\n",
    "        rec = recall_score(y_val, pred, zero_division=0)\n",
    "        pre = precision_score(y_val, pred, zero_division=0)\n",
    "        pos_rate = pred.mean()\n",
    "        score = acc if metric=='accuracy' else f1 if metric=='f1' else rec if metric=='recall' else pre\n",
    "\n",
    "        # 约束：最小精度\n",
    "        if (min_precision is not None) and (pre < min_precision):\n",
    "            continue\n",
    "        cand.append((t, score, pos_rate))\n",
    "\n",
    "    # 若无可行解，回退到“precision 最大”的阈值（保证尽量抑制假阳性）\n",
    "    if not cand:\n",
    "        best = None\n",
    "        best_pre = -1\n",
    "        for t in ths:\n",
    "            pred = (p_val >= t).astype(int)\n",
    "            pre = precision_score(y_val, pred, zero_division=0)\n",
    "            if pre > best_pre:\n",
    "                best_pre = pre; best = t\n",
    "        return float(best if best is not None else 0.5)\n",
    "\n",
    "    if target_pos_rate is not None:\n",
    "        cand.sort(key=lambda x: (abs(x[2]-target_pos_rate), -x[1]))\n",
    "        return float(cand[0][0])\n",
    "\n",
    "    cand.sort(key=lambda x: -x[1])\n",
    "    return float(cand[0][0])\n",
    "\n",
    "def block_bootstrap(n, ratio, block=20, rng=None):\n",
    "    m = int(n * ratio); idx = []\n",
    "    if n <= 0: return np.array([], dtype=int)\n",
    "    if block <= 0: block = 1\n",
    "    while len(idx) < m:\n",
    "        s = rng.randint(0, max(1, n - block + 1)); idx.extend(range(s, min(s + block, n)))\n",
    "    idx = np.array(idx[:m], dtype=int); idx.sort()\n",
    "    return idx\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3):\n",
    "    if len(np.unique(y_val_fit)) >= 2: return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "    n_total, tail = len(y_tr), len(y_val_fit)\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail: break\n",
    "        X_tr_fit, y_tr_fit = X_tr_raw[:n_total-new_tail], y_tr[:n_total-new_tail]\n",
    "        X_val_fit, y_val_fit = X_tr_raw[n_total-new_tail:], y_tr[n_total-new_tail:]\n",
    "        tail = new_tail\n",
    "    if len(np.unique(y_val_fit)) < 2 and len(np.unique(y_tr)) == 2:\n",
    "        missing = 1 - int(np.unique(y_val_fit)[0]); pool_idx = np.where(y_tr_fit == missing)[0]\n",
    "        if len(pool_idx) > 0:\n",
    "            k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "            pick = np.random.RandomState(1234).choice(pool_idx, k, replace=False)\n",
    "            X_val_fit, y_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]]), np.concatenate([y_val_fit, y_tr_fit[pick]])\n",
    "            mask = np.ones(len(y_tr_fit), dtype=bool); mask[pick] = False\n",
    "            X_tr_fit, y_tr_fit = X_tr_fit[mask], y_tr_fit[mask]\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "def ensure_both_classes_in_es(y_full, es_idx, pool_idx, rng, max_tries=10):\n",
    "    if len(es_idx) == 0: return es_idx\n",
    "    for _ in range(max_tries):\n",
    "        if len(np.unique(y_full[es_idx])) >= 2: return es_idx\n",
    "        present = int(np.unique(y_full[es_idx])[0]); missing = 1 - present\n",
    "        cand = pool_idx[y_full[pool_idx] == missing]\n",
    "        if len(cand) == 0:\n",
    "            es_idx = rng.choice(pool_idx, size=max(1, len(es_idx)), replace=True); continue\n",
    "        k = min(len(cand), max(1, len(es_idx)//2))\n",
    "        replace_pos = rng.choice(len(es_idx), size=k, replace=False)\n",
    "        add_from_cand = rng.choice(cand, size=k, replace=False)\n",
    "        es_idx = es_idx.copy(); es_idx[replace_pos] = add_from_cand\n",
    "    return es_idx\n",
    "\n",
    "# =========================\n",
    "# 2) 训练设置 & 固定基础参数\n",
    "# =========================\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 外部阈值学习的可选约束（按需开启）\n",
    "EXT_MIN_PRECISION   = None   # 例如 0.80；None 表示不启用\n",
    "EXT_TARGET_POS_RATE = None   # 例如 0.55；None 表示不启用\n",
    "\n",
    "# 固定 Val 片双类\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "# —— 你的最优 LightGBM 基础参数（固定不搜索）——\n",
    "BEST_BASE_CFG = {\n",
    "    \"n_estimators\": 1661,\n",
    "    \"learning_rate\": 0.060360719357661304,\n",
    "    \"num_leaves\": 365,\n",
    "    \"min_child_samples\": 42,\n",
    "    \"subsample\": 0.8704853901045029,\n",
    "    \"colsample_bytree\": 0.938018723296346,\n",
    "    \"reg_alpha\": 2.528948814898404e-07,\n",
    "    \"reg_lambda\": 4.6251017710258054e-07,\n",
    "    \"objective\": \"binary\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# 3) 训练若干子模型并获取验证集预测（固定基础参数）\n",
    "# =========================\n",
    "def build_cfg_with_jitter(base_cfg, rng, scale):\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * scale; cfg = base_cfg.copy()\n",
    "    cfg[\"subsample\"] = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"] = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"] = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"] = int(np.clip(round(cfg.get(\"max_depth\", -1) if cfg.get(\"max_depth\", -1) != -1 else 8 * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "    return cfg\n",
    "\n",
    "def train_ensemble_val_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG, seed_offset=0):\n",
    "    n_train = X_tr_fit.shape[0]; local_rng = np.random.RandomState(RANDOM_SEED + seed_offset)\n",
    "    val_probs_list = []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_train, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx, es_idx = (idx_boot[:es_pt], idx_boot[es_pt:]) if len(idx_boot) > es_pt else (idx_boot, idx_boot[:1])\n",
    "        es_idx = ensure_both_classes_in_es(y_tr_fit, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        # 抖动后的基础参数\n",
    "        cfg = build_cfg_with_jitter(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "\n",
    "        # 合并覆盖，避免重复传参\n",
    "        params = cfg.copy()\n",
    "        params[\"random_state\"] = (RANDOM_SEED + seed_offset + b)\n",
    "        params.setdefault(\"objective\", \"binary\")\n",
    "        params.setdefault(\"verbosity\", -1)\n",
    "        params.setdefault(\"n_jobs\", -1)\n",
    "        params[\"class_weight\"] = \"balanced\"  # 平衡权重\n",
    "\n",
    "        clf = LGBMClassifier(**params)\n",
    "        clf.fit(\n",
    "            X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "            eval_set=[(X_tr_fit[es_idx], y_tr_fit[es_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "    return np.column_stack(val_probs_list)\n",
    "\n",
    "# =========================\n",
    "# 4) Optuna 目标函数（只搜索 Bagging/Ensemble 参数）\n",
    "# =========================\n",
    "def objective_joint(trial, optimization_metric='auc'):\n",
    "    # 固定基础参数\n",
    "    base_cfg = BEST_BASE_CFG.copy()\n",
    "\n",
    "    # 只搜索 ensemble 参数\n",
    "    BAGS = trial.suggest_int(\"BAGS\", 8, 40)\n",
    "    SAMPLE_RATIO = trial.suggest_float(\"SAMPLE_RATIO\", 0.6, 0.95)\n",
    "    JITTER_SCALE = trial.suggest_float(\"JITTER_SCALE\", 0.05, 0.25)\n",
    "    BLOCK_SIZE   = trial.suggest_int(\"BLOCK_SIZE\", 5, 60)\n",
    "\n",
    "    # 训练并获取验证集预测\n",
    "    val_probs = train_ensemble_val_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, base_cfg, seed_offset=trial.number)\n",
    "\n",
    "    # 融合：Val-AUC 权重\n",
    "    weights = np.array([max(safe_auc(y_val_fit, val_probs[:, j]) or 0.5, 0.0) for j in range(val_probs.shape[1])])\n",
    "    if weights.sum() == 0:\n",
    "        alphas = np.ones(val_probs.shape[1]) / val_probs.shape[1]\n",
    "    else:\n",
    "        ex = np.exp(weights - weights.max()); alphas = ex / ex.sum()\n",
    "    val_wavg = (val_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    # 评估分数\n",
    "    om = optimization_metric.lower()\n",
    "    if om == 'auc':\n",
    "        score = safe_auc(y_val_fit, val_wavg)\n",
    "        if np.isnan(score): score = 0.5\n",
    "        best_t = 0.5\n",
    "    elif om in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "        best_t = best_thr_on_val(\n",
    "            y_val_fit, val_wavg, metric=om,\n",
    "            min_precision=EXT_MIN_PRECISION, target_pos_rate=EXT_TARGET_POS_RATE\n",
    "        )\n",
    "        y_pred_val = (val_wavg >= best_t).astype(int)\n",
    "        if om == 'accuracy':\n",
    "            score = accuracy_score(y_val_fit, y_pred_val)\n",
    "        elif om == 'f1':\n",
    "            score = f1_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "        elif om == 'recall':\n",
    "            score = recall_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "        else:  # precision\n",
    "            score = precision_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的优化指标: {optimization_metric}\")\n",
    "\n",
    "    trial.set_user_attr(\"alphas\", alphas)\n",
    "    trial.set_user_attr(\"best_thr\", best_t)\n",
    "    return float(score)\n",
    "\n",
    "def run_optimization(metric='auc', n_trials=50):\n",
    "    print(f\"\\n🚀 开始联合调参. 目标: 在验证集上最大化 '{metric.upper()}'.\")\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(lambda trial: objective_joint(trial, optimization_metric=metric),\n",
    "                   n_trials=n_trials, show_progress_bar=True)\n",
    "    print(f\"\\n[调参结束] 最佳分数 ({metric.upper()}): {study.best_value:.6f}\")\n",
    "    print(f\"[调参结束] 最佳参数(仅ensemble): {study.best_params}\")\n",
    "    return study\n",
    "\n",
    "# =========================\n",
    "# 5) 执行调参并准备最终评估\n",
    "# =========================\n",
    "OPTIMIZATION_TARGET = 'f1'   # 可改：'auc' / 'f1' / 'recall' / 'precision'\n",
    "N_TRIALS = 50\n",
    "study_joint = run_optimization(metric=OPTIMIZATION_TARGET, n_trials=N_TRIALS)\n",
    "\n",
    "# 取最优的 ensemble 参数\n",
    "BEST_PARAMS = study_joint.best_params\n",
    "BEST_BASE_CFG = BEST_BASE_CFG.copy()  # 再拷一份，确保不被修改\n",
    "BEST_BAGS        = BEST_PARAMS.get(\"BAGS\", 16)\n",
    "BEST_SAMPLE_RATIO= BEST_PARAMS.get(\"SAMPLE_RATIO\", 0.8)\n",
    "BEST_JITTER_SCALE= BEST_PARAMS.get(\"JITTER_SCALE\", 0.1)\n",
    "BEST_BLOCK_SIZE  = BEST_PARAMS.get(\"BLOCK_SIZE\", 20)\n",
    "\n",
    "print(\"\\n===== 演练阶段: 在验证集上学习阈值和融合权重 =====\")\n",
    "val_probs_best = train_ensemble_val_preds(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG, seed_offset=999\n",
    ")\n",
    "\n",
    "# 策略1: 简单平均\n",
    "val_avg = val_probs_best.mean(axis=1)\n",
    "t_avg = best_thr_on_val(\n",
    "    y_val_fit, val_avg, metric=OPTIMIZATION_TARGET,\n",
    "    min_precision=EXT_MIN_PRECISION, target_pos_rate=EXT_TARGET_POS_RATE\n",
    ")\n",
    "print(f\"  - [简单平均] 在验证集上学到的最优阈值: {t_avg:.3f}\")\n",
    "\n",
    "# 策略2: Val-AUC 加权（来自 Joint Study 的 alphas），阈值重新按同样约束计算\n",
    "alphas_best = np.array(study_joint.best_trial.user_attrs[\"alphas\"])\n",
    "val_wavg_best = (val_probs_best * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "t_wavg_best = best_thr_on_val(\n",
    "    y_val_fit, val_wavg_best, metric=OPTIMIZATION_TARGET,\n",
    "    min_precision=EXT_MIN_PRECISION, target_pos_rate=EXT_TARGET_POS_RATE\n",
    ")\n",
    "print(f\"  - [Val-AUC加权] 在验证集上学到的最优阈值: {t_wavg_best:.3f}\")\n",
    "\n",
    "# 策略3: Optuna 学习融合权重（仅在验证集上）\n",
    "def objective_blend_on_val(trial, val_probs):\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(val_probs.shape[1])])\n",
    "    a = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "    val_blend = (val_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "    best_t = best_thr_on_val(\n",
    "        y_val_fit, val_blend, metric=OPTIMIZATION_TARGET,\n",
    "        min_precision=EXT_MIN_PRECISION, target_pos_rate=EXT_TARGET_POS_RATE\n",
    "    )\n",
    "    y_pred_val = (val_blend >= best_t).astype(int)\n",
    "    om = OPTIMIZATION_TARGET.lower()\n",
    "    if om == 'f1':\n",
    "        score = f1_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    elif om == 'accuracy':\n",
    "        score = accuracy_score(y_val_fit, y_pred_val)\n",
    "    elif om == 'recall':\n",
    "        score = recall_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    elif om == 'precision':\n",
    "        score = precision_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    else:\n",
    "        score = safe_auc(y_val_fit, val_blend)\n",
    "    trial.set_user_attr(\"best_t\", best_t)\n",
    "    return score\n",
    "\n",
    "sampler2 = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study_blend = optuna.create_study(direction=\"maximize\", sampler=sampler2)\n",
    "study_blend.optimize(lambda t: objective_blend_on_val(t, val_probs_best),\n",
    "                     n_trials=100, show_progress_bar=False)\n",
    "best_w = np.array([study_blend.best_params[k] for k in sorted(study_blend.best_params.keys(),\n",
    "                                                              key=lambda s: int(s[1:]))])\n",
    "a_opt = np.exp(best_w); a_opt /= (a_opt.sum() + 1e-12)\n",
    "t_blend_best = float(study_blend.best_trial.user_attrs[\"best_t\"])\n",
    "print(f\"  - [Optuna融合] 在验证集上学到的最优阈值: {t_blend_best:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 6) 最终重训练与评估（在80%训练集上bagging，20%上评估）\n",
    "# =========================\n",
    "print(\"\\n===== 最终阶段: 在完整80%数据上重训, 并在20%测试集上评估三种策略 =====\")\n",
    "def train_ensemble_full_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG):\n",
    "    n_full, local_rng = X_tr_raw.shape[0], np.random.RandomState(RANDOM_SEED + 2025)\n",
    "    te_probs_list = []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_full, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx, es_idx = (idx_boot[:es_pt], idx_boot[es_pt:]) if len(idx_boot) > es_pt else (idx_boot, idx_boot[:1])\n",
    "        es_idx = ensure_both_classes_in_es(y_tr, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        cfg = build_cfg_with_jitter(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "\n",
    "        params = cfg.copy()\n",
    "        params[\"random_state\"] = 10000 + b\n",
    "        params.setdefault(\"objective\", \"binary\")\n",
    "        params.setdefault(\"verbosity\", -1)\n",
    "        params.setdefault(\"n_jobs\", -1)\n",
    "        params[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "        clf = LGBMClassifier(**params)\n",
    "        clf.fit(\n",
    "            X_tr_raw[tr_idx], y_tr[tr_idx],\n",
    "            eval_set=[(X_tr_raw[es_idx], y_tr[es_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        te_probs_list.append(clf.predict_proba(X_te)[:, 1])\n",
    "    return np.column_stack(te_probs_list)\n",
    "\n",
    "te_probs_final = train_ensemble_full_preds(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG\n",
    ")\n",
    "\n",
    "# --- 应用策略1: 简单平均 ---\n",
    "y_prob_avg_final = te_probs_final.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg_final, thr=t_avg, title=\"FINAL - Simple Average\")\n",
    "\n",
    "# --- 应用策略2: Val-AUC 加权 ---\n",
    "y_prob_wavg_final = (te_probs_final * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_wavg_final, thr=t_wavg_best, title=\"FINAL - Val-AUC Weighted\")\n",
    "\n",
    "# --- 应用策略3: Optuna 学习权重 ---\n",
    "y_prob_opt_final = (te_probs_final * a_opt.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_opt_final, thr=t_blend_best, title=\"FINAL - Optuna Weights\")\n",
    "\n",
    "# =========================\n",
    "# 7) 结果导出与ROC图\n",
    "# =========================\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "test_index = getattr(df_clean, \"index\", pd.RangeIndex(len(df_clean)))[split_pt:]\n",
    "df_out = pd.DataFrame({\n",
    "    \"index\": test_index, \"y_true\": y_te,\n",
    "    \"prob_simple_avg\": y_prob_avg_final, \"pred_simple_avg\": (y_prob_avg_final >= t_avg).astype(int),\n",
    "    \"prob_valauc_weighted\": y_prob_wavg_final, \"pred_valauc_weighted\": (y_prob_wavg_final >= t_wavg_best).astype(int),\n",
    "    \"prob_optuna_weights\": y_prob_opt_final, \"pred_optuna_weights\": (y_prob_opt_final >= t_blend_best).astype(int),\n",
    "})\n",
    "xlsx_path = os.path.join(\"reports\", f\"results_test_3_blends_optimized_for_{OPTIMIZATION_TARGET}.xlsx\")\n",
    "df_out.to_excel(xlsx_path, index=False)\n",
    "print(f\"\\n[导出] 包含三种策略的逐样本结果已导出: {xlsx_path}\")\n",
    "\n",
    "# 绘制ROC曲线对比\n",
    "plt.figure(figsize=(7, 6), dpi=120)\n",
    "def add_roc_curve(y_true, y_score, label):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_v = roc_auc_score(y_true, y_score)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{label} (AUC={auc_v:.4f})\")\n",
    "\n",
    "add_roc_curve(y_te, y_prob_avg_final, \"Simple Avg\")\n",
    "add_roc_curve(y_te, y_prob_wavg_final, \"Val-AUC Weighted\")\n",
    "add_roc_curve(y_te, y_prob_opt_final, \"Optuna Weights\")\n",
    "\n",
    "plt.plot([0,1], [0,1], ls=\"--\", lw=1.2, color=\"gray\", label=\"Chance\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves on Test Set for 3 Blending Strategies\")\n",
    "plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
    "roc_path = os.path.join(\"reports\", f\"roc_curves_3_blends_{OPTIMIZATION_TARGET}.png\")\n",
    "plt.savefig(roc_path); plt.close()\n",
    "print(f\"[绘图] 三种策略的ROC对比曲线已保存: {roc_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becdb657",
   "metadata": {},
   "source": [
    "### 自由的评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ae0592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:23,273] A new study created in memory with name: no-name-87d1ad5c-de29-4934-9d68-223f80cebf72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 1234, Val-fit size: 138, Classes in Val: (array([0, 1]), array([99, 39]))\n",
      "\n",
      "🚀 开始联合调参. 目标: 在验证集上最大化 'F1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.5:   1%|          | 1/100 [00:02<04:36,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:26,062] Trial 0 finished with value: 0.5 and parameters: {'BAGS': 20, 'SAMPLE_RATIO': 0.9327500072434707, 'JITTER_SCALE': 0.19639878836228103, 'BLOCK_SIZE': 38}. Best is trial 0 with value: 0.5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.5:   2%|▏         | 2/100 [00:04<03:12,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:27,440] Trial 1 finished with value: 0.4881889763779528 and parameters: {'BAGS': 13, 'SAMPLE_RATIO': 0.6545980821176709, 'JITTER_SCALE': 0.061616722433639894, 'BLOCK_SIZE': 53}. Best is trial 0 with value: 0.5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.5:   3%|▎         | 3/100 [00:07<04:06,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:30,674] Trial 2 finished with value: 0.47058823529411764 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.8478254022286159, 'JITTER_SCALE': 0.05411689885916049, 'BLOCK_SIZE': 59}. Best is trial 0 with value: 0.5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.513761:   4%|▍         | 4/100 [00:11<04:56,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:34,607] Trial 3 finished with value: 0.5137614678899083 and parameters: {'BAGS': 35, 'SAMPLE_RATIO': 0.6743186887373966, 'JITTER_SCALE': 0.08636499344142012, 'BLOCK_SIZE': 15}. Best is trial 3 with value: 0.5137614678899083.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.513761:   5%|▌         | 5/100 [00:13<04:23,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:36,830] Trial 4 finished with value: 0.48695652173913045 and parameters: {'BAGS': 18, 'SAMPLE_RATIO': 0.7836647510712832, 'JITTER_SCALE': 0.13638900372842316, 'BLOCK_SIZE': 21}. Best is trial 3 with value: 0.5137614678899083.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:   6%|▌         | 6/100 [00:16<04:21,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:39,634] Trial 5 finished with value: 0.5333333333333333 and parameters: {'BAGS': 28, 'SAMPLE_RATIO': 0.6488228512282146, 'JITTER_SCALE': 0.10842892970704364, 'BLOCK_SIZE': 25}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:   7%|▋         | 7/100 [00:19<04:31,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:42,833] Trial 6 finished with value: 0.49504950495049505 and parameters: {'BAGS': 23, 'SAMPLE_RATIO': 0.8748115864875547, 'JITTER_SCALE': 0.08993475643167195, 'BLOCK_SIZE': 33}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:   8%|▊         | 8/100 [00:22<04:33,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:45,909] Trial 7 finished with value: 0.5046728971962616 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.6162576444519992, 'JITTER_SCALE': 0.17150897038028767, 'BLOCK_SIZE': 14}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:   9%|▉         | 9/100 [00:24<04:04,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:47,970] Trial 8 finished with value: 0.5045045045045045 and parameters: {'BAGS': 10, 'SAMPLE_RATIO': 0.9321099380386666, 'JITTER_SCALE': 0.24312640661491186, 'BLOCK_SIZE': 50}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  10%|█         | 10/100 [00:26<03:44,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:50,020] Trial 9 finished with value: 0.49572649572649574 and parameters: {'BAGS': 18, 'SAMPLE_RATIO': 0.6341852399022343, 'JITTER_SCALE': 0.1868466053024314, 'BLOCK_SIZE': 29}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  11%|█         | 11/100 [00:33<05:35,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:07:56,679] Trial 10 finished with value: 0.5094339622641509 and parameters: {'BAGS': 39, 'SAMPLE_RATIO': 0.7273046857675708, 'JITTER_SCALE': 0.12450753744847112, 'BLOCK_SIZE': 6}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  12%|█▏        | 12/100 [00:43<08:17,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:06,655] Trial 11 finished with value: 0.5098039215686274 and parameters: {'BAGS': 35, 'SAMPLE_RATIO': 0.705197688067271, 'JITTER_SCALE': 0.10108869175303983, 'BLOCK_SIZE': 20}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  13%|█▎        | 13/100 [00:54<10:37,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:17,815] Trial 12 finished with value: 0.49557522123893805 and parameters: {'BAGS': 33, 'SAMPLE_RATIO': 0.6971070527811642, 'JITTER_SCALE': 0.09313760280821318, 'BLOCK_SIZE': 5}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  14%|█▍        | 14/100 [01:00<09:46,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:23,459] Trial 13 finished with value: 0.5172413793103449 and parameters: {'BAGS': 32, 'SAMPLE_RATIO': 0.7596811952458024, 'JITTER_SCALE': 0.11850319874755139, 'BLOCK_SIZE': 23}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  15%|█▌        | 15/100 [01:04<08:30,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:27,598] Trial 14 finished with value: 0.5087719298245614 and parameters: {'BAGS': 30, 'SAMPLE_RATIO': 0.7701025825872136, 'JITTER_SCALE': 0.15767957860731457, 'BLOCK_SIZE': 40}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  16%|█▌        | 16/100 [01:08<07:32,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:31,531] Trial 15 finished with value: 0.49523809523809526 and parameters: {'BAGS': 30, 'SAMPLE_RATIO': 0.7847226125605111, 'JITTER_SCALE': 0.11732466081535677, 'BLOCK_SIZE': 26}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  17%|█▋        | 17/100 [01:13<07:14,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:36,426] Trial 16 finished with value: 0.5045045045045045 and parameters: {'BAGS': 40, 'SAMPLE_RATIO': 0.7445024230925967, 'JITTER_SCALE': 0.14625769859320456, 'BLOCK_SIZE': 39}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  18%|█▊        | 18/100 [01:15<06:03,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:39,008] Trial 17 finished with value: 0.5137614678899083 and parameters: {'BAGS': 24, 'SAMPLE_RATIO': 0.6010066722402185, 'JITTER_SCALE': 0.22274629762932008, 'BLOCK_SIZE': 24}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  19%|█▉        | 19/100 [01:20<06:00,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:43,495] Trial 18 finished with value: 0.4915254237288136 and parameters: {'BAGS': 30, 'SAMPLE_RATIO': 0.8321922500141938, 'JITTER_SCALE': 0.11249860763046739, 'BLOCK_SIZE': 13}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  20%|██        | 20/100 [01:25<06:06,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:48,388] Trial 19 finished with value: 0.5 and parameters: {'BAGS': 36, 'SAMPLE_RATIO': 0.8260949136936163, 'JITTER_SCALE': 0.07776256751051762, 'BLOCK_SIZE': 32}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  21%|██        | 21/100 [01:28<05:24,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:51,370] Trial 20 finished with value: 0.5225225225225225 and parameters: {'BAGS': 26, 'SAMPLE_RATIO': 0.6780502049755542, 'JITTER_SCALE': 0.13304132327266005, 'BLOCK_SIZE': 44}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  22%|██▏       | 22/100 [01:31<04:58,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:54,556] Trial 21 finished with value: 0.49523809523809526 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.6649950645956298, 'JITTER_SCALE': 0.1360130106152112, 'BLOCK_SIZE': 46}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  23%|██▎       | 23/100 [01:33<04:28,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:57,243] Trial 22 finished with value: 0.5185185185185185 and parameters: {'BAGS': 22, 'SAMPLE_RATIO': 0.699178024094224, 'JITTER_SCALE': 0.16135347222182525, 'BLOCK_SIZE': 45}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  24%|██▍       | 24/100 [01:36<04:05,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:08:59,879] Trial 23 finished with value: 0.5178571428571429 and parameters: {'BAGS': 24, 'SAMPLE_RATIO': 0.6981869567832866, 'JITTER_SCALE': 0.16363987828384632, 'BLOCK_SIZE': 46}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  25%|██▌       | 25/100 [01:38<03:41,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:02,206] Trial 24 finished with value: 0.5 and parameters: {'BAGS': 20, 'SAMPLE_RATIO': 0.6401628000251961, 'JITTER_SCALE': 0.18211984916569168, 'BLOCK_SIZE': 45}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  26%|██▌       | 26/100 [01:41<03:30,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:04,793] Trial 25 finished with value: 0.5137614678899083 and parameters: {'BAGS': 22, 'SAMPLE_RATIO': 0.7225539335486499, 'JITTER_SCALE': 0.2051649772099251, 'BLOCK_SIZE': 57}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  27%|██▋       | 27/100 [01:44<03:27,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:07,644] Trial 26 finished with value: 0.4713375796178344 and parameters: {'BAGS': 26, 'SAMPLE_RATIO': 0.6735349800782126, 'JITTER_SCALE': 0.14609506196922306, 'BLOCK_SIZE': 42}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  28%|██▊       | 28/100 [01:46<03:06,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:09,608] Trial 27 finished with value: 0.4897959183673469 and parameters: {'BAGS': 16, 'SAMPLE_RATIO': 0.6253249861959989, 'JITTER_SCALE': 0.13338143210746367, 'BLOCK_SIZE': 33}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  29%|██▉       | 29/100 [01:48<03:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:12,040] Trial 28 finished with value: 0.509090909090909 and parameters: {'BAGS': 21, 'SAMPLE_RATIO': 0.6794985658808087, 'JITTER_SCALE': 0.10775075564436926, 'BLOCK_SIZE': 51}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  30%|███       | 30/100 [01:50<02:48,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:14,124] Trial 29 finished with value: 0.49504950495049505 and parameters: {'BAGS': 15, 'SAMPLE_RATIO': 0.7249903294161059, 'JITTER_SCALE': 0.07184572966186314, 'BLOCK_SIZE': 36}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  31%|███       | 31/100 [01:54<03:02,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:17,333] Trial 30 finished with value: 0.4888888888888889 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.6464037900214903, 'JITTER_SCALE': 0.20588564046233576, 'BLOCK_SIZE': 36}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  32%|███▏      | 32/100 [01:57<03:07,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:20,359] Trial 31 finished with value: 0.5142857142857142 and parameters: {'BAGS': 24, 'SAMPLE_RATIO': 0.7016024963031067, 'JITTER_SCALE': 0.16465576017507738, 'BLOCK_SIZE': 46}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  33%|███▎      | 33/100 [02:00<03:09,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:23,370] Trial 32 finished with value: 0.4954128440366973 and parameters: {'BAGS': 28, 'SAMPLE_RATIO': 0.6921748330133284, 'JITTER_SCALE': 0.17406599049061564, 'BLOCK_SIZE': 53}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  34%|███▍      | 34/100 [02:02<03:03,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:26,029] Trial 33 finished with value: 0.5 and parameters: {'BAGS': 22, 'SAMPLE_RATIO': 0.6632468119876427, 'JITTER_SCALE': 0.15347051304281342, 'BLOCK_SIZE': 43}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  35%|███▌      | 35/100 [02:05<02:54,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:28,500] Trial 34 finished with value: 0.5252525252525253 and parameters: {'BAGS': 19, 'SAMPLE_RATIO': 0.7469434829712025, 'JITTER_SCALE': 0.12921782996821873, 'BLOCK_SIZE': 48}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  36%|███▌      | 36/100 [02:07<02:45,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:30,827] Trial 35 finished with value: 0.5087719298245614 and parameters: {'BAGS': 18, 'SAMPLE_RATIO': 0.7269914625489727, 'JITTER_SCALE': 0.1277723547015732, 'BLOCK_SIZE': 56}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  37%|███▋      | 37/100 [02:09<02:39,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:33,249] Trial 36 finished with value: 0.5 and parameters: {'BAGS': 16, 'SAMPLE_RATIO': 0.7440341707403819, 'JITTER_SCALE': 0.1441310359752957, 'BLOCK_SIZE': 49}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  38%|███▊      | 38/100 [02:12<02:29,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:35,360] Trial 37 finished with value: 0.4842105263157895 and parameters: {'BAGS': 11, 'SAMPLE_RATIO': 0.8019791190568561, 'JITTER_SCALE': 0.10630556934139211, 'BLOCK_SIZE': 60}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  39%|███▉      | 39/100 [02:14<02:20,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:37,438] Trial 38 finished with value: 0.5098039215686274 and parameters: {'BAGS': 19, 'SAMPLE_RATIO': 0.6508015495136811, 'JITTER_SCALE': 0.09684604352728009, 'BLOCK_SIZE': 53}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  40%|████      | 40/100 [02:15<02:06,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:39,085] Trial 39 finished with value: 0.4948453608247423 and parameters: {'BAGS': 14, 'SAMPLE_RATIO': 0.6100580265109681, 'JITTER_SCALE': 0.08286873050523386, 'BLOCK_SIZE': 37}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  41%|████      | 41/100 [02:18<02:21,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:42,137] Trial 40 finished with value: 0.5 and parameters: {'BAGS': 20, 'SAMPLE_RATIO': 0.9033046360496739, 'JITTER_SCALE': 0.1236868064758096, 'BLOCK_SIZE': 28}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  42%|████▏     | 42/100 [02:22<02:36,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:45,578] Trial 41 finished with value: 0.48598130841121495 and parameters: {'BAGS': 28, 'SAMPLE_RATIO': 0.685115354188232, 'JITTER_SCALE': 0.16448290266454932, 'BLOCK_SIZE': 47}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  43%|████▎     | 43/100 [02:25<02:37,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:48,484] Trial 42 finished with value: 0.48214285714285715 and parameters: {'BAGS': 24, 'SAMPLE_RATIO': 0.707315956979514, 'JITTER_SCALE': 0.19010664015731193, 'BLOCK_SIZE': 42}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  44%|████▍     | 44/100 [02:26<02:08,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:49,706] Trial 43 finished with value: 0.49019607843137253 and parameters: {'BAGS': 8, 'SAMPLE_RATIO': 0.7390130568409397, 'JITTER_SCALE': 0.15831343879254767, 'BLOCK_SIZE': 49}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  45%|████▌     | 45/100 [02:29<02:12,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:52,387] Trial 44 finished with value: 0.4909090909090909 and parameters: {'BAGS': 23, 'SAMPLE_RATIO': 0.7109273016895044, 'JITTER_SCALE': 0.1410977117493552, 'BLOCK_SIZE': 55}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  46%|████▌     | 46/100 [02:31<02:11,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:54,868] Trial 45 finished with value: 0.5050505050505051 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.6597784993798832, 'JITTER_SCALE': 0.054198563335539976, 'BLOCK_SIZE': 44}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  47%|████▋     | 47/100 [02:35<02:31,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:09:58,691] Trial 46 finished with value: 0.4915254237288136 and parameters: {'BAGS': 29, 'SAMPLE_RATIO': 0.752877571116284, 'JITTER_SCALE': 0.1720120572399025, 'BLOCK_SIZE': 40}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  48%|████▊     | 48/100 [02:39<02:39,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:02,288] Trial 47 finished with value: 0.49572649572649574 and parameters: {'BAGS': 32, 'SAMPLE_RATIO': 0.6823507547336185, 'JITTER_SCALE': 0.13120573454225445, 'BLOCK_SIZE': 48}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  49%|████▉     | 49/100 [02:41<02:32,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:05,070] Trial 48 finished with value: 0.5045045045045045 and parameters: {'BAGS': 26, 'SAMPLE_RATIO': 0.6309418902288164, 'JITTER_SCALE': 0.11969559451932499, 'BLOCK_SIZE': 30}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  50%|█████     | 50/100 [02:44<02:30,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:08,161] Trial 49 finished with value: 0.5043478260869565 and parameters: {'BAGS': 22, 'SAMPLE_RATIO': 0.7690704206556045, 'JITTER_SCALE': 0.15154666428923677, 'BLOCK_SIZE': 51}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  51%|█████     | 51/100 [02:47<02:25,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:11,004] Trial 50 finished with value: 0.4915254237288136 and parameters: {'BAGS': 21, 'SAMPLE_RATIO': 0.7157398018930783, 'JITTER_SCALE': 0.10291063756750507, 'BLOCK_SIZE': 18}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  52%|█████▏    | 52/100 [02:51<02:37,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:15,039] Trial 51 finished with value: 0.48598130841121495 and parameters: {'BAGS': 32, 'SAMPLE_RATIO': 0.7594684557147318, 'JITTER_SCALE': 0.1142658219480607, 'BLOCK_SIZE': 22}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  53%|█████▎    | 53/100 [02:56<02:48,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:19,321] Trial 52 finished with value: 0.5046728971962616 and parameters: {'BAGS': 33, 'SAMPLE_RATIO': 0.7863440859702654, 'JITTER_SCALE': 0.1371417477040941, 'BLOCK_SIZE': 25}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  54%|█████▍    | 54/100 [03:00<02:58,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:23,920] Trial 53 finished with value: 0.5272727272727272 and parameters: {'BAGS': 36, 'SAMPLE_RATIO': 0.7982800656087556, 'JITTER_SCALE': 0.12334633145613637, 'BLOCK_SIZE': 19}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  55%|█████▌    | 55/100 [03:05<03:11,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:29,023] Trial 54 finished with value: 0.5 and parameters: {'BAGS': 38, 'SAMPLE_RATIO': 0.8049420841910034, 'JITTER_SCALE': 0.16445073098617943, 'BLOCK_SIZE': 10}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  56%|█████▌    | 56/100 [03:08<02:49,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:31,938] Trial 55 finished with value: 0.49572649572649574 and parameters: {'BAGS': 19, 'SAMPLE_RATIO': 0.7997927286277071, 'JITTER_SCALE': 0.1814971068651144, 'BLOCK_SIZE': 18}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  57%|█████▋    | 57/100 [03:13<03:02,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:37,072] Trial 56 finished with value: 0.5045045045045045 and parameters: {'BAGS': 36, 'SAMPLE_RATIO': 0.852464363534615, 'JITTER_SCALE': 0.12680827121892696, 'BLOCK_SIZE': 20}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  58%|█████▊    | 58/100 [03:16<02:41,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:39,996] Trial 57 finished with value: 0.5148514851485149 and parameters: {'BAGS': 26, 'SAMPLE_RATIO': 0.6744586122692061, 'JITTER_SCALE': 0.09490091606630997, 'BLOCK_SIZE': 17}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  59%|█████▉    | 59/100 [03:18<02:17,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:42,223] Trial 58 finished with value: 0.4838709677419355 and parameters: {'BAGS': 17, 'SAMPLE_RATIO': 0.6974514928204065, 'JITTER_SCALE': 0.24965671723320074, 'BLOCK_SIZE': 27}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  60%|██████    | 60/100 [03:24<02:35,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:47,325] Trial 59 finished with value: 0.5185185185185185 and parameters: {'BAGS': 38, 'SAMPLE_RATIO': 0.7407645381770949, 'JITTER_SCALE': 0.13894477107007963, 'BLOCK_SIZE': 12}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  61%|██████    | 61/100 [03:29<02:44,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:52,297] Trial 60 finished with value: 0.5 and parameters: {'BAGS': 38, 'SAMPLE_RATIO': 0.7389071171986411, 'JITTER_SCALE': 0.111760451684311, 'BLOCK_SIZE': 10}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  62%|██████▏   | 62/100 [03:34<02:51,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:10:57,557] Trial 61 finished with value: 0.5 and parameters: {'BAGS': 34, 'SAMPLE_RATIO': 0.776355562644348, 'JITTER_SCALE': 0.14274474051289265, 'BLOCK_SIZE': 13}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  63%|██████▎   | 63/100 [03:42<03:26,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:05,579] Trial 62 finished with value: 0.5046728971962616 and parameters: {'BAGS': 40, 'SAMPLE_RATIO': 0.8288824139804493, 'JITTER_SCALE': 0.15088238249505384, 'BLOCK_SIZE': 9}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  64%|██████▍   | 64/100 [03:47<03:19,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:11,014] Trial 63 finished with value: 0.5137614678899083 and parameters: {'BAGS': 37, 'SAMPLE_RATIO': 0.7336980941249871, 'JITTER_SCALE': 0.1591843938412985, 'BLOCK_SIZE': 15}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  65%|██████▌   | 65/100 [03:50<02:46,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:13,964] Trial 64 finished with value: 0.48484848484848486 and parameters: {'BAGS': 23, 'SAMPLE_RATIO': 0.6895043242714544, 'JITTER_SCALE': 0.12100383111738061, 'BLOCK_SIZE': 8}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  66%|██████▌   | 66/100 [03:54<02:32,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:17,780] Trial 65 finished with value: 0.5046728971962616 and parameters: {'BAGS': 31, 'SAMPLE_RATIO': 0.7180084997640711, 'JITTER_SCALE': 0.131811850790107, 'BLOCK_SIZE': 45}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  67%|██████▋   | 67/100 [03:58<02:21,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:21,643] Trial 66 finished with value: 0.4909090909090909 and parameters: {'BAGS': 28, 'SAMPLE_RATIO': 0.8168934544352828, 'JITTER_SCALE': 0.14138816656076292, 'BLOCK_SIZE': 16}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  68%|██████▊   | 68/100 [04:04<02:32,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:27,490] Trial 67 finished with value: 0.48598130841121495 and parameters: {'BAGS': 39, 'SAMPLE_RATIO': 0.7543439084603102, 'JITTER_SCALE': 0.08853748929798977, 'BLOCK_SIZE': 34}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  69%|██████▉   | 69/100 [04:09<02:30,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:32,549] Trial 68 finished with value: 0.4915254237288136 and parameters: {'BAGS': 35, 'SAMPLE_RATIO': 0.6708562917858789, 'JITTER_SCALE': 0.11171651033458695, 'BLOCK_SIZE': 31}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.533333:  70%|███████   | 70/100 [04:12<02:08,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:35,563] Trial 69 finished with value: 0.5098039215686274 and parameters: {'BAGS': 21, 'SAMPLE_RATIO': 0.6465840533094176, 'JITTER_SCALE': 0.13533824581145218, 'BLOCK_SIZE': 51}. Best is trial 5 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 70. Best value: 0.537037:  71%|███████   | 71/100 [04:18<02:21,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:41,808] Trial 70 finished with value: 0.5370370370370371 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.7869809618203744, 'JITTER_SCALE': 0.10017747777187302, 'BLOCK_SIZE': 41}. Best is trial 70 with value: 0.5370370370370371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  72%|███████▏  | 72/100 [04:23<02:17,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:46,734] Trial 71 finished with value: 0.5420560747663551 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.8433267974719155, 'JITTER_SCALE': 0.07123482258769696, 'BLOCK_SIZE': 39}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  73%|███████▎  | 73/100 [04:27<02:07,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:51,108] Trial 72 finished with value: 0.509090909090909 and parameters: {'BAGS': 29, 'SAMPLE_RATIO': 0.8528832490069899, 'JITTER_SCALE': 0.07064145059836933, 'BLOCK_SIZE': 39}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  74%|███████▍  | 74/100 [04:31<01:52,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:54,533] Trial 73 finished with value: 0.5142857142857142 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.7931580937342382, 'JITTER_SCALE': 0.06623141062843517, 'BLOCK_SIZE': 42}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  75%|███████▌  | 75/100 [04:35<01:46,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:11:58,608] Trial 74 finished with value: 0.4915254237288136 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.8728951666537118, 'JITTER_SCALE': 0.08412540588270574, 'BLOCK_SIZE': 34}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  76%|███████▌  | 76/100 [04:39<01:38,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:02,273] Trial 75 finished with value: 0.5087719298245614 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.8174056803012248, 'JITTER_SCALE': 0.10134834908532964, 'BLOCK_SIZE': 41}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  77%|███████▋  | 77/100 [04:41<01:25,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:05,090] Trial 76 finished with value: 0.4578313253012048 and parameters: {'BAGS': 23, 'SAMPLE_RATIO': 0.7703730575208274, 'JITTER_SCALE': 0.12594492819837208, 'BLOCK_SIZE': 37}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  78%|███████▊  | 78/100 [04:45<01:23,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:09,160] Trial 77 finished with value: 0.49557522123893805 and parameters: {'BAGS': 29, 'SAMPLE_RATIO': 0.8669980422362331, 'JITTER_SCALE': 0.060069466710627156, 'BLOCK_SIZE': 43}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  79%|███████▉  | 79/100 [04:48<01:14,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:12,075] Trial 78 finished with value: 0.4954128440366973 and parameters: {'BAGS': 20, 'SAMPLE_RATIO': 0.9133318164411226, 'JITTER_SCALE': 0.0777964823028003, 'BLOCK_SIZE': 44}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  80%|████████  | 80/100 [04:51<01:08,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:15,222] Trial 79 finished with value: 0.5142857142857142 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.8362981894423492, 'JITTER_SCALE': 0.1153362261945514, 'BLOCK_SIZE': 39}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  81%|████████  | 81/100 [04:55<01:07,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:19,156] Trial 80 finished with value: 0.5185185185185185 and parameters: {'BAGS': 31, 'SAMPLE_RATIO': 0.7859559598148612, 'JITTER_SCALE': 0.09199683659708685, 'BLOCK_SIZE': 24}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  82%|████████▏ | 82/100 [04:59<01:06,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:23,079] Trial 81 finished with value: 0.5192307692307693 and parameters: {'BAGS': 31, 'SAMPLE_RATIO': 0.7906136220795749, 'JITTER_SCALE': 0.09162477324921355, 'BLOCK_SIZE': 23}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  83%|████████▎ | 83/100 [05:03<01:02,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:26,730] Trial 82 finished with value: 0.5 and parameters: {'BAGS': 26, 'SAMPLE_RATIO': 0.8117321088123012, 'JITTER_SCALE': 0.10706659073515772, 'BLOCK_SIZE': 20}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  84%|████████▍ | 84/100 [05:07<01:02,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:31,223] Trial 83 finished with value: 0.5132743362831859 and parameters: {'BAGS': 36, 'SAMPLE_RATIO': 0.7768905427537279, 'JITTER_SCALE': 0.09609659380121248, 'BLOCK_SIZE': 22}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  85%|████████▌ | 85/100 [05:12<00:59,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:35,325] Trial 84 finished with value: 0.46296296296296297 and parameters: {'BAGS': 34, 'SAMPLE_RATIO': 0.7657468768935511, 'JITTER_SCALE': 0.07770574564610215, 'BLOCK_SIZE': 47}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  86%|████████▌ | 86/100 [05:16<00:57,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:39,670] Trial 85 finished with value: 0.5 and parameters: {'BAGS': 30, 'SAMPLE_RATIO': 0.8992593179960101, 'JITTER_SCALE': 0.12066575596339198, 'BLOCK_SIZE': 41}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  87%|████████▋ | 87/100 [05:20<00:51,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:43,357] Trial 86 finished with value: 0.5052631578947369 and parameters: {'BAGS': 28, 'SAMPLE_RATIO': 0.7513434379806193, 'JITTER_SCALE': 0.10246643036857891, 'BLOCK_SIZE': 12}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  88%|████████▊ | 88/100 [05:24<00:50,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:48,170] Trial 87 finished with value: 0.5 and parameters: {'BAGS': 39, 'SAMPLE_RATIO': 0.8434561929620589, 'JITTER_SCALE': 0.10903510143395027, 'BLOCK_SIZE': 26}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  89%|████████▉ | 89/100 [05:27<00:40,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:50,601] Trial 88 finished with value: 0.5094339622641509 and parameters: {'BAGS': 24, 'SAMPLE_RATIO': 0.6207723474576208, 'JITTER_SCALE': 0.14710909244769124, 'BLOCK_SIZE': 28}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  90%|█████████ | 90/100 [05:30<00:34,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:53,383] Trial 89 finished with value: 0.5 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.6546010161006226, 'JITTER_SCALE': 0.11752635980579897, 'BLOCK_SIZE': 5}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  91%|█████████ | 91/100 [05:33<00:31,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:12:56,902] Trial 90 finished with value: 0.5 and parameters: {'BAGS': 22, 'SAMPLE_RATIO': 0.7922856829079473, 'JITTER_SCALE': 0.12777459404758382, 'BLOCK_SIZE': 19}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  92%|█████████▏| 92/100 [05:38<00:31,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:02,029] Trial 91 finished with value: 0.5132743362831859 and parameters: {'BAGS': 31, 'SAMPLE_RATIO': 0.7840890550817756, 'JITTER_SCALE': 0.09076857297776385, 'BLOCK_SIZE': 24}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  93%|█████████▎| 93/100 [05:42<00:27,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:06,130] Trial 92 finished with value: 0.5048543689320388 and parameters: {'BAGS': 31, 'SAMPLE_RATIO': 0.6362779882325559, 'JITTER_SCALE': 0.10007452188367688, 'BLOCK_SIZE': 24}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  94%|█████████▍| 94/100 [05:48<00:27,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:12,043] Trial 93 finished with value: 0.5178571428571429 and parameters: {'BAGS': 29, 'SAMPLE_RATIO': 0.9474796705588391, 'JITTER_SCALE': 0.08080835234163823, 'BLOCK_SIZE': 22}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  95%|█████████▌| 95/100 [05:53<00:22,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:16,548] Trial 94 finished with value: 0.48333333333333334 and parameters: {'BAGS': 33, 'SAMPLE_RATIO': 0.8093571959892021, 'JITTER_SCALE': 0.08771059591331183, 'BLOCK_SIZE': 49}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  96%|█████████▌| 96/100 [05:57<00:18,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:21,113] Trial 95 finished with value: 0.5148514851485149 and parameters: {'BAGS': 30, 'SAMPLE_RATIO': 0.7936498997273933, 'JITTER_SCALE': 0.13760399971052917, 'BLOCK_SIZE': 46}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  97%|█████████▋| 97/100 [06:02<00:14,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:26,122] Trial 96 finished with value: 0.5045045045045045 and parameters: {'BAGS': 37, 'SAMPLE_RATIO': 0.7639456411071124, 'JITTER_SCALE': 0.0926862820166786, 'BLOCK_SIZE': 21}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  98%|█████████▊| 98/100 [06:07<00:09,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:30,617] Trial 97 finished with value: 0.4897959183673469 and parameters: {'BAGS': 34, 'SAMPLE_RATIO': 0.7782614101161334, 'JITTER_SCALE': 0.15449744795415762, 'BLOCK_SIZE': 29}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056:  99%|█████████▉| 99/100 [06:10<00:04,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:34,010] Trial 98 finished with value: 0.48598130841121495 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.7574965679486285, 'JITTER_SCALE': 0.07369102578437858, 'BLOCK_SIZE': 44}. Best is trial 71 with value: 0.5420560747663551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 71. Best value: 0.542056: 100%|██████████| 100/100 [06:14<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:38,164] Trial 99 finished with value: 0.48148148148148145 and parameters: {'BAGS': 32, 'SAMPLE_RATIO': 0.7320883574474434, 'JITTER_SCALE': 0.1319473975325208, 'BLOCK_SIZE': 26}. Best is trial 71 with value: 0.5420560747663551.\n",
      "\n",
      "[调参结束] 最佳分数 (F1): 0.542056\n",
      "[调参结束] 最佳参数(仅ensemble): {'BAGS': 25, 'SAMPLE_RATIO': 0.8433267974719155, 'JITTER_SCALE': 0.07123482258769696, 'BLOCK_SIZE': 39}\n",
      "\n",
      "===== 演练阶段: 在验证集上学习阈值和融合权重 =====\n",
      "  - [简单平均] 在验证集上学到的最优阈值: 0.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:42,258] A new study created in memory with name: no-name-b743e1eb-27f7-4bf3-aec2-f9e52f628f32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - [Val-AUC加权] 在验证集上学到的最优阈值: 0.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:13:42,628] Trial 0 finished with value: 0.49557522123893805 and parameters: {'w0': -0.6272994057631875, 'w1': 2.2535715320495804, 'w2': 1.1599697090570253, 'w3': 0.493292420985183, 'w4': -1.7199067977878175, 'w5': -1.7200273983189867, 'w6': -2.2095819391590026, 'w7': 1.8308807288746758, 'w8': 0.5055750587160439, 'w9': 1.0403628889802272, 'w10': -2.3970775285209878, 'w11': 2.3495492608099715, 'w12': 1.662213204002109, 'w13': -1.4383044466086192, 'w14': -1.590875163964497, 'w15': -1.582977450732831, 'w16': -0.9787887852023114, 'w17': 0.12378215816118932, 'w18': -0.3402749067894213, 'w19': -1.0438542990097903, 'w20': 0.5592644736118975, 'w21': -1.8025306967397907, 'w22': -1.0392767573239092, 'w23': -0.6681907835315415, 'w24': -0.21965007891482013}. Best is trial 0 with value: 0.49557522123893805.\n",
      "[I 2025-09-08 14:13:43,001] Trial 1 finished with value: 0.4722222222222222 and parameters: {'w0': 1.4258798069650682, 'w1': -1.5016310892082014, 'w2': 0.07117219206805814, 'w3': 0.46207284431021245, 'w4': -2.2677479364000113, 'w5': 0.5377242595071916, 'w6': -1.6473793815635425, 'w7': -2.1747420350736024, 'w8': 2.2444276862666666, 'w9': 2.328160165372797, 'w10': 1.5419867405823053, 'w11': -0.9769311541331467, 'w12': -2.0116394299680804, 'w13': 0.9211651325607844, 'w14': -0.29923753130199326, 'w15': -1.8898088257761059, 'w16': -0.024115449443649073, 'w17': -2.328057394423908, 'w18': 2.0466020103939107, 'w19': -1.2061000919999154, 'w20': 0.8126114217699101, 'w21': -0.9414446195529451, 'w22': 0.10034010588905407, 'w23': 0.23355139671639824, 'w24': -1.5757277223723647}. Best is trial 0 with value: 0.49557522123893805.\n",
      "[I 2025-09-08 14:13:43,390] Trial 2 finished with value: 0.5132743362831859 and parameters: {'w0': 2.347923138822793, 'w1': 1.3756641168055728, 'w2': 2.1974947078209457, 'w3': 1.9741367521382438, 'w4': 0.4894998940554256, 'w5': 2.1093711751155837, 'w6': -2.0575374897404024, 'w7': -1.520085687904274, 'w8': -2.27386355544731, 'w9': -0.8733483461836782, 'w10': -0.5566135515525898, 'w11': -1.1432548411305206, 'w12': 1.6436875457596472, 'w13': -0.7162333665320535, 'w14': -1.0953274515630962, 'w15': 0.21348041579124244, 'w16': -1.7953788751261868, 'w17': 1.5109849037701988, 'w18': -2.127246781601146, 'w19': 2.4344346830025865, 'w20': 1.3612238464832869, 'w21': -1.506421592329138, 'w22': -2.472389414381988, 'w23': 1.5773071422741705, 'w24': 1.0342867192380858}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:43,741] Trial 3 finished with value: 0.48739495798319327 and parameters: {'w0': 1.1450358402049368, 'w1': 1.3563517334297286, 'w2': -2.129776741329548, 'w3': -0.7076713572786368, 'w4': -1.9206547023743514, 'w5': 1.8155171293779677, 'w6': 0.6164906341377896, 'w7': -0.8455098757367541, 'w8': -2.1822082485698817, 'w9': -0.945088391421689, 'w10': -0.8740833898662648, 'w11': 1.1480308916903201, 'w12': 0.6877873567760657, 'w13': 1.9360637128816327, 'w14': -0.13892537419025341, 'w15': -1.9020287703084915, 'w16': 1.0662239361149748, 'w17': 1.3039252430844872, 'w18': 0.3063859878474813, 'w19': 1.3548358997728052, 'w20': -0.031022018178046284, 'w21': 0.1136641469099704, 'w22': -0.36229490820725196, 'w23': -2.372904366279524, 'w24': -1.9605428650334777}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:44,094] Trial 4 finished with value: 0.49122807017543857 and parameters: {'w0': -2.342854071566329, 'w1': 0.6820520563189021, 'w2': -0.9282200946183665, 'w3': 0.042853455823514075, 'w4': 2.0378323696304648, 'w5': -1.2535388542556252, 'w6': -0.44808538482185156, 'w7': 1.2777556927152434, 'w8': -1.3560091725418877, 'w9': -2.115100450856035, 'w10': -1.0512427354311598, 'w11': -1.693893563729978, 'w12': 2.148488261712865, 'w13': 1.5406018978220848, 'w14': 0.6670187825521174, 'w15': 1.857302950938589, 'w16': 1.5183603844955726, 'w17': -1.567149705569821, 'w18': 1.962794992449889, 'w19': 0.1967112095782535, 'w20': 1.5372007758203123, 'w21': 1.9804564996174658, 'w22': -0.9099826251406806, 'w23': -1.9497403773616162, 'w24': -1.3603241872902916}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:44,448] Trial 5 finished with value: 0.5 and parameters: {'w0': -0.36446105686871855, 'w1': 1.5900738296124652, 'w2': 1.8036529162817168, 'w3': -2.4652393473440464, 'w4': 0.05373651288782888, 'w5': -0.41294498425610504, 'w6': -1.3894609476463486, 'w7': -1.9006731633315859, 'w8': -0.8119241429818602, 'w9': 2.2145485195625962, 'w10': -0.8839853398962239, 'w11': 0.0939531087168306, 'w12': 1.015094794475889, 'w13': -0.6818519881035301, 'w14': 2.3589104136048036, 'w15': 2.3122364747105557, 'w16': -1.2410885208731792, 'w17': -0.013757470538072525, 'w18': -0.9956084509161518, 'w19': -1.075797528112662, 'w20': -2.3155652632273362, 'w21': 0.5478216698994842, 'w22': 0.01339511614430755, 'w23': -2.2426062437500534, 'w24': -1.1067676788169427}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:44,808] Trial 6 finished with value: 0.5050505050505051 and parameters: {'w0': 2.0413294298332687, 'w1': -1.302190546665138, 'w2': -1.7755256395438845, 'w3': -0.052736198612184815, 'w4': 2.4282522705530036, 'w5': -1.2897236424424978, 'w6': 0.860677737029393, 'w7': 1.3080980766435877, 'w8': -1.3118122800380017, 'w9': 1.1410817430592979, 'w10': -0.661084336403734, 'w11': 0.6615291529678973, 'w12': 0.6676485538044736, 'w13': 0.1788734203737925, 'w14': -2.0485511497279587, 'w15': 1.67651247794619, 'w16': -0.8960996751413208, 'w17': -1.5674074480007287, 'w18': -2.2961242922261804, 'w19': 0.4544647159412092, 'w20': 0.8878218092114123, 'w21': -2.4170608553607194, 'w22': 0.060465291496405005, 'w23': -1.3675211240103102, 'w24': 0.7258639520472494}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:45,171] Trial 7 finished with value: 0.4716981132075472 and parameters: {'w0': -1.6281678549750427, 'w1': 0.95468869051233, 'w2': -0.566323268497313, 'w3': 2.1836499436836725, 'w4': -1.8123952792700337, 'w5': -0.7946682447487075, 'w6': -1.9326323937970546, 'w7': 2.123468091392814, 'w8': 1.8866967669049046, 'w9': -1.210291861424222, 'w10': 0.799920230170895, 'w11': 1.5861110010060795, 'w12': 0.27600405799731176, 'w13': 0.14825289178003231, 'w14': -1.2907385454977416, 'w15': -2.034486160970504, 'w16': 1.9860787897666334, 'w17': 2.002090285816652, 'w18': 0.6655072863663398, 'w19': -0.8048510447564965, 'w20': -0.7539521269366956, 'w21': 1.129778394351197, 'w22': 1.9855512997628857, 'w23': 1.9354321213255865, 'w24': 1.399377729288119}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:45,524] Trial 8 finished with value: 0.48333333333333334 and parameters: {'w0': 0.7101582307714387, 'w1': -2.079300175024756, 'w2': -1.6918564295269312, 'w3': 1.9927709426353966, 'w4': 0.5321452982979498, 'w5': -2.454014741916852, 'w6': -1.9926422856698394, 'w7': 0.8175088455402788, 'w8': -2.4746920807689063, 'w9': -1.6959597429125068, 'w10': 0.24366894683293072, 'w11': 0.959475988463466, 'w12': 0.7598062975130029, 'w13': -1.378653452697201, 'w14': 1.0608961067376792, 'w15': -1.3137545625159996, 'w16': -0.8730015092036614, 'w17': 1.2324570255901208, 'w18': 0.7481644952360735, 'w19': 1.7461170524708898, 'w20': 0.7880644615017167, 'w21': 0.34154301667735787, 'w22': -2.0316261608595374, 'w23': -0.6614209847028323, 'w24': -1.1739881615913728}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:45,868] Trial 9 finished with value: 0.47706422018348627 and parameters: {'w0': -1.2800517831045821, 'w1': 2.365052773762228, 'w2': -0.534511376666198, 'w3': 1.9602327758855669, 'w4': 0.6556931299863145, 'w5': 1.474056517708242, 'w6': 0.01318546552596045, 'w7': 0.38451942313179543, 'w8': -0.03741153090568039, 'w9': -1.5237850610097774, 'w10': 1.1122605763075266, 'w11': -1.096138187795721, 'w12': -2.378420167842731, 'w13': 0.7273614795358392, 'w14': -1.6144466029647553, 'w15': 2.2022929217645713, 'w16': 2.269642885012937, 'w17': 2.0743219511022426, 'w18': -0.6492064987227781, 'w19': -2.422716917355663, 'w20': 2.141592812938627, 'w21': -0.35907925841342836, 'w22': 2.333274095218348, 'w23': 2.318099885446264, 'w24': 1.7650472773368007}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:46,266] Trial 10 finished with value: 0.49557522123893805 and parameters: {'w0': 2.3974790189554565, 'w1': -0.1333633927266571, 'w2': 2.34768555393933, 'w3': 1.2786003775178587, 'w4': -0.8419124277621179, 'w5': 0.8466824940711117, 'w6': 2.2988537297271012, 'w7': -0.7972997370492096, 'w8': 0.6344182245328387, 'w9': -0.2786537264873129, 'w10': 2.3376821718810903, 'w11': -2.4351938325902074, 'w12': -0.8455646354957307, 'w13': -2.0345451566145294, 'w14': -0.7874200313112165, 'w15': 0.3963404112395452, 'w16': -2.4436259350224843, 'w17': 0.11706574802651741, 'w18': -2.4610056602125736, 'w19': 2.2441916117269383, 'w20': 2.3120571619324126, 'w21': -1.2959603124954495, 'w22': -2.327024245053072, 'w23': 1.1759417289210752, 'w24': 2.356835918829547}. Best is trial 2 with value: 0.5132743362831859.\n",
      "[I 2025-09-08 14:13:46,662] Trial 11 finished with value: 0.5137614678899083 and parameters: {'w0': 2.4517075051704884, 'w1': -0.6352860127754765, 'w2': 0.7239726800350534, 'w3': -1.114466499306039, 'w4': 2.4142459929932043, 'w5': 2.4968121932077567, 'w6': 1.3397685020521903, 'w7': -0.5297987890515885, 'w8': -1.4813941984223116, 'w9': 0.6534896789515799, 'w10': -1.883981085336829, 'w11': -0.029790597930996254, 'w12': -0.5432463622149881, 'w13': -0.4727635521460025, 'w14': -2.488809005745821, 'w15': 0.6554217176948268, 'w16': -2.3188115594005136, 'w17': -0.9739093340815077, 'w18': -2.141253230478824, 'w19': 1.024635413007553, 'w20': -0.5752544908277281, 'w21': -2.3823275104990693, 'w22': 1.4732268205604453, 'w23': 0.6565060680988855, 'w24': 0.6537270221232502}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:47,053] Trial 12 finished with value: 0.5 and parameters: {'w0': 2.4134307838890234, 'w1': -0.276102944038663, 'w2': 0.8527257130244335, 'w3': -1.3934672101143564, 'w4': 1.4155307339423753, 'w5': 2.173288743954072, 'w6': 1.9620017826840046, 'w7': -0.569907150262773, 'w8': -1.7900129487185295, 'w9': 0.3158786913356663, 'w10': -2.207045609829948, 'w11': -0.49906069714461604, 'w12': -0.7080485760472901, 'w13': -0.8990393610339444, 'w14': -2.485381228841686, 'w15': 0.19201089231502488, 'w16': -2.2191007208621056, 'w17': -0.5087453648035787, 'w18': -1.4499880283197306, 'w19': 1.2363576794855256, 'w20': -1.2164653051528598, 'w21': -2.409990953814836, 'w22': 1.1495142028529353, 'w23': 0.8389622479204634, 'w24': 0.25284722900159823}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:47,448] Trial 13 finished with value: 0.4864864864864865 and parameters: {'w0': 0.37558570489655096, 'w1': 0.2602328141496357, 'w2': 0.7802191721076832, 'w3': -1.3787749336179487, 'w4': 1.4881699048816315, 'w5': 2.4342304376035373, 'w6': 1.4566761165645583, 'w7': -1.4445199879426764, 'w8': -0.6684145867261817, 'w9': -0.23055094741317772, 'w10': -1.6591997323337553, 'w11': 0.06940578768255595, 'w12': -0.5315615646884271, 'w13': -0.4092295885896291, 'w14': -2.3581625349868003, 'w15': 0.9206384374856996, 'w16': -1.7694964798056052, 'w17': -1.0743515836923627, 'w18': -1.6801302834622776, 'w19': 2.4843195009478016, 'w20': -0.5117468423472067, 'w21': -1.6169803499757174, 'w22': 1.296130445565212, 'w23': 1.2824291282826394, 'w24': 0.7143437498002505}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:47,855] Trial 14 finished with value: 0.5106382978723404 and parameters: {'w0': 1.6453937491483006, 'w1': -0.6949807249072739, 'w2': 2.395680703088677, 'w3': -2.495287816710541, 'w4': -0.5784583385535496, 'w5': 1.148067102061629, 'w6': -0.8777615923868243, 'w7': -0.10195116598705001, 'w8': -1.76885836507055, 'w9': 0.6368079975136287, 'w10': -0.09470082483388953, 'w11': -1.85611277413066, 'w12': -1.247473731493162, 'w13': -2.0708077443296466, 'w14': -0.9158239437118842, 'w15': -0.5274093149245478, 'w16': -1.6892586264194063, 'w17': 1.1386877683560537, 'w18': -1.7497557669366086, 'w19': 0.8229137945806375, 'w20': -1.564836120983375, 'w21': -0.7045107745312614, 'w22': 0.9829864365626977, 'w23': 0.48703663310563017, 'w24': -0.19411622115243846}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:48,254] Trial 15 finished with value: 0.5 and parameters: {'w0': 0.9497441263759068, 'w1': -0.9582111519786001, 'w2': 1.55499736109382, 'w3': 1.1862838512833185, 'w4': 1.345041141455987, 'w5': 0.33049016754836236, 'w6': 1.1207412723664116, 'w7': -1.289799144020538, 'w8': -0.5503718083976208, 'w9': 1.5664007880072273, 'w10': -1.6065499788018982, 'w11': -0.6434973829353672, 'w12': 1.6789920542997023, 'w13': -1.211875699633974, 'w14': 0.7780456262216129, 'w15': 1.1338978548289618, 'w16': -0.10968910274835181, 'w17': 0.75457358229598, 'w18': -1.1498277286821756, 'w19': 1.8002042718175737, 'w20': 1.6175076336038263, 'w21': -2.1132469628055297, 'w22': -1.6385640682170481, 'w23': 1.7393444371546192, 'w24': 1.2915762032226452}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:48,645] Trial 16 finished with value: 0.4948453608247423 and parameters: {'w0': 1.9984491559802904, 'w1': -2.3733570236054873, 'w2': 0.3529985325150209, 'w3': -1.1710604062004557, 'w4': -0.9425544771666133, 'w5': 1.82275184634352, 'w6': 0.18596807625145684, 'w7': -2.48707710069379, 'w8': -1.774288354429845, 'w9': -0.6769871977441163, 'w10': -1.765055946626735, 'w11': -1.484102046080514, 'w12': 2.4260387378513664, 'w13': -2.426093974126571, 'w14': -1.7399543980030847, 'w15': -0.5140450289655603, 'w16': 0.6579174014800895, 'w17': -0.9402700536770493, 'w18': -2.057743103234259, 'w19': -0.3798502919099884, 'w20': 0.04801215905279754, 'w21': -1.3275253206575361, 'w22': 0.7155358205304956, 'w23': 1.4913423977384077, 'w24': 2.373782050594545}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:49,039] Trial 17 finished with value: 0.5137614678899083 and parameters: {'w0': 0.15441571878147053, 'w1': 0.5006744529471008, 'w2': 1.8072212425736016, 'w3': -0.5136038179144669, 'w4': 0.8400594735250894, 'w5': 2.4170179603047446, 'w6': -0.9011111411752046, 'w7': 0.0005503765472365529, 'w8': -1.1517857415250068, 'w9': -2.4717498310174446, 'w10': -0.09422992074769593, 'w11': -0.17399884274620397, 'w12': 0.020714639776846067, 'w13': -0.17933889066627218, 'w14': -0.847199467228153, 'w15': -0.5625453544580349, 'w16': -2.004327126433007, 'w17': -2.277064929083822, 'w18': -0.1978937140532877, 'w19': 0.8986342865092957, 'w20': 1.4300289249589824, 'w21': -1.843877518841661, 'w22': 1.8832804432247328, 'w23': -0.35817207097219783, 'w24': 0.4903335416108241}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:49,461] Trial 18 finished with value: 0.509090909090909 and parameters: {'w0': 0.1476013308084853, 'w1': 0.4492461288188349, 'w2': 1.4208353105158413, 'w3': -0.5793939341400284, 'w4': 2.4743931204659675, 'w5': 1.3673786286947396, 'w6': -1.0744482112375275, 'w7': -0.03939923208166992, 'w8': -0.13537004347456016, 'w9': -2.3300279177885255, 'w10': -0.013975420397782545, 'w11': -0.2753772020230761, 'w12': -0.09500402659350649, 'w13': 0.8150529583181293, 'w14': 1.7188041328920889, 'w15': -0.6436589155579377, 'w16': -0.4465928633140306, 'w17': -2.3905424258993335, 'w18': 0.1084464787124384, 'w19': 0.6870849459805737, 'w20': 0.0011523081169434457, 'w21': 2.4597823268162418, 'w22': 1.6645165140757245, 'w23': -0.39651949477184134, 'w24': -0.569651716608057}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:49,853] Trial 19 finished with value: 0.4864864864864865 and parameters: {'w0': -0.8271266104441949, 'w1': -0.5419775489541162, 'w2': 0.526388073897393, 'w3': -1.6063366182447973, 'w4': 0.9794340271888152, 'w5': 2.488486633368437, 'w6': -0.5674688035319175, 'w7': 0.4027721928506345, 'w8': 1.0166657111756843, 'w9': 0.3722809330224325, 'w10': 2.2541904747710295, 'w11': 0.269026319429955, 'w12': -1.4724039785277914, 'w13': 0.12387300667349643, 'w14': 0.2102470085578919, 'w15': -2.478654041841464, 'w16': -2.424517473918846, 'w17': -1.9410364913657532, 'w18': 1.3213488900119985, 'w19': -0.29774031374268295, 'w20': -1.8015647265719266, 'w21': -1.9839788594960646, 'w22': 2.4394473646795625, 'w23': -0.16382150212822563, 'w24': -2.4796538379054334}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:50,248] Trial 20 finished with value: 0.5132743362831859 and parameters: {'w0': -0.14866259670441728, 'w1': -1.717249800498755, 'w2': 1.7180217908407538, 'w3': -1.9573283436869124, 'w4': 1.960284080752745, 'w5': -0.3474154843019521, 'w6': 1.4366437446995524, 'w7': -0.44083781131373956, 'w8': -1.1260173902894466, 'w9': 1.399894207504424, 'w10': 0.5003018478755081, 'w11': 1.9150766457251591, 'w12': -0.07024706940309722, 'w13': -0.31666520678828297, 'w14': -0.41155443365057964, 'w15': -0.9975090207433917, 'w16': -1.460291141220122, 'w17': -1.0669318163428818, 'w18': 1.3784409540512754, 'w19': 1.0729949919110002, 'w20': -0.6426734750329635, 'w21': -0.7110996588710541, 'w22': 0.5341816043992852, 'w23': -1.2621969691258557, 'w24': 0.33051900358992126}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:50,640] Trial 21 finished with value: 0.47863247863247865 and parameters: {'w0': 2.0108111733403278, 'w1': 1.5773800243047686, 'w2': 2.188515408308541, 'w3': -0.7080893259391597, 'w4': -0.07697105201855892, 'w5': 1.92053658007872, 'w6': -1.3143913016664024, 'w7': -1.3522723651199984, 'w8': -2.438578081190466, 'w9': -1.9074285977666756, 'w10': -0.3946652230656782, 'w11': -0.8890708704247607, 'w12': 1.4511740735524596, 'w13': -0.38830488005912633, 'w14': -0.9127704060066418, 'w15': 0.8749284614874697, 'w16': -1.9329166445942878, 'w17': 2.4170570826114264, 'w18': -0.39815357354963554, 'w19': 1.807273358679185, 'w20': 1.751406293997781, 'w21': -1.4356682389492197, 'w22': 1.744757150627236, 'w23': 0.7274349821253168, 'w24': 0.8236082485710865}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:51,043] Trial 22 finished with value: 0.5045045045045045 and parameters: {'w0': 1.6603315729779216, 'w1': 1.042578844625923, 'w2': 1.887958823316305, 'w3': -0.3074695313219471, 'w4': 0.1737147503133376, 'w5': 2.178678348606049, 'w6': -2.4628477483365634, 'w7': -1.1382280282503507, 'w8': -1.805304622919564, 'w9': -2.4539936567245952, 'w10': -1.3188676311211456, 'w11': 0.49438225525648194, 'w12': -0.3523707656314801, 'w13': -0.8753606215521027, 'w14': -1.2661696077384597, 'w15': -0.16940626246791612, 'w16': -1.9894199126382233, 'w17': -0.565211732455863, 'w18': -2.033409040012204, 'w19': 1.49902618267035, 'w20': 1.100006063646204, 'w21': -2.4518114568295433, 'w22': 1.509192608846646, 'w23': 0.1494061583285955, 'w24': 1.2180276398999275}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:51,444] Trial 23 finished with value: 0.4954128440366973 and parameters: {'w0': 0.5204763161370004, 'w1': 0.097696575766818, 'w2': 1.1691499667683418, 'w3': 0.9653492298608906, 'w4': 1.0068379880414258, 'w5': 1.5625208712951781, 'w6': -0.41978261802098427, 'w7': -1.6660649779454129, 'w8': -1.0609173810492032, 'w9': -0.6834532228413582, 'w10': -0.3686807582720314, 'w11': -0.28983395781321225, 'w12': 0.21217180978189676, 'w13': 0.45329957272478116, 'w14': -2.067739320036717, 'w15': 0.5194147329268218, 'w16': -1.3523462193903446, 'w17': -1.7249940683597633, 'w18': -1.23764120542636, 'w19': 2.2145825939791495, 'w20': 0.34865792783935046, 'w21': -1.9437906751773981, 'w22': 2.0645381453547853, 'w23': 0.9562519670653926, 'w24': 1.8232828195718462}. Best is trial 11 with value: 0.5137614678899083.\n",
      "[I 2025-09-08 14:13:51,831] Trial 24 finished with value: 0.5178571428571429 and parameters: {'w0': 1.186697371673977, 'w1': 1.9188323208071023, 'w2': 1.968486912955722, 'w3': -0.9913025745101572, 'w4': 1.8893813875730257, 'w5': 1.1211352286775953, 'w6': 0.37617447308701346, 'w7': -0.35768452748288815, 'w8': -2.1055616640663146, 'w9': -1.3523776493158635, 'w10': -2.0972280496434617, 'w11': -1.3215337898789663, 'w12': -1.2500437155885111, 'w13': 1.3922105403021021, 'w14': 0.21704751659160965, 'w15': -0.12354522388894618, 'w16': -0.46047301424555176, 'w17': -0.4688841312811578, 'w18': -0.6607834698909538, 'w19': 0.1310664690094776, 'w20': 1.3224883271530705, 'w21': -0.9506835779965637, 'w22': -0.782497468109913, 'w23': 2.393152326006641, 'w24': 0.5014110930753848}. Best is trial 24 with value: 0.5178571428571429.\n",
      "[I 2025-09-08 14:13:52,223] Trial 25 finished with value: 0.509090909090909 and parameters: {'w0': 1.16247615575381, 'w1': 1.9167398336019112, 'w2': 1.1484158885557785, 'w3': -1.0121487110734635, 'w4': 1.9026628500588476, 'w5': 1.010348819034574, 'w6': 0.45168658822516905, 'w7': 0.4275222578618573, 'w8': -1.5533592600336394, 'w9': -1.36532057067284, 'w10': -2.1066488286981633, 'w11': -1.4424599797389304, 'w12': -1.254255340304157, 'w13': 2.467494579128464, 'w14': 0.2948891943852309, 'w15': -0.323598608567503, 'w16': 0.5358921594762187, 'w17': -0.3933088414812842, 'w18': -0.27524867411911513, 'w19': 0.20862247315028204, 'w20': 1.9838392734914363, 'w21': -1.067448582740345, 'w22': -0.7139292682466782, 'w23': 2.3246200635263126, 'w24': -0.47341341153612304}. Best is trial 24 with value: 0.5178571428571429.\n",
      "[I 2025-09-08 14:13:52,611] Trial 26 finished with value: 0.5 and parameters: {'w0': 0.01472635136036586, 'w1': 0.5830301509933242, 'w2': -0.0755410421506843, 'w3': -0.9297013931991888, 'w4': 1.8276392133347987, 'w5': 0.5969057056993714, 'w6': 1.7175762820363576, 'w7': -0.2755304761862203, 'w8': -0.4054938964837628, 'w9': -1.9308865507816415, 'w10': -2.4690026739390682, 'w11': -2.2184612376624955, 'w12': -1.5892321574330182, 'w13': 1.327953409186251, 'w14': 1.3676283208293842, 'w15': -1.0790108792103799, 'w16': -0.5000382804502945, 'w17': -1.266975365209915, 'w18': -0.7868792976246258, 'w19': -0.19776963498881778, 'w20': 1.2234168006519297, 'w21': -0.5111216054984886, 'w22': -1.4260511859164742, 'w23': -1.095075687520172, 'w24': 0.3069174738397684}. Best is trial 24 with value: 0.5178571428571429.\n",
      "[I 2025-09-08 14:13:53,016] Trial 27 finished with value: 0.509090909090909 and parameters: {'w0': 0.8519320134526637, 'w1': -1.0506143886113037, 'w2': 1.9534999725010342, 'w3': -1.8495198527304502, 'w4': 2.25179934000302, 'w5': 0.1948626570330788, 'w6': -0.17680861005411241, 'w7': 0.889796573524211, 'w8': -2.08943566766361, 'w9': 0.052681961087671425, 'w10': -1.9585621996639848, 'w11': -0.14536388366771696, 'w12': -1.0184907320290937, 'w13': 1.2726176449042497, 'w14': -0.47766169124218294, 'w15': 1.3300289698340224, 'w16': -0.5639837175766418, 'w17': 0.5152637392623352, 'w18': 0.6281773899075036, 'w19': 0.8752540844592414, 'w20': -1.070542897823651, 'w21': -0.07990776659701934, 'w22': 0.4915991877345245, 'w23': 0.4884151359212032, 'w24': -0.6184834945807225}. Best is trial 24 with value: 0.5178571428571429.\n",
      "[I 2025-09-08 14:13:53,413] Trial 28 finished with value: 0.5 and parameters: {'w0': 1.6751674080193104, 'w1': -0.35428966518843374, 'w2': 1.3871115623547208, 'w3': -0.3428188947879936, 'w4': 1.6319403489333257, 'w5': 1.6136568009248906, 'w6': 1.0130739496016945, 'w7': -0.6756614503526479, 'w8': -0.9255594706467918, 'w9': 1.8190361597067395, 'w10': 1.6951888313328172, 'w11': -0.7127435081721432, 'w12': -1.8354846742344266, 'w13': 2.17425922706438, 'w14': 0.30455699919088464, 'w15': 0.5932451295082267, 'w16': 0.2716087186615006, 'w17': -0.7838997885019566, 'w18': 0.034785395038442246, 'w19': 0.45284632292057825, 'w20': 2.491982384834259, 'w21': -2.0772749009714406, 'w22': -0.3490142077413519, 'w23': 2.040016993704522, 'w24': 0.018475537402761644}. Best is trial 24 with value: 0.5178571428571429.\n",
      "[I 2025-09-08 14:13:53,802] Trial 29 finished with value: 0.4791666666666667 and parameters: {'w0': -0.7423835949242191, 'w1': 2.176560051205831, 'w2': 0.9808504442280142, 'w3': 0.4144534327027327, 'w4': 1.1265420057299251, 'w5': 1.1496876880096005, 'w6': 2.3829986283475195, 'w7': 0.23192943926110599, 'w8': 0.6632693308449735, 'w9': 0.8370835893745601, 'w10': -1.3068988961538677, 'w11': 2.4826720346340556, 'w12': -0.19058277622942787, 'w13': 0.44470338186162506, 'w14': -0.6058712459299078, 'w15': -0.8471999198392046, 'w16': -1.1139151276463082, 'w17': -2.0687544023445352, 'w18': -0.7010417980257153, 'w19': -0.655780781589051, 'w20': 0.43824737535777236, 'w21': -1.8244581023832351, 'w22': -0.5383191151487807, 'w23': -0.9021516271991665, 'w24': 1.7417432658915093}. Best is trial 24 with value: 0.5178571428571429.\n",
      "[I 2025-09-08 14:13:54,205] Trial 30 finished with value: 0.5045045045045045 and parameters: {'w0': 0.23662822502896574, 'w1': 1.9020033571830037, 'w2': 0.5655423979738203, 'w3': 0.11774756428392819, 'w4': 2.2400977058403075, 'w5': 2.4790233741040737, 'w6': 0.47159666129154654, 'w7': -1.054684372556805, 'w8': -1.3942656155102906, 'w9': -2.486078112881377, 'w10': -1.2690475707139486, 'w11': 0.925977906628968, 'w12': 0.37295232773936204, 'w13': -0.17121895400032544, 'w14': 0.020680573203696984, 'w15': -0.04347069232842993, 'w16': -2.1263800691859833, 'w17': -0.12023037580514817, 'w18': 1.150827706686156, 'w19': -1.6566784032547548, 'w20': -0.30269663120147783, 'w21': -1.707690832741252, 'w22': -1.4821235403278836, 'w23': -0.27026600121479294, 'w24': 0.5383141175798148}. Best is trial 24 with value: 0.5178571428571429.\n",
      "[I 2025-09-08 14:13:54,598] Trial 31 finished with value: 0.5185185185185185 and parameters: {'w0': 2.438377976033784, 'w1': 1.12554172260109, 'w2': 2.128630005765834, 'w3': 2.4228954138613794, 'w4': 0.5559179480955869, 'w5': 2.0169013847496724, 'w6': -1.7520547612272104, 'w7': -0.34754921464637006, 'w8': -2.1701323089910276, 'w9': -1.0784929171168929, 'w10': -0.4457700615761429, 'w11': -1.372818203655461, 'w12': 1.306657403177987, 'w13': -0.728939127283037, 'w14': -1.2480642117890188, 'w15': 0.11925749886683908, 'w16': -1.5443922461809372, 'w17': 0.5447783718099678, 'w18': -1.7133068787663648, 'w19': 0.3392397527468193, 'w20': 1.3132691009269295, 'w21': -1.0802942537376745, 'w22': -1.1817547327807802, 'w23': 1.7196573670828874, 'w24': 1.0195840626226451}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:54,977] Trial 32 finished with value: 0.5137614678899083 and parameters: {'w0': 1.438897658850661, 'w1': 0.9493611143492149, 'w2': 2.032910532330168, 'w3': 2.4437966007996033, 'w4': 0.7725050112422025, 'w5': 2.104174776833919, 'w6': -1.6304879582156786, 'w7': -0.2919679564729316, 'w8': -2.0862816887176496, 'w9': -1.1042169634305796, 'w10': 0.2186137184459469, 'w11': -2.048482307545062, 'w12': 1.1248679554826264, 'w13': -1.699421696325598, 'w14': -1.5031597479775103, 'w15': -0.00446996857228589, 'w16': -1.5329196024477267, 'w17': 0.6375023582994905, 'w18': -1.449740835151426, 'w19': 0.14641309395308966, 'w20': 1.8290151022080474, 'w21': -1.095882235565799, 'w22': -1.0796666945109736, 'w23': 2.447447646623189, 'w24': 0.07006136261004697}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:55,361] Trial 33 finished with value: 0.5 and parameters: {'w0': 2.0243662501799884, 'w1': 1.2387904767165372, 'w2': 1.5434015110367088, 'w3': -0.3794642028148208, 'w4': -0.39118884579233093, 'w5': 1.901407743570268, 'w6': -0.8465680111030847, 'w7': 0.7380526568340167, 'w8': -1.964248410193892, 'w9': -1.5530276425194098, 'w10': 0.7502784134458516, 'w11': -1.3037409987286972, 'w12': -0.5301214850679526, 'w13': -1.1256782697387542, 'w14': -1.9551774967463103, 'w15': -1.442274211283308, 'w16': -2.2567408698109435, 'w17': 0.41859616353371165, 'w18': -0.29406266356535665, 'w19': 0.4891746748768741, 'w20': 1.0184101376783883, 'w21': -0.9229126429669977, 'w22': -1.1566998719554906, 'w23': 1.7894585863651573, 'w24': 1.0008627880196825}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:55,745] Trial 34 finished with value: 0.5052631578947369 and parameters: {'w0': 1.507529199802629, 'w1': 2.009270223201855, 'w2': 2.379490437178286, 'w3': -2.048143996823473, 'w4': 0.35824244998505295, 'w5': 2.2285441287965555, 'w6': -1.58781741090452, 'w7': -0.1553854418587852, 'w8': -2.4986512205273383, 'w9': -0.09536394350146571, 'w10': -2.446283821358053, 'w11': -0.9608889547002335, 'w12': -2.1751159349091007, 'w13': -0.6212315054463602, 'w14': -0.24154873292877732, 'w15': 0.21259652085315894, 'w16': -0.817725584043344, 'w17': -0.15240014523369716, 'w18': -1.7693897554308609, 'w19': -0.0311178978341768, 'w20': 0.6132516924008381, 'w21': -1.6112639113781828, 'w22': -2.0365131987379295, 'w23': 2.10676756459431, 'w24': 1.4830761422625096}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:56,128] Trial 35 finished with value: 0.49557522123893805 and parameters: {'w0': 2.4532739928784766, 'w1': 1.6426787031774315, 'w2': 0.026716225871282084, 'w3': 0.7771930013123609, 'w4': 1.7123379326530435, 'w5': 0.7309783061020546, 'w6': -1.1346803124424483, 'w7': 0.1373787478864758, 'w8': -1.5277770974190612, 'w9': -0.8393559478314452, 'w10': -1.961084761766412, 'w11': -1.6717427413345665, 'w12': -1.0125080699741171, 'w13': -0.024399010352977257, 'w14': -1.3892620954744628, 'w15': 0.7273517700133819, 'w16': -1.668266834753803, 'w17': -2.499632936634451, 'w18': -1.4003039761674274, 'w19': 1.0909384709758227, 'w20': 1.5545099198510148, 'w21': -2.1931164247307287, 'w22': -0.31254893317412336, 'w23': 1.404107702625241, 'w24': 0.5154518695149184}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:56,514] Trial 36 finished with value: 0.5 and parameters: {'w0': 1.1736608491895306, 'w1': 0.703895388943212, 'w2': 1.2725357093315668, 'w3': -0.8500904397690898, 'w4': 1.2895189322083667, 'w5': 1.6668041594871763, 'w6': 0.2214584748557089, 'w7': -0.9021458794985422, 'w8': -1.1656547795256547, 'w9': -2.028139012746849, 'w10': -0.6454634893642757, 'w11': -0.45348101496239235, 'w12': 1.8368146242691759, 'w13': 0.4459649035159672, 'w14': -1.0221051743904748, 'w15': 1.3600871431017167, 'w16': -2.490034312471796, 'w17': -1.4125293374480563, 'w18': -0.9311019959300737, 'w19': 0.6883480928176986, 'w20': 1.236902179117627, 'w21': -0.3022189459775264, 'w22': 0.2688815426122727, 'w23': 0.5016786523598451, 'w24': -0.20557202540058814}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:56,898] Trial 37 finished with value: 0.5094339622641509 and parameters: {'w0': 2.110733283149669, 'w1': 0.18079539668709316, 'w2': 2.483921594512325, 'w3': -1.20412329432604, 'w4': -1.3839535248047725, 'w5': 1.9981880345249488, 'w6': -2.273541677791431, 'w7': -0.5432865090930578, 'w8': -2.2424051887529526, 'w9': -0.3180255641546445, 'w10': -0.9463723289854735, 'w11': 0.37364175535938293, 'w12': -1.7361201959987351, 'w13': -0.57519445351643, 'w14': -0.63822957617506, 'w15': -0.25641438605984745, 'w16': -1.1925073021316732, 'w17': 0.8963906628285627, 'w18': 2.4664032451148508, 'w19': -1.432589059414811, 'w20': 1.473532965453677, 'w21': 0.8792747383936019, 'w22': -0.7937069736237286, 'w23': -1.5563161054101136, 'w24': 1.011770279751437}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:57,280] Trial 38 finished with value: 0.5087719298245614 and parameters: {'w0': -0.3523133859641221, 'w1': 1.321172925035795, 'w2': 1.841217452917899, 'w3': 0.13005233804661898, 'w4': 2.125229903511428, 'w5': 1.3332278841241723, 'w6': 0.8489339915106604, 'w7': 1.3439860484604027, 'w8': -0.3173451037678121, 'w9': -0.5756458118114914, 'w10': -0.22419465490125012, 'w11': -0.7975095586831984, 'w12': 1.3586025396818218, 'w13': 1.8537992730128028, 'w14': 0.5920272238684516, 'w15': 0.41686684080505576, 'w16': -0.21307145288646667, 'w17': 0.34306972088423976, 'w18': 0.2563024216590223, 'w19': 1.4816854875623249, 'w20': 0.32153424053815194, 'w21': -1.2273557176737224, 'w22': 2.0205976509179235, 'w23': 0.12571985816825593, 'w24': 0.5174829053282073}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:57,662] Trial 39 finished with value: 0.5106382978723404 and parameters: {'w0': 0.6083841996260706, 'w1': 2.4727891403679974, 'w2': 2.112074014520828, 'w3': -1.6279115931076285, 'w4': 0.8440557779174547, 'w5': 2.3564356282563033, 'w6': -0.6829409229356689, 'w7': 0.6566254539351697, 'w8': 1.8225653549667997, 'w9': -1.1163603047351975, 'w10': -1.435697215871846, 'w11': 0.6712260896824209, 'w12': 0.5551262444300865, 'w13': -0.9859094830848725, 'w14': 0.011744925238645232, 'w15': 0.1387804265486412, 'w16': 1.0552714455957821, 'w17': -2.027818015360126, 'w18': -2.313809650093078, 'w19': 0.4054527929027353, 'w20': 0.7063239862015593, 'w21': -0.8565674599741278, 'w22': -0.2096961879782041, 'w23': -0.5543643047180908, 'w24': 1.9993174951323285}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:58,047] Trial 40 finished with value: 0.4793388429752066 and parameters: {'w0': -2.22553633488781, 'w1': 0.7876849929348786, 'w2': 1.6461230453180697, 'w3': 1.5225152117187375, 'w4': -2.263260454641072, 'w5': 1.762434490998527, 'w6': -0.23002093991663264, 'w7': -1.8006995668324854, 'w8': 0.28547780732718064, 'w9': -1.7529511886145848, 'w10': -1.0700223921487928, 'w11': 1.5192093606746084, 'w12': 1.0471435585658897, 'w13': -1.650550742093266, 'w14': -1.7722404922289132, 'w15': -0.7790221197816138, 'w16': -1.9455331822668716, 'w17': 1.6739776106622108, 'w18': -0.44403613229208705, 'w19': -0.6900805950101113, 'w20': -0.24193301551744056, 'w21': -2.2281353095085024, 'w22': 0.8607616305556235, 'w23': 1.127993713193232, 'w24': 0.8381898446412612}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:58,432] Trial 41 finished with value: 0.5137614678899083 and parameters: {'w0': 1.2762916748325595, 'w1': 0.38574071987414443, 'w2': 2.0272042184731247, 'w3': 2.4383707697192296, 'w4': 0.7669511307784381, 'w5': 2.140474192965948, 'w6': -1.8166915054001391, 'w7': -0.35187265947692303, 'w8': -2.165158958072406, 'w9': -1.0692939552053793, 'w10': 0.25958883158908386, 'w11': -1.973094494154931, 'w12': 1.1037320861658175, 'w13': -1.702860179465236, 'w14': -2.2169795263285, 'w15': -0.030370501421670776, 'w16': -1.5164511294002452, 'w17': 0.6074402408770109, 'w18': -1.5064392284781973, 'w19': 0.19260389045478765, 'w20': 1.7767753871218788, 'w21': -1.5958366598549172, 'w22': -1.2579936949114912, 'w23': 2.4904045577878158, 'w24': 0.09015856864584332}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:58,807] Trial 42 finished with value: 0.5 and parameters: {'w0': 1.8061027940481833, 'w1': 0.9868251462226185, 'w2': 1.9579282762688963, 'w3': 1.7219247927876276, 'w4': 0.44478495172515176, 'w5': 2.0635297601830667, 'w6': -1.3856555288020131, 'w7': 0.04394914933287754, 'w8': -1.9842251729395726, 'w9': -1.398330388415181, 'w10': 0.13479222284023218, 'w11': -2.4620247193493534, 'w12': 2.029751395325655, 'w13': -1.4507026324726966, 'w14': -1.8184176830558076, 'w15': -0.36240325047548116, 'w16': -1.4845801725311274, 'w17': 1.0266035330088557, 'w18': -1.8471969214260773, 'w19': 0.09161215588102295, 'w20': 1.9018234288319493, 'w21': -1.1121279584124832, 'w22': -0.9680795691235335, 'w23': 2.1726372491202817, 'w24': 0.022265810604304714}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:59,193] Trial 43 finished with value: 0.49572649572649574 and parameters: {'w0': 2.1923642619195576, 'w1': 1.107120047634773, 'w2': 2.197315459887528, 'w3': -0.5669537826609198, 'w4': 0.013799436808600227, 'w5': -2.4728538287439354, 'w6': -1.7613161999379225, 'w7': -0.86685559598677, 'w8': -1.618949929381662, 'w9': -2.177317095268032, 'w10': 0.5332713308766803, 'w11': -2.106075627799903, 'w12': 0.8758274188405178, 'w13': -0.18544197254600348, 'w14': -1.4974369083311698, 'w15': 0.3287224617136291, 'w16': -0.9786492042943127, 'w17': 0.24924349900427578, 'w18': -1.2095558853376502, 'w19': -0.48032847081729846, 'w20': 1.3981811847366545, 'w21': -0.009723805637570249, 'w22': -1.7751620810680888, 'w23': 2.492103925656566, 'w24': -0.3729907447320142}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:59,581] Trial 44 finished with value: 0.49056603773584906 and parameters: {'w0': 1.837004785533308, 'w1': -0.10512112079415137, 'w2': -1.2976601849861724, 'w3': 2.4155639281222063, 'w4': -0.2422065275900276, 'w5': -2.098195997445644, 'w6': -1.5690875407967035, 'w7': -0.25825750328902136, 'w8': -1.3455398601854247, 'w9': -0.4416280279639788, 'w10': 1.2369672411120078, 'w11': -1.2649327748711647, 'w12': 0.14327865315549926, 'w13': 1.0800085397811219, 'w14': -1.1742846332111085, 'w15': 0.0893516764310342, 'w16': -2.15203417906875, 'w17': -0.23400832272647243, 'w18': -0.9883212719976501, 'w19': 0.9609038055346253, 'w20': 2.044012546340876, 'w21': -0.5371904112405242, 'w22': -1.1375941116414565, 'w23': 1.584922714296667, 'w24': -0.7349045292671093}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:13:59,975] Trial 45 finished with value: 0.4954128440366973 and parameters: {'w0': 1.405796961220422, 'w1': 1.553266522715154, 'w2': 0.9813997166019006, 'w3': 2.122088128696321, 'w4': 1.5969743966099825, 'w5': 2.2901429346266284, 'w6': -2.156803121923006, 'w7': -0.6501904099950803, 'w8': -1.9830749607396974, 'w9': 0.18663200221106102, 'w10': -0.5728095192410283, 'w11': -1.6969439105332507, 'w12': 1.297302156917508, 'w13': -0.612599229492415, 'w14': -1.5674857281913899, 'w15': -1.132703787412309, 'w16': -1.610514857649038, 'w17': 1.5284624558811561, 'w18': -2.2473942361104693, 'w19': -0.08349391447226465, 'w20': 2.279197482151878, 'w21': -1.3646344067685714, 'w22': -0.026110691881685133, 'w23': 1.82991962815979, 'w24': 1.1894186602922798}. Best is trial 31 with value: 0.5185185185185185.\n",
      "[I 2025-09-08 14:14:00,350] Trial 46 finished with value: 0.5225225225225225 and parameters: {'w0': 2.259538555411221, 'w1': 0.7469090301116841, 'w2': 1.7391544552618488, 'w3': 1.8128466159377337, 'w4': 0.23204069540720174, 'w5': 1.2690431928501027, 'w6': -1.0867735121205824, 'w7': 2.428108092564653, 'w8': -2.346969336029971, 'w9': -1.246261059323273, 'w10': 0.37605366162119425, 'w11': -2.211678576496019, 'w12': -0.7595862907527993, 'w13': -1.9416343712944553, 'w14': -2.2180130678736774, 'w15': 0.6667887510412338, 'w16': -0.707248356262329, 'w17': -0.6678187910579655, 'w18': -1.928257207059922, 'w19': 1.2343879117824268, 'w20': -0.8920542871695658, 'w21': -1.821233934953265, 'w22': -0.5422863079796642, 'w23': 2.253676251530898, 'w24': -0.9240642794663045}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:00,731] Trial 47 finished with value: 0.5137614678899083 and parameters: {'w0': 2.285096924185891, 'w1': 0.4835494271903622, 'w2': -0.3619894983536369, 'w3': 1.7684627991464836, 'w4': 0.2405955836091861, 'w5': 0.8801085903323633, 'w6': -1.056192131137981, 'w7': 2.2918151577481756, 'w8': -2.3248798241606883, 'w9': 0.4896576677610953, 'w10': 0.9566728174676851, 'w11': -2.2588875508426742, 'w12': -0.8143233474781195, 'w13': -2.3781440188186407, 'w14': -2.4482831727797705, 'w15': 1.0842253416567464, 'w16': -0.7256230095812678, 'w17': -0.7071431233853243, 'w18': -2.451592016638764, 'w19': 1.3152126229463592, 'w20': -1.0441647858955598, 'w21': -1.792352927099921, 'w22': -0.5906016198841935, 'w23': -0.09838564597862365, 'w24': -1.015389919743028}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:01,107] Trial 48 finished with value: 0.4827586206896552 and parameters: {'w0': -1.0436248413320073, 'w1': 0.7733581623660293, 'w2': -2.351572599478872, 'w3': 0.5887786344395357, 'w4': 0.5289085336082888, 'w5': 1.2458289487868885, 'w6': 2.0846600779532416, 'w7': 2.009552503879635, 'w8': -1.6714796604376359, 'w9': 0.9727369528165053, 'w10': 0.45904293719141515, 'w11': -1.0537307357139103, 'w12': -0.41447026329663905, 'w13': 0.6081755011685797, 'w14': -2.0713315927129194, 'w15': 1.5254976611971065, 'w16': 0.041270186585646296, 'w17': 0.07558952568362654, 'w18': -2.0409041428823134, 'w19': 1.5855303393765923, 'w20': -0.90194324330564, 'w21': -2.266289022152014, 'w22': 2.1942193243444796, 'w23': 1.6508819356028912, 'w24': -0.9406518971510627}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:01,485] Trial 49 finished with value: 0.5137614678899083 and parameters: {'w0': 2.4289967603166485, 'w1': -0.7836901335800079, 'w2': 1.6789471274091676, 'w3': 1.4497274538925033, 'w4': 1.1792829701992444, 'w5': 0.3922042395537775, 'w6': 1.4685784924293974, 'w7': 1.6933625443025053, 'w8': -0.897211696724123, 'w9': -1.6118201481542729, 'w10': 1.4924316135513196, 'w11': -0.05305241981392039, 'w12': -1.1216464541504214, 'w13': -2.0553852005929736, 'w14': -2.24004855715288, 'w15': 0.6652041780773934, 'w16': -1.1233716935167741, 'w17': -0.378050415508991, 'w18': 0.4345234869367679, 'w19': 0.708735529661831, 'w20': -1.4794598782095751, 'w21': -2.460696291829018, 'w22': 1.445199589635315, 'w23': 1.8978558515122503, 'w24': -1.7264928822400059}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:01,860] Trial 50 finished with value: 0.49557522123893805 and parameters: {'w0': 2.2152893852225835, 'w1': -1.4799145444066375, 'w2': 0.6754633246386226, 'w3': -0.2019129273104865, 'w4': 2.3964582324389365, 'w5': -0.008162925269968868, 'w6': -0.7342486719377649, 'w7': 2.470275305526898, 'w8': -2.3530553529170204, 'w9': -0.8889478962464442, 'w10': -2.2202326966744375, 'w11': -0.4582104363162447, 'w12': -0.7205492513418945, 'w13': 1.6123942455542515, 'w14': 2.1546993120389684, 'w15': 0.9415002254794267, 'w16': -1.8968337250340281, 'w17': -1.229190068951047, 'w18': -1.8971213209898556, 'w19': 1.2163220134633002, 'w20': -2.3379041780821517, 'w21': 1.6251905880421624, 'w22': -0.11817748624438018, 'w23': 1.3095526232530368, 'w24': -1.350059986505475}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:02,237] Trial 51 finished with value: 0.4954128440366973 and parameters: {'w0': 0.9675719134550598, 'w1': 0.8911319952103502, 'w2': 0.2786305371510207, 'w3': 2.2460718026585518, 'w4': 0.7570323564061069, 'w5': 1.503567765780252, 'w6': -1.2530495338449859, 'w7': 1.639262779644535, 'w8': -2.1409167878276696, 'w9': -1.3124021422658199, 'w10': 0.17691781726255124, 'w11': -1.9444321824158923, 'w12': 0.47698708865039396, 'w13': -1.7328766014283017, 'w14': -1.869789993110622, 'w15': 2.0039656770158785, 'w16': -0.36630674853365175, 'w17': -0.795388351188292, 'w18': -1.6536123546869281, 'w19': 0.3066996879404864, 'w20': 0.9574072197466337, 'w21': -1.8454218608137316, 'w22': -0.5456548435194606, 'w23': 2.253318983382174, 'w24': 0.669752667302274}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:02,618] Trial 52 finished with value: 0.5192307692307693 and parameters: {'w0': 1.8398625785771237, 'w1': 1.1718629623537986, 'w2': 2.258615411113158, 'w3': 1.8962609858483432, 'w4': 0.5961045880360271, 'w5': 1.7847881844966988, 'w6': -1.549797613634992, 'w7': 1.0584258634225876, 'w8': -1.9104393021403574, 'w9': -1.781270740346571, 'w10': -0.17271896194068664, 'w11': -1.8732526338197042, 'w12': -1.4731719102218044, 'w13': -1.3792578036258436, 'w14': -2.239953188583139, 'w15': -0.4626486156349924, 'w16': -1.3042110146018782, 'w17': 0.1603871513271924, 'w18': -1.3876373341855321, 'w19': 0.5939446546525062, 'w20': 1.7323570020614274, 'w21': -1.4820579134481948, 'w22': -0.8471551023009358, 'w23': 1.9946554161384324, 'w24': 0.2776392317790512}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:02,995] Trial 53 finished with value: 0.5137614678899083 and parameters: {'w0': 1.8879618095922774, 'w1': 1.4198741671395563, 'w2': 2.261732895191317, 'w3': 1.9030437237806566, 'w4': -0.14161650661472902, 'w5': 1.827702265307919, 'w6': -2.0408955407100358, 'w7': 1.1172353095733447, 'w8': -1.8755229772529096, 'w9': -1.7116693586481726, 'w10': -0.17333727210424144, 'w11': -1.5896928195886502, 'w12': -1.391614371662539, 'w13': -1.3331297602642471, 'w14': -2.231061503112651, 'w15': -0.5581193790448004, 'w16': -1.2948450589764717, 'w17': 0.09731072422838694, 'w18': -1.5900185187122238, 'w19': 0.5161350185901639, 'w20': -0.4590407948594215, 'w21': -1.4279489865168524, 'w22': -0.8314398896848986, 'w23': 2.002812529819388, 'w24': 0.3314020193792766}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:03,374] Trial 54 finished with value: 0.5087719298245614 and parameters: {'w0': 2.4990269177774023, 'w1': 1.6992151372664925, 'w2': 1.4668876570828193, 'w3': -1.1721308184355133, 'w4': 0.2350385840268699, 'w5': 2.487265532736841, 'w6': -0.9518028946206045, 'w7': 1.5034257145491536, 'w8': -1.4379508941437624, 'w9': -2.1834142894332635, 'w10': -0.4853079414141636, 'w11': -1.7777702010946863, 'w12': -0.9087469634862891, 'w13': -0.8673335527685202, 'w14': -2.4743110864137066, 'w15': -0.19805957236189942, 'w16': -0.9711507972863154, 'w17': -0.565573609758252, 'w18': -0.5296061457132722, 'w19': 0.9973999926483985, 'w20': -2.0298141851768463, 'w21': -2.006853257581742, 'w22': -1.2823849802459848, 'w23': 1.0614210229147658, 'w24': -0.24367164698938565}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:03,760] Trial 55 finished with value: 0.5137614678899083 and parameters: {'w0': 2.240562735670537, 'w1': 1.2002807303211789, 'w2': 2.495108117081063, 'w3': 2.187557085394337, 'w4': 0.5910411027159076, 'w5': 1.3934571691051607, 'w6': -0.31603392021913135, 'w7': 1.0840867476944163, 'w8': -1.2787891159297502, 'w9': -2.2669804186614995, 'w10': -0.7369867602194358, 'w11': -1.23347076080156, 'w12': -1.995525343132004, 'w13': -1.0727314629619047, 'w14': -2.115369840667677, 'w15': -0.4238314438008173, 'w16': -0.6573065428771208, 'w17': -1.6485861231507957, 'w18': -0.11425215415215237, 'w19': 2.0558317286365155, 'w20': 0.17209041373352538, 'w21': -1.5206861118929753, 'w22': 0.1671903989808851, 'w23': 0.7258855033300412, 'w24': 1.447606141316598}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:04,145] Trial 56 finished with value: 0.5 and parameters: {'w0': 1.6132586582661608, 'w1': 0.27725748573420095, 'w2': 1.8131271961654454, 'w3': -1.3937614978605348, 'w4': -0.5102062958416835, 'w5': -1.2583276244160606, 'w6': 0.7222929187259144, 'w7': 0.3155693819250663, 'w8': -1.6924736237941562, 'w9': -1.8625667459112718, 'w10': 0.004250728826344918, 'w11': -2.28918602117756, 'w12': -0.6248173132728099, 'w13': -2.2286245193481315, 'w14': 0.5249378091589426, 'w15': 0.3391985845823279, 'w16': -0.27337399645670307, 'w17': -0.3469334771045781, 'w18': -1.2607921497775172, 'w19': 0.6799409233947106, 'w20': 1.2443334779349917, 'w21': -0.7912669141186313, 'w22': 1.7501842815385742, 'w23': 2.224155382135254, 'w24': 0.8536762010070207}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:04,527] Trial 57 finished with value: 0.5178571428571429 and parameters: {'w0': 1.9869020182322543, 'w1': 0.012510956612128164, 'w2': 2.1656821742675083, 'w3': 1.1478650719367245, 'w4': 0.9526865299378514, 'w5': 0.9769469153423448, 'w6': -1.4763216201176972, 'w7': -1.1065313955994909, 'w8': -2.258810323077212, 'w9': -1.468483244454003, 'w10': -1.8570947578332693, 'w11': 0.16875668368184876, 'w12': -1.2296381583734461, 'w13': -1.8951156796640534, 'w14': 0.8424659936398979, 'w15': -0.7594146855000086, 'w16': -1.8083983736432723, 'w17': -0.9940127913736552, 'w18': -2.1476658456124276, 'w19': 1.1542954927640436, 'w20': -1.33262605871997, 'w21': 0.28607507165436674, 'w22': 1.2084869691476667, 'w23': 1.5220443972582358, 'w24': -2.2722023610912996}. Best is trial 46 with value: 0.5225225225225225.\n",
      "[I 2025-09-08 14:14:04,909] Trial 58 finished with value: 0.5272727272727272 and parameters: {'w0': 1.9233452905308575, 'w1': -0.02380700784048935, 'w2': 2.219083303292169, 'w3': 1.2190722378101189, 'w4': 2.041088957137495, 'w5': 0.9627397131420381, 'w6': -1.4854169843701495, 'w7': -1.04317989580056, 'w8': -2.4993466909640807, 'w9': -1.4523156018739383, 'w10': -1.7728610815895922, 'w11': -1.5125418515801605, 'w12': -1.2822019222287273, 'w13': -1.8886420717732892, 'w14': 1.0410677641845234, 'w15': -1.7024155850939287, 'w16': 0.058719988601826256, 'w17': -1.0161212485912654, 'w18': -2.2089887828572574, 'w19': 1.924942699089752, 'w20': -1.3372542003346894, 'w21': 0.321014253346751, 'w22': 1.150899918439717, 'w23': 1.6145455163489542, 'w24': -2.132407732659136}. Best is trial 58 with value: 0.5272727272727272.\n",
      "[I 2025-09-08 14:14:05,309] Trial 59 finished with value: 0.5272727272727272 and parameters: {'w0': 1.8511635762338092, 'w1': -0.043403784044218074, 'w2': 2.263844898610559, 'w3': 1.150365784979922, 'w4': 1.5203428120291607, 'w5': 0.9539055941097596, 'w6': -1.8545217984113764, 'w7': -1.1884284484307888, 'w8': -2.303677828149703, 'w9': -1.4725393178518489, 'w10': -1.6810595804117507, 'w11': -1.4175331831373765, 'w12': -1.6086501345659654, 'w13': -1.9222137655733247, 'w14': 0.835411223463291, 'w15': -1.7397439621365502, 'w16': -0.009804120766777003, 'w17': -0.8971341760914306, 'w18': -2.4760188978902944, 'w19': 1.6866543084903185, 'w20': -1.4154810691137942, 'w21': 0.5201044632407439, 'w22': 1.0821051081264592, 'w23': 1.5178533641013046, 'w24': -2.365940787665599}. Best is trial 58 with value: 0.5272727272727272.\n",
      "[I 2025-09-08 14:14:05,695] Trial 60 finished with value: 0.5225225225225225 and parameters: {'w0': 1.7427731024686937, 'w1': -0.3787340496495561, 'w2': 2.298448715031409, 'w3': 1.4982868591334741, 'w4': 1.3629656681916718, 'w5': 0.6991434650681314, 'w6': -1.8236629171421892, 'w7': -1.4297248739227757, 'w8': -2.394410077547949, 'w9': -0.9919536696442908, 'w10': -1.6664664228381272, 'w11': -1.420338115131715, 'w12': -2.481182788663057, 'w13': -1.5138711159684914, 'w14': 1.1056626289335394, 'w15': -1.8722116821141077, 'w16': 0.10267124477867198, 'w17': -1.2296636351937427, 'w18': -2.4624938429874836, 'w19': 2.0102519407601718, 'w20': -1.717475094421773, 'w21': 0.6763619170487906, 'w22': 0.4109663279762914, 'w23': 1.9611788876619112, 'w24': -1.9832073699738917}. Best is trial 58 with value: 0.5272727272727272.\n",
      "[I 2025-09-08 14:14:06,078] Trial 61 finished with value: 0.5225225225225225 and parameters: {'w0': 1.7753122775034913, 'w1': -0.34152715085773105, 'w2': 2.3042613610973173, 'w3': 1.5025404525956054, 'w4': 1.7324436263285357, 'w5': 0.6163466969435634, 'w6': -1.8533186062904166, 'w7': -2.068101992668082, 'w8': -2.4028768984400677, 'w9': -1.2681942898164538, 'w10': -1.658086991463263, 'w11': -1.4534299078581208, 'w12': -2.356917381586089, 'w13': -1.4983636761837922, 'w14': 1.160905075706955, 'w15': -1.9191380925334063, 'w16': 0.19070383444243233, 'w17': -1.2410387080818543, 'w18': -2.428742429428606, 'w19': 2.015181103923088, 'w20': -1.7695382708970373, 'w21': 0.8777945887629411, 'w22': 0.405879364848855, 'w23': 1.7397221863913366, 'w24': -2.076801631366744}. Best is trial 58 with value: 0.5272727272727272.\n",
      "[I 2025-09-08 14:14:06,457] Trial 62 finished with value: 0.5225225225225225 and parameters: {'w0': 1.8522539883251803, 'w1': -0.4664117770988858, 'w2': 2.2945155640931216, 'w3': 1.4593783585037663, 'w4': 1.3283775479693136, 'w5': 0.6286909005771182, 'w6': -1.9076769805169116, 'w7': -2.132991665004563, 'w8': -2.3805962936285496, 'w9': -1.203978839302562, 'w10': -1.658448155718385, 'w11': -1.809815221910911, 'w12': -2.43028572211602, 'w13': -1.4932133585377727, 'w14': 1.1158927846142075, 'w15': -1.738299529920962, 'w16': 0.11225555362322648, 'w17': -1.3406669497237862, 'w18': -2.4977223141337164, 'w19': 1.9901887753395693, 'w20': -1.8304944474885316, 'w21': 0.6370534532110008, 'w22': 0.41233904927459275, 'w23': 1.681507845919499, 'w24': -1.9519608553168202}. Best is trial 58 with value: 0.5272727272727272.\n",
      "[I 2025-09-08 14:14:06,838] Trial 63 finished with value: 0.5272727272727272 and parameters: {'w0': 1.7185855850597247, 'w1': -0.2251471804415404, 'w2': 2.315768495616123, 'w3': 1.4386947939652943, 'w4': 1.4082312355216753, 'w5': 0.6499256423061325, 'w6': -2.3937714851261003, 'w7': -2.1739213398730546, 'w8': -2.479826823524608, 'w9': -1.2411939735733193, 'w10': -1.6376553765010042, 'w11': -1.5549191749682412, 'w12': -2.4607729018766027, 'w13': -1.4903096995995426, 'w14': 1.2116217749820708, 'w15': -1.7339001462683528, 'w16': 0.1957226494641165, 'w17': -1.3977489258976876, 'w18': -2.4826907229414474, 'w19': 1.9706606697016562, 'w20': -1.8950628917141255, 'w21': 0.7022170028978055, 'w22': 0.44961570772760723, 'w23': 1.9273167071936623, 'w24': -2.020511097396169}. Best is trial 58 with value: 0.5272727272727272.\n",
      "[I 2025-09-08 14:14:07,218] Trial 64 finished with value: 0.5225225225225225 and parameters: {'w0': 1.6414124775476022, 'w1': -0.38691380289665006, 'w2': 2.343482313515374, 'w3': 1.4195878601469811, 'w4': 1.4708911490250447, 'w5': 0.634829386269063, 'w6': -2.430609675613717, 'w7': -2.1489638419781754, 'w8': -2.4719243771880346, 'w9': -0.7815761612403619, 'w10': -1.567438994389344, 'w11': -1.5137042809371126, 'w12': -2.461749606470355, 'w13': -1.8704632926442317, 'w14': 1.2844398410505031, 'w15': -1.7729032073049396, 'w16': 0.12471551428173355, 'w17': -1.4572250932368045, 'w18': -2.483434441288378, 'w19': 2.00350611385389, 'w20': -2.0671926037694464, 'w21': 0.6694216233669871, 'w22': 0.5559404861313589, 'w23': 1.3184935722780806, 'w24': -2.015353968950281}. Best is trial 58 with value: 0.5272727272727272.\n",
      "[I 2025-09-08 14:14:07,594] Trial 65 finished with value: 0.5283018867924528 and parameters: {'w0': 1.470467292823895, 'w1': -0.5231970598950844, 'w2': 2.36379970572794, 'w3': 1.0257413028613436, 'w4': 2.0820867631609996, 'w5': 0.05273222109769393, 'w6': -1.8945484840332467, 'w7': -2.1689569665740485, 'w8': -2.3414158975676975, 'w9': -1.2176379800004962, 'w10': -1.4517166263763546, 'w11': -1.1277982602762482, 'w12': -2.093293689009745, 'w13': -1.4852229787184008, 'w14': 1.5996344994068625, 'w15': -2.2165417816854385, 'w16': 0.44260618600086343, 'w17': -1.244291626839604, 'w18': -2.3140607278463725, 'w19': 2.3744177381916387, 'w20': -1.7032349681876595, 'w21': 1.3977831915220014, 'w22': 0.36593971587735286, 'w23': 1.8714687995911323, 'w24': -1.777612224182291}. Best is trial 65 with value: 0.5283018867924528.\n",
      "[I 2025-09-08 14:14:07,969] Trial 66 finished with value: 0.5178571428571429 and parameters: {'w0': 1.3136586418134653, 'w1': -0.2561371942182583, 'w2': 2.422429620916589, 'w3': 1.2108048932175863, 'w4': 1.78032781774215, 'w5': -0.018781728254982394, 'w6': -2.170171403281617, 'w7': -2.447383139974066, 'w8': -2.3167489836827695, 'w9': -0.9688057066194711, 'w10': -1.1864044987833875, 'w11': -1.1214761431978322, 'w12': -2.17344602619931, 'w13': -2.230182851243612, 'w14': 1.534408865210421, 'w15': -2.2675279231075596, 'w16': 0.5010122918167854, 'w17': -1.879892520078367, 'w18': -2.281343451714053, 'w19': 2.342004484668424, 'w20': -1.663772746666422, 'w21': 1.155910571422622, 'w22': 1.0000375900488365, 'w23': 1.4644867236164922, 'w24': -2.494177905702389}. Best is trial 65 with value: 0.5283018867924528.\n",
      "[I 2025-09-08 14:14:08,347] Trial 67 finished with value: 0.5333333333333333 and parameters: {'w0': 1.5159274251727581, 'w1': -0.8221719180150027, 'w2': 2.0782843697882347, 'w3': 0.951358029157782, 'w4': 2.118498500833682, 'w5': -0.24839223092933027, 'w6': -2.2943972336802343, 'w7': -1.5852142916195886, 'w8': -2.48629065584909, 'w9': -1.251157925078539, 'w10': -1.493698648492801, 'w11': -1.6302959359368898, 'w12': -2.2468837303451346, 'w13': -1.5708375504599599, 'w14': 1.86447659356786, 'w15': -1.9797697449555847, 'w16': 0.36552582568637515, 'w17': -1.1787397229932253, 'w18': -1.9299778903401765, 'w19': 1.6651071101005344, 'w20': -2.48332919414603, 'w21': 1.3240729334691932, 'w22': 0.7465586024590576, 'w23': 2.1236894554127606, 'w24': -1.5827504702568416}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:08,734] Trial 68 finished with value: 0.5283018867924528 and parameters: {'w0': 0.9621495944171232, 'w1': -1.0701249882012436, 'w2': 1.7452853395549726, 'w3': 0.9380831296688296, 'w4': 2.0600110471770297, 'w5': -0.6884865576688577, 'w6': -2.2602251617940774, 'w7': -1.6076420413751316, 'w8': -2.034822120469273, 'w9': -1.548391933258863, 'w10': -1.4581603357013717, 'w11': -2.094703504875016, 'w12': -1.9065934372459583, 'w13': -1.8559715866774211, 'w14': 1.9355329754480128, 'w15': -2.1404779643062404, 'w16': 0.9085500313257153, 'w17': -1.1154603622180201, 'w18': -1.958540874138168, 'w19': 1.6822788658523251, 'w20': -2.0279836160882154, 'w21': 1.3894074567473655, 'w22': 0.7616227568133085, 'w23': 1.9259578305559377, 'w24': -1.5791175243287292}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:09,110] Trial 69 finished with value: 0.5333333333333333 and parameters: {'w0': 0.9589729374030757, 'w1': -1.0743022251175938, 'w2': 1.7509117568642303, 'w3': 0.9660015805299895, 'w4': 2.1014077363682357, 'w5': -0.9503211430804821, 'w6': -2.3157490091748034, 'w7': -1.7181150980023463, 'w8': -2.024762104910574, 'w9': -1.5674134978148864, 'w10': -1.4810150580954986, 'w11': -2.3576348926011117, 'w12': -1.8985701747932446, 'w13': -1.9079134105836248, 'w14': 1.8540464030865658, 'w15': -2.252068807957812, 'w16': 0.9302179782199621, 'w17': -0.9226977589581442, 'w18': -1.972467855576288, 'w19': 1.7324859675070337, 'w20': -2.1457528574800824, 'w21': 1.6178076641741017, 'w22': 0.6670292673316216, 'w23': 2.1328060392698736, 'w24': -1.6219807352122466}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:09,486] Trial 70 finished with value: 0.5233644859813084 and parameters: {'w0': 1.0239507756132806, 'w1': -1.227687841205384, 'w2': 1.2678406311797992, 'w3': 0.9581694509788442, 'w4': 2.0888564714827798, 'w5': -0.9476042531829068, 'w6': -2.32118230448346, 'w7': -1.6540401452351692, 'w8': -2.087855762776505, 'w9': -1.5870074255214555, 'w10': -1.4646110982064167, 'w11': -2.498453439381215, 'w12': -1.7953809460586971, 'w13': -2.4617262519508936, 'w14': 1.9104519906693838, 'w15': -2.170108059960832, 'w16': 0.9831166373487952, 'w17': -0.8967825681093824, 'w18': -2.084103916531477, 'w19': 1.7086191301924423, 'w20': -2.471883509479917, 'w21': 1.5350342083935824, 'w22': 0.7371157032373222, 'w23': 2.116994089628389, 'w24': -1.6538480872446426}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:09,864] Trial 71 finished with value: 0.5233644859813084 and parameters: {'w0': 0.9513832976687879, 'w1': -1.2114347931196765, 'w2': 1.5713599668811182, 'w3': 0.7594503985692647, 'w4': 2.01314742572738, 'w5': -0.9624914485201153, 'w6': -2.2954445411200632, 'w7': -1.6772067272388074, 'w8': -2.0751543278995013, 'w9': -1.5526709969144186, 'w10': -1.5096863757569918, 'w11': -2.3894481536572667, 'w12': -1.8467602874255453, 'w13': -2.2461539617675514, 'w14': 1.9216538558326797, 'w15': -2.200470859956868, 'w16': 0.9774366035484061, 'w17': -0.8711513644817241, 'w18': -2.1989514052606216, 'w19': 1.6856306520719069, 'w20': -2.4323379007208166, 'w21': 1.5694951243988446, 'w22': 0.7558971427688614, 'w23': 2.0984044220568268, 'w24': -1.6317869229998674}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:10,237] Trial 72 finished with value: 0.5233644859813084 and parameters: {'w0': 0.8022145252561041, 'w1': -0.8913767008345568, 'w2': 1.3359765157442833, 'w3': 0.9211972310433446, 'w4': 2.1454378258825875, 'w5': -0.5037262112673369, 'w6': -2.3599468069742615, 'w7': -1.5921915304058796, 'w8': -1.804583708594519, 'w9': -2.0296201603568553, 'w10': -1.4289063174320802, 'w11': -2.0809233033233308, 'w12': -2.198738460089448, 'w13': -2.4823750686204202, 'w14': 2.4151053098569513, 'w15': -2.4969340564388967, 'w16': 1.513772824605452, 'w17': -1.0647297842736994, 'w18': -1.9918404684768012, 'w19': 1.860277400225215, 'w20': -2.106619120856842, 'w21': 1.4877486695535918, 'w22': 0.9959139731963725, 'w23': 1.8513411288821762, 'w24': -1.363213034211866}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:10,616] Trial 73 finished with value: 0.5333333333333333 and parameters: {'w0': 1.0542781464485242, 'w1': -1.6711588977016245, 'w2': 1.9421350817176402, 'w3': 1.0412914077577708, 'w4': 2.309758093018913, 'w5': -1.5163914706989112, 'w6': -2.0403528348048634, 'w7': -1.9369926748198596, 'w8': -1.9763446036452015, 'w9': -1.4939975112674246, 'w10': -1.1125546800305668, 'w11': -2.463294230892199, 'w12': -2.012853846222509, 'w13': -2.1593761132082427, 'w14': 1.7731258032763881, 'w15': -2.1403126949539395, 'w16': 0.8190727476760391, 'w17': -1.7640938092041214, 'w18': -2.1035292398056677, 'w19': 2.3091230799794484, 'w20': -2.1849525955942997, 'w21': 2.018295699284299, 'w22': 0.7531710128569649, 'w23': 2.3166132771736847, 'w24': -1.8010986846241488}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:10,997] Trial 74 finished with value: 0.5233644859813084 and parameters: {'w0': 1.514936611991487, 'w1': -1.789550827105672, 'w2': 1.9204994037022303, 'w3': 0.3109121511176369, 'w4': 2.269485613042558, 'w5': -1.777145052587843, 'w6': -2.0497782264412265, 'w7': -2.314149761446329, 'w8': -2.2521192508434122, 'w9': -1.4346239069634121, 'w10': -1.1467594271544672, 'w11': -1.6550163256727755, 'w12': -1.9886347060928682, 'w13': -1.2573800242613336, 'w14': 1.6623553404724691, 'w15': -1.438290752646325, 'w16': 0.7925946464499554, 'w17': -1.5388166592710313, 'w18': -2.2888061555211756, 'w19': 2.48884744721723, 'w20': -2.1848498323904666, 'w21': 2.007377744518248, 'w22': 0.6242168316222747, 'w23': 2.3163526094377116, 'w24': -1.8321003076615225}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:11,371] Trial 75 finished with value: 0.5333333333333333 and parameters: {'w0': 0.45317971193745366, 'w1': -0.590937749243754, 'w2': 2.0780219080055042, 'w3': 1.0385369680068026, 'w4': 2.4776281677368086, 'w5': -0.19159349705464634, 'w6': -2.4626740177800377, 'w7': -1.951602953848957, 'w8': -2.4795366654210445, 'w9': -1.8600228328533046, 'w10': -1.830029854608354, 'w11': -2.111982472788203, 'w12': -1.6489580626405365, 'w13': -2.1150506644085727, 'w14': 2.214013605481638, 'w15': -2.3357282132356136, 'w16': 1.3340568272998494, 'w17': -1.8446163219457896, 'w18': -1.8012281968794788, 'w19': 2.3110084549762706, 'w20': -1.9055298253700395, 'w21': 1.8828711119001662, 'w22': 1.2578513392488477, 'w23': 1.8850483937244458, 'w24': -2.26177160902439}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:11,792] Trial 76 finished with value: 0.5283018867924528 and parameters: {'w0': 0.4198865009252966, 'w1': -0.6319309338871251, 'w2': 2.103724732228752, 'w3': 1.0891974747710955, 'w4': 2.4888174779141017, 'w5': -0.278645170963043, 'w6': -2.1472537685030733, 'w7': -1.9751590961842145, 'w8': 1.3138345667300544, 'w9': -1.986703722464753, 'w10': -1.7975710791129635, 'w11': -2.1021601004188053, 'w12': -1.5997305792499765, 'w13': -2.115627022309114, 'w14': 2.2058674113734837, 'w15': -2.363628740133546, 'w16': 1.383105035581623, 'w17': -1.8253524796742615, 'w18': -1.7566761305259118, 'w19': 2.1921789796877573, 'w20': -2.2570713471165407, 'w21': 2.038129572045116, 'w22': 1.3698867667122157, 'w23': 1.5716056235251548, 'w24': -2.2562027694715248}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:12,187] Trial 77 finished with value: 0.5333333333333333 and parameters: {'w0': 0.4090918044542128, 'w1': -1.0440295902411365, 'w2': 2.0925761874003794, 'w3': 0.618996822660511, 'w4': 2.381332728148958, 'w5': -0.6006987347965429, 'w6': -2.4991256848470673, 'w7': -1.948094011144575, 'w8': 1.3646966680069863, 'w9': -2.0281367920564106, 'w10': -1.8325771775816124, 'w11': -2.340399452440098, 'w12': -1.6623603899936372, 'w13': -2.126500651101293, 'w14': 2.2637882334770416, 'w15': -2.0816751896455714, 'w16': 1.3426783973021932, 'w17': -1.8153486753806214, 'w18': -1.8521544765642879, 'w19': 2.225489963254667, 'w20': -2.250222119981215, 'w21': 2.177330604855207, 'w22': 1.3538718149027253, 'w23': -2.215814617134348, 'w24': -2.1957721611847227}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:12,571] Trial 78 finished with value: 0.5333333333333333 and parameters: {'w0': 0.44057023120064787, 'w1': -0.6268280127483128, 'w2': 2.0138989047740656, 'w3': 0.7790629778294867, 'w4': 2.4166929788067946, 'w5': -0.18612839676490678, 'w6': -2.1174207453963465, 'w7': -1.9351437430814153, 'w8': 1.5483379989255173, 'w9': -1.9698591454209322, 'w10': -0.8762776249801172, 'w11': -2.3707841598708574, 'w12': -1.66108813383105, 'w13': -2.118385455375519, 'w14': 2.2069156838265873, 'w15': -2.3044609072452564, 'w16': 1.6248403238263565, 'w17': -1.80104052459132, 'w18': -1.9144640658758871, 'w19': 2.277985226263341, 'w20': -2.2458018521177476, 'w21': 2.2674612187861123, 'w22': 1.3170405525372142, 'w23': -2.3419982974199622, 'w24': -1.4689647814858133}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:12,952] Trial 79 finished with value: 0.509090909090909 and parameters: {'w0': 0.31808139746521835, 'w1': -0.9703637047114408, 'w2': 1.7756666638819865, 'w3': 0.6402715296853421, 'w4': 2.323041934251109, 'w5': -0.5382217068749345, 'w6': -1.9931142682557579, 'w7': -1.837851729629186, 'w8': 2.4106586814264297, 'w9': -2.370723592821587, 'w10': -0.8763399929385072, 'w11': -2.356372201994876, 'w12': -2.2499659511844285, 'w13': -2.131033504103687, 'w14': 2.2484141912567632, 'w15': -2.0315514943952233, 'w16': 1.9077062563840697, 'w17': -2.1803859644780266, 'w18': -1.532429687462551, 'w19': 2.3441191546381286, 'w20': -1.9621248661616097, 'w21': 2.4078948291805045, 'w22': 1.6159302229211279, 'w23': -1.6685409128234112, 'w24': -1.377983875432577}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:13,331] Trial 80 finished with value: 0.5137614678899083 and parameters: {'w0': 0.6669925463531354, 'w1': -1.559313385065015, 'w2': 2.0192341318684663, 'w3': 0.3337571980638063, 'w4': 1.8922691426573035, 'w5': -0.1489487254641355, 'w6': -2.4771746029420343, 'w7': -2.3560571106999193, 'w8': 1.4653609424791016, 'w9': -1.8713866872723957, 'w10': -2.306795994823257, 'w11': -2.2164782806445347, 'w12': -2.0630453182183053, 'w13': -2.340249600159807, 'w14': 2.01804532404654, 'w15': -2.0658305942043143, 'w16': 1.782836832676817, 'w17': -1.649633163784743, 'w18': -1.8254103086126117, 'w19': 2.172405824130644, 'w20': -2.346932343641385, 'w21': 1.799458520310756, 'w22': 0.8350462626117957, 'w23': -1.95145387561791, 'w24': -1.473093982482808}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:13,705] Trial 81 finished with value: 0.5333333333333333 and parameters: {'w0': 0.4482809105151426, 'w1': -0.631253021021269, 'w2': 2.073455528537878, 'w3': 1.0064974277612373, 'w4': 2.48956176652408, 'w5': -0.29020902667724524, 'w6': -2.174404504881955, 'w7': -1.9564905969370374, 'w8': 1.2592995332325654, 'w9': -2.0570446764640584, 'w10': -2.0480122441443886, 'w11': -2.1225238787389116, 'w12': -1.6386427936780394, 'w13': -2.105522463271659, 'w14': 2.304410752020522, 'w15': -2.3347577395460735, 'w16': 1.3268452343915798, 'w17': -1.805894110226338, 'w18': -1.7669775585445198, 'w19': 2.2587326767371088, 'w20': -2.2435771556800597, 'w21': 2.2299039296411727, 'w22': 1.3771410733256202, 'w23': -2.1226903033960998, 'w24': -2.2125391011404334}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:14,077] Trial 82 finished with value: 0.5333333333333333 and parameters: {'w0': 0.08548542081092358, 'w1': -1.10871938305056, 'w2': 1.6093350623094107, 'w3': 0.7714148010047327, 'w4': 2.1937991332549083, 'w5': -0.8223674778178048, 'w6': -2.2099743667940337, 'w7': -1.9268619626211492, 'w8': 1.6641035187670743, 'w9': -2.1245265210141118, 'w10': -2.13116660948611, 'w11': -1.9351841426940382, 'w12': -1.7036395794385024, 'w13': -1.7951517946296656, 'w14': 1.7591150793812105, 'w15': -2.3096466862102396, 'w16': 1.2754539476599591, 'w17': -1.792151714006521, 'w18': -1.967576838029403, 'w19': 2.3306549724229324, 'w20': -2.1713463750459767, 'w21': 2.2662792074125155, 'w22': 1.2450825448090566, 'w23': -2.4740933100980276, 'w24': -1.7692808832086642}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:14,460] Trial 83 finished with value: 0.5185185185185185 and parameters: {'w0': -0.2872396604692986, 'w1': -0.8425660082455326, 'w2': 1.5681349644499514, 'w3': 0.7567579584949838, 'w4': 2.353701135869181, 'w5': -1.446880106941399, 'w6': -2.152040577591717, 'w7': -1.973386872634343, 'w8': 1.9941136955269703, 'w9': -2.1420005609556516, 'w10': -2.010621828649737, 'w11': -1.9633469185733707, 'w12': -1.6240791931323826, 'w13': -1.7511496692516029, 'w14': 2.4985518885173414, 'w15': -2.3470764952357053, 'w16': 1.2297597180607256, 'w17': -2.1110509619359243, 'w18': -1.6091924036319258, 'w19': 2.3305911363038376, 'w20': -2.230608623579283, 'w21': 2.137684832171013, 'w22': 1.2614861940920759, 'w23': -2.38858575063611, 'w24': -1.8222518099723366}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:14,840] Trial 84 finished with value: 0.5192307692307693 and parameters: {'w0': -0.059513559712059405, 'w1': -0.7191536133588541, 'w2': 1.8871551203029646, 'w3': 0.5098219007821578, 'w4': 2.194445579525958, 'w5': 0.1840190800561664, 'w6': -2.473965146658959, 'w7': -1.777039175443661, 'w8': 1.5347130713494141, 'w9': -2.3025862244952195, 'w10': -2.173234979299723, 'w11': -2.361789849944319, 'w12': -1.7421479619459643, 'w13': -1.6308919118195737, 'w14': 1.7311205890839854, 'w15': -2.362076138296327, 'w16': 1.7170152536904741, 'w17': -2.284123947325258, 'w18': -2.0912254581411864, 'w19': 2.1468934930708095, 'w20': -2.162268762207646, 'w21': 2.307655870225944, 'w22': 1.5571664161829695, 'w23': -2.2556834887192854, 'w24': -1.149438335100191}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:15,224] Trial 85 finished with value: 0.5283018867924528 and parameters: {'w0': 0.5371219603282984, 'w1': -2.1293082831930437, 'w2': 2.06638489407305, 'w3': 0.8567996482469253, 'w4': 2.431189325164686, 'w5': -0.7356596565426219, 'w6': -1.9865991698230925, 'w7': -2.2904901497947114, 'w8': 1.7444329045128601, 'w9': -2.067997266431865, 'w10': -2.354241836835032, 'w11': -2.192313835065761, 'w12': -2.1013541149878234, 'w13': -1.9987689861723488, 'w14': 1.514005104593998, 'w15': -1.9069295180621462, 'w16': 1.2022020552654098, 'w17': -1.6914050415672905, 'w18': -1.869973174829551, 'w19': 2.391654780584314, 'w20': -1.6130048047385874, 'w21': 1.8531085216085728, 'w22': 1.8184251715239255, 'w23': -1.9453392684690365, 'w24': -1.8352653500694358}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:15,605] Trial 86 finished with value: 0.5233644859813084 and parameters: {'w0': 0.7778398193787399, 'w1': -1.3907547648324967, 'w2': 1.46662894881955, 'w3': 0.6325990412651232, 'w4': 2.257566375358894, 'w5': -0.22282855705901367, 'w6': -2.165945510845834, 'w7': -1.9518979929581834, 'w8': 1.0098890971361985, 'w9': -1.72404594738749, 'w10': -2.0283433124482153, 'w11': -1.87758166066142, 'w12': -1.4433851517697311, 'w13': -2.134018453292161, 'w14': 2.062989568262579, 'w15': -2.029032453905312, 'w16': 0.5510299365337266, 'w17': -1.867208431838056, 'w18': -1.3168247198421335, 'w19': 2.4965645326167474, 'w20': -2.4826502764169267, 'w21': 2.22143206379264, 'w22': 1.3583213786041097, 'w23': -2.472502856782292, 'w24': -2.2512285911235637}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:15,979] Trial 87 finished with value: 0.5283018867924528 and parameters: {'w0': 0.034719982852308096, 'w1': -0.6112733654696921, 'w2': 1.9308440438718766, 'w3': 1.075073795746084, 'w4': 1.9274763842503746, 'w5': -1.0637936199352063, 'w6': -1.6938682369263627, 'w7': -1.478860021209973, 'w8': 1.057758893830756, 'w9': -1.863423079085649, 'w10': -1.3318889240336693, 'w11': -2.4636065631589634, 'w12': -1.9185721855632554, 'w13': -2.3242663273905477, 'w14': 2.3070418555935714, 'w15': -1.5105014915723685, 'w16': 0.35653780802562274, 'w17': -1.9745764936065195, 'w18': -1.0839066251428024, 'w19': 2.185957819219512, 'w20': -1.924732118758597, 'w21': 1.8176455784127148, 'w22': 0.9025917732896348, 'w23': -2.0821081114725457, 'w24': -1.2718679877350367}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:16,350] Trial 88 finished with value: 0.5185185185185185 and parameters: {'w0': 0.1350400413261144, 'w1': -1.110634000367609, 'w2': 1.6558777418143436, 'w3': 0.804949997228549, 'w4': 2.191872537108224, 'w5': -0.39799826230632185, 'w6': -2.270200851247985, 'w7': -1.753350733185686, 'w8': 1.9533472227645774, 'w9': -1.6759223366379439, 'w10': -1.0007800861944625, 'w11': -1.7460974916682104, 'w12': -2.3003455352526796, 'w13': -1.6117622897905755, 'w14': 1.7952628219043605, 'w15': -2.2596274332036637, 'w16': 2.40081650335769, 'w17': -1.7821700184222968, 'w18': -1.7014142076488108, 'w19': 2.27639249140054, 'w20': -2.2557343706623936, 'w21': 2.463505338592284, 'w22': 0.26799421697961734, 'w23': -2.2853807085421476, 'w24': -2.1646388227963023}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:16,726] Trial 89 finished with value: 0.5283018867924528 and parameters: {'w0': 0.42487366196708226, 'w1': -1.7851266826696641, 'w2': 2.0877798110887285, 'w3': 1.337693170215925, 'w4': 2.447619189128182, 'w5': -0.5969804836968573, 'w6': -2.0575873021824003, 'w7': -1.3240418699644503, 'w8': 2.1428740650175992, 'w9': -2.246979507394981, 'w10': -1.9104931533509772, 'w11': -2.314377773368372, 'w12': -1.6840072636162366, 'w13': -1.7632903160819027, 'w14': 2.145139612958559, 'w15': -2.4348356868692567, 'w16': 1.2884523834986203, 'w17': -1.561096387165543, 'w18': -1.9624130463587344, 'w19': 1.5039622588539994, 'w20': -2.3806848333609443, 'w21': 1.6940758703802938, 'w22': 1.0798475044024558, 'w23': -1.6416215000918333, 'w24': -1.7797816883442636}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:17,110] Trial 90 finished with value: 0.5333333333333333 and parameters: {'w0': 0.28551312630238657, 'w1': -0.5173804719441205, 'w2': 1.8407825570868628, 'w3': 1.02710587378153, 'w4': 2.324621273013455, 'w5': 0.17032256749119876, 'w6': -2.3823437603007944, 'w7': -2.0339972829736026, 'w8': 1.3044473565346708, 'w9': -1.938721886894058, 'w10': -1.1787997221605977, 'w11': -2.165511588473915, 'w12': -1.521983868879359, 'w13': -2.1772154893797167, 'w14': 1.5849970105869036, 'w15': -2.0604387955755596, 'w16': 0.754769370925444, 'w17': -2.19429174584529, 'w18': -2.3359953772329876, 'w19': 1.82725008369873, 'w20': -2.149694335007866, 'w21': 2.13625177120093, 'w22': 1.424240253634934, 'w23': -2.069984364252908, 'w24': -1.4764199606212665}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:17,483] Trial 91 finished with value: 0.5233644859813084 and parameters: {'w0': 0.27395385859086346, 'w1': -0.5199602869240474, 'w2': 1.8461592156691506, 'w3': 0.9989590980253007, 'w4': 2.337458476538836, 'w5': -0.12352177812626786, 'w6': -2.4999512762195373, 'w7': -2.0220236382353334, 'w8': 1.2109117562254705, 'w9': -2.0909634381906264, 'w10': -1.2076436249347775, 'w11': -2.0241363923026863, 'w12': -1.4979306345356038, 'w13': -2.0352521934910053, 'w14': 2.378514264123847, 'w15': -2.0944224960920392, 'w16': 0.7478603112629473, 'w17': -2.3848333874003242, 'w18': -1.8033170860413115, 'w19': 2.1091698144836113, 'w20': -2.1178113642755143, 'w21': 2.18796975690587, 'w22': 1.3454064112633806, 'w23': -2.042990720789044, 'w24': -1.5150258092768085}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:17,865] Trial 92 finished with value: 0.5185185185185185 and parameters: {'w0': 0.5543744549476399, 'w1': -0.7404109414843298, 'w2': 1.1212666894625716, 'w3': 0.45715624240431035, 'w4': 2.4867727097025645, 'w5': 0.18541802079502584, 'w6': -2.3874128569291964, 'w7': -1.9165714563830258, 'w8': 0.8456631626996384, 'w9': -2.4008639964678267, 'w10': -1.1081726483288796, 'w11': -2.125193509538218, 'w12': -1.35213243664607, 'w13': -2.219664440454482, 'w14': 1.5477979049341903, 'w15': -1.959978226176341, 'w16': 1.5595064065326418, 'w17': -2.1519522616002273, 'w18': -2.3364940211179457, 'w19': 1.8564597368620788, 'w20': -1.8419719105122818, 'w21': 1.3506986316190128, 'w22': 1.533343248880619, 'w23': -2.1164394541504854, 'w24': -2.348939774805424}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:18,237] Trial 93 finished with value: 0.5283018867924528 and parameters: {'w0': 1.0855498361248463, 'w1': -0.9678853092631384, 'w2': 1.9837469366219278, 'w3': 1.3012939434577802, 'w4': 1.988443250678111, 'w5': 0.419846473847307, 'w6': -2.0857724825776502, 'w7': -2.2270745890265866, 'w8': 1.6965285205425447, 'w9': -1.9550929934790076, 'w10': -1.3576911500494806, 'w11': -1.9331622789174545, 'w12': -2.1010297739925403, 'w13': -1.7973059300931005, 'w14': 1.7774285932295226, 'w15': -1.5944494538071912, 'w16': 1.1217631744518783, 'w17': -1.9803438805686249, 'w18': -2.1350441991426017, 'w19': 2.2682768090247927, 'w20': -2.314435656090329, 'w21': 1.909862511574596, 'w22': 1.4381722670949917, 'w23': -1.7875703072225138, 'w24': -1.7100469414066504}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:18,611] Trial 94 finished with value: 0.5045045045045045 and parameters: {'w0': -0.581928850685541, 'w1': -1.2798775872133155, 'w2': -0.9475698206656462, 'w3': 1.6469473243891757, 'w4': 2.1277449974888403, 'w5': -1.4841955652665728, 'w6': -2.1848791449685976, 'w7': -2.4870161579062557, 'w8': 1.4380323842029317, 'w9': -1.8145488301146333, 'w10': -2.1294766224160573, 'w11': -2.371605162025052, 'w12': -1.932581921463468, 'w13': -1.9848708504396293, 'w14': 1.3575434430707698, 'w15': -2.2756889311592223, 'w16': 1.3847293308149127, 'w17': -1.4960846233307836, 'w18': -2.0777978611512133, 'w19': 2.439342198872922, 'w20': -1.9528578194345778, 'w21': 2.125261012818449, 'w22': 0.9356324066475358, 'w23': -2.4107366854698027, 'w24': -1.9080262013597664}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:18,984] Trial 95 finished with value: 0.5233644859813084 and parameters: {'w0': 0.7339246708922185, 'w1': -1.140294623324877, 'w2': 2.1434387004488515, 'w3': 0.7068750565871678, 'w4': 1.819712121066805, 'w5': -0.8232338634085151, 'w6': -2.2724888016637994, 'w7': -1.8447880877305594, 'w8': 0.20134175529873088, 'w9': -1.6528062129985153, 'w10': -0.7389145050231679, 'w11': -2.201832596540808, 'w12': -1.8157049394648714, 'w13': -2.31361831106952, 'w14': 2.073944648001969, 'w15': -2.4153193529152475, 'w16': 0.8333287762137088, 'w17': -1.7629833741788723, 'w18': -2.329231262256336, 'w19': 1.8083735466702593, 'w20': -1.5749495763533712, 'w21': 2.3275553650446597, 'w22': 1.9377430911792053, 'w23': -2.1552525110310707, 'w24': -1.5028843472569011}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:19,360] Trial 96 finished with value: 0.5283018867924528 and parameters: {'w0': -0.20644377589527485, 'w1': -1.6432443004287562, 'w2': 2.445237006972115, 'w3': 1.0476023203054892, 'w4': 2.3190126706416896, 'w5': 0.10024750949747593, 'w6': -1.9399863900954561, 'w7': -2.066886009646951, 'w8': 1.5906765945242958, 'w9': -2.1443730904521936, 'w10': -1.8098657985966125, 'w11': -2.2797562591032974, 'w12': -1.1324556805970574, 'w13': -2.1626030563647483, 'w14': 1.8654340668304852, 'w15': -2.1708245101202053, 'w16': 0.6771501250861436, 'w17': -2.25034912112426, 'w18': -1.676657519585799, 'w19': 2.1229095015982766, 'w20': -2.164728199468232, 'w21': 1.6987514697641437, 'w22': 1.2215696979062953, 'w23': -1.3190345033358888, 'w24': -1.208917193922765}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:19,735] Trial 97 finished with value: 0.5148514851485149 and parameters: {'w0': 0.1096037269608473, 'w1': -0.8557571419113561, 'w2': 1.6728144355184533, 'w3': 0.8513963647582928, 'w4': 1.663364024364325, 'w5': -0.32328305113727096, 'w6': -2.3563689536116303, 'w7': -1.5263449588479934, 'w8': 1.2783335976786585, 'w9': 2.1370680749413107, 'w10': -0.9775206912856863, 'w11': -2.493420042163628, 'w12': -1.7054881498748715, 'w13': -2.3598180076082804, 'w14': 1.6134905247745746, 'w15': -1.2346367928003457, 'w16': 0.42815075721017654, 'w17': -1.631206657019261, 'w18': -1.8877345339533074, 'w19': 1.3573228105123243, 'w20': -2.02787057695874, 'w21': 1.937799323047223, 'w22': 0.6347720340539869, 'w23': -2.242611836941617, 'w24': -2.1423117243553818}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:20,116] Trial 98 finished with value: 0.5192307692307693 and parameters: {'w0': 0.4512460032187219, 'w1': -0.542172683736983, 'w2': 1.8404113645613265, 'w3': 0.1922032151906803, 'w4': 2.213593263456929, 'w5': -0.4418100792722478, 'w6': -1.9292038415102741, 'w7': -2.3766055274581905, 'w8': 1.1472008611704063, 'w9': -1.9541558337132825, 'w10': -0.8154592878756032, 'w11': -1.8491751369282772, 'w12': -1.5423337107253552, 'w13': -2.0463376948667364, 'w14': 2.0194891060808566, 'w15': -1.828257939866288, 'w16': 2.156216846574228, 'w17': -2.045705482104449, 'w18': -1.500047061122616, 'w19': 1.8942677095644016, 'w20': -2.4976135324754325, 'w21': 2.277755357807248, 'w22': 1.710681971133828, 'w23': -0.9432096580678744, 'w24': -2.3894444630405585}. Best is trial 67 with value: 0.5333333333333333.\n",
      "[I 2025-09-08 14:14:20,493] Trial 99 finished with value: 0.5283018867924528 and parameters: {'w0': 0.6555035019925444, 'w1': -1.3899420753256146, 'w2': 1.5202407148695585, 'w3': 0.547092618375442, 'w4': 2.3811027678934504, 'w5': -0.07311027226932856, 'w6': -2.085679335190689, 'w7': -1.7485667392160187, 'w8': 0.770215572407125, 'w9': -2.4808428766670843, 'w10': -1.2831409137958292, 'w11': -1.9924857205965685, 'w12': -2.0355061583469114, 'w13': -1.5604733952624334, 'w14': 2.2999325738132166, 'w15': -1.9824117435344923, 'w16': 1.5070916643591938, 'w17': -1.332708313335924, 'w18': -1.9924761301034515, 'w19': 1.5820726155359899, 'w20': -2.3580756626542945, 'w21': 2.096919116239466, 'w22': 1.0946519390699851, 'w23': -1.8629470110921913, 'w24': -1.879594584736346}. Best is trial 67 with value: 0.5333333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - [Optuna融合] 在验证集上学到的最优阈值: 0.430\n",
      "\n",
      "===== 最终阶段: 在完整80%数据上重训, 并在20%测试集上评估三种策略 =====\n",
      "\n",
      "==== FINAL - Simple Average Performance ====\n",
      "Accuracy:        0.555233\n",
      "AUC:             0.643516\n",
      "PR-AUC:          0.504503\n",
      "LogLoss:         0.660604\n",
      "Precision@0.400: 0.471774\n",
      "Recall@0.400:    0.841727\n",
      "F1@0.400:        0.604651\n",
      "\n",
      "==== FINAL - Val-AUC Weighted Performance ====\n",
      "Accuracy:        0.555233\n",
      "AUC:             0.644043\n",
      "PR-AUC:          0.505295\n",
      "LogLoss:         0.660534\n",
      "Precision@0.400: 0.471774\n",
      "Recall@0.400:    0.841727\n",
      "F1@0.400:        0.604651\n",
      "\n",
      "==== FINAL - Optuna Weights Performance ====\n",
      "Accuracy:        0.610465\n",
      "AUC:             0.643938\n",
      "PR-AUC:          0.509922\n",
      "LogLoss:         0.657437\n",
      "Precision@0.430: 0.513966\n",
      "Recall@0.430:    0.661871\n",
      "F1@0.430:        0.578616\n",
      "\n",
      "[导出] 包含三种策略的逐样本结果已导出: reports\\results_test_3_blends_optimized_for_f1.xlsx\n",
      "[绘图] 三种策略的ROC对比曲线已保存: reports\\roc_curves_3_blends_f1.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss,\n",
    "    roc_curve\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 0) 数据准备\n",
    "# =========================\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,      y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# =========================\n",
    "# 1) 工具函数（评估 / 采样 / 双类保障 / 阈值寻优）\n",
    "# =========================\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:        {acc:.6f}\")\n",
    "    print(f\"AUC:             {auc:.6f}\")\n",
    "    print(f\"PR-AUC:          {ap:.6f}\")\n",
    "    print(f\"LogLoss:         {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on_val(y_val, p_val, metric='f1', min_precision=None, target_pos_rate=None):\n",
    "    \"\"\"\n",
    "    网格搜阈值:\n",
    "      metric ∈ {'accuracy','f1','recall','precision'}\n",
    "      可选约束:\n",
    "        - min_precision: 阈值必须满足 Precision >= 该值\n",
    "        - target_pos_rate: 可行解内优先选择正例率最接近该目标的阈值\n",
    "    \"\"\"\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    metric = metric.lower()\n",
    "    if metric not in {'accuracy','f1','recall','precision'}:\n",
    "        raise ValueError(f\"不支持的阈值寻优指标: {metric}\")\n",
    "\n",
    "    cand = []\n",
    "    for t in ths:\n",
    "        pred = (p_val >= t).astype(int)\n",
    "        acc = accuracy_score(y_val, pred)\n",
    "        f1  = f1_score(y_val, pred, zero_division=0)\n",
    "        rec = recall_score(y_val, pred, zero_division=0)\n",
    "        pre = precision_score(y_val, pred, zero_division=0)\n",
    "        pos_rate = pred.mean()\n",
    "        score = acc if metric=='accuracy' else f1 if metric=='f1' else rec if metric=='recall' else pre\n",
    "\n",
    "        # 约束：最小精度\n",
    "        if (min_precision is not None) and (pre < min_precision):\n",
    "            continue\n",
    "        cand.append((t, score, pos_rate))\n",
    "\n",
    "    # 若无可行解，回退到“precision 最大”的阈值（保证尽量抑制假阳性）\n",
    "    if not cand:\n",
    "        best = None\n",
    "        best_pre = -1\n",
    "        for t in ths:\n",
    "            pred = (p_val >= t).astype(int)\n",
    "            pre = precision_score(y_val, pred, zero_division=0)\n",
    "            if pre > best_pre:\n",
    "                best_pre = pre; best = t\n",
    "        return float(best if best is not None else 0.5)\n",
    "\n",
    "    if target_pos_rate is not None:\n",
    "        cand.sort(key=lambda x: (abs(x[2]-target_pos_rate), -x[1]))\n",
    "        return float(cand[0][0])\n",
    "\n",
    "    cand.sort(key=lambda x: -x[1])\n",
    "    return float(cand[0][0])\n",
    "\n",
    "def block_bootstrap(n, ratio, block=20, rng=None):\n",
    "    m = int(n * ratio); idx = []\n",
    "    if n <= 0: return np.array([], dtype=int)\n",
    "    if block <= 0: block = 1\n",
    "    while len(idx) < m:\n",
    "        s = rng.randint(0, max(1, n - block + 1)); idx.extend(range(s, min(s + block, n)))\n",
    "    idx = np.array(idx[:m], dtype=int); idx.sort()\n",
    "    return idx\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3):\n",
    "    if len(np.unique(y_val_fit)) >= 2: return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "    n_total, tail = len(y_tr), len(y_val_fit)\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail: break\n",
    "        X_tr_fit, y_tr_fit = X_tr_raw[:n_total-new_tail], y_tr[:n_total-new_tail]\n",
    "        X_val_fit, y_val_fit = X_tr_raw[n_total-new_tail:], y_tr[n_total-new_tail:]\n",
    "        tail = new_tail\n",
    "    if len(np.unique(y_val_fit)) < 2 and len(np.unique(y_tr)) == 2:\n",
    "        missing = 1 - int(np.unique(y_val_fit)[0]); pool_idx = np.where(y_tr_fit == missing)[0]\n",
    "        if len(pool_idx) > 0:\n",
    "            k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "            pick = np.random.RandomState(1234).choice(pool_idx, k, replace=False)\n",
    "            X_val_fit, y_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]]), np.concatenate([y_val_fit, y_tr_fit[pick]])\n",
    "            mask = np.ones(len(y_tr_fit), dtype=bool); mask[pick] = False\n",
    "            X_tr_fit, y_tr_fit = X_tr_fit[mask], y_tr_fit[mask]\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "def ensure_both_classes_in_es(y_full, es_idx, pool_idx, rng, max_tries=10):\n",
    "    if len(es_idx) == 0: return es_idx\n",
    "    for _ in range(max_tries):\n",
    "        if len(np.unique(y_full[es_idx])) >= 2: return es_idx\n",
    "        present = int(np.unique(y_full[es_idx])[0]); missing = 1 - present\n",
    "        cand = pool_idx[y_full[pool_idx] == missing]\n",
    "        if len(cand) == 0:\n",
    "            es_idx = rng.choice(pool_idx, size=max(1, len(es_idx)), replace=True); continue\n",
    "        k = min(len(cand), max(1, len(es_idx)//2))\n",
    "        replace_pos = rng.choice(len(es_idx), size=k, replace=False)\n",
    "        add_from_cand = rng.choice(cand, size=k, replace=False)\n",
    "        es_idx = es_idx.copy(); es_idx[replace_pos] = add_from_cand\n",
    "    return es_idx\n",
    "\n",
    "# =========================\n",
    "# 2) 训练设置 & 固定基础参数\n",
    "# =========================\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 外部阈值学习的可选约束（按需开启）\n",
    "EXT_MIN_PRECISION   = None   # 例如 0.80；None 表示不启用\n",
    "EXT_TARGET_POS_RATE = None   # 例如 0.55；None 表示不启用\n",
    "\n",
    "# 固定 Val 片双类\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "# —— 你的最优 LightGBM 基础参数（固定不搜索）——\n",
    "BEST_BASE_CFG = {\n",
    "    'n_estimators': 1638, \n",
    "    'learning_rate': 0.041623407511894216, \n",
    "    'num_leaves': 63, \n",
    "    'min_child_samples': 133, \n",
    "    'subsample': 0.9662670249843152, \n",
    "    'colsample_bytree': 0.5446815645555632, \n",
    "    'reg_alpha': 2.1622934507153384e-08, \n",
    "    'reg_lambda': 0.6182092272404153\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) 训练若干子模型并获取验证集预测（固定基础参数）\n",
    "# =========================\n",
    "def build_cfg_with_jitter(base_cfg, rng, scale):\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * scale; cfg = base_cfg.copy()\n",
    "    cfg[\"subsample\"] = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"] = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"] = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"] = int(np.clip(round(cfg.get(\"max_depth\", -1) if cfg.get(\"max_depth\", -1) != -1 else 8 * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "    return cfg\n",
    "\n",
    "def train_ensemble_val_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG, seed_offset=0):\n",
    "    n_train = X_tr_fit.shape[0]; local_rng = np.random.RandomState(RANDOM_SEED + seed_offset)\n",
    "    val_probs_list = []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_train, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx, es_idx = (idx_boot[:es_pt], idx_boot[es_pt:]) if len(idx_boot) > es_pt else (idx_boot, idx_boot[:1])\n",
    "        es_idx = ensure_both_classes_in_es(y_tr_fit, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        # 抖动后的基础参数\n",
    "        cfg = build_cfg_with_jitter(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "\n",
    "        # 合并覆盖，避免重复传参\n",
    "        params = cfg.copy()\n",
    "        params[\"random_state\"] = (RANDOM_SEED + seed_offset + b)\n",
    "        params.setdefault(\"objective\", \"binary\")\n",
    "        params.setdefault(\"verbosity\", -1)\n",
    "        params.setdefault(\"n_jobs\", -1)\n",
    "        params[\"class_weight\"] = \"balanced\"  # 平衡权重\n",
    "\n",
    "        clf = LGBMClassifier(**params)\n",
    "        clf.fit(\n",
    "            X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "            eval_set=[(X_tr_fit[es_idx], y_tr_fit[es_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "    return np.column_stack(val_probs_list)\n",
    "\n",
    "# =========================\n",
    "# 4) Optuna 目标函数（只搜索 Bagging/Ensemble 参数）\n",
    "# =========================\n",
    "def objective_joint(trial, optimization_metric='auc'):\n",
    "    # 固定基础参数\n",
    "    base_cfg = BEST_BASE_CFG.copy()\n",
    "\n",
    "    # 只搜索 ensemble 参数\n",
    "    BAGS = trial.suggest_int(\"BAGS\", 8, 40)\n",
    "    SAMPLE_RATIO = trial.suggest_float(\"SAMPLE_RATIO\", 0.6, 0.95)\n",
    "    JITTER_SCALE = trial.suggest_float(\"JITTER_SCALE\", 0.05, 0.25)\n",
    "    BLOCK_SIZE   = trial.suggest_int(\"BLOCK_SIZE\", 5, 60)\n",
    "\n",
    "    # 训练并获取验证集预测\n",
    "    val_probs = train_ensemble_val_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, base_cfg, seed_offset=trial.number)\n",
    "\n",
    "    # 融合：Val-AUC 权重\n",
    "    weights = np.array([max(safe_auc(y_val_fit, val_probs[:, j]) or 0.5, 0.0) for j in range(val_probs.shape[1])])\n",
    "    if weights.sum() == 0:\n",
    "        alphas = np.ones(val_probs.shape[1]) / val_probs.shape[1]\n",
    "    else:\n",
    "        ex = np.exp(weights - weights.max()); alphas = ex / ex.sum()\n",
    "    val_wavg = (val_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    # 评估分数\n",
    "    om = optimization_metric.lower()\n",
    "    if om == 'auc':\n",
    "        score = safe_auc(y_val_fit, val_wavg)\n",
    "        if np.isnan(score): score = 0.5\n",
    "        best_t = 0.5\n",
    "    elif om in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "        best_t = best_thr_on_val(\n",
    "            y_val_fit, val_wavg, metric=om,\n",
    "            min_precision=EXT_MIN_PRECISION, target_pos_rate=EXT_TARGET_POS_RATE\n",
    "        )\n",
    "        y_pred_val = (val_wavg >= best_t).astype(int)\n",
    "        if om == 'accuracy':\n",
    "            score = accuracy_score(y_val_fit, y_pred_val)\n",
    "        elif om == 'f1':\n",
    "            score = f1_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "        elif om == 'recall':\n",
    "            score = recall_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "        else:  # precision\n",
    "            score = precision_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的优化指标: {optimization_metric}\")\n",
    "\n",
    "    trial.set_user_attr(\"alphas\", alphas)\n",
    "    trial.set_user_attr(\"best_thr\", best_t)\n",
    "    return float(score)\n",
    "\n",
    "def run_optimization(metric='auc', n_trials=50):\n",
    "    print(f\"\\n🚀 开始联合调参. 目标: 在验证集上最大化 '{metric.upper()}'.\")\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(lambda trial: objective_joint(trial, optimization_metric=metric),\n",
    "                   n_trials=n_trials, show_progress_bar=True)\n",
    "    print(f\"\\n[调参结束] 最佳分数 ({metric.upper()}): {study.best_value:.6f}\")\n",
    "    print(f\"[调参结束] 最佳参数(仅ensemble): {study.best_params}\")\n",
    "    return study\n",
    "\n",
    "# =========================\n",
    "# 5) 执行调参并准备最终评估\n",
    "# =========================\n",
    "OPTIMIZATION_TARGET = 'f1'   # 可改：'auc' / 'f1' / 'recall' / 'precision'\n",
    "N_TRIALS = 100\n",
    "study_joint = run_optimization(metric=OPTIMIZATION_TARGET, n_trials=N_TRIALS)\n",
    "\n",
    "# 取最优的 ensemble 参数\n",
    "BEST_PARAMS = study_joint.best_params\n",
    "BEST_BASE_CFG = BEST_BASE_CFG.copy()  # 再拷一份，确保不被修改\n",
    "BEST_BAGS        = BEST_PARAMS.get(\"BAGS\", 16)\n",
    "BEST_SAMPLE_RATIO= BEST_PARAMS.get(\"SAMPLE_RATIO\", 0.8)\n",
    "BEST_JITTER_SCALE= BEST_PARAMS.get(\"JITTER_SCALE\", 0.1)\n",
    "BEST_BLOCK_SIZE  = BEST_PARAMS.get(\"BLOCK_SIZE\", 20)\n",
    "\n",
    "print(\"\\n===== 演练阶段: 在验证集上学习阈值和融合权重 =====\")\n",
    "val_probs_best = train_ensemble_val_preds(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG, seed_offset=999\n",
    ")\n",
    "\n",
    "# 策略1: 简单平均\n",
    "val_avg = val_probs_best.mean(axis=1)\n",
    "t_avg = best_thr_on_val(\n",
    "    y_val_fit, val_avg, metric=OPTIMIZATION_TARGET,\n",
    "    min_precision=EXT_MIN_PRECISION, target_pos_rate=EXT_TARGET_POS_RATE\n",
    ")\n",
    "print(f\"  - [简单平均] 在验证集上学到的最优阈值: {t_avg:.3f}\")\n",
    "\n",
    "# 策略2: Val-AUC 加权（来自 Joint Study 的 alphas），阈值重新按同样约束计算\n",
    "alphas_best = np.array(study_joint.best_trial.user_attrs[\"alphas\"])\n",
    "val_wavg_best = (val_probs_best * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "t_wavg_best = best_thr_on_val(\n",
    "    y_val_fit, val_wavg_best, metric=OPTIMIZATION_TARGET,\n",
    "    min_precision=EXT_MIN_PRECISION, target_pos_rate=EXT_TARGET_POS_RATE\n",
    ")\n",
    "print(f\"  - [Val-AUC加权] 在验证集上学到的最优阈值: {t_wavg_best:.3f}\")\n",
    "\n",
    "# 策略3: Optuna 学习融合权重（仅在验证集上）\n",
    "def objective_blend_on_val(trial, val_probs):\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(val_probs.shape[1])])\n",
    "    a = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "    val_blend = (val_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "    best_t = best_thr_on_val(\n",
    "        y_val_fit, val_blend, metric=OPTIMIZATION_TARGET,\n",
    "        min_precision=EXT_MIN_PRECISION, target_pos_rate=EXT_TARGET_POS_RATE\n",
    "    )\n",
    "    y_pred_val = (val_blend >= best_t).astype(int)\n",
    "    om = OPTIMIZATION_TARGET.lower()\n",
    "    if om == 'f1':\n",
    "        score = f1_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    elif om == 'accuracy':\n",
    "        score = accuracy_score(y_val_fit, y_pred_val)\n",
    "    elif om == 'recall':\n",
    "        score = recall_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    elif om == 'precision':\n",
    "        score = precision_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    else:\n",
    "        score = safe_auc(y_val_fit, val_blend)\n",
    "    trial.set_user_attr(\"best_t\", best_t)\n",
    "    return score\n",
    "\n",
    "sampler2 = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study_blend = optuna.create_study(direction=\"maximize\", sampler=sampler2)\n",
    "study_blend.optimize(lambda t: objective_blend_on_val(t, val_probs_best),\n",
    "                     n_trials=100, show_progress_bar=False)\n",
    "best_w = np.array([study_blend.best_params[k] for k in sorted(study_blend.best_params.keys(),\n",
    "                                                              key=lambda s: int(s[1:]))])\n",
    "a_opt = np.exp(best_w); a_opt /= (a_opt.sum() + 1e-12)\n",
    "t_blend_best = float(study_blend.best_trial.user_attrs[\"best_t\"])\n",
    "print(f\"  - [Optuna融合] 在验证集上学到的最优阈值: {t_blend_best:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 6) 最终重训练与评估（在80%训练集上bagging，20%上评估）\n",
    "# =========================\n",
    "print(\"\\n===== 最终阶段: 在完整80%数据上重训, 并在20%测试集上评估三种策略 =====\")\n",
    "def train_ensemble_full_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG):\n",
    "    n_full, local_rng = X_tr_raw.shape[0], np.random.RandomState(RANDOM_SEED + 2025)\n",
    "    te_probs_list = []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_full, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx, es_idx = (idx_boot[:es_pt], idx_boot[es_pt:]) if len(idx_boot) > es_pt else (idx_boot, idx_boot[:1])\n",
    "        es_idx = ensure_both_classes_in_es(y_tr, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        cfg = build_cfg_with_jitter(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "\n",
    "        params = cfg.copy()\n",
    "        params[\"random_state\"] = 10000 + b\n",
    "        params.setdefault(\"objective\", \"binary\")\n",
    "        params.setdefault(\"verbosity\", -1)\n",
    "        params.setdefault(\"n_jobs\", -1)\n",
    "        params[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "        clf = LGBMClassifier(**params)\n",
    "        clf.fit(\n",
    "            X_tr_raw[tr_idx], y_tr[tr_idx],\n",
    "            eval_set=[(X_tr_raw[es_idx], y_tr[es_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        te_probs_list.append(clf.predict_proba(X_te)[:, 1])\n",
    "    return np.column_stack(te_probs_list)\n",
    "\n",
    "te_probs_final = train_ensemble_full_preds(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG\n",
    ")\n",
    "\n",
    "# --- 应用策略1: 简单平均 ---\n",
    "y_prob_avg_final = te_probs_final.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg_final, thr=t_avg, title=\"FINAL - Simple Average\")\n",
    "\n",
    "# --- 应用策略2: Val-AUC 加权 ---\n",
    "y_prob_wavg_final = (te_probs_final * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_wavg_final, thr=t_wavg_best, title=\"FINAL - Val-AUC Weighted\")\n",
    "\n",
    "# --- 应用策略3: Optuna 学习权重 ---\n",
    "y_prob_opt_final = (te_probs_final * a_opt.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_opt_final, thr=t_blend_best, title=\"FINAL - Optuna Weights\")\n",
    "\n",
    "# =========================\n",
    "# 7) 结果导出与ROC图\n",
    "# =========================\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "test_index = getattr(df_clean, \"index\", pd.RangeIndex(len(df_clean)))[split_pt:]\n",
    "df_out = pd.DataFrame({\n",
    "    \"index\": test_index, \"y_true\": y_te,\n",
    "    \"prob_simple_avg\": y_prob_avg_final, \"pred_simple_avg\": (y_prob_avg_final >= t_avg).astype(int),\n",
    "    \"prob_valauc_weighted\": y_prob_wavg_final, \"pred_valauc_weighted\": (y_prob_wavg_final >= t_wavg_best).astype(int),\n",
    "    \"prob_optuna_weights\": y_prob_opt_final, \"pred_optuna_weights\": (y_prob_opt_final >= t_blend_best).astype(int),\n",
    "})\n",
    "xlsx_path = os.path.join(\"reports\", f\"results_test_3_blends_optimized_for_{OPTIMIZATION_TARGET}.xlsx\")\n",
    "df_out.to_excel(xlsx_path, index=False)\n",
    "print(f\"\\n[导出] 包含三种策略的逐样本结果已导出: {xlsx_path}\")\n",
    "\n",
    "# 绘制ROC曲线对比\n",
    "plt.figure(figsize=(7, 6), dpi=120)\n",
    "def add_roc_curve(y_true, y_score, label):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_v = roc_auc_score(y_true, y_score)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{label} (AUC={auc_v:.4f})\")\n",
    "\n",
    "add_roc_curve(y_te, y_prob_avg_final, \"Simple Avg\")\n",
    "add_roc_curve(y_te, y_prob_wavg_final, \"Val-AUC Weighted\")\n",
    "add_roc_curve(y_te, y_prob_opt_final, \"Optuna Weights\")\n",
    "\n",
    "plt.plot([0,1], [0,1], ls=\"--\", lw=1.2, color=\"gray\", label=\"Chance\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves on Test Set for 3 Blending Strategies\")\n",
    "plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
    "roc_path = os.path.join(\"reports\", f\"roc_curves_3_blends_{OPTIMIZATION_TARGET}.png\")\n",
    "plt.savefig(roc_path); plt.close()\n",
    "print(f\"[绘图] 三种策略的ROC对比曲线已保存: {roc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ae5a2",
   "metadata": {},
   "source": [
    "### 固定参数+自由评优+阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e2132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 11:14:48,815] A new study created in memory with name: no-name-c6b4212c-f858-46c2-abba-256c86945a60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 720, Val-fit size: 80, Classes in Val: (array([0, 1]), array([45, 35]))\n",
      "\n",
      "🚀 开始联合调参. 目标: 在验证集上最大化 'F1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.831169:   2%|▏         | 1/50 [00:03<02:46,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 11:14:52,219] Trial 0 finished with value: 0.8311688311688312 and parameters: {'BAGS': 20, 'SAMPLE_RATIO': 0.9327500072434707, 'JITTER_SCALE': 0.19639878836228103, 'BLOCK_SIZE': 38}. Best is trial 0 with value: 0.8311688311688312.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837838:   4%|▍         | 2/50 [00:05<02:03,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 11:14:54,191] Trial 1 finished with value: 0.8378378378378378 and parameters: {'BAGS': 13, 'SAMPLE_RATIO': 0.6545980821176709, 'JITTER_SCALE': 0.061616722433639894, 'BLOCK_SIZE': 53}. Best is trial 1 with value: 0.8378378378378378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837838:   6%|▌         | 3/50 [00:10<02:46,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 11:14:58,881] Trial 2 finished with value: 0.8354430379746836 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.8478254022286159, 'JITTER_SCALE': 0.05411689885916049, 'BLOCK_SIZE': 59}. Best is trial 1 with value: 0.8378378378378378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837838:   8%|▊         | 4/50 [00:14<03:04,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 11:15:03,637] Trial 3 finished with value: 0.825 and parameters: {'BAGS': 35, 'SAMPLE_RATIO': 0.6743186887373966, 'JITTER_SCALE': 0.08636499344142012, 'BLOCK_SIZE': 15}. Best is trial 1 with value: 0.8378378378378378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837838:  10%|█         | 5/50 [00:17<02:46,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 11:15:06,751] Trial 4 finished with value: 0.8311688311688312 and parameters: {'BAGS': 18, 'SAMPLE_RATIO': 0.7836647510712832, 'JITTER_SCALE': 0.13638900372842316, 'BLOCK_SIZE': 21}. Best is trial 1 with value: 0.8378378378378378.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.837838:  12%|█▏        | 6/50 [00:21<02:39,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 11:15:10,255] Trial 5 finished with value: 0.8378378378378378 and parameters: {'BAGS': 28, 'SAMPLE_RATIO': 0.6488228512282146, 'JITTER_SCALE': 0.10842892970704364, 'BLOCK_SIZE': 25}. Best is trial 1 with value: 0.8378378378378378.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss,\n",
    "    roc_curve\n",
    ")\n",
    "import optuna\n",
    "\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,      y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# =========================\n",
    "# 1) 工具函数（评估 / 采样 / 双类保障 / 阈值寻优）\n",
    "# =========================\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:        {acc:.6f}\")\n",
    "    print(f\"AUC:             {auc:.6f}\")\n",
    "    print(f\"PR-AUC:          {ap:.6f}\")\n",
    "    print(f\"LogLoss:         {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on_val(y_val, p_val, metric='f1'):\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    if metric == 'accuracy':\n",
    "        scores = [accuracy_score(y_val, (p_val >= t).astype(int)) for t in ths]\n",
    "    elif metric == 'f1':\n",
    "        scores = [f1_score(y_val, (p_val >= t).astype(int), zero_division=0) for t in ths]\n",
    "    elif metric == 'recall':\n",
    "        scores = [recall_score(y_val, (p_val >= t).astype(int), zero_division=0) for t in ths]\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的阈值寻优指标: {metric}\")\n",
    "    return float(ths[int(np.argmax(scores))])\n",
    "\n",
    "def block_bootstrap(n, ratio, block=20, rng=None):\n",
    "    m = int(n * ratio); idx = []\n",
    "    if n <= 0: return np.array([], dtype=int)\n",
    "    if block <= 0: block = 1\n",
    "    while len(idx) < m:\n",
    "        s = rng.randint(0, max(1, n - block + 1)); idx.extend(range(s, min(s + block, n)))\n",
    "    idx = np.array(idx[:m], dtype=int); idx.sort()\n",
    "    return idx\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3):\n",
    "    if len(np.unique(y_val_fit)) >= 2: return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "    n_total, tail = len(y_tr), len(y_val_fit)\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail: break\n",
    "        X_tr_fit, y_tr_fit = X_tr_raw[:n_total-new_tail], y_tr[:n_total-new_tail]\n",
    "        X_val_fit, y_val_fit = X_tr_raw[n_total-new_tail:], y_tr[n_total-new_tail:]\n",
    "        tail = new_tail\n",
    "    if len(np.unique(y_val_fit)) < 2 and len(np.unique(y_tr)) == 2:\n",
    "        missing = 1 - int(np.unique(y_val_fit)[0]); pool_idx = np.where(y_tr_fit == missing)[0]\n",
    "        if len(pool_idx) > 0:\n",
    "            k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "            pick = np.random.RandomState(1234).choice(pool_idx, k, replace=False)\n",
    "            X_val_fit, y_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]]), np.concatenate([y_val_fit, y_tr_fit[pick]])\n",
    "            mask = np.ones(len(y_tr_fit), dtype=bool); mask[pick] = False\n",
    "            X_tr_fit, y_tr_fit = X_tr_fit[mask], y_tr_fit[mask]\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "def ensure_both_classes_in_es(y_full, es_idx, pool_idx, rng, max_tries=10):\n",
    "    if len(es_idx) == 0: return es_idx\n",
    "    for _ in range(max_tries):\n",
    "        if len(np.unique(y_full[es_idx])) >= 2: return es_idx\n",
    "        present = int(np.unique(y_full[es_idx])[0]); missing = 1 - present\n",
    "        cand = pool_idx[y_full[pool_idx] == missing]\n",
    "        if len(cand) == 0:\n",
    "            es_idx = rng.choice(pool_idx, size=max(1, len(es_idx)), replace=True); continue\n",
    "        k = min(len(cand), max(1, len(es_idx)//2))\n",
    "        replace_pos = rng.choice(len(es_idx), size=k, replace=False)\n",
    "        add_from_cand = rng.choice(cand, size=k, replace=False)\n",
    "        es_idx = es_idx.copy(); es_idx[replace_pos] = add_from_cand\n",
    "    return es_idx\n",
    "\n",
    "# =========================\n",
    "# 2) 训练设置 & 固定基础参数\n",
    "# =========================\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 固定 Val 片双类\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "# —— 你的最优 LightGBM 基础参数（固定不搜索）——\n",
    "BEST_BASE_CFG = {\n",
    "    \"n_estimators\": 1661,\n",
    "    \"learning_rate\": 0.060360719357661304,\n",
    "    \"num_leaves\": 365,\n",
    "    \"min_child_samples\": 42,\n",
    "    \"subsample\": 0.8704853901045029,\n",
    "    \"colsample_bytree\": 0.938018723296346,\n",
    "    \"reg_alpha\": 2.528948814898404e-07,\n",
    "    \"reg_lambda\": 4.6251017710258054e-07,\n",
    "    \"objective\": \"binary\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": -1,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# 3) 训练若干子模型并获取验证集预测（固定基础参数）\n",
    "# =========================\n",
    "def build_cfg_with_jitter(base_cfg, rng, scale):\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * scale; cfg = base_cfg.copy()\n",
    "    cfg[\"subsample\"] = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"] = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"] = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"] = int(np.clip(round(cfg.get(\"max_depth\", -1) if cfg.get(\"max_depth\", -1) != -1 else 8 * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "    return cfg\n",
    "\n",
    "def train_ensemble_val_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG, seed_offset=0):\n",
    "    n_train = X_tr_fit.shape[0]; local_rng = np.random.RandomState(RANDOM_SEED + seed_offset)\n",
    "    val_probs_list = []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_train, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx, es_idx = (idx_boot[:es_pt], idx_boot[es_pt:]) if len(idx_boot) > es_pt else (idx_boot, idx_boot[:1])\n",
    "        es_idx = ensure_both_classes_in_es(y_tr_fit, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        # 抖动后的基础参数\n",
    "        cfg = build_cfg_with_jitter(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "\n",
    "        # 合并覆盖，避免重复传参\n",
    "        params = cfg.copy()\n",
    "        # 用当前 bag 的随机种子覆盖 cfg 里的 random_state\n",
    "        params[\"random_state\"] = (RANDOM_SEED + seed_offset + b)\n",
    "        # 如需强制这些设置，可在这里覆盖；若 cfg 里已有相同键，不会重复传参\n",
    "        params.setdefault(\"objective\", \"binary\")\n",
    "        params.setdefault(\"verbosity\", -1)\n",
    "        params.setdefault(\"n_jobs\", -1)\n",
    "        params[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "        clf = LGBMClassifier(**params)\n",
    "        clf.fit(\n",
    "            X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "            eval_set=[(X_tr_fit[es_idx], y_tr_fit[es_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "    return np.column_stack(val_probs_list)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Optuna 目标函数（只搜索 Bagging/Ensemble 参数）\n",
    "# =========================\n",
    "def objective_joint(trial, optimization_metric='auc'):\n",
    "    # 固定基础参数\n",
    "    base_cfg = BEST_BASE_CFG.copy()\n",
    "\n",
    "    # 只搜索 ensemble 参数\n",
    "    BAGS = trial.suggest_int(\"BAGS\", 8, 40)\n",
    "    SAMPLE_RATIO = trial.suggest_float(\"SAMPLE_RATIO\", 0.6, 0.95)\n",
    "    JITTER_SCALE = trial.suggest_float(\"JITTER_SCALE\", 0.05, 0.25)\n",
    "    BLOCK_SIZE   = trial.suggest_int(\"BLOCK_SIZE\", 5, 60)\n",
    "\n",
    "    # 训练并获取验证集预测\n",
    "    val_probs = train_ensemble_val_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, base_cfg, seed_offset=trial.number)\n",
    "\n",
    "    # 融合：Val-AUC 权重\n",
    "    weights = np.array([max(safe_auc(y_val_fit, val_probs[:, j]) or 0.5, 0.0) for j in range(val_probs.shape[1])])\n",
    "    if weights.sum() == 0:\n",
    "        alphas = np.ones(val_probs.shape[1]) / val_probs.shape[1]\n",
    "    else:\n",
    "        ex = np.exp(weights - weights.max()); alphas = ex / ex.sum()\n",
    "\n",
    "    val_wavg = (val_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    # 评估分数\n",
    "    if optimization_metric == 'auc':\n",
    "        score = safe_auc(y_val_fit, val_wavg)\n",
    "        if np.isnan(score): score = 0.5\n",
    "        best_t = 0.5\n",
    "    elif optimization_metric in ['accuracy', 'f1', 'recall']:\n",
    "        best_t = best_thr_on_val(y_val_fit, val_wavg, metric=optimization_metric)\n",
    "        y_pred_val = (val_wavg >= best_t).astype(int)\n",
    "        if optimization_metric == 'accuracy':\n",
    "            score = accuracy_score(y_val_fit, y_pred_val)\n",
    "        elif optimization_metric == 'f1':\n",
    "            score = f1_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "        elif optimization_metric == 'recall':\n",
    "            score = recall_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的优化指标: {optimization_metric}\")\n",
    "\n",
    "    trial.set_user_attr(\"alphas\", alphas)\n",
    "    trial.set_user_attr(\"best_thr\", best_t)\n",
    "    return float(score)\n",
    "\n",
    "def run_optimization(metric='auc', n_trials=50):\n",
    "    print(f\"\\n🚀 开始联合调参. 目标: 在验证集上最大化 '{metric.upper()}'.\")\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(lambda trial: objective_joint(trial, optimization_metric=metric),\n",
    "                   n_trials=n_trials, show_progress_bar=True)\n",
    "    print(f\"\\n[调参结束] 最佳分数 ({metric.upper()}): {study.best_value:.6f}\")\n",
    "    print(f\"[调参结束] 最佳参数(仅ensemble): {study.best_params}\")\n",
    "    return study\n",
    "\n",
    "# =========================\n",
    "# 5) 执行调参并准备最终评估\n",
    "# =========================\n",
    "OPTIMIZATION_TARGET = 'f1'   # 可改：'auc' / 'f1' / 'recall'\n",
    "N_TRIALS = 50                      # 演示值；实际可增大\n",
    "study_joint = run_optimization(metric=OPTIMIZATION_TARGET, n_trials=N_TRIALS)\n",
    "\n",
    "# 取最优的 ensemble 参数\n",
    "BEST_PARAMS = study_joint.best_params\n",
    "BEST_BASE_CFG = BEST_BASE_CFG.copy()  # 再拷一份，确保不被修改\n",
    "BEST_BAGS        = BEST_PARAMS.get(\"BAGS\", 16)\n",
    "BEST_SAMPLE_RATIO= BEST_PARAMS.get(\"SAMPLE_RATIO\", 0.8)\n",
    "BEST_JITTER_SCALE= BEST_PARAMS.get(\"JITTER_SCALE\", 0.1)\n",
    "BEST_BLOCK_SIZE  = BEST_PARAMS.get(\"BLOCK_SIZE\", 20)\n",
    "\n",
    "print(\"\\n===== 演练阶段: 在验证集上学习阈值和融合权重 =====\")\n",
    "val_probs_best = train_ensemble_val_preds(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG, seed_offset=999\n",
    ")\n",
    "\n",
    "# 策略1: 简单平均\n",
    "val_avg = val_probs_best.mean(axis=1)\n",
    "t_avg = best_thr_on_val(y_val_fit, val_avg, metric=OPTIMIZATION_TARGET)\n",
    "print(f\"  - [简单平均] 在验证集上学到的最优阈值: {t_avg:.3f}\")\n",
    "\n",
    "# 策略2: Val-AUC 加权（来自 Joint Study）\n",
    "alphas_best = np.array(study_joint.best_trial.user_attrs[\"alphas\"])\n",
    "t_wavg_best = float(study_joint.best_trial.user_attrs[\"best_thr\"])\n",
    "print(f\"  - [Val-AUC加权] 使用主流程学到的权重和阈值: {t_wavg_best:.3f}\")\n",
    "\n",
    "# 策略3: Optuna 学习融合权重（仅在验证集上）\n",
    "def objective_blend_on_val(trial, val_probs):\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(val_probs.shape[1])])\n",
    "    a = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "    val_blend = (val_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "    best_t = best_thr_on_val(y_val_fit, val_blend, metric=OPTIMIZATION_TARGET)\n",
    "    y_pred_val = (val_blend >= best_t).astype(int)\n",
    "    if OPTIMIZATION_TARGET == 'f1':\n",
    "        score = f1_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    elif OPTIMIZATION_TARGET == 'accuracy':\n",
    "        score = accuracy_score(y_val_fit, y_pred_val)\n",
    "    elif OPTIMIZATION_TARGET == 'recall':\n",
    "        score = recall_score(y_val_fit, y_pred_val, zero_division=0)\n",
    "    else:\n",
    "        score = safe_auc(y_val_fit, val_blend)\n",
    "    trial.set_user_attr(\"best_t\", best_t)\n",
    "    return score\n",
    "\n",
    "sampler2 = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study_blend = optuna.create_study(direction=\"maximize\", sampler=sampler2)\n",
    "study_blend.optimize(lambda t: objective_blend_on_val(t, val_probs_best),\n",
    "                     n_trials=100, show_progress_bar=False)\n",
    "best_w = np.array([study_blend.best_params[k] for k in sorted(study_blend.best_params.keys(),\n",
    "                                                              key=lambda s: int(s[1:]))])\n",
    "a_opt = np.exp(best_w); a_opt /= (a_opt.sum() + 1e-12)\n",
    "t_blend_best = float(study_blend.best_trial.user_attrs[\"best_t\"])\n",
    "print(f\"  - [Optuna融合] 在验证集上学到的最优阈值: {t_blend_best:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 6) 最终重训练与评估（在80%训练集上bagging，20%上评估）\n",
    "# =========================\n",
    "print(\"\\n===== 最终阶段: 在完整80%数据上重训, 并在20%测试集上评估三种策略 =====\")\n",
    "def train_ensemble_full_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG):\n",
    "    n_full, local_rng = X_tr_raw.shape[0], np.random.RandomState(RANDOM_SEED + 2025)\n",
    "    te_probs_list = []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_full, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx, es_idx = (idx_boot[:es_pt], idx_boot[es_pt:]) if len(idx_boot) > es_pt else (idx_boot, idx_boot[:1])\n",
    "        es_idx = ensure_both_classes_in_es(y_tr, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        cfg = build_cfg_with_jitter(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "\n",
    "        params = cfg.copy()\n",
    "        params[\"random_state\"] = 10000 + b\n",
    "        params.setdefault(\"objective\", \"binary\")\n",
    "        params.setdefault(\"verbosity\", -1)\n",
    "        params.setdefault(\"n_jobs\", -1)\n",
    "        params[\"class_weight\"] = \"balanced\"\n",
    "\n",
    "        clf = LGBMClassifier(**params)\n",
    "        clf.fit(\n",
    "            X_tr_raw[tr_idx], y_tr[tr_idx],\n",
    "            eval_set=[(X_tr_raw[es_idx], y_tr[es_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        te_probs_list.append(clf.predict_proba(X_te)[:, 1])\n",
    "    return np.column_stack(te_probs_list)\n",
    "\n",
    "\n",
    "te_probs_final = train_ensemble_full_preds(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG\n",
    ")\n",
    "\n",
    "# --- 应用策略1: 简单平均 ---\n",
    "y_prob_avg_final = te_probs_final.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg_final, thr=t_avg, title=\"FINAL - Simple Average\")\n",
    "\n",
    "# --- 应用策略2: Val-AUC 加权 ---\n",
    "y_prob_wavg_final = (te_probs_final * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_wavg_final, thr=t_wavg_best, title=\"FINAL - Val-AUC Weighted\")\n",
    "\n",
    "# --- 应用策略3: Optuna 学习权重 ---\n",
    "y_prob_opt_final = (te_probs_final * a_opt.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_opt_final, thr=t_blend_best, title=\"FINAL - Optuna Weights\")\n",
    "\n",
    "# =========================\n",
    "# 7) 结果导出与ROC图\n",
    "# =========================\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "test_index = getattr(df_clean, \"index\", pd.RangeIndex(len(df_clean)))[split_pt:]\n",
    "df_out = pd.DataFrame({\n",
    "    \"index\": test_index, \"y_true\": y_te,\n",
    "    \"prob_simple_avg\": y_prob_avg_final, \"pred_simple_avg\": (y_prob_avg_final >= t_avg).astype(int),\n",
    "    \"prob_valauc_weighted\": y_prob_wavg_final, \"pred_valauc_weighted\": (y_prob_wavg_final >= t_wavg_best).astype(int),\n",
    "    \"prob_optuna_weights\": y_prob_opt_final, \"pred_optuna_weights\": (y_prob_opt_final >= t_blend_best).astype(int),\n",
    "})\n",
    "xlsx_path = os.path.join(\"reports\", f\"results_test_3_blends_optimized_for_{OPTIMIZATION_TARGET}.xlsx\")\n",
    "df_out.to_excel(xlsx_path, index=False)\n",
    "print(f\"\\n[导出] 包含三种策略的逐样本结果已导出: {xlsx_path}\")\n",
    "\n",
    "# 绘制ROC曲线对比\n",
    "plt.figure(figsize=(7, 6), dpi=120)\n",
    "def add_roc_curve(y_true, y_score, label):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_v = roc_auc_score(y_true, y_score)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{label} (AUC={auc_v:.4f})\")\n",
    "\n",
    "add_roc_curve(y_te, y_prob_avg_final, \"Simple Avg\")\n",
    "add_roc_curve(y_te, y_prob_wavg_final, \"Val-AUC Weighted\")\n",
    "add_roc_curve(y_te, y_prob_opt_final, \"Optuna Weights\")\n",
    "\n",
    "plt.plot([0,1], [0,1], ls=\"--\", lw=1.2, color=\"gray\", label=\"Chance\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves on Test Set for 3 Blending Strategies\")\n",
    "plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
    "roc_path = os.path.join(\"reports\", f\"roc_curves_3_blends_{OPTIMIZATION_TARGET}.png\")\n",
    "plt.savefig(roc_path); plt.close()\n",
    "print(f\"[绘图] 三种策略的ROC对比曲线已保存: {roc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ea7fc",
   "metadata": {},
   "source": [
    "### ACC全调参，但是XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14a6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 15:00:58,161] A new study created in memory with name: no-name-b5ecc477-1937-467f-8992-2d14b4b32631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 1234, Val-fit size: 138, Classes in Val: (array([0, 1]), array([99, 39]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 15:01:26,940] Trial 0 finished with value: 0.7536231884057971 and parameters: {'learning_rate': 0.03574712922600244, 'max_depth': 12, 'min_child_weight': 4.480392682684062, 'gamma': 2.993292420985183, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'reg_alpha': 2.5502648504032812e-08, 'reg_lambda': 0.011567327199145964, 'n_estimators': 1282, 'BAGS': 31, 'SAMPLE_RATIO': 0.6072045730035308, 'JITTER_SCALE': 0.2439819704323989, 'BLOCK_SIZE': 51}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:01:40,478] Trial 1 finished with value: 0.7463768115942029 and parameters: {'learning_rate': 0.020589728197687916, 'max_depth': 4, 'min_child_weight': 0.8661333735273129, 'gamma': 1.5212112147976886, 'subsample': 0.762378215816119, 'colsample_bytree': 0.7159725093210578, 'reg_alpha': 1.092959278721938e-06, 'reg_lambda': 0.00019185373703841887, 'n_estimators': 451, 'BAGS': 17, 'SAMPLE_RATIO': 0.7282266451527921, 'JITTER_SCALE': 0.14121399684340719, 'BLOCK_SIZE': 48}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:03:49,046] Trial 2 finished with value: 0.7463768115942029 and parameters: {'learning_rate': 0.019721610970574007, 'max_depth': 8, 'min_child_weight': 2.949301205216348, 'gamma': 0.23225206359998862, 'subsample': 0.8037724259507192, 'colsample_bytree': 0.5852620618436457, 'reg_alpha': 2.853390105240219e-08, 'reg_lambda': 0.04387314432435398, 'n_estimators': 1939, 'BAGS': 34, 'SAMPLE_RATIO': 0.7066148192106797, 'JITTER_SCALE': 0.06953442280127678, 'BLOCK_SIZE': 43}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:04:29,844] Trial 3 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.044684675025045834, 'max_depth': 4, 'min_child_weight': 2.2039920190846214, 'gamma': 0.17194260557609198, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085, 'reg_alpha': 0.000434166180036173, 'reg_lambda': 1.5204688692198897e-06, 'n_estimators': 1136, 'BAGS': 26, 'SAMPLE_RATIO': 0.6646990594339345, 'JITTER_SCALE': 0.24391692555291172, 'BLOCK_SIZE': 48}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:04:41,868] Trial 4 finished with value: 0.7463768115942029 and parameters: {'learning_rate': 0.24420460844911424, 'max_depth': 11, 'min_child_weight': 2.99816694120633, 'gamma': 4.609371175115584, 'subsample': 0.5442462510259598, 'colsample_bytree': 0.5979914312095727, 'reg_alpha': 2.072960479129113e-08, 'reg_lambda': 1.8937049541631268e-06, 'n_estimators': 900, 'BAGS': 16, 'SAMPLE_RATIO': 0.8900581282031752, 'JITTER_SCALE': 0.12135066533871786, 'BLOCK_SIZE': 20}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:05:34,807] Trial 5 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.06333268775321843, 'max_depth': 4, 'min_child_weight': 5.529073188281502, 'gamma': 0.3727532183988541, 'subsample': 0.9934434683002586, 'colsample_bytree': 0.8861223846483287, 'reg_alpha': 2.4604229580184137e-07, 'reg_lambda': 1.0930872279404512e-08, 'n_estimators': 1668, 'BAGS': 31, 'SAMPLE_RATIO': 0.8551525088143455, 'JITTER_SCALE': 0.20425406933718915, 'BLOCK_SIZE': 9}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:06:16,719] Trial 6 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.0338452204120114, 'max_depth': 4, 'min_child_weight': 6.635802485202448, 'gamma': 3.1164906341377896, 'subsample': 0.6654490124263246, 'colsample_bytree': 0.5317791751430119, 'reg_alpha': 1.5027137214154512e-06, 'reg_lambda': 1.8892231305534347e-06, 'n_estimators': 1514, 'BAGS': 29, 'SAMPLE_RATIO': 0.9105244599017143, 'JITTER_SCALE': 0.14444298503238986, 'BLOCK_SIZE': 11}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:06:20,502] Trial 7 finished with value: 0.7463768115942029 and parameters: {'learning_rate': 0.1131225105716033, 'max_depth': 10, 'min_child_weight': 2.6866338002255548, 'gamma': 3.854835899772805, 'subsample': 0.7468977981821954, 'colsample_bytree': 0.7613664146909971, 'reg_alpha': 9.835289062589953e-06, 'reg_lambda': 1.5063777323554413e-08, 'n_estimators': 394, 'BAGS': 9, 'SAMPLE_RATIO': 0.8227436439423231, 'JITTER_SCALE': 0.11287119621526534, 'BLOCK_SIZE': 33}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:06:56,362] Trial 8 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.21907142272152816, 'max_depth': 5, 'min_child_weight': 1.7095842058829473, 'gamma': 3.7777556927152434, 'subsample': 0.6143990827458112, 'colsample_bytree': 0.5384899549143964, 'reg_alpha': 1.067235272504377e-06, 'reg_lambda': 1.3444634828135513e-07, 'n_estimators': 1874, 'BAGS': 34, 'SAMPLE_RATIO': 0.8216913147786482, 'JITTER_SCALE': 0.22429211803754356, 'BLOCK_SIZE': 50}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:07:36,564] Trial 9 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.018861950443028862, 'max_depth': 11, 'min_child_weight': 2.515767132835161, 'gamma': 4.037200775820312, 'subsample': 0.9480456499617467, 'colsample_bytree': 0.6590017374859319, 'reg_alpha': 5.893366793227604e-08, 'reg_lambda': 3.940452872934755e-07, 'n_estimators': 969, 'BAGS': 34, 'SAMPLE_RATIO': 0.9012557041397202, 'JITTER_SCALE': 0.051390426106238146, 'BLOCK_SIZE': 33}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:09:00,023] Trial 10 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.011546954953097507, 'max_depth': 8, 'min_child_weight': 9.12781579951032, 'gamma': 1.8971000105817315, 'subsample': 0.5076838686640521, 'colsample_bytree': 0.953832397641259, 'reg_alpha': 0.05228718023161359, 'reg_lambda': 0.0680736910050809, 'n_estimators': 1329, 'BAGS': 40, 'SAMPLE_RATIO': 0.6094470165426243, 'JITTER_SCALE': 0.1890927652912878, 'BLOCK_SIZE': 56}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:09:12,956] Trial 11 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.02538603913295334, 'max_depth': 6, 'min_child_weight': 0.5341192340049861, 'gamma': 1.8776410961522325, 'subsample': 0.8107290673998314, 'colsample_bytree': 0.7517245125626177, 'reg_alpha': 0.00014451321231782587, 'reg_lambda': 0.0014293863958231936, 'n_estimators': 223, 'BAGS': 20, 'SAMPLE_RATIO': 0.7402791543479966, 'JITTER_SCALE': 0.17448224928944484, 'BLOCK_SIZE': 60}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:09:42,547] Trial 12 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.010239401274195488, 'max_depth': 12, 'min_child_weight': 0.7977767623360338, 'gamma': 1.5595371002056282, 'subsample': 0.7039294159774774, 'colsample_bytree': 0.7084623041637503, 'reg_alpha': 9.764129908154304e-06, 'reg_lambda': 0.0002031300397612329, 'n_estimators': 629, 'BAGS': 15, 'SAMPLE_RATIO': 0.6045991105012329, 'JITTER_SCALE': 0.1621249400738106, 'BLOCK_SIZE': 40}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:09:55,691] Trial 13 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.06743809278881063, 'max_depth': 7, 'min_child_weight': 1.1897865826188856, 'gamma': 2.793992915216572, 'subsample': 0.8563249947330406, 'colsample_bytree': 0.838891511825567, 'reg_alpha': 3.3989005736333235e-07, 'reg_lambda': 0.003209187577310387, 'n_estimators': 717, 'BAGS': 22, 'SAMPLE_RATIO': 0.6710139959292654, 'JITTER_SCALE': 0.10246448417043291, 'BLOCK_SIZE': 52}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:10:04,004] Trial 14 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.0978309976596495, 'max_depth': 9, 'min_child_weight': 4.774801574519217, 'gamma': 1.1762820793654707, 'subsample': 0.6271641836327536, 'colsample_bytree': 0.8129989624132341, 'reg_alpha': 1.0769878275681248e-08, 'reg_lambda': 4.0944961849131904e-05, 'n_estimators': 1262, 'BAGS': 8, 'SAMPLE_RATIO': 0.7698569809315106, 'JITTER_SCALE': 0.14039949212400382, 'BLOCK_SIZE': 39}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:10:16,119] Trial 15 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.03484052557384363, 'max_depth': 3, 'min_child_weight': 1.0501807704344759, 'gamma': 2.3713850249658375, 'subsample': 0.5820277679886149, 'colsample_bytree': 0.6664120814330841, 'reg_alpha': 0.0037614112797884304, 'reg_lambda': 0.004491047294411956, 'n_estimators': 666, 'BAGS': 18, 'SAMPLE_RATIO': 0.6775275592242997, 'JITTER_SCALE': 0.21381347524690025, 'BLOCK_SIZE': 24}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:11:03,942] Trial 16 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.016152802811564962, 'max_depth': 7, 'min_child_weight': 4.053480672878539, 'gamma': 1.2625064845523823, 'subsample': 0.71451395067503, 'colsample_bytree': 0.5098383221117895, 'reg_alpha': 3.7661040722565517e-06, 'reg_lambda': 0.00015103817204726092, 'n_estimators': 1486, 'BAGS': 25, 'SAMPLE_RATIO': 0.7306471883834174, 'JITTER_SCALE': 0.08988885231555943, 'BLOCK_SIZE': 46}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:11:11,131] Trial 17 finished with value: 0.717391304347826 and parameters: {'learning_rate': 0.028078044744603136, 'max_depth': 6, 'min_child_weight': 0.5065040648610765, 'gamma': 3.111304172807005, 'subsample': 0.8717887378779445, 'colsample_bytree': 0.7053243672636744, 'reg_alpha': 2.0713993688065152e-07, 'reg_lambda': 0.000994328084849022, 'n_estimators': 403, 'BAGS': 13, 'SAMPLE_RATIO': 0.6378947909466202, 'JITTER_SCALE': 0.2442813804877597, 'BLOCK_SIZE': 60}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:12:01,818] Trial 18 finished with value: 0.7536231884057971 and parameters: {'learning_rate': 0.043390662943922936, 'max_depth': 12, 'min_child_weight': 1.5685823959364116, 'gamma': 0.8369103411318621, 'subsample': 0.7857168963916564, 'colsample_bytree': 0.9848024319125552, 'reg_alpha': 7.145388826310133e-05, 'reg_lambda': 0.010122093366283615, 'n_estimators': 946, 'BAGS': 39, 'SAMPLE_RATIO': 0.7827708714634865, 'JITTER_SCALE': 0.18798554432803122, 'BLOCK_SIZE': 25}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:12:44,469] Trial 19 finished with value: 0.7463768115942029 and parameters: {'learning_rate': 0.09053564512671186, 'max_depth': 12, 'min_child_weight': 1.6667994031047997, 'gamma': 0.8908627013330581, 'subsample': 0.6638566555335021, 'colsample_bytree': 0.9986997408242411, 'reg_alpha': 0.00055941689676277, 'reg_lambda': 0.009621747553109888, 'n_estimators': 945, 'BAGS': 40, 'SAMPLE_RATIO': 0.9497947229306897, 'JITTER_SCALE': 0.19126318927752461, 'BLOCK_SIZE': 25}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:13:25,398] Trial 20 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.04387789366657501, 'max_depth': 10, 'min_child_weight': 3.735345024641602, 'gamma': 2.1929933123641607, 'subsample': 0.8766024825006535, 'colsample_bytree': 0.9040072623519521, 'reg_alpha': 4.3824922843652853e-05, 'reg_lambda': 0.016957600240153792, 'n_estimators': 1167, 'BAGS': 37, 'SAMPLE_RATIO': 0.7969019368814848, 'JITTER_SCALE': 0.2163677397016583, 'BLOCK_SIZE': 16}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:14:19,092] Trial 21 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.023646230465814544, 'max_depth': 11, 'min_child_weight': 0.7772819167795854, 'gamma': 0.5910502447860333, 'subsample': 0.7848943877592466, 'colsample_bytree': 0.8191697453444327, 'reg_alpha': 4.037195350360932e-05, 'reg_lambda': 0.00042946902315239345, 'n_estimators': 765, 'BAGS': 30, 'SAMPLE_RATIO': 0.7654129505205306, 'JITTER_SCALE': 0.1652301061353007, 'BLOCK_SIZE': 28}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:15:18,565] Trial 22 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.014065996062720673, 'max_depth': 12, 'min_child_weight': 1.288131164195671, 'gamma': 0.7735279050433931, 'subsample': 0.7430480642737715, 'colsample_bytree': 0.5750947907463552, 'reg_alpha': 8.847529371161725e-08, 'reg_lambda': 3.3600171525531324e-05, 'n_estimators': 503, 'BAGS': 27, 'SAMPLE_RATIO': 0.7124651884091061, 'JITTER_SCALE': 0.1367644102428236, 'BLOCK_SIZE': 35}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:15:47,150] Trial 23 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.046901179565471365, 'max_depth': 10, 'min_child_weight': 1.7779773946674935, 'gamma': 1.4079048225856845, 'subsample': 0.8393075698028708, 'colsample_bytree': 0.6982663270962196, 'reg_alpha': 1.1757107232585624e-06, 'reg_lambda': 0.019914469662191996, 'n_estimators': 221, 'BAGS': 37, 'SAMPLE_RATIO': 0.8007168448517917, 'JITTER_SCALE': 0.17873466362913207, 'BLOCK_SIZE': 53}. Best is trial 0 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:19,163] Trial 24 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.03230970154978363, 'max_depth': 9, 'min_child_weight': 0.848164583083642, 'gamma': 2.757969736292901, 'subsample': 0.7759225883645008, 'colsample_bytree': 0.780324692289167, 'reg_alpha': 0.008254873731265707, 'reg_lambda': 8.377650380895323e-06, 'n_estimators': 1392, 'BAGS': 22, 'SAMPLE_RATIO': 0.7470111176047819, 'JITTER_SCALE': 0.2316001348041027, 'BLOCK_SIZE': 44}. Best is trial 0 with value: 0.7536231884057971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Joint Tuning - XGB] Best value (Val Acc of W-avg@best_thr): 0.7536231884057971\n",
      "[Joint Tuning - XGB] Best params: {'learning_rate': 0.03574712922600244, 'max_depth': 12, 'min_child_weight': 4.480392682684062, 'gamma': 2.993292420985183, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'reg_alpha': 2.5502648504032812e-08, 'reg_lambda': 0.011567327199145964, 'n_estimators': 1282, 'BAGS': 31, 'SAMPLE_RATIO': 0.6072045730035308, 'JITTER_SCALE': 0.2439819704323989, 'BLOCK_SIZE': 51}\n",
      "[Best] BAGS=31, SAMPLE_RATIO=0.607, JITTER_SCALE=0.244, BLOCK_SIZE=51\n",
      "       BASE_CFG: {'learning_rate': 0.03574712922600244, 'max_depth': 12, 'min_child_weight': 4.480392682684062, 'gamma': 2.993292420985183, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'reg_alpha': 2.5502648504032812e-08, 'reg_lambda': 0.011567327199145964, 'n_estimators': 1282}\n",
      "       (Val) alphas first 10: [0.0301 0.0327 0.0301 0.0327 0.0323 0.0319 0.032  0.031  0.0318 0.0319]\n",
      "       (Val) best thr (accuracy): 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 15:16:50,230] A new study created in memory with name: no-name-95118a49-2c0b-4d14-93f4-1e66e177fb3e\n",
      "[I 2025-09-01 15:16:50,270] Trial 0 finished with value: 0.7318840579710145 and parameters: {'w0': -0.6272994057631875, 'w1': 2.2535715320495804, 'w2': 1.1599697090570253, 'w3': 0.493292420985183, 'w4': -1.7199067977878175, 'w5': -1.7200273983189867, 'w6': -2.2095819391590026, 'w7': 1.8308807288746758, 'w8': 0.5055750587160439, 'w9': 1.0403628889802272, 'w10': -2.3970775285209878, 'w11': 2.3495492608099715, 'w12': 1.662213204002109, 'w13': -1.4383044466086192, 'w14': -1.590875163964497, 'w15': -1.582977450732831, 'w16': -0.9787887852023114, 'w17': 0.12378215816118932, 'w18': -0.3402749067894213, 'w19': -1.0438542990097903, 'w20': 0.5592644736118975, 'w21': -1.8025306967397907, 'w22': -1.0392767573239092, 'w23': -0.6681907835315415, 'w24': -0.21965007891482013, 'w25': 1.4258798069650682, 'w26': -1.5016310892082014, 'w27': 0.07117219206805814, 'w28': 0.46207284431021245, 'w29': -2.2677479364000113, 'w30': 0.5377242595071916}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 15:16:50,300] Trial 1 finished with value: 0.7463768115942029 and parameters: {'w0': -1.6473793815635425, 'w1': -2.1747420350736024, 'w2': 2.2444276862666666, 'w3': 2.328160165372797, 'w4': 1.5419867405823053, 'w5': -0.9769311541331467, 'w6': -2.0116394299680804, 'w7': 0.9211651325607844, 'w8': -0.29923753130199326, 'w9': -1.8898088257761059, 'w10': -0.024115449443649073, 'w11': -2.328057394423908, 'w12': 2.0466020103939107, 'w13': -1.2061000919999154, 'w14': 0.8126114217699101, 'w15': -0.9414446195529451, 'w16': 0.10034010588905407, 'w17': 0.23355139671639824, 'w18': -1.5757277223723647, 'w19': 2.347923138822793, 'w20': 1.3756641168055728, 'w21': 2.1974947078209457, 'w22': 1.9741367521382438, 'w23': 0.4894998940554256, 'w24': 2.1093711751155837, 'w25': -2.0575374897404024, 'w26': -1.520085687904274, 'w27': -2.27386355544731, 'w28': -0.8733483461836782, 'w29': -0.5566135515525898, 'w30': -1.1432548411305206}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 15:16:50,327] Trial 2 finished with value: 0.7391304347826086 and parameters: {'w0': 1.6436875457596472, 'w1': -0.7162333665320535, 'w2': -1.0953274515630962, 'w3': 0.21348041579124244, 'w4': -1.7953788751261868, 'w5': 1.5109849037701988, 'w6': -2.127246781601146, 'w7': 2.4344346830025865, 'w8': 1.3612238464832869, 'w9': -1.506421592329138, 'w10': -2.472389414381988, 'w11': 1.5773071422741705, 'w12': 1.0342867192380858, 'w13': 1.1450358402049368, 'w14': 1.3563517334297286, 'w15': -2.129776741329548, 'w16': -0.7076713572786368, 'w17': -1.9206547023743514, 'w18': 1.8155171293779677, 'w19': 0.6164906341377896, 'w20': -0.8455098757367541, 'w21': -2.1822082485698817, 'w22': -0.945088391421689, 'w23': -0.8740833898662648, 'w24': 1.1480308916903201, 'w25': 0.6877873567760657, 'w26': 1.9360637128816327, 'w27': -0.13892537419025341, 'w28': -1.9020287703084915, 'w29': 1.0662239361149748, 'w30': 1.3039252430844872}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 15:16:50,352] Trial 3 finished with value: 0.7391304347826086 and parameters: {'w0': 0.3063859878474813, 'w1': 1.3548358997728052, 'w2': -0.031022018178046284, 'w3': 0.1136641469099704, 'w4': -0.36229490820725196, 'w5': -2.372904366279524, 'w6': -1.9605428650334777, 'w7': -2.342854071566329, 'w8': 0.6820520563189021, 'w9': -0.9282200946183665, 'w10': 0.042853455823514075, 'w11': 2.0378323696304648, 'w12': -1.2535388542556252, 'w13': -0.44808538482185156, 'w14': 1.2777556927152434, 'w15': -1.3560091725418877, 'w16': -2.115100450856035, 'w17': -1.0512427354311598, 'w18': -1.693893563729978, 'w19': 2.148488261712865, 'w20': 1.5406018978220848, 'w21': 0.6670187825521174, 'w22': 1.857302950938589, 'w23': 1.5183603844955726, 'w24': -1.567149705569821, 'w25': 1.962794992449889, 'w26': 0.1967112095782535, 'w27': 1.5372007758203123, 'w28': 1.9804564996174658, 'w29': -0.9099826251406806, 'w30': -1.9497403773616162}. Best is trial 1 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 15:16:50,377] Trial 4 finished with value: 0.7536231884057971 and parameters: {'w0': -1.3603241872902916, 'w1': -0.36446105686871855, 'w2': 1.5900738296124652, 'w3': 1.8036529162817168, 'w4': -2.4652393473440464, 'w5': 0.05373651288782888, 'w6': -0.41294498425610504, 'w7': -1.3894609476463486, 'w8': -1.9006731633315859, 'w9': -0.8119241429818602, 'w10': 2.2145485195625962, 'w11': -0.8839853398962239, 'w12': 0.0939531087168306, 'w13': 1.015094794475889, 'w14': -0.6818519881035301, 'w15': 2.3589104136048036, 'w16': 2.3122364747105557, 'w17': -1.2410885208731792, 'w18': -0.013757470538072525, 'w19': -0.9956084509161518, 'w20': -1.075797528112662, 'w21': -2.3155652632273362, 'w22': 0.5478216698994842, 'w23': 0.01339511614430755, 'w24': -2.2426062437500534, 'w25': -1.1067676788169427, 'w26': 2.0413294298332687, 'w27': -1.302190546665138, 'w28': -1.7755256395438845, 'w29': -0.052736198612184815, 'w30': 2.4282522705530036}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,401] Trial 5 finished with value: 0.7463768115942029 and parameters: {'w0': -1.2897236424424978, 'w1': 0.860677737029393, 'w2': 1.3080980766435877, 'w3': -1.3118122800380017, 'w4': 1.1410817430592979, 'w5': -0.661084336403734, 'w6': 0.6615291529678973, 'w7': 0.6676485538044736, 'w8': 0.1788734203737925, 'w9': -2.0485511497279587, 'w10': 1.67651247794619, 'w11': -0.8960996751413208, 'w12': -1.5674074480007287, 'w13': -2.2961242922261804, 'w14': 0.4544647159412092, 'w15': 0.8878218092114123, 'w16': -2.4170608553607194, 'w17': 0.060465291496405005, 'w18': -1.3675211240103102, 'w19': 0.7258639520472494, 'w20': -1.6281678549750427, 'w21': 0.95468869051233, 'w22': -0.566323268497313, 'w23': 2.1836499436836725, 'w24': -1.8123952792700337, 'w25': -0.7946682447487075, 'w26': -1.9326323937970546, 'w27': 2.123468091392814, 'w28': 1.8866967669049046, 'w29': -1.210291861424222, 'w30': 0.799920230170895}. Best is trial 4 with value: 0.7536231884057971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== (Tuned XGB) Bagging — Simple Avg (thr from val) Performance ====\n",
      "Accuracy:      0.595930\n",
      "AUC:           0.642815\n",
      "PR-AUC:        0.506457\n",
      "LogLoss:       0.684053\n",
      "Precision@0.660: 0.500000\n",
      "Recall@0.660:    0.251799\n",
      "F1@0.660:        0.334928\n",
      "\n",
      "==== (Tuned XGB) Bagging — Val-AUC Weighted (thr from val) Performance ====\n",
      "Accuracy:      0.601744\n",
      "AUC:           0.642955\n",
      "PR-AUC:        0.506598\n",
      "LogLoss:       0.684100\n",
      "Precision@0.670: 0.515152\n",
      "Recall@0.670:    0.244604\n",
      "F1@0.670:        0.331707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 15:16:50,426] Trial 6 finished with value: 0.7463768115942029 and parameters: {'w0': 1.5861110010060795, 'w1': 0.27600405799731176, 'w2': 0.14825289178003231, 'w3': -1.2907385454977416, 'w4': -2.034486160970504, 'w5': 1.9860787897666334, 'w6': 2.002090285816652, 'w7': 0.6655072863663398, 'w8': -0.8048510447564965, 'w9': -0.7539521269366956, 'w10': 1.129778394351197, 'w11': 1.9855512997628857, 'w12': 1.9354321213255865, 'w13': 1.399377729288119, 'w14': 0.7101582307714387, 'w15': -2.079300175024756, 'w16': -1.6918564295269312, 'w17': 1.9927709426353966, 'w18': 0.5321452982979498, 'w19': -2.454014741916852, 'w20': -1.9926422856698394, 'w21': 0.8175088455402788, 'w22': -2.4746920807689063, 'w23': -1.6959597429125068, 'w24': 0.24366894683293072, 'w25': 0.959475988463466, 'w26': 0.7598062975130029, 'w27': -1.378653452697201, 'w28': 1.0608961067376792, 'w29': -1.3137545625159996, 'w30': -0.8730015092036614}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,453] Trial 7 finished with value: 0.7391304347826086 and parameters: {'w0': 1.2324570255901208, 'w1': 0.7481644952360735, 'w2': 1.7461170524708898, 'w3': 0.7880644615017167, 'w4': 0.34154301667735787, 'w5': -2.0316261608595374, 'w6': -0.6614209847028323, 'w7': -1.1739881615913728, 'w8': -1.2800517831045821, 'w9': 2.365052773762228, 'w10': -0.534511376666198, 'w11': 1.9602327758855669, 'w12': 0.6556931299863145, 'w13': 1.474056517708242, 'w14': 0.01318546552596045, 'w15': 0.38451942313179543, 'w16': -0.03741153090568039, 'w17': -1.5237850610097774, 'w18': 1.1122605763075266, 'w19': -1.096138187795721, 'w20': -2.378420167842731, 'w21': 0.7273614795358392, 'w22': -1.6144466029647553, 'w23': 2.2022929217645713, 'w24': 2.269642885012937, 'w25': 2.0743219511022426, 'w26': -0.6492064987227781, 'w27': -2.422716917355663, 'w28': 2.141592812938627, 'w29': -0.35907925841342836, 'w30': 2.333274095218348}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,478] Trial 8 finished with value: 0.7536231884057971 and parameters: {'w0': 2.318099885446264, 'w1': 1.7650472773368007, 'w2': -1.0277555396520714, 'w3': -0.5745113569903737, 'w4': 1.7556833575842843, 'w5': -0.9153899742186118, 'w6': -1.6525362665695376, 'w7': 0.2840063122917509, 'w8': 2.180773870803905, 'w9': 0.9801489833748649, 'w10': 0.3503058504468246, 'w11': -2.0141175311461574, 'w12': 0.5750361334958489, 'w13': 2.450269250521316, 'w14': -1.79957992381738, 'w15': 0.0916482618186838, 'w16': 1.8868653596397769, 'w17': 1.203843088771022, 'w18': 0.9850787049763401, 'w19': 1.0124204199355464, 'w20': -0.7025442439012242, 'w21': -1.0320407786775332, 'w22': 1.546805777392568, 'w23': 1.5505669733959042, 'w24': 1.8353615929005187, 'w25': 2.066202762782357, 'w26': 0.056711994304689206, 'w27': 0.007581473435998021, 'w28': 1.4914758948338758, 'w29': 0.7498196538888258, 'w30': 1.0098343862885168}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,502] Trial 9 finished with value: 0.7463768115942029 and parameters: {'w0': 1.478963347180505, 'w1': 1.9500267090878314, 'w2': -0.810024215742321, 'w3': -0.62208523680028, 'w4': -2.030090300795655, 'w5': 0.3914007049808701, 'w6': -2.3202886310162896, 'w7': -0.17200990933769944, 'w8': 0.2132231735378829, 'w9': -1.067293739358578, 'w10': 0.45416630284505377, 'w11': -2.347498750304753, 'w12': -2.313259056253928, 'w13': 1.6130028032982917, 'w14': -0.6990467929436854, 'w15': -1.8646974367405762, 'w16': 0.11121630027402185, 'w17': 1.3499677654930542, 'w18': -1.4208948625157842, 'w19': 0.6144523790950012, 'w20': -2.07326267503116, 'w21': -2.2415913941569614, 'w22': 0.15677315784073986, 'w23': 0.20317560805053247, 'w24': 0.687149507491033, 'w25': 1.1304566686133075, 'w26': 2.379260397312673, 'w27': 0.08150174150597644, 'w28': -0.8852176352937702, 'w29': 1.4759309738435182, 'w30': -1.145838743689629}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,602] Trial 10 finished with value: 0.7463768115942029 and parameters: {'w0': -2.368662177179374, 'w1': -0.8575961249325543, 'w2': -2.462263403418534, 'w3': 2.269716353866983, 'w4': -0.6365808144898499, 'w5': 0.5879655064650399, 'w6': 0.23633915559974428, 'w7': -2.430838493087884, 'w8': -2.325503208723311, 'w9': 0.13296027697238488, 'w10': 2.461962498181124, 'w11': 0.29262365389645084, 'w12': -0.4363075099119267, 'w13': 0.17812132017744953, 'w14': 2.3062158090006752, 'w15': 2.200435839071896, 'w16': 2.417896679664363, 'w17': -2.429038848542518, 'w18': -0.2950207168103944, 'w19': -0.9211581076217893, 'w20': 0.15536550480050204, 'w21': -0.771531273758666, 'w22': 0.7471056803225444, 'w23': -2.068155390903647, 'w24': -0.7618328475170857, 'w25': -1.0525282423878732, 'w26': 1.3585500973293068, 'w27': -1.1736295404512171, 'w28': -2.1076880751660965, 'w29': 2.3537312075022645, 'w30': 2.4968121932077567}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,698] Trial 11 finished with value: 0.7536231884057971 and parameters: {'w0': 2.3673850459357744, 'w1': -0.5394941263976631, 'w2': -1.2922253350983, 'w3': 1.255534137336905, 'w4': 2.4895721082856497, 'w5': -0.5255806027184847, 'w6': -0.8307142235391318, 'w7': -0.8909607351210915, 'w8': 2.480084946806068, 'w9': 0.6554217176948268, 'w10': -1.2138085718202478, 'w11': -1.0798374120569896, 'w12': 0.15094956457990322, 'w13': 2.176851293475168, 'w14': -2.3927803064968742, 'w15': 2.4867849954080574, 'w16': 2.346349260243591, 'w17': -0.8279490703545989, 'w18': 2.0986120052866237, 'w19': -0.16142322967606004, 'w20': -0.7860652691023418, 'w21': -0.992145851921945, 'w22': 1.0111843241421061, 'w23': 1.0296940118191262, 'w24': -2.4561085173118933, 'w25': -0.20164359128399317, 'w26': -0.3226567483410536, 'w27': -0.8600733926576878, 'w28': -0.7084896299524401, 'w29': 0.6214827262084228, 'w30': 1.6427415317902114}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,796] Trial 12 finished with value: 0.7463768115942029 and parameters: {'w0': 0.13739447673608574, 'w1': -1.8550164881856808, 'w2': 0.4298411278450334, 'w3': -2.381522942470839, 'w4': 2.2465247366804117, 'w5': 0.9483721260588365, 'w6': -0.8625470617858949, 'w7': -1.2536148779267968, 'w8': -2.3184759338394083, 'w9': 1.4823934447105231, 'w10': 2.4797400233978735, 'w11': -1.2995207490158953, 'w12': -0.34169645614418115, 'w13': 2.353488478060938, 'w14': -1.027922758485008, 'w15': 1.2350685891001694, 'w16': 1.3623168051088284, 'w17': 0.9084635969806545, 'w18': 0.5640844959657809, 'w19': 1.48748925223184, 'w20': -0.7396710218573228, 'w21': -1.1364072774602703, 'w22': 2.456385980717999, 'w23': -0.44889788705345113, 'w24': 1.3368974710096109, 'w25': -2.127959505658938, 'w26': 1.0271361139278068, 'w27': 0.9321407627157269, 'w28': 0.6325874576268284, 'w29': 0.3873918470881389, 'w30': 0.0941269374331051}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,896] Trial 13 finished with value: 0.7391304347826086 and parameters: {'w0': -0.7732262405404118, 'w1': -0.12020757077580085, 'w2': -1.7053885050877418, 'w3': 1.4722762948702672, 'w4': -0.9742716362899126, 'w5': -0.09076543891935862, 'w6': 1.1949964789575889, 'w7': -0.5835322589880652, 'w8': 1.8851205152878565, 'w9': -0.052560456131325164, 'w10': 1.1051629518100712, 'w11': -0.03352256875377346, 'w12': 0.6432697372185989, 'w13': 0.7004115480452928, 'w14': -2.44580372480086, 'w15': -0.29451133932200124, 'w16': 1.1975720163871988, 'w17': 2.2957074065884613, 'w18': 1.3213465184657414, 'w19': -2.2228062481789843, 'w20': -1.252830949193045, 'w21': -0.40649213519783167, 'w22': 1.089969793121721, 'w23': 1.3144260729610397, 'w24': -0.6574672177427896, 'w25': -1.2963590034050116, 'w26': -0.841449242194118, 'w27': -0.5355119253652226, 'w28': -0.22359566556136423, 'w29': 1.9999987809587911, 'w30': 1.5881744436646454}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:50,993] Trial 14 finished with value: 0.7536231884057971 and parameters: {'w0': -2.4280303985336174, 'w1': -1.435213598049938, 'w2': -0.5900019410467556, 'w3': -0.6658622956694921, 'w4': 0.46342285872231237, 'w5': -1.1638163943033903, 'w6': -1.2834113139103909, 'w7': -1.7890547502083032, 'w8': -1.6401989627682196, 'w9': 2.049675431715083, 'w10': -1.1288374895983755, 'w11': -1.7751716143903005, 'w12': -0.8510413203403264, 'w13': 0.46012210179428226, 'w14': -1.475572177937258, 'w15': 1.5022749076727213, 'w16': 1.4756610949285427, 'w17': -0.801515016806032, 'w18': -0.5448147740510938, 'w19': -0.37203224871139806, 'w20': -0.06814966142719348, 'w21': -1.5756513024582244, 'w22': 0.3034125328743924, 'w23': 0.6840595176362234, 'w24': 1.5308240045791788, 'w25': 0.00928934564465969, 'w26': 0.21064350193248135, 'w27': -1.761080374861641, 'w28': 1.2457606187390202, 'w29': 0.1025423594403283, 'w30': 1.9633167870654478}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,093] Trial 15 finished with value: 0.7463768115942029 and parameters: {'w0': 0.5722055317783774, 'w1': 1.4378097113326977, 'w2': 0.7664926273637418, 'w3': 1.5848950491358373, 'w4': 1.0990302867209918, 'w5': 0.06690118840924653, 'w6': -0.342514587875153, 'w7': 0.03939138995591546, 'w8': 1.5967235620796894, 'w9': -0.07874301306715648, 'w10': 1.772101100480875, 'w11': -0.21445432979360732, 'w12': 1.3844506431141552, 'w13': 2.478306864632049, 'w14': -0.4987610688536237, 'w15': -0.28805526667302894, 'w16': 1.884098357073924, 'w17': 1.3557895557022057, 'w18': 0.261626338125576, 'w19': -1.6073660298926307, 'w20': 0.7419090806775861, 'w21': -2.4838417853077477, 'w22': 1.3671455159594799, 'w23': -1.3527860349646625, 'w24': -1.0933796267164593, 'w25': 0.09585267908974071, 'w26': 1.7161786414759777, 'w27': 0.9658641281625546, 'w28': -1.6064845077000658, 'w29': 1.1278282741572307, 'w30': 1.0821209852317006}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,196] Trial 16 finished with value: 0.7391304347826086 and parameters: {'w0': -0.5882267969003431, 'w1': 0.24905708415198102, 'w2': 2.251535234403179, 'w3': -0.4936599418894785, 'w4': 1.8113759415818604, 'w5': 1.1954922527667982, 'w6': -1.463373259133195, 'w7': 1.2217555857880282, 'w8': -0.4602354114549878, 'w9': -2.44430411412919, 'w10': 0.9846817819563267, 'w11': 0.9874972094251981, 'w12': 0.24725538844870631, 'w13': -0.3291013743499609, 'w14': -1.7577017646871882, 'w15': 1.695103461940345, 'w16': 0.8878251619964123, 'w17': -0.4274633523872151, 'w18': -2.4190232794003004, 'w19': 1.3142647173690756, 'w20': 2.463434379764088, 'w21': -0.03939923208166992, 'w22': 1.5730603474675555, 'w23': -0.2514722213803422, 'w24': 0.11462412948682821, 'w25': -1.5389297546918213, 'w26': 2.396890601907215, 'w27': 0.8150529583181293, 'w28': 2.4926958681848754, 'w29': 0.6438139901304712, 'w30': 0.012669103365401127}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,299] Trial 17 finished with value: 0.7391304347826086 and parameters: {'w0': 2.4661934319325263, 'w1': -1.2834970587214267, 'w2': -2.0303427745179956, 'w3': -2.015884453144168, 'w4': -1.1076481403861145, 'w5': -1.4871602990398198, 'w6': 0.003141628054759593, 'w7': 0.011531622093680109, 'w8': 0.9783228806140316, 'w9': 0.5658581691967319, 'w10': 1.759765379587059, 'w11': -0.6890017725422162, 'w12': 0.9794340271888152, 'w13': 0.8513380958050657, 'w14': -0.24994152292991026, 'w15': 0.4587976326277849, 'w16': 0.7393410128040176, 'w17': 0.7231898116666153, 'w18': 1.097944353922205, 'w19': 0.144984973777468, 'w20': -0.4001629054602861, 'w21': -1.584899968488431, 'w22': 0.6641318788667783, 'w23': 1.7054608416168815, 'w24': -2.110987586291917, 'w25': 2.4958132709669965, 'w26': 0.6442970751617799, 'w27': -1.784661407559995, 'w28': -2.482255939452608, 'w29': -1.9336927401168977, 'w30': 2.0345673936857596}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,398] Trial 18 finished with value: 0.7463768115942029 and parameters: {'w0': -1.7333479388067745, 'w1': 1.7067416162665827, 'w2': -0.4998366540676418, 'w3': -1.3188466276092088, 'w4': 0.19929178834695804, 'w5': -0.27182222989904203, 'w6': -1.3279002146315408, 'w7': -1.59307204306021, 'w8': 2.422172299870718, 'w9': 1.6663516743437774, 'w10': -1.5477661465820434, 'w11': -1.5790244828022386, 'w12': 2.405181241541141, 'w13': 1.9813404871040716, 'w14': -1.0701538962142414, 'w15': -0.852722261767556, 'w16': 1.8508641282396976, 'w17': -1.582847991329937, 'w18': -0.8582940099526818, 'w19': 1.693851324478675, 'w20': -1.2701911330471285, 'w21': 2.4902043826569193, 'w22': -0.4093584356101436, 'w23': 2.4853544092961664, 'w24': 0.6706041066499908, 'w25': -0.567359793786155, 'w26': -1.0679450541505062, 'w27': -0.3249087816739409, 'w28': 0.015195426090950592, 'w29': -0.2032965638151601, 'w30': -0.4372741785352976}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,495] Trial 19 finished with value: 0.7463768115942029 and parameters: {'w0': 0.6961087981661942, 'w1': 0.881754042180013, 'w2': -0.1409154451687724, 'w3': 0.948904368610245, 'w4': 0.7380032668054519, 'w5': -1.031687050039438, 'w6': 0.6317824109289358, 'w7': -0.1799699306321081, 'w8': -1.6369628740424498, 'w9': -0.4491768967144478, 'w10': 0.5704116120177326, 'w11': -2.0781200379365803, 'w12': -0.25700487457339083, 'w13': 1.8419978505400567, 'w14': -1.7879009318649404, 'w15': 1.7902542515736974, 'w16': 1.944373251422485, 'w17': 1.6543002069183967, 'w18': 1.6149202272151124, 'w19': -1.7395003014559036, 'w20': -1.4169830421086402, 'w21': -1.2823933393891735, 'w22': 2.3562472026867303, 'w23': 0.11372488076897759, 'w24': 1.8205332276595627, 'w25': 0.49792413071962915, 'w26': -2.379711355530669, 'w27': 0.2467633495116335, 'w28': 0.9646961145192162, 'w29': 1.5531494099799101, 'w30': 0.514564359681825}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,592] Trial 20 finished with value: 0.7536231884057971 and parameters: {'w0': -0.27530259009427716, 'w1': 2.492085667476562, 'w2': 1.7348258393427445, 'w3': -0.29589824094112377, 'w4': -1.216903445931266, 'w5': 2.489116246127256, 'w6': 1.5512183053804613, 'w7': -0.5975205887211612, 'w8': -1.3676204117405284, 'w9': 1.0629742431460218, 'w10': -0.6494777543939623, 'w11': -0.4587642281280799, 'w12': -0.8678653317717671, 'w13': 1.0493452760094573, 'w14': 0.06817807022933353, 'w15': 0.7905450975550422, 'w16': 0.7839714139637461, 'w17': 0.6327112980703471, 'w18': 2.482409522597624, 'w19': -0.6077980187045707, 'w20': -0.10926045386192262, 'w21': -0.488081488076213, 'w22': 0.4301352397286327, 'w23': 0.9061051875093785, 'w24': 2.4898423192064154, 'w25': -1.6692411438456163, 'w26': 1.4767873364899187, 'w27': -0.7800998910743395, 'w28': -1.2813671011220074, 'w29': 0.14883488707073655, 'w30': -2.4484350088969133}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,687] Trial 21 finished with value: 0.7536231884057971 and parameters: {'w0': 2.4222548393638275, 'w1': -0.5054834673410189, 'w2': -1.3831172812658779, 'w3': 1.5847874488511309, 'w4': 2.492649539175462, 'w5': -0.5008705189240523, 'w6': -0.8157069996098071, 'w7': -0.9668160156286618, 'w8': 2.33405095364706, 'w9': 0.6422765273123401, 'w10': -1.7183523406583874, 'w11': -1.120876305195217, 'w12': 0.024007530475376154, 'w13': 2.1126064293818803, 'w14': -2.359624602788309, 'w15': 2.4851143083411307, 'w16': 2.4601438034666376, 'w17': -0.5685336359501788, 'w18': 2.334929287021713, 'w19': -0.00438199606571299, 'w20': -0.8252543867855016, 'w21': -0.9340872094334735, 'w22': 1.0849558198952494, 'w23': 1.1589288407001397, 'w24': -1.4112154822003093, 'w25': -0.5217629356686342, 'w26': -0.25133518501670365, 'w27': -0.9943066095382539, 'w28': -0.45537224879029486, 'w29': 0.5749940425447488, 'w30': 1.5431654591037065}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,784] Trial 22 finished with value: 0.7536231884057971 and parameters: {'w0': 2.014182094029742, 'w1': -0.26900937550804366, 'w2': -1.5266709398188634, 'w3': 1.128707053077317, 'w4': 1.9342768973938094, 'w5': 0.32291426432949744, 'w6': -0.3462505250467077, 'w7': -1.7559298714948428, 'w8': 2.0304117182126906, 'w9': 0.5693420446034481, 'w10': -0.8681848871148998, 'w11': 0.4681248454155994, 'w12': 0.37873557789292195, 'w13': 1.9735212407848979, 'w14': -2.15396836559856, 'w15': 2.13063087191867, 'w16': 2.4929292357695445, 'w17': -1.187725022507724, 'w18': 1.968676568068899, 'w19': -0.041112006390860545, 'w20': -0.5536216443657207, 'w21': 0.07383539256345673, 'w22': 1.0684974460506222, 'w23': 1.8386075344797632, 'w24': -2.4943217140647347, 'w25': -0.31624607792359116, 'w26': -0.2818704872105764, 'w27': -1.5578033661873456, 'w28': -1.1492680953643348, 'w29': 0.8447975879723766, 'w30': 1.8139895019539791}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,883] Trial 23 finished with value: 0.7463768115942029 and parameters: {'w0': 1.0743520388869183, 'w1': -0.9413904368084485, 'w2': -1.0659133263563008, 'w3': 1.950948923303478, 'w4': 2.1376429472979197, 'w5': -0.6214964862867831, 'w6': -1.6376552045491353, 'w7': -0.6967049588380014, 'w8': 1.2707750886078935, 'w9': 1.199202812558581, 'w10': -0.2098807678193929, 'w11': -1.531672585026057, 'w12': 1.1534213924328989, 'w13': 2.3709472456072107, 'w14': -1.1874080782449088, 'w15': 2.306056333471059, 'w16': 2.0033633654340006, 'w17': -0.30238373900193083, 'w18': 0.7115958632575932, 'w19': 1.0720940484104324, 'w20': -1.0288875914737763, 'w21': -1.8786757725475196, 'w22': -0.08114825488018429, 'w23': 0.9702482676549091, 'w24': -2.476904045689006, 'w25': 0.24932512268558987, 'w26': 0.49960817852687217, 'w27': -0.7421676277776608, 'w28': -0.6062558367674251, 'w29': 1.4426807361417273, 'w30': 0.9770718633114566}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:51,980] Trial 24 finished with value: 0.7536231884057971 and parameters: {'w0': 1.9522887166705638, 'w1': 0.16043851158431766, 'w2': -0.3462787018961744, 'w3': 1.888961192631821, 'w4': -2.3736545041170283, 'w5': -1.483368905735261, 'w6': -1.0270591911023597, 'w7': 0.4801652986290423, 'w8': 1.8906397191312871, 'w9': -0.3645212892226435, 'w10': -1.493210755907917, 'w11': -1.811864500605059, 'w12': 0.6098639213177994, 'w13': 1.5076745886641023, 'w14': -1.8642746905299408, 'w15': 1.2540093591127368, 'w16': 1.69873432320294, 'w17': -2.2414591524200382, 'w18': 0.0280319187928161, 'w19': -0.3919910820923298, 'w20': -1.8308506325729366, 'w21': 0.11629135722639261, 'w22': 1.643910813260646, 'w23': 0.4901979278564729, 'w24': -1.9987610740084212, 'w25': -2.479234608149098, 'w26': -0.48126032842543054, 'w27': 0.5190314874421516, 'w28': 0.06830121062045813, 'w29': 0.21729274208015598, 'w30': 2.1138674952560557}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,080] Trial 25 finished with value: 0.7536231884057971 and parameters: {'w0': 2.0768488227614585, 'w1': -1.3369612670867168, 'w2': -1.9079877553515747, 'w3': 0.5632212038756708, 'w4': 1.5620106723487497, 'w5': 0.79063175683499, 'w6': -0.26380645629249105, 'w7': 1.3900100985293364, 'w8': 2.3558943468754583, 'w9': 0.4048017742368514, 'w10': -2.1160428088147385, 'w11': -1.0382705734179942, 'w12': 0.03351280018635805, 'w13': 0.4648634989618151, 'w14': -2.098859347174234, 'w15': 1.9380719480669801, 'w16': 2.080189689728698, 'w17': -1.6228532317576176, 'w18': 0.9124930887823646, 'w19': 0.30440740991657916, 'w20': -0.3681232315024021, 'w21': -1.3080143946650007, 'w22': 0.7861227482680405, 'w23': 0.13458158791084263, 'w24': -1.4402817462995796, 'w25': -0.9793169635185544, 'w26': -0.021788034767389573, 'w27': -2.005873178894569, 'w28': -1.5537486343065727, 'w29': -0.6313395793604513, 'w30': 1.4529641008749996}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,185] Trial 26 finished with value: 0.7463768115942029 and parameters: {'w0': 0.9404268682027093, 'w1': 0.5388313045291473, 'w2': -2.3460685249938584, 'w3': 1.189670154276866, 'w4': 2.4935463642932576, 'w5': 0.06686563246840549, 'w6': -1.6748028282657343, 'w7': -1.4690889375511065, 'w8': 1.6341872256767396, 'w9': -1.202052214461694, 'w10': 0.5132307101061584, 'w11': -0.44883131157455747, 'w12': -0.7772850474136228, 'w13': 1.205121569234054, 'w14': -1.2690475707139486, 'w15': 0.018503417099416594, 'w16': 1.2199374661001927, 'w17': -0.9168315883881033, 'w18': 1.4490253798455537, 'w19': -1.7125649734831438, 'w20': 0.3368658760627514, 'w21': -0.46426142797590686, 'w22': 2.1352914626428743, 'w23': 1.557124868548359, 'w24': -0.511481469867314, 'w25': 1.443658980966827, 'w26': -1.0970480347791944, 'w27': -1.2037212925542191, 'w28': 1.5008359000918596, 'w29': 0.927199159992984, 'w30': 0.5596603153526006}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,286] Trial 27 finished with value: 0.7463768115942029 and parameters: {'w0': -1.1665361793254754, 'w1': -0.31365597895770025, 'w2': -1.1290438767990465, 'w3': -1.0158459228898098, 'w4': -0.14283532012553457, 'w5': -0.2821130376342019, 'w6': 0.2223453335147204, 'w7': -1.9622676295822268, 'w8': 1.0833430673944477, 'w9': -0.503571324331058, 'w10': -0.969691421203243, 'w11': -2.499622718849571, 'w12': 0.3763311798275229, 'w13': 1.8039241329286533, 'w14': -0.7021777527528186, 'w15': 1.3586526936950336, 'w16': 2.1817757070381805, 'w17': -1.272057272943039, 'w18': 2.0988599662304983, 'w19': -1.3386271809681505, 'w20': 0.9847703133521235, 'w21': 1.7196573670828874, 'w22': 1.417545759321349, 'w23': -0.9353271948366322, 'w24': -1.0567001891468513, 'w25': 0.4633652193062196, 'w26': 1.1447904646128877, 'w27': -0.40389487559066317, 'w28': -2.4601750325717124, 'w29': -0.13165913387202524, 'w30': 1.288800595837586}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,386] Trial 28 finished with value: 0.7463768115942029 and parameters: {'w0': -1.8312342265633492, 'w1': -2.498666134094127, 'w2': 0.471232100074517, 'w3': 1.8780996424028151, 'w4': 1.1248679554826264, 'w5': -0.9314784264989177, 'w6': -0.45907019638919033, 'w7': 0.3290566053968057, 'w8': -0.6860645241747563, 'w9': 1.5051403204932896, 'w10': 2.094545874860895, 'w11': -1.379305744603291, 'w12': -1.4756767263504162, 'w13': 2.4735530397110876, 'w14': -2.017950010800159, 'w15': 0.9006079843998558, 'w16': 1.5830941170810298, 'w17': -0.22697705292879866, 'w18': 0.20659822029616876, 'w19': -0.7019163105340878, 'w20': -2.492119329675287, 'w21': -0.8447816330959306, 'w22': -0.07394683068035368, 'w23': -0.19802648066893103, 'w24': -2.2610776569660387, 'w25': -0.26676607584336187, 'w26': 1.9903093379492336, 'w27': -0.8369944959174741, 'w28': -1.8926727617559247, 'w29': 0.5299167661363986, 'w30': 1.7197370987844354}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,485] Trial 29 finished with value: 0.7463768115942029 and parameters: {'w0': -0.4225006300872173, 'w1': 1.1387333044589585, 'w2': 0.9948730832830242, 'w3': 0.40539683294378337, 'w4': 1.6399760080114119, 'w5': -1.7701796209531795, 'w6': -1.0579254175752693, 'w7': -0.9362780829952667, 'w8': 0.4991021613448385, 'w9': 0.7585540749361037, 'w10': -2.03946159157443, 'w11': -1.9611063595592437, 'w12': 1.483605619905571, 'w13': -0.1802138168279761, 'w14': -1.4354072778966485, 'w15': -0.8556098743971358, 'w16': 0.46676559583462685, 'w17': 0.4589454234076542, 'w18': -0.3258384666738108, 'w19': 1.056860400261285, 'w20': -1.5575500692199582, 'w21': -1.9396801401575607, 'w22': 1.2128331700992012, 'w23': 0.6890228272006513, 'w24': -0.2434485684940646, 'w25': 1.4912351001646766, 'w26': -1.3872110546886152, 'w27': 0.33821633398285345, 'w28': 0.4244575888671487, 'w29': 1.853723484115013, 'w30': 2.2556435999083257}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,583] Trial 30 finished with value: 0.7391304347826086 and parameters: {'w0': -0.13206583420643314, 'w1': 2.0885110687453445, 'w2': -0.7677105744766971, 'w3': -0.0014011281592190006, 'w4': 0.8011100316262971, 'w5': -1.385819716936663, 'w6': 0.8067795211785994, 'w7': -0.3921106458955961, 'w8': -1.9789722416300393, 'w9': 0.19302143746595446, 'w10': -1.2598654096950908, 'w11': -0.8362754968964958, 'w12': -0.6150647947425796, 'w13': -0.8378537251407314, 'w14': -1.647595313180306, 'w15': -2.484429425648442, 'w16': -0.8424614145042266, 'w17': -0.7026976313250584, 'w18': -0.6938463319374786, 'w19': -0.2759300852799915, 'w20': -1.0562659469955362, 'w21': -1.5671858048211624, 'w22': 0.5162033300709957, 'w23': 1.9907157244343803, 'w24': 0.6472293000468918, 'w25': -1.3191647746766324, 'w26': 0.2569880575663025, 'w27': 1.4311477042871563, 'w28': 0.5644090097596666, 'w29': -1.5888787902757238, 'w30': 0.4448203695067754}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,693] Trial 31 finished with value: 0.7463768115942029 and parameters: {'w0': -2.206230993516834, 'w1': -1.4239458466462573, 'w2': -0.582792570631558, 'w3': -0.7604624466912668, 'w4': 0.5420354893915991, 'w5': -1.2045932092266565, 'w6': -1.2506276967627683, 'w7': -1.9489139012262362, 'w8': -1.8715998644298681, 'w9': 2.302736972299143, 'w10': -0.45348101496239235, 'w11': -1.7307272836231407, 'w12': -1.0023572675373922, 'w13': 0.44318318483638475, 'w14': -1.4725061634708052, 'w15': 1.6350176670921357, 'w16': 1.492764382455792, 'w17': -0.8958708589782591, 'w18': -0.7644627907352364, 'w19': -0.34358595463034036, 'w20': -0.11910143476292766, 'w21': -1.5344291989590038, 'w22': 0.3153372917210851, 'w23': 0.7800041524106865, 'w24': 1.4189797095565815, 'w25': -0.11715722176765056, 'w26': 0.15701286367690287, 'w27': -1.775773350895529, 'w28': 1.3968080613360698, 'w29': 0.04795025754235713, 'w30': 1.9198344990411473}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,793] Trial 32 finished with value: 0.7536231884057971 and parameters: {'w0': -2.0165088413982564, 'w1': -1.808513719737672, 'w2': -0.8903052217134536, 'w3': -0.2184812293689281, 'w4': 1.2898497762208434, 'w5': -0.8314603748374201, 'w6': -1.7999757144366424, 'w7': -2.0951290598792527, 'w8': -1.0500601035668478, 'w9': 1.858564843585616, 'w10': -1.0821628034682742, 'w11': -2.0829337666545134, 'w12': -2.001503852667444, 'w13': 0.05387499818754815, 'w14': -2.3711636207624096, 'w15': 2.4451207479336707, 'w16': 2.2487514945589893, 'w17': -1.948540332826031, 'w18': -0.5410659665883268, 'w19': -1.3166461717551887, 'w20': 0.44761610813639097, 'w21': -2.0516403958852623, 'w22': -0.4244336857434958, 'w23': 1.2609531837352996, 'w24': 1.6912570397842475, 'w25': -0.6954982548232573, 'w26': -0.15666346716861668, 'w27': -2.0759114256549283, 'w28': 1.4990487303041986, 'w29': -0.7028227246618619, 'w30': 1.9912538237048643}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,892] Trial 33 finished with value: 0.7536231884057971 and parameters: {'w0': -1.1631382486778903, 'w1': -1.0344516640737669, 'w2': -1.3310850431648196, 'w3': -1.0133583126642307, 'w4': 2.0605271022026974, 'w5': -1.8613634179247505, 'w6': -2.438997711255877, 'w7': -1.381894279114588, 'w8': -1.7324362346853626, 'w9': 2.032485904048148, 'w10': 0.10550273503690599, 'w11': -1.3258621734817053, 'w12': -0.14631174821240267, 'w13': 0.6870761613705669, 'w14': -0.8829730531439881, 'w15': 2.0815838443803303, 'w16': 1.0869099344214854, 'w17': -0.18948700771065485, 'w18': -1.0706664063209812, 'w19': 0.4331398977045625, 'w20': -0.371309862827159, 'w21': -2.464585624542732, 'w22': 0.8140549195183712, 'w23': 0.2707243989059625, 'w24': 1.0164101955078007, 'w25': 0.9176960863064545, 'w26': 0.4471379550968084, 'w27': -1.5693425192864683, 'w28': 0.32681601096072455, 'w29': -0.4094235034789261, 'w30': 1.179226594448041}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:52,992] Trial 34 finished with value: 0.7463768115942029 and parameters: {'w0': -2.4785966731384548, 'w1': -0.6848711858857598, 'w2': -0.27778298077723607, 'w3': 2.4467176699117448, 'w4': -1.539910374212854, 'w5': -0.46366748648437517, 'w6': -1.182346343802652, 'w7': -0.9251707520839318, 'w8': -0.150885977920042, 'w9': 1.1443431588884998, 'w10': -1.976057365693158, 'w11': -2.11462939399664, 'w12': 0.8622415318488853, 'w13': -1.0411067484608274, 'w14': -1.4728384788062712, 'w15': 1.5244604227373861, 'w16': 1.6218531480131175, 'w17': 0.13305481865026084, 'w18': 0.23486984395089983, 'w19': -0.7931791269248982, 'w20': -0.6340320625607848, 'w21': -1.6968270223748352, 'w22': 1.8725503761522462, 'w23': 0.611970144416097, 'w24': 1.921113491155075, 'w25': -1.8379962686557199, 'w26': 0.9879510214228809, 'w27': -0.13809682176248916, 'w28': 0.7931573891457844, 'w29': 0.3399249846610783, 'w30': 2.454020163542542}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,090] Trial 35 finished with value: 0.7463768115942029 and parameters: {'w0': -1.4410852998321915, 'w1': -1.5473894361605458, 'w2': 2.490056658122003, 'w3': -1.924843068919442, 'w4': -0.5251000779269399, 'w5': -1.0458260235245929, 'w6': -2.0402678222710664, 'w7': 1.766214574555609, 'w8': -2.168641758125427, 'w9': -1.6044800296229451, 'w10': -0.15435518403646586, 'w11': -0.6885360563967777, 'w12': -1.146767168810277, 'w13': -2.0550746659805554, 'w14': -0.48945106129176363, 'w15': 1.9205589175607136, 'w16': 2.2016551784961114, 'w17': -0.7047656478723927, 'w18': -0.24970920854627132, 'w19': 2.0381881550543826, 'w20': -0.16715321012362816, 'w21': -1.292101215589997, 'w22': -1.0662749009251904, 'w23': -0.5715066209529094, 'w24': -1.7730365721423922, 'w25': 1.9265480685817997, 'w26': -0.5577472226491555, 'w27': -2.175254981445736, 'w28': 1.1741611691295335, 'w29': 1.112552854480784, 'w30': 1.730434304002626}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,190] Trial 36 finished with value: 0.7391304347826086 and parameters: {'w0': 2.184528119868511, 'w1': -0.46181655710083314, 'w2': 0.17959462535735943, 'w3': 0.29945752287425875, 'w4': -0.11166619628082675, 'w5': -2.4620247193493534, 'w6': -0.6556248795023212, 'w7': -2.1941670193992966, 'w8': -1.601801495217143, 'w9': 0.8860988488108765, 'w10': -1.2678271056646446, 'w11': -1.6869849077888834, 'w12': 0.1389472264353802, 'w13': 1.2017921629811004, 'w14': -2.023371362911007, 'w15': -1.309495919411038, 'w16': -1.3086102264385828, 'w17': -1.3438195267134092, 'w18': 1.6928735341746832, 'w19': 0.8465544559576341, 'w20': -1.013784805935836, 'w21': -2.236029225341883, 'w22': 0.09404160687794039, 'w23': 1.125668207519726, 'w24': 2.146852611051016, 'w25': 0.07797247444756722, 'w26': -1.7436745089071535, 'w27': -1.1935015647087541, 'w28': 1.7516523128477224, 'w29': -1.058811993694823, 'w30': 0.845188113867758}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,293] Trial 37 finished with value: 0.7463768115942029 and parameters: {'w0': 1.7282306831267924, 'w1': -1.0915587958938788, 'w2': 1.5689517609969863, 'w3': -0.08920999426911894, 'w4': 1.51892704320782, 'w5': -0.760097280774988, 'w6': -1.3847843599874057, 'w7': -1.820925128830384, 'w8': -1.0877819707390097, 'w9': 1.31696691513682, 'w10': 1.3526380108895308, 'w11': -1.1585838105437927, 'w12': -0.5448886676573008, 'w13': -1.593882177679562, 'w14': 0.4216468607676136, 'w15': 1.0153947776894405, 'w16': -0.4537061619183198, 'w17': -1.881640619302805, 'w18': -1.8163904847501149, 'w19': -0.5300263714036724, 'w20': 1.7835018276357995, 'w21': -0.7057609165691258, 'w22': -0.7529243553457341, 'w23': 0.39222599740532504, 'w24': 1.4685847380042774, 'w25': 0.39426990288125136, 'w26': 0.7710285583419845, 'w27': -0.6268464571682109, 'w28': -0.7272141132357226, 'w29': 0.8159611449391991, 'w30': 1.3712789988011824}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,392] Trial 38 finished with value: 0.7463768115942029 and parameters: {'w0': -0.8366569040257013, 'w1': 0.03333037118393056, 'w2': -1.7978784087593065, 'w3': -0.9283375107593359, 'w4': 0.16049551891579394, 'w5': -2.1409098778167572, 'w6': -0.01957788254325743, 'w7': 2.314570198181165, 'w8': 2.064526507088836, 'w9': 2.4982716625028383, 'w10': 0.20624526147057676, 'w11': -2.2406930336190314, 'w12': -1.7294138841456972, 'w13': 2.1749234293195854, 'w14': -2.494462754650975, 'w15': 2.4861989898052714, 'w16': 1.7764954295904307, 'w17': -0.9610031783888602, 'w18': -0.04739164366020088, 'w19': -0.11914801641511687, 'w20': 0.14744510668640867, 'w21': -1.0485012317006785, 'w22': 1.644030241733492, 'w23': -0.07588736410036802, 'w24': 1.0636608102327363, 'w25': 1.7292132634874438, 'w26': -0.7917851881927501, 'w27': -2.4424962587577452, 'w28': -1.0899135541620864, 'w29': -0.05490298898602994, 'w30': 2.117443738240458}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,493] Trial 39 finished with value: 0.7463768115942029 and parameters: {'w0': 1.359196082830054, 'w1': 0.39846252700065254, 'w2': -1.1655167332973584, 'w3': 0.6078637553651014, 'w4': -2.480347513837064, 'w5': -1.242871749931342, 'w6': -2.1277064512651096, 'w7': -1.1807207715973254, 'w8': -2.4677588479329153, 'w9': -0.6932943469319628, 'w10': -2.4087846445455545, 'w11': 2.405309615004154, 'w12': 0.4652470269286734, 'w13': 0.3409461456439487, 'w14': -1.277597514342977, 'w15': 0.5168799197743751, 'w16': 2.246766390770053, 'w17': -0.005103696303938143, 'w18': -1.0603149374766834, 'w19': -0.987161666536874, 'w20': 0.7713214466306816, 'w21': 0.4814628431999639, 'w22': 0.8452822870349656, 'w23': 1.419055370208772, 'w24': 0.38186285299581035, 'w25': 2.271612172056873, 'w26': 2.163871688243981, 'w27': -1.6465181160055755, 'w28': -0.3619894983536369, 'w29': -0.8369465650311912, 'w30': 2.2710155961960474}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,591] Trial 40 finished with value: 0.7463768115942029 and parameters: {'w0': -1.5295546173310042, 'w1': -1.7324844436087563, 'w2': 0.15848710801669208, 'w3': -1.537141400016673, 'w4': -0.7822604852338138, 'w5': 0.3237757584276928, 'w6': -0.6842800448404365, 'w7': -1.659785217484209, 'w8': 0.14550788134639503, 'w9': 2.0877248620126165, 'w10': 0.8083591259833147, 'w11': -1.8600871539536898, 'w12': -0.1374806492560795, 'w13': 0.9005296529498061, 'w14': 1.411672267014516, 'w15': 0.130441935112948, 'w16': 0.4039041948047881, 'w17': 0.3072123228814597, 'w18': 0.7709473258387582, 'w19': 0.3841670679724113, 'w20': -1.9103087497445241, 'w21': -1.859884294307629, 'w22': -1.388777999425622, 'w23': 0.885498921783191, 'w24': -1.6423390678969845, 'w25': 1.1936563077743458, 'w26': 0.222254930784459, 'w27': -0.9957371514527393, 'w28': 2.178151629389778, 'w29': -2.434762880304973, 'w30': -0.34786310976562707}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,690] Trial 41 finished with value: 0.7463768115942029 and parameters: {'w0': -0.2659019881945939, 'w1': 2.4090450486896615, 'w2': 1.7352597168751884, 'w3': -0.5798726011421267, 'w4': -1.390609780615414, 'w5': 1.9179852022168866, 'w6': 1.9618125496079237, 'w7': -0.6045327321785612, 'w8': -1.4243580458671035, 'w9': 0.9460885071355356, 'w10': -0.6618478401925008, 'w11': -0.42007348470013933, 'w12': -0.824318926247873, 'w13': 1.0751867034211682, 'w14': 0.29495419241566384, 'w15': 0.7050854475062723, 'w16': 0.9392980078694729, 'w17': 0.8921791204304448, 'w18': 2.4161777829567215, 'w19': -0.6145605638885479, 'w20': -0.09259947441190264, 'w21': -0.5115101979145014, 'w22': 0.44043554954008995, 'w23': 1.0370204155730127, 'w24': 2.4817187408369703, 'w25': -1.6689866330530856, 'w26': 1.6583504430193658, 'w27': -0.14501920116767533, 'w28': -1.3960911339918773, 'w29': 0.2304249058034532, 'w30': -2.2287333615026017}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,791] Trial 42 finished with value: 0.7463768115942029 and parameters: {'w0': 0.406533603306779, 'w1': 2.44789548137167, 'w2': 1.3736234391594786, 'w3': -0.30507631074989733, 'w4': -1.7423058299600838, 'w5': 2.49101339309026, 'w6': 2.2947946887068444, 'w7': -0.41381472121075874, 'w8': -1.3392987395812408, 'w9': 0.34800052217482585, 'w10': -0.7094343065470013, 'w11': 0.45120676430131684, 'w12': -1.2895545983218284, 'w13': 1.7172473093880232, 'w14': -0.12906523023757632, 'w15': -0.4308592542370072, 'w16': 1.3941126636037897, 'w17': 1.399556142493704, 'w18': 2.1439300927729494, 'w19': -1.1732112489122724, 'w20': 0.14836442715306242, 'w21': -0.3594125735835968, 'w22': 0.32233820387436524, 'w23': 0.4962627894198421, 'w24': 2.4088692694368503, 'w25': -2.313670321851997, 'w26': 1.6503178994890995, 'w27': 2.318568150275126, 'w28': -1.904923564830994, 'w29': 0.09495775098782917, 'w30': -1.8386940636058413}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,892] Trial 43 finished with value: 0.7391304347826086 and parameters: {'w0': -0.8790985133365067, 'w1': 1.8186733139068392, 'w2': 2.0185328924152603, 'w3': -0.45760968242819344, 'w4': -1.0787343908924754, 'w5': 1.556343353980862, 'w6': 1.3546494745953326, 'w7': 0.8591623603675668, 'w8': -0.7166177863575216, 'w9': 1.6063690775860713, 'w10': -0.2950331789429956, 'w11': -0.41636834188510247, 'w12': -0.9286166285502047, 'w13': 1.36750366296965, 'w14': 1.0789011929746328, 'w15': 0.22734267194054875, 'w16': 0.5618889938772813, 'w17': 0.4752342520235536, 'w18': 1.216555090352113, 'w19': -0.22938346410375282, 'w20': -0.8268147768622442, 'w21': -0.1085988885908274, 'w22': -0.21454804832961794, 'w23': -0.8629206023112834, 'w24': 1.8835392349804225, 'w25': -1.027292795656319, 'w26': 1.3764889334687567, 'w27': -0.9260265472499049, 'w28': -1.0232103116295503, 'w29': -0.32773148183215567, 'w30': -1.557283954070416}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:53,994] Trial 44 finished with value: 0.7463768115942029 and parameters: {'w0': 0.15314304314310778, 'w1': 2.21910454498772, 'w2': 1.1497568630577895, 'w3': 0.12148082133170246, 'w4': -2.171111009044257, 'w5': -0.26315404294578126, 'w6': -1.0305387461885678, 'w7': 0.2672934376148803, 'w8': -1.0162321253834934, 'w9': 1.028714200369753, 'w10': -1.2053044018297667, 'w11': -0.9078474446388565, 'w12': -0.5554449657900347, 'w13': -0.6623219215075737, 'w14': -0.39949191017319224, 'w15': 1.4355595099457665, 'w16': -0.04323652813276768, 'w17': 1.0084180824397568, 'w18': 2.49202398174061, 'w19': 0.1884293205206773, 'w20': -0.5462580301549557, 'w21': -1.3860826829696073, 'w22': 0.2622482623981357, 'w23': 1.4152100450149285, 'w24': 2.192975845298527, 'w25': -1.9181452943394859, 'w26': 2.1604108052053768, 'w27': -1.3609454745049416, 'w28': -1.5480629299974085, 'w29': 1.2662689638269204, 'w30': -0.9097736990245603}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,098] Trial 45 finished with value: 0.7463768115942029 and parameters: {'w0': 1.7496611995389768, 'w1': 1.5244984336271918, 'w2': 1.9451069844437066, 'w3': -0.7381256047028969, 'w4': -1.3138843367100024, 'w5': 2.4076194716524055, 'w6': 1.521117739392777, 'w7': -0.9123332133539006, 'w8': -2.134583577390482, 'w9': -0.20554664914094933, 'w10': 2.109098178691064, 'w11': -0.17730582569996456, 'w12': -0.3952030553114189, 'w13': 0.6215727637669785, 'w14': -0.8561587652390484, 'w15': 1.14823122308763, 'w16': 1.3382925808386483, 'w17': 1.101779968977951, 'w18': 1.7676486821454798, 'w19': -0.8529285511201916, 'w20': -0.28836323728992597, 'w21': -0.671350327783339, 'w22': 0.9539254426499442, 'w23': 0.8004455769571408, 'w24': 1.5312390111195533, 'w25': -1.3566614800633081, 'w26': 1.4303839016297828, 'w27': -0.42827189753818357, 'w28': -2.184758856662033, 'w29': 0.7053781184590656, 'w30': 0.2664612974462207}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,198] Trial 46 finished with value: 0.7536231884057971 and parameters: {'w0': -2.034209365436121, 'w1': -2.059248804394551, 'w2': 0.7953174682110835, 'w3': -0.297183504377187, 'w4': 2.3325998825705367, 'w5': 1.5141056602397223, 'w6': -1.888649576654261, 'w7': -0.214552163942064, 'w8': -0.40838178221707744, 'w9': 1.377993973624672, 'w10': -1.5168442790899292, 'w11': 0.16148914678817844, 'w12': 0.20093270148434672, 'w13': 0.9032804527019557, 'w14': -0.06904481270704083, 'w15': 0.6432394318098115, 'w16': 0.9757417541680643, 'w17': 1.9111941886047688, 'w18': 0.45179972857524964, 'w19': 2.4162649285604063, 'w20': -1.284162757114291, 'w21': -1.0797536409180715, 'w22': 0.5411459722554561, 'w23': 1.6945244025136899, 'w24': 2.1198756752081254, 'w25': -0.8429972316961161, 'w26': -0.415957586433463, 'w27': -1.3565687358040672, 'w28': -1.3366881732015043, 'w29': 0.4815079492394916, 'w30': 2.4968820626633708}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,302] Trial 47 finished with value: 0.7463768115942029 and parameters: {'w0': -0.9860862561382029, 'w1': 1.957410650529332, 'w2': -1.6069512912840322, 'w3': 2.1654284887395203, 'w4': -0.33083793767233427, 'w5': 1.2320714673967654, 'w6': -1.5648965720097319, 'w7': -1.3271327759526006, 'w8': 0.4172371676417468, 'w9': 1.826966499376819, 'w10': -0.44542605255084067, 'w11': -0.6071705699388066, 'w12': 0.8064383581471144, 'w13': 2.1422018811305197, 'w14': 0.8411621674529425, 'w15': -0.5361672202215243, 'w16': 1.8153550457611187, 'w17': 0.6603469555663771, 'w18': 1.4464540009392186, 'w19': -0.5124924966392767, 'w20': 0.0025509737459283865, 'w21': 1.269741405396364, 'w22': 1.2380464817961252, 'w23': 2.1765580961591446, 'w24': 1.2112809243000051, 'w25': 0.6890578016837263, 'w26': 0.9005405431220737, 'w27': -0.04592443455101948, 'w28': -0.7300539337759033, 'w29': 0.3121458436092852, 'w30': -0.45758980034692565}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,414] Trial 48 finished with value: 0.7391304347826086 and parameters: {'w0': 2.2837932154479033, 'w1': 1.2133105271515667, 'w2': -0.8944472920700359, 'w3': 1.2835304795383378, 'w4': -1.9277697342156208, 'w5': 1.9820879279492964, 'w6': 0.0140173277436062, 'w7': -2.4814096532565326, 'w8': 1.5624143968868225, 'w9': -1.2296381583734461, 'w10': -0.779099622900489, 'w11': -1.488113377872113, 'w12': 1.1693378028596917, 'w13': 0.20660712574672935, 'w14': 1.7034142627638627, 'w15': 1.899850427052907, 'w16': 0.23080810886719727, 'w17': -0.5184551179116796, 'w18': 2.2409091787561395, 'w19': 0.6070501266530726, 'w20': -1.6836043363054123, 'w21': 0.2887484459057462, 'w22': -2.491758829812374, 'w23': -0.3289608635054452, 'w24': 1.6736487464623646, 'w25': -1.522586056486299, 'w26': 1.1705876600746428, 'w27': -1.9198331219044258, 'w28': -1.7589640661725843, 'w29': -0.3527143112149116, 'w30': 1.6396878516818303}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,521] Trial 49 finished with value: 0.7463768115942029 and parameters: {'w0': -2.250021624442842, 'w1': -0.6706126401412563, 'w2': -0.5680914031333932, 'w3': -1.3063964885511905, 'w4': -0.8183090944586968, 'w5': -1.5688777015875028, 'w6': -0.5493406367154776, 'w7': -0.707464053908264, 'w8': -1.9008788357290647, 'w9': 0.3236649820712797, 'w10': 0.29021344931750315, 'w11': 0.9271944149920339, 'w12': -0.16826785960997193, 'w13': 1.3613166157431142, 'w14': 0.11280143955820647, 'w15': -0.15679906955942485, 'w16': 2.305135364331035, 'w17': 1.573875889490144, 'w18': 1.8459222943638214, 'w19': -1.9675991633695449, 'w20': 0.6506723142319659, 'w21': -0.20298493617831503, 'w22': 0.5669506564675176, 'w23': 0.3475820405509192, 'w24': -0.1352220770488235, 'w25': -2.0193767993661096, 'w26': 2.466117094083762, 'w27': -0.7013432118029446, 'w28': -0.1191120820093623, 'w29': 0.036660851717619236, 'w30': 0.8308723262458888}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,625] Trial 50 finished with value: 0.7463768115942029 and parameters: {'w0': -0.6418052317624563, 'w1': 0.5319217603792532, 'w2': -2.1538549803683527, 'w3': -1.50932413922939, 'w4': 1.7770706460881136, 'w5': -2.0760842358044416, 'w6': 0.6741973946472599, 'w7': -1.1073360390624791, 'w8': -1.563230482777065, 'w9': 0.11826855935739977, 'w10': 1.4131696583844988, 'w11': -1.1845041153521731, 'w12': -1.840110016491645, 'w13': 1.62342048406219, 'w14': -2.2265076600805007, 'w15': 2.1870808145873704, 'w16': 0.699289059127215, 'w17': -0.0469142278322896, 'w18': -0.5190749150806501, 'w19': -1.4170312168326011, 'w20': 1.0404458307538242, 'w21': -2.3260653803212143, 'w22': 0.11697505943841541, 'w23': 0.009603281401677573, 'w24': -2.1834982249889414, 'w25': -1.1618394566378314, 'w26': 1.8816687527587939, 'w27': 0.23165085615795922, 'w28': 1.8665796086421917, 'w29': 1.282985911937783, 'w30': -2.300543281374721}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,728] Trial 51 finished with value: 0.7463768115942029 and parameters: {'w0': 2.360130034574518, 'w1': -0.5836876120350405, 'w2': -1.2236865133862083, 'w3': 1.392625528304564, 'w4': 2.471807339369764, 'w5': -0.5172744966106233, 'w6': -0.8439539413274513, 'w7': -1.0338478290902926, 'w8': 2.3097397163449065, 'w9': 0.7942456601436122, 'w10': -1.7776391105741896, 'w11': -1.0078099973696528, 'w12': 0.5608857649170962, 'w13': 2.1984322034650714, 'w14': -2.278262390349091, 'w15': 2.2956121936177887, 'w16': 2.3646657570600667, 'w17': -0.5951099833169387, 'w18': 2.257515737368186, 'w19': 0.05195303997106909, 'w20': -0.8536715797638506, 'w21': -0.8768036637417903, 'w22': 1.035590358976209, 'w23': 1.179187631823042, 'w24': -1.2617275255530014, 'w25': -0.4904898631135899, 'w26': -0.2045359825040617, 'w27': -1.0014079265265958, 'w28': -0.3366709086504125, 'w29': 0.4705957347349728, 'w30': 1.5705249881017276}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,831] Trial 52 finished with value: 0.7536231884057971 and parameters: {'w0': 2.464076736276288, 'w1': -0.11619088611751671, 'w2': -1.4124567472273373, 'w3': 1.7735131697311906, 'w4': 2.1916162774950614, 'w5': -0.12399181810169235, 'w6': -0.7991778158593386, 'w7': -1.4998067929307277, 'w8': 2.247099631275684, 'w9': 0.6196801062611987, 'w10': -1.700384896874882, 'w11': -0.8448948980269191, 'w12': -0.0015291284927210769, 'w13': 2.094532099629417, 'w14': -1.8337905114493, 'w15': 2.498459133262155, 'w16': 2.020617506316955, 'w17': -1.4234983483197707, 'w18': 1.996097224695047, 'w19': -0.05565389125902642, 'w20': -0.7628894269670248, 'w21': -0.9818496943233124, 'w22': 1.4683149254445633, 'w23': 1.588998880527903, 'w24': -2.280003049564964, 'w25': -0.38295247228187546, 'w26': -0.0260437369563688, 'w27': -1.089911893567336, 'w28': -0.5150456769654099, 'w29': 0.667603878037865, 'w30': 1.8589543947040237}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:54,932] Trial 53 finished with value: 0.7536231884057971 and parameters: {'w0': 1.8920955239577808, 'w1': -0.48472795581466716, 'w2': -0.7039413968451348, 'w3': 1.603807305126832, 'w4': 1.3510745343662567, 'w5': -0.6586645890780519, 'w6': -0.9808507939411646, 'w7': -0.7684635775720663, 'w8': 2.1359515265910813, 'w9': 0.6142121184125156, 'w10': -1.054384632744123, 'w11': -1.1930679739301233, 'w12': 0.2720744037903938, 'w13': 1.9265410504511826, 'w14': -1.6793780605660624, 'w15': 2.0971940990464075, 'w16': 2.4935341814372833, 'w17': -1.1289293576383668, 'w18': 2.338560465533155, 'w19': -1.0106541358627488, 'w20': -1.153092338919933, 'w21': -1.1376297870448608, 'w22': 1.7470223471786284, 'w23': 0.9849141068104794, 'w24': -1.8560866394223607, 'w25': -0.0735863963277515, 'w26': 0.45829723758300184, 'w27': -1.4529451538440257, 'w28': 0.22176271010841542, 'w29': 0.9147584514412029, 'w30': 1.4379651223292982}. Best is trial 4 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 15:16:55,035] Trial 54 finished with value: 0.7608695652173914 and parameters: {'w0': 1.5244276906785186, 'w1': -0.8878185306254143, 'w2': -1.057360065890838, 'w3': 2.288096267628913, 'w4': 1.8939455216655758, 'w5': -1.0855982358315521, 'w6': -0.31089161397282594, 'w7': -0.4367375738125522, 'w8': 2.4854275311048832, 'w9': 1.118081510388382, 'w10': -1.3692423339673718, 'w11': -1.5422215480790018, 'w12': -0.011681072818835625, 'w13': 2.300083997124746, 'w14': -1.9524496974063803, 'w15': 1.6557000016136065, 'w16': 1.9461332388944228, 'w17': -0.8221536103763044, 'w18': 1.0089416152803308, 'w19': -0.43337446853888795, 'w20': -0.5550258376608357, 'w21': -0.6937184560761628, 'w22': 1.2070439275739244, 'w23': 1.2804032236329483, 'w24': -1.3870466913288484, 'w25': -0.7679057363338704, 'w26': -0.8215229127253706, 'w27': -0.5519314234960623, 'w28': -1.260817275638432, 'w29': -0.19325881061473302, 'w30': 1.15151207198379}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,143] Trial 55 finished with value: 0.7536231884057971 and parameters: {'w0': 1.5658617605714293, 'w1': -1.1259451232649549, 'w2': -0.9600863217952512, 'w3': 2.162921608165888, 'w4': 0.8943169121271884, 'w5': -1.2420224826460924, 'w6': -0.23784224279378333, 'w7': -0.37504622233243645, 'w8': 1.7645864612140327, 'w9': 1.274695777802451, 'w10': -1.3782638825099334, 'w11': -1.6012505485902924, 'w12': -0.684844501193854, 'w13': 2.4722835060090618, 'w14': -1.933683630617074, 'w15': 1.6684772982061045, 'w16': 1.9653577344219366, 'w17': -1.7649622300618608, 'w18': 0.9703563839887144, 'w19': -0.4430586828770472, 'w20': -0.5192605046370629, 'w21': -0.6133536603184843, 'w22': 1.3556609206715706, 'w23': 1.8203633113182476, 'w24': -2.0209622398427065, 'w25': -0.8315430058226057, 'w26': -1.0757970791458957, 'w27': -0.3363998127091402, 'w28': -1.288757623843187, 'w29': -0.5467107199816146, 'w30': 1.0508843795629883}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,241] Trial 56 finished with value: 0.7536231884057971 and parameters: {'w0': 1.1464579630029164, 'w1': -0.207579755607398, 'w2': -0.39993878088713597, 'w3': 0.920160784021133, 'w4': 2.012871827613556, 'w5': 0.49984251211628183, 'w6': 0.3360070585984398, 'w7': 0.09723923587668559, 'w8': 2.4650988949680093, 'w9': 1.0745960564634613, 'w10': -0.961140971849572, 'w11': -2.398253867017119, 'w12': -0.37614906906207257, 'w13': 2.2947262831160526, 'w14': 0.17764223285010416, 'w15': 1.005017707327618, 'w16': 1.7309717335350112, 'w17': -0.7858002140060671, 'w18': 0.5454490862890612, 'w19': -0.6746500854300111, 'w20': -1.4345835578695378, 'w21': -1.4222677552379577, 'w22': 2.1029660465644873, 'w23': 1.3381657970879286, 'w24': -0.8654999138419321, 'w25': -1.7204018987767822, 'w26': -0.8349721201469031, 'w27': -0.5981228135282532, 'w28': -0.8241919653078857, 'w29': -0.14421616920961144, 'w30': -0.21744029359219175}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,339] Trial 57 finished with value: 0.7463768115942029 and parameters: {'w0': 0.8017182515898535, 'w1': -0.7397480798854514, 'w2': 2.147032275291518, 'w3': -0.8178039865158593, 'w4': 0.531113708248264, 'w5': -1.0667245275977186, 'w6': -0.12174283738348843, 'w7': -0.14007482528666027, 'w8': 1.9154072619025884, 'w9': 1.8251899553788289, 'w10': 0.7944691005870814, 'w11': -1.34224417858124, 'w12': -1.183747758631873, 'w13': 1.0362000269290819, 'w14': -1.1158735808194236, 'w15': 0.7144949262099597, 'w16': -2.2178996813451257, 'w17': -1.142743915285494, 'w18': -0.04819688449467874, 'w19': 1.7520252107332683, 'w20': -0.23708210027189314, 'w21': -0.3109630578050888, 'w22': 0.6466258449737865, 'w23': 0.542013539580799, 'w24': 2.32901481285961, 'w25': -0.6363618808705953, 'w26': -1.4478584661748806, 'w27': -0.7559227195452174, 'w28': -0.936426006221083, 'w29': -0.5074129229543822, 'w30': 0.6941173555429229}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,444] Trial 58 finished with value: 0.7463768115942029 and parameters: {'w0': 2.170225217678346, 'w1': -1.565010437988707, 'w2': 0.4351494794966373, 'w3': 2.0701005780541992, 'w4': 1.7437201455957418, 'w5': -0.8781339916339175, 'w6': 0.4182828130980156, 'w7': 0.5753824592494426, 'w8': 0.9086871943507209, 'w9': -2.2185872798192987, 'w10': -0.6374204128565425, 'w11': -1.8589351955764684, 'w12': 0.6969962148097559, 'w13': -0.1846040913420252, 'w14': -1.5841938135249798, 'w15': 1.815772215719573, 'w16': 1.2009743522177634, 'w17': -0.39058825077496295, 'w18': 1.3976543960887573, 'w19': -1.2364594797783595, 'w20': -2.1360667815763676, 'w21': -2.0952094111358885, 'w22': 1.2390001004629017, 'w23': 2.4922474828221346, 'w24': -2.405962152085881, 'w25': -1.1872170079067845, 'w26': -0.6877108307636258, 'w27': -0.4813801426398219, 'w28': -2.0856051090586627, 'w29': 0.2662158592913039, 'w30': -1.321469007292872}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,546] Trial 59 finished with value: 0.7463768115942029 and parameters: {'w0': 0.49243325446562325, 'w1': -0.8085149422473226, 'w2': -0.0821944651661668, 'w3': 2.448020102838103, 'w4': 2.292491379672273, 'w5': -1.6651676278653478, 'w6': -0.41501985018428944, 'w7': -0.5546197605180928, 'w8': 2.203878730233133, 'w9': -0.11102600215185698, 'w10': -2.2696937293895827, 'w11': -0.19640819540901466, 'w12': 1.0299884643115507, 'w13': 1.6479979690154547, 'w14': -0.6751659407959724, 'w15': 1.18029793536858, 'w16': 1.6131745286415144, 'w17': 1.2102376627836025, 'w18': 0.38914525367740305, 'w19': -0.1937121958889547, 'w20': 0.29365894325667674, 'w21': -1.7350927800874036, 'w22': 0.9207896248574683, 'w23': -2.4786525079292017, 'w24': -1.907771473756319, 'w25': 0.21732738433904178, 'w26': -1.257914405221514, 'w27': 0.5418685567107666, 'w28': -1.176604080706156, 'w29': -0.26851916128801273, 'w30': 1.2740702764518987}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,647] Trial 60 finished with value: 0.7463768115942029 and parameters: {'w0': 1.3247546176461094, 'w1': -1.1832131699207022, 'w2': 1.4925931771753942, 'w3': 1.6753688853483373, 'w4': 0.9723842540771851, 'w5': -0.3519510739017504, 'w6': 0.9988065174011158, 'w7': 0.15641149048051983, 'w8': -2.1835167502984327, 'w9': 1.508630895020842, 'w10': -1.7900487083174172, 'w11': -1.4769171562250698, 'w12': -2.4242159120375395, 'w13': 1.9364398840677106, 'w14': -2.1268050822996223, 'w15': 0.2688935938542747, 'w16': 2.058427712155573, 'w17': 0.7246398889224299, 'w18': 0.762090873403453, 'w19': -1.4988789138406649, 'w20': -0.9203572543735256, 'w21': -1.2132895208095609, 'w22': -1.9799009913649241, 'w23': 2.0818982083964137, 'w24': 0.8719212365944443, 'w25': -0.23122467644866163, 'w26': -0.4046130472394169, 'w27': -0.1710346335578083, 'w28': -1.6864899271184495, 'w29': 0.12627102946448177, 'w30': 2.288918574675668}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,748] Trial 61 finished with value: 0.7536231884057971 and parameters: {'w0': 1.8402314422952448, 'w1': -0.41956151372599737, 'w2': -1.3207276036172315, 'w3': 2.001732081971185, 'w4': 2.4317781101324982, 'w5': 0.07727041391365808, 'w6': -0.6171296075935341, 'w7': -1.2620734887441794, 'w8': 2.4501406342038328, 'w9': 0.7862432751317048, 'w10': -1.4114292723464699, 'w11': -0.9943702754112089, 'w12': 0.020523656417361754, 'w13': 2.070064861374077, 'w14': -2.3584089983040855, 'w15': 2.268809265407395, 'w16': 2.4194600470413707, 'w17': -0.9843731476145476, 'w18': 1.9044893572926729, 'w19': 0.1348661357831068, 'w20': -0.6452857972275415, 'w21': -0.905795180920638, 'w22': 1.1194917278484833, 'w23': 1.1368318538645608, 'w24': -1.4334943505150541, 'w25': -0.4889343976409289, 'w26': 0.04748530595566075, 'w27': -1.2590154214230458, 'w28': -0.5367318023666591, 'w29': 0.5565368780399743, 'w30': 1.5269627481214232}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,848] Trial 62 finished with value: 0.7391304347826086 and parameters: {'w0': 2.492992373518042, 'w1': -0.8902724128348256, 'w2': -1.5990430560788562, 'w3': 1.4303501895596265, 'w4': 1.9285012120595786, 'w5': -0.5421487528909505, 'w6': -1.1932267457749433, 'w7': -0.8155467850091285, 'w8': 1.4112525795593842, 'w9': 0.41300051253316417, 'w10': -1.640696351421802, 'w11': -0.6631804229264814, 'w12': 0.3555367066135176, 'w13': 2.3654676230782705, 'w14': -1.9486065493006577, 'w15': 2.113926361561953, 'w16': 2.176033019495432, 'w17': -0.5688308961014417, 'w18': 1.609656038836384, 'w19': -0.7708643556261385, 'w20': -0.47995677072494314, 'w21': -0.5723924914278763, 'w22': 0.7112855693093205, 'w23': 0.7350452150207073, 'w24': -1.0930714760117193, 'w25': -1.5042906034781356, 'w26': -0.281767408301172, 'w27': -0.8208092556115569, 'w28': 1.2765295244661243, 'w29': 0.7270994993523155, 'w30': 2.1682762671783484}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:55,947] Trial 63 finished with value: 0.7536231884057971 and parameters: {'w0': 1.9977282858537695, 'w1': 0.10707893548718894, 'w2': -1.076512053243098, 'w3': 2.3046401276768003, 'w4': 1.4066452047260491, 'w5': -0.7753999411940369, 'w6': -1.4878408475082698, 'w7': -0.4752787935205002, 'w8': 1.762900017694602, 'w9': 0.5063120974122552, 'w10': -1.9159496570221235, 'w11': -1.9700670645597969, 'w12': 0.11732560374378881, 'w13': 1.8584952954492189, 'w14': -2.2157059097140848, 'w15': 1.525095865766793, 'w16': 1.8856984438082172, 'w17': -0.8027391865904592, 'w18': 2.065136016542123, 'w19': -0.33310088546639327, 'w20': -0.7405976723521069, 'w21': -0.7761565057559117, 'w22': 1.5735982988015447, 'w23': 0.9592802112998624, 'w24': -1.620597695974457, 'w25': -0.949041378607723, 'w26': -0.6293778584018053, 'w27': -1.6871081262845142, 'w28': 0.9621309745053461, 'w29': 0.996387632841959, 'w30': 1.8990649927343872}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,046] Trial 64 finished with value: 0.7463768115942029 and parameters: {'w0': 2.189945261271547, 'w1': -0.3632705752525629, 'w2': -1.4534785505364147, 'w3': 1.7590949132063267, 'w4': 2.162921700416317, 'w5': 0.7882093295780701, 'w6': -1.7267985487185522, 'w7': -0.2246962241125569, 'w8': 2.0336259025009333, 'w9': 0.12526729960529526, 'w10': -1.165330772292576, 'w11': -2.213427847725976, 'w12': 1.874413643239321, 'w13': 2.2788759705266832, 'w14': -1.7408284197704713, 'w15': 2.0701135707429925, 'w16': 1.4483524538210935, 'w17': -1.5034396380537935, 'w18': -0.2007905724310346, 'w19': 0.5125125822435684, 'w20': -1.153384288524645, 'w21': -1.5167737522700624, 'w22': 0.4073090530388511, 'w23': 1.4498537505228082, 'w24': -0.3979059527906783, 'w25': -0.761253485002779, 'w26': 0.3238095080611443, 'w27': 0.06329915379913065, 'w28': -1.4819902067246318, 'w29': -0.08617052879089837, 'w30': 1.1631309979946058}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,147] Trial 65 finished with value: 0.7536231884057971 and parameters: {'w0': 1.48407656400938, 'w1': -0.09263061592557725, 'w2': -0.641346411102375, 'w3': 1.0098022653791838, 'w4': 1.8921956092069152, 'w5': -1.356980216118787, 'w6': -1.3158554630860435, 'w7': -1.5387647933418434, 'w8': 2.2647786670596397, 'w9': 1.1633635383129326, 'w10': -1.3377071912615248, 'w11': -0.5229886221852412, 'w12': -0.23498566256598943, 'w13': 1.5097479407970116, 'w14': -1.3218185479074307, 'w15': 2.364074719215194, 'w16': 2.121852679799887, 'w17': 2.4062407836953232, 'w18': 2.4930914824302133, 'w19': 0.26036604124450874, 'w20': 0.042653987599590576, 'w21': -0.24950802591168963, 'w22': -0.1531359442632117, 'w23': 1.9190043934271814, 'w24': -0.817007695377346, 'w25': 0.7278337461737505, 'w26': -0.9631635618910794, 'w27': -0.9691302359555019, 'w28': -0.1579563651944631, 'w29': 0.42862045882533606, 'w30': 1.7241943403260689}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,245] Trial 66 finished with value: 0.7536231884057971 and parameters: {'w0': -1.255475749284419, 'w1': 1.6255977035814277, 'w2': -1.8435397115790908, 'w3': 0.7258989061670593, 'w4': -1.564475660549724, 'w5': 0.18941139221724268, 'w6': -0.8159804756218748, 'w7': -1.08993157238788, 'w8': 2.476796441626083, 'w9': -0.8738372042092124, 'w10': -2.225591104111752, 'w11': -1.1571208312076848, 'w12': -1.3658665978794762, 'w13': 0.6703916427793888, 'w14': -0.27709829917790374, 'w15': 1.3368132710837182, 'w16': 2.343719171807168, 'w17': -0.31151675735267464, 'w18': 0.1569832665082126, 'w19': -0.07904181769414609, 'w20': -0.3638040315299557, 'w21': -1.0017862003376632, 'w22': 0.9680027591124216, 'w23': 1.5836939000062304, 'w24': 0.3647606451155634, 'w25': -0.18044268892396204, 'w26': 0.6611435014965122, 'w27': -2.2757092383355597, 'w28': -1.1850154914320077, 'w29': 1.5946319868195928, 'w30': 0.9753099173503815}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,344] Trial 67 finished with value: 0.7536231884057971 and parameters: {'w0': -1.84590441795351, 'w1': -1.3972816144656228, 'w2': -0.992620772417327, 'w3': -0.40885454565083895, 'w4': 1.6302370652030866, 'w5': -1.0377502707466182, 'w6': -0.22416712883118334, 'w7': -1.715113995994891, 'w8': -1.1935578916777947, 'w9': 0.8875801862526678, 'w10': -0.3529797370863094, 'w11': -1.7341840710502363, 'w12': 0.5019005631907787, 'w13': 2.482482002010715, 'w14': 0.6256827701289992, 'w15': 1.7777760108903207, 'w16': 1.9382040611049285, 'w17': -1.2620627044435122, 'w18': -0.484601264792394, 'w19': 0.9273579706487123, 'w20': -0.9841781439797357, 'w21': -1.9799292532820756, 'w22': 1.3034113050829477, 'w23': 0.6813751049841343, 'w24': 2.0176696842546016, 'w25': -0.38627218230291704, 'w26': -1.6599465675006502, 'w27': -1.8985436173387527, 'w28': 1.6661481775291427, 'w29': 0.10116593099021076, 'w30': 2.04236423203094}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,445] Trial 68 finished with value: 0.7536231884057971 and parameters: {'w0': 2.32132292908983, 'w1': 0.7484884882502905, 'w2': -0.7731134268906338, 'w3': -0.002495945004428235, 'w4': -2.167773228132672, 'w5': -0.39157865253284363, 'w6': -0.5396800893033448, 'w7': -2.299588701395443, 'w8': 1.9217287945861978, 'w9': -1.5120216659801862, 'w10': -0.9095241023667433, 'w11': 2.122792160226843, 'w12': -1.0670956176119284, 'w13': 0.47304985612874784, 'w14': -2.4821904612150476, 'w15': 2.011974431483698, 'w16': 1.5598598027478285, 'w17': 0.2162704825338716, 'w18': 1.6231108815791089, 'w19': 1.3270951548188528, 'w20': -1.426649275575211, 'w21': -1.65159057345535, 'w22': 2.0031327583733027, 'w23': 1.251623947185923, 'w24': -1.3747281078943767, 'w25': -1.2008433883675536, 'w26': -0.09742931478496344, 'w27': -1.0929522088161514, 'w28': 0.1161208667113444, 'w29': 0.57024836965473, 'w30': 0.649226790998118}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,553] Trial 69 finished with value: 0.7463768115942029 and parameters: {'w0': 2.0670524175248666, 'w1': -0.5773829935099254, 'w2': -2.073168572545023, 'w3': -0.11792498016526165, 'w4': 2.3196734126657175, 'w5': -0.200620192386042, 'w6': 0.15606078346674346, 'w7': -0.028794592386835016, 'w8': 0.7083951208486048, 'w9': -0.26644756543656944, 'w10': -0.0706131078087584, 'w11': -0.8085674359864002, 'w12': -0.05706821085186142, 'w13': 1.2636657038589976, 'w14': -0.9795764425483586, 'w15': 2.3336540012112286, 'w16': -0.29521663039353374, 'w17': -0.09806464450083774, 'w18': 2.1665399433957195, 'w19': -0.9287497570749543, 'w20': -0.6305577353275086, 'w21': -0.4514766996231021, 'w22': 0.7356005283491532, 'w23': 1.698513733901157, 'w24': -2.3367846888681107, 'w25': 2.4886229423965376, 'w26': 0.07975250267596501, 'w27': -0.5575168922659667, 'w28': 2.228693132830853, 'w29': -0.20175566306432638, 'w30': 0.3508929092233175}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,656] Trial 70 finished with value: 0.7391304347826086 and parameters: {'w0': -0.3585045888732348, 'w1': -0.9812253694375112, 'w2': 2.494871508352441, 'w3': -1.1656227547485651, 'w4': 2.0736950903109297, 'w5': -1.8921841133366701, 'w6': -1.1331167768699713, 'w7': 0.3937295172765549, 'w8': -1.6935725271614919, 'w9': 2.1506966496436446, 'w10': 2.1231436442646956, 'w11': -1.410324453582738, 'w12': -0.8314515669665481, 'w13': 1.7991784524266805, 'w14': -2.0926495796787674, 'w15': 0.8449742358014309, 'w16': 1.7154631707496224, 'w17': -2.1706346298773056, 'w18': -0.9687116997699569, 'w19': -0.5441726533934881, 'w20': 0.35711287065501074, 'w21': 0.1997382538103224, 'w22': 1.118200727772328, 'w23': 0.8637717209584322, 'w24': -1.7179876995880667, 'w25': 0.22318832998323146, 'w26': 2.2476682967257373, 'w27': -0.27357614453766743, 'w28': -0.8946920967100911, 'w29': -0.6871369291593393, 'w30': 1.3180003812372427}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,755] Trial 71 finished with value: 0.7536231884057971 and parameters: {'w0': 1.7059477804446312, 'w1': -0.1989988865611217, 'w2': -1.4540668356166133, 'w3': 1.145068231696049, 'w4': 1.812315390756095, 'w5': 0.3000441037009848, 'w6': -0.7004655403331816, 'w7': -1.7850421774056036, 'w8': 2.0557622526026123, 'w9': 0.6111037669943027, 'w10': -0.919794809263268, 'w11': 0.5536466966090494, 'w12': 0.3356401492460391, 'w13': 1.9379168062538643, 'w14': -1.5753712058433256, 'w15': 2.2155046121982593, 'w16': 2.484615436275442, 'w17': -1.1282014159868743, 'w18': 2.3311940534554267, 'w19': 0.04793706586307783, 'w20': -0.1934515132275736, 'w21': 0.013305064833035951, 'w22': 1.456611809877243, 'w23': 1.8016558067254773, 'w24': -2.0975791225983214, 'w25': -0.02780044188999109, 'w26': -0.27155441734325503, 'w27': -1.530345936519305, 'w28': -0.7052420696114245, 'w29': 0.8407001525538786, 'w30': 1.7478993568103096}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,864] Trial 72 finished with value: 0.7536231884057971 and parameters: {'w0': 2.0530049209299506, 'w1': -0.2866605137279925, 'w2': -1.5689317939569476, 'w3': 1.540074886612374, 'w4': 2.008502285044238, 'w5': -0.7174495871429882, 'w6': -0.38609879619655607, 'w7': -1.9628897608132756, 'w8': 2.332221068428286, 'w9': 1.0091523567625273, 'w10': -0.787413530517372, 'w11': 0.9282129391291043, 'w12': 0.765184397997116, 'w13': 2.118878718379784, 'w14': -2.3517312030906683, 'w15': 1.52112721919999, 'w16': 2.1356528506800783, 'w17': -1.2785720733992956, 'w18': 2.034598415721795, 'w19': -0.1313681152458328, 'w20': -0.4272714219369049, 'w21': -0.8164897167194513, 'w22': 0.2103214676978054, 'w23': 1.0315482473612962, 'w24': -2.4337877750161354, 'w25': -0.6752108734109075, 'w26': -0.40358037809836184, 'w27': -1.7649345212433452, 'w28': -1.0503004922964614, 'w29': 1.1931153111568704, 'w30': 1.897418475781408}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:56,974] Trial 73 finished with value: 0.7463768115942029 and parameters: {'w0': 2.2820822288818268, 'w1': 0.22867735440065834, 'w2': -1.2554204261913666, 'w3': 1.8373951086209575, 'w4': 2.487165643350725, 'w5': -0.10927815215408915, 'w6': -0.9840925422120673, 'w7': -1.3710216428717144, 'w8': -1.4973335351721375, 'w9': 0.680255938270877, 'w10': -0.548808128387817, 'w11': 0.2104089019940406, 'w12': 0.15080428113511157, 'w13': 1.4971204362049386, 'w14': -2.152578725166843, 'w15': 1.9330234035647744, 'w16': 2.300971240500656, 'w17': -0.70146641676668, 'w18': 1.908292941916785, 'w19': -0.33542520395931646, 'w20': -0.6559759607317677, 'w21': 0.5136796015275927, 'w22': 0.01417558227702631, 'w23': -1.4080475800893189, 'w24': -2.4890298767187597, 'w25': -0.3521291580442061, 'w26': -0.6652238019670869, 'w27': -1.28656716991459, 'w28': -0.4471566349336091, 'w29': 1.039338177367433, 'w30': 1.523850702177387}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,082] Trial 74 finished with value: 0.7536231884057971 and parameters: {'w0': -1.5308062705821786, 'w1': -0.022145962290074594, 'w2': 1.839288803521314, 'w3': 1.248876770554356, 'w4': 1.1896793763431894, 'w5': 2.2679431609057885, 'w6': -0.06997363704430337, 'w7': -0.9471153876462011, 'w8': 1.7233804961238037, 'w9': 0.2632840374257972, 'w10': -1.127896633144911, 'w11': 1.1841502445489938, 'w12': -0.48733030878680716, 'w13': 1.7523433804153037, 'w14': -1.8294011142065219, 'w15': 2.3893626139449693, 'w16': 2.045888044788546, 'w17': -1.6139396260891004, 'w18': 1.1998242480492165, 'w19': -1.116734856278769, 'w20': -1.1950715495732187, 'w21': 0.006251327247681182, 'w22': 1.7301926068956086, 'w23': 2.351302519208428, 'w24': -2.269464681453314, 'w25': -0.5145296326703095, 'w26': -0.29229014959500266, 'w27': -0.8660224650976114, 'w28': -1.2212606031250337, 'w29': 0.34642707144747364, 'w30': 2.364987173079331}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,181] Trial 75 finished with value: 0.7536231884057971 and parameters: {'w0': 0.15321264856265648, 'w1': -0.5629444114733297, 'w2': -1.7783025536819639, 'w3': 0.3682121101585587, 'w4': 0.5979293533116672, 'w5': -1.1799957410352961, 'w6': -0.3325708142608053, 'w7': -2.0561264616757677, 'w8': -1.8002821189659763, 'w9': 0.4854965038698273, 'w10': -1.58014113951901, 'w11': 0.5801011427684274, 'w12': 0.45022129258243565, 'w13': 2.3039616393846036, 'w14': -1.4352084995354117, 'w15': 1.6062916379383556, 'w16': 1.8498584133792444, 'w17': -0.8498172522599573, 'w18': 1.5584620141446541, 'w19': -0.6775163376575606, 'w20': -0.8520647279982354, 'w21': -1.1894224760160925, 'w22': 0.8810750105703615, 'w23': 0.17490158587556426, 'w24': -2.0247419319173376, 'w25': -0.9218206820363708, 'w26': -0.5019290620596812, 'w27': -1.1216991595375616, 'w28': -1.4612782688437447, 'w29': 0.7820933794057943, 'w30': 2.115242378210709}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,287] Trial 76 finished with value: 0.7463768115942029 and parameters: {'w0': 1.8777943204341578, 'w1': 2.303282541247619, 'w2': -0.4202504313237282, 'w3': 1.0304424259547498, 'w4': -0.43039694335313683, 'w5': -0.9016315550452185, 'w6': 0.08499688106785361, 'w7': -0.6427768479291354, 'w8': 1.4893530860061135, 'w9': 1.6769656418192285, 'w10': -1.8981111868188394, 'w11': -1.6383381023458974, 'w12': 0.9257393665958606, 'w13': 0.9631240359447304, 'w14': -1.8690662279916566, 'w15': 1.801717361135735, 'w16': 2.439547993871212, 'w17': -0.42615120526676686, 'w18': 1.0304132923605005, 'w19': 0.32028220023766507, 'w20': -0.2986156678756281, 'w21': 0.9852128324858707, 'w22': 1.0818854820146104, 'w23': 1.301563264563521, 'w24': 0.10120708106807541, 'w25': 0.060924940872308264, 'w26': 0.34535220154182217, 'w27': -1.4779222780731134, 'w28': -1.7419906929967768, 'w29': 0.1780218406707257, 'w30': 1.7824665615635908}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,386] Trial 77 finished with value: 0.7608695652173914 and parameters: {'w0': -0.15484965979055643, 'w1': -1.2426117967075088, 'w2': -0.8351647284743255, 'w3': -0.6364225023216203, 'w4': 0.2581489327877296, 'w5': -0.6018847064444943, 'w6': -1.4009079982070463, 'w7': -1.6284776882571426, 'w8': 2.002610599967401, 'w9': 0.004439262749799333, 'w10': 2.3044482337377836, 'w11': 0.029527834565872824, 'w12': -0.688276533669063, 'w13': 0.8280927900561488, 'w14': -2.0238080680552457, 'w15': -1.1131669414863845, 'w16': 2.2238750364364455, 'w17': -1.0587479833807003, 'w18': -1.4080035168799157, 'w19': 0.7655040164260789, 'w20': -0.07875662452993008, 'w21': -0.6795255067122175, 'w22': -0.30079160491668055, 'w23': 1.962614740364315, 'w24': -1.893190762402075, 'w25': 1.244893863851669, 'w26': -0.9549848391379117, 'w27': -0.7295202345873069, 'w28': -1.9416678453594431, 'w29': -0.037391866702478405, 'w30': -2.482619752073875}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,490] Trial 78 finished with value: 0.7318840579710145 and parameters: {'w0': -0.06367641100982604, 'w1': -1.2323010348842978, 'w2': -0.2113113115593364, 'w3': -0.7000540249522843, 'w4': 0.329107318581631, 'w5': -0.6150661407315166, 'w6': -1.3072695757306416, 'w7': 0.7885336690809314, 'w8': -0.8998676380775658, 'w9': -0.668958219461583, 'w10': 2.4925943918516595, 'w11': 0.08282354471591304, 'w12': -0.6881628530870599, 'w13': 0.7658033103436599, 'w14': -2.3547317581754283, 'w15': -1.4950657009253983, 'w16': 1.2894280695786733, 'w17': -0.9631604536843763, 'w18': -1.9136471014358791, 'w19': 1.151891238463047, 'w20': -0.07543741443155937, 'w21': -0.7046256812528049, 'w22': -0.3435134935684785, 'w23': 1.9742346886599105, 'w24': -1.567627855801728, 'w25': 1.6914910062257809, 'w26': -2.181039286971051, 'w27': 1.7347623508201815, 'w28': -1.890755648950986, 'w29': -0.04020034775010865, 'w30': -2.4078781830407845}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,591] Trial 79 finished with value: 0.7536231884057971 and parameters: {'w0': -0.575912253548185, 'w1': -1.970645565129165, 'w2': -1.1144101795502892, 'w3': -0.5533997414620812, 'w4': 0.07410945019509985, 'w5': -1.372542921380577, 'w6': -1.4941463012965839, 'w7': -1.2520712938612204, 'w8': 2.1879103333355414, 'w9': -0.5410107722490611, 'w10': 1.920848160844508, 'w11': -0.090091718947861, 'w12': -0.29531757692771543, 'w13': 0.2970880424720169, 'w14': -2.001750659528419, 'w15': -2.252236221036914, 'w16': 1.0732869134531724, 'w17': -1.0479869589647284, 'w18': -1.317919324832535, 'w19': 0.7287826597052447, 'w20': 0.07644612617371854, 'w21': -1.3903203929079153, 'w22': -0.5225704555187811, 'w23': 1.132194876995546, 'w24': -1.2571117480100096, 'w25': 1.239412003378971, 'w26': 1.8563950108485239, 'w27': 0.19243643205710032, 'w28': -2.340746089236722, 'w29': -0.46030430678670264, 'w30': -1.844205248997831}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,694] Trial 80 finished with value: 0.7463768115942029 and parameters: {'w0': -0.21182608999665087, 'w1': -1.7052208473126336, 'w2': -0.8370943534828704, 'w3': -0.9048835057731617, 'w4': -0.26826961683664097, 'w5': 1.7507423060622762, 'w6': -1.8655487199702907, 'w7': -0.8691937990817142, 'w8': -2.0261873882651793, 'w9': -0.06115623986993987, 'w10': 1.5916860837803775, 'w11': -0.31718300207210637, 'w12': -1.4791268592437299, 'w13': 0.5490263891371174, 'w14': -1.6085111674804164, 'w15': -0.6052102611535468, 'w16': 0.7951142884114326, 'w17': -0.723406196501392, 'w18': -1.5843655893872945, 'w19': 1.4003495750794897, 'w20': 0.23808313880331267, 'w21': -0.5373462100293822, 'w22': -0.7427453591172681, 'w23': 0.2931621745708901, 'w24': -1.8455616036433615, 'w25': 2.039839502522264, 'w26': -1.2372485184420698, 'w27': -0.23171735891664202, 'w28': -1.9488255612457774, 'w29': 0.23788525050180342, 'w30': -1.753984239356673}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,801] Trial 81 finished with value: 0.7536231884057971 and parameters: {'w0': 0.26979935329031735, 'w1': -0.8944125483331798, 'w2': -1.3365198371254305, 'w3': -0.37634170470498973, 'w4': 0.3565299001822541, 'w5': -0.4244256538619817, 'w6': -0.4670905230502918, 'w7': -1.6186144275699, 'w8': 1.9732798604643393, 'w9': 1.3528325561316903, 'w10': 2.2459210083177408, 'w11': 0.3917169812196719, 'w12': -0.9440276619079748, 'w13': 0.8157388408423993, 'w14': -2.0605245265495897, 'w15': -0.1588435873156605, 'w16': 2.2954433467474122, 'w17': -1.2258669756164677, 'w18': -0.7066765568662696, 'w19': -0.4453610481722291, 'w20': 0.48944496726931475, 'w21': -0.10659554666782223, 'w22': 0.4150847503385213, 'w23': 1.513304929298453, 'w24': 1.7285614411048515, 'w25': 0.8932443498469254, 'w26': -0.9559314373403817, 'w27': -0.7277517187453398, 'w28': -1.6024594903816205, 'w29': -0.8462058800383949, 'w30': -2.1075483271993765}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:57,904] Trial 82 finished with value: 0.7536231884057971 and parameters: {'w0': -1.0241861573576627, 'w1': -1.027165172048273, 'w2': -0.9912115584196131, 'w3': -0.6454717139678149, 'w4': 1.5416535513454757, 'w5': 1.221427720456492, 'w6': -0.71921604695088, 'w7': 1.0626049150559214, 'w8': 1.1718724156933553, 'w9': 0.6981503821701176, 'w10': 2.300019528810347, 'w11': -1.9554402378891387, 'w12': 0.6032150787934701, 'w13': 2.034110694370359, 'w14': -2.255023350840105, 'w15': -0.9532367185604802, 'w16': 2.2102279646547234, 'w17': -0.6408006402460575, 'w18': -2.2822680821910573, 'w19': -0.27302910999421487, 'w20': -0.4799801736833132, 'w21': -0.3911027166070663, 'w22': 0.7689484252451524, 'w23': 1.7970839544318415, 'w24': -2.1517707872569654, 'w25': 1.3484617629850941, 'w26': -0.1228824160557189, 'w27': 0.42406755086997266, 'w28': -1.3629897561410873, 'w29': 0.6393954258078121, 'w30': -2.0567838365968427}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,005] Trial 83 finished with value: 0.7463768115942029 and parameters: {'w0': 2.3776656253066495, 'w1': -2.281632933963229, 'w2': 0.06529856913591492, 'w3': -0.19541412871711683, 'w4': -0.18011574159965965, 'w5': -0.016700385636347903, 'w6': -0.9268054015351261, 'w7': -1.8020874248410717, 'w8': 2.1396504020792033, 'w9': 0.9676121536723186, 'w10': -0.7993617770296715, 'w11': -0.023955001722244684, 'w12': -0.10072052359142969, 'w13': 0.10080389809026563, 'w14': -1.7373869532303814, 'w15': 2.179021551312079, 'w16': 1.948459437785447, 'w17': -1.4157528773921668, 'w18': 2.3437681388279534, 'w19': 0.7749379775859393, 'w20': -1.07789645750999, 'w21': -0.923031072713228, 'w22': -0.2745920593521948, 'w23': 2.186036395886071, 'w24': -1.9236095524294465, 'w25': 1.8379525877806018, 'w26': 1.5105980568878463, 'w27': -1.3559666583043413, 'w28': -2.138977723439594, 'w29': 0.36516569752872613, 'w30': -2.3879490677745996}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,109] Trial 84 finished with value: 0.7536231884057971 and parameters: {'w0': 2.1848972967239852, 'w1': -1.5076931247371244, 'w2': -1.2041605753929177, 'w3': 0.20384333758814743, 'w4': -0.6981692680577468, 'w5': 0.6222517817367462, 'w6': -2.2075642139890608, 'w7': -1.4203179092412104, 'w8': 2.380544278580635, 'w9': 0.04455680547664487, 'w10': 1.9263583142826495, 'w11': -1.2819959516112416, 'w12': 0.10170367298548268, 'w13': 1.1794067916362128, 'w14': -2.490505958252332, 'w15': -1.0838967290547836, 'w16': 2.4927063532597327, 'w17': -1.7343062486629535, 'w18': -1.197978676949901, 'w19': 0.01006007822250825, 'w20': -0.5911444041826909, 'w21': -0.6914031376897891, 'w22': 0.5709639981325324, 'w23': 1.6519198506520278, 'w24': -2.2385077505284743, 'w25': 0.36013378309127053, 'w26': 0.13054678748356835, 'w27': -0.41987747142389775, 'w28': -0.9688113253124186, 'w29': -0.22239072601838356, 'w30': 1.994374294044333}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,209] Trial 85 finished with value: 0.7463768115942029 and parameters: {'w0': 0.07243915926578412, 'w1': -0.7274389925044377, 'w2': -1.9452539780507876, 'w3': 2.203513086435791, 'w4': -0.03602095121594234, 'w5': -0.9747989142689304, 'w6': 1.6206574403278324, 'w7': -1.152074944853041, 'w8': -0.1295464573403593, 'w9': 1.2653793206378243, 'w10': 2.366109677237479, 'w11': -0.9004880804212567, 'w12': 1.1630960338102465, 'w13': 1.0352540360220992, 'w14': -1.961680510481851, 'w15': -1.82733903206669, 'w16': -1.6844004601425167, 'w17': -0.5039551516374816, 'w18': 1.7747939911330874, 'w19': 0.15612526183772207, 'w20': -0.10243350416149935, 'w21': -1.277597275497681, 'w22': 0.031078017227647803, 'w23': 1.4398887126597586, 'w24': -0.9656643058946841, 'w25': 2.23546726067194, 'w26': -0.75369389524644, 'w27': -0.6688370992069501, 'w28': -0.6605799825970067, 'w29': 0.008570492841499792, 'w30': 0.9076144285090045}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,309] Trial 86 finished with value: 0.7463768115942029 and parameters: {'w0': 0.7022293352903698, 'w1': -1.3294153240011826, 'w2': -1.693816585056761, 'w3': 1.9452779536948788, 'w4': 2.3280362193693542, 'w5': -1.141916959549965, 'w6': -1.6250080548445562, 'w7': -0.3215537081230547, 'w8': 1.8281845806081372, 'w9': 0.4597423304378656, 'w10': -1.4949549863892502, 'w11': -0.6969840319293272, 'w12': 0.26346241018905503, 'w13': 1.3023061477008404, 'w14': -1.339623908172234, 'w15': 0.4884375143177918, 'w16': 2.1154133678809997, 'w17': -0.8697577307625934, 'w18': 2.196467995193552, 'w19': 0.42903402042967254, 'w20': 2.4532149243299384, 'w21': -1.0627999093612126, 'w22': 1.1733000452141489, 'w23': 0.8858872135744674, 'w24': 1.231402385233689, 'w25': -1.390876400838227, 'w26': 0.5544522464703174, 'w27': -1.6359842625631968, 'w28': -0.31265912405237495, 'w29': 1.4285418442042852, 'w30': 1.183309079880728}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,410] Trial 87 finished with value: 0.7463768115942029 and parameters: {'w0': 2.498800195083481, 'w1': 1.9890063847550907, 'w2': 1.6768871390293827, 'w3': -1.108132532611624, 'w4': 2.1729893537884557, 'w5': -0.6046964084695292, 'w6': -1.1202888925972134, 'w7': -2.236965978370026, 'w8': 1.6171301233462922, 'w9': 0.8076189157436253, 'w10': -1.3029662189113291, 'w11': 0.7140589207197708, 'w12': -0.43159812474543074, 'w13': 2.2011301115887676, 'w14': 2.240238487845589, 'w15': 1.9669198333359799, 'w16': 1.7747432321755874, 'w17': 1.6999613988143192, 'w18': 0.6526609990799347, 'w19': 1.54530637701576, 'w20': -1.31633219301194, 'w21': 0.38661251595689183, 'w22': 0.28409669523796577, 'w23': 2.3377660185950813, 'w24': 2.0121977458623768, 'w25': -0.28588815912334065, 'w26': -0.8909228679543003, 'w27': -1.0163860381515908, 'w28': -0.8203316556253082, 'w29': 0.5274703626466722, 'w30': 1.6235910487606278}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,513] Trial 88 finished with value: 0.7463768115942029 and parameters: {'w0': -0.4945061485264963, 'w1': -0.2585999923352758, 'w2': 1.263320590205356, 'w3': 1.3830004275753303, 'w4': -1.2677708199916582, 'w5': -0.891996052750848, 'w6': 2.4938807908725384, 'w7': -1.8877967793034263, 'w8': -2.346942169894697, 'w9': -1.7362621648142267, 'w10': -1.040940768840478, 'w11': -1.10295960989751, 'w12': -0.7334662574124278, 'w13': 2.389598330006487, 'w14': -2.2397673824979147, 'w15': 2.464730828177073, 'w16': 2.316274614966226, 'w17': -0.196735420608101, 'w18': 0.8766420770983903, 'w19': -0.8258057856965874, 'w20': -0.7075360134250925, 'w21': -0.18679974901596402, 'w22': 0.9891563476595443, 'w23': 1.8873498518967318, 'w24': -0.6219122395048278, 'w25': -1.0873857217567018, 'w26': -1.186514261148154, 'w27': -0.8387159269015715, 'w28': -2.295076967443003, 'w29': 0.19309845236042117, 'w30': 1.445119752948429}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,617] Trial 89 finished with value: 0.7463768115942029 and parameters: {'w0': -2.1154549033237444, 'w1': 1.0159057873311768, 'w2': -1.4640750788542296, 'w3': 1.652394435570818, 'w4': -0.9270788167516224, 'w5': 1.0464009755989125, 'w6': -0.17390064162603944, 'w7': -0.5192851982029508, 'w8': 2.365465362110821, 'w9': -1.132004806733663, 'w10': 1.1857708699005904, 'w11': -0.3225872225604929, 'w12': -0.22005384814215292, 'w13': 0.3495361378918758, 'w14': -0.7244285599030174, 'w15': 0.05227244883764759, 'w16': 1.4949842059820426, 'w17': -1.0613955891393119, 'w18': 0.05629728238780943, 'w19': 1.1830395149089434, 'w20': -0.2926375015541779, 'w21': -1.821074449609301, 'w22': 1.4945692023989448, 'w23': 1.2352592075469653, 'w24': 2.2783126865549734, 'w25': 0.5563091443822215, 'w26': -0.5726168380956465, 'w27': -1.2540792339790348, 'w28': 2.0095083824562625, 'w29': 0.40535576895048486, 'w30': -2.479874389130739}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,725] Trial 90 finished with value: 0.7463768115942029 and parameters: {'w0': -2.470600358714854, 'w1': -0.4928231814203736, 'w2': 0.9855692076261705, 'w3': -0.5124529543659083, 'w4': -1.8544071932009, 'w5': -0.2610633635637333, 'w6': -0.524557888665923, 'w7': -1.6005183842284567, 'w8': 2.498511410903191, 'w9': 0.27647322746900893, 'w10': -1.4419513462754365, 'w11': -1.7514743721076225, 'w12': 0.4389215472857459, 'w13': -0.07776378052832045, 'w14': -1.1780402171812059, 'w15': 0.3054779891680558, 'w16': 1.6445344642000561, 'w17': -1.3947005202939988, 'w18': 0.32157531479860535, 'w19': 0.9389824831119733, 'w20': -0.9540900065465275, 'w21': 0.12111549019949208, 'w22': 0.6363137008984774, 'w23': 0.40524142849916, 'w24': -1.7425361101686299, 'w25': 1.5862258809426164, 'w26': 2.023224759540316, 'w27': -1.904111931496979, 'w28': -1.8149503801532512, 'w29': 0.9756324416523608, 'w30': 2.3750437845378607}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,831] Trial 91 finished with value: 0.7536231884057971 and parameters: {'w0': 1.9434722334661234, 'w1': -0.8333177419954949, 'w2': -0.43743650311728943, 'w3': 2.326967795606064, 'w4': -2.4827428042376, 'w5': -0.7614036091731142, 'w6': -0.8836320414431973, 'w7': 0.26666018837961536, 'w8': 2.0837988201926656, 'w9': -0.4885399936118735, 'w10': -1.2306935179752434, 'w11': -2.0753298080799056, 'w12': 1.2940912618948506, 'w13': 1.5337791604731956, 'w14': -1.876510715926207, 'w15': 1.0528801330679418, 'w16': 2.199512453542997, 'w17': -2.263360670385689, 'w18': -0.0853019660607609, 'w19': -0.4517983609262278, 'w20': -1.7027193147072843, 'w21': 0.11831928190232015, 'w22': 1.8771707876170272, 'w23': 0.5285906115062932, 'w24': -2.0169735910610624, 'w25': -2.475385479622212, 'w26': -0.45066693003212943, 'w27': 0.6190073760830372, 'w28': 0.6191147482197492, 'w29': 0.8850094200555747, 'w30': 2.1809319983605606}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:58,938] Trial 92 finished with value: 0.7536231884057971 and parameters: {'w0': 1.5793823430378708, 'w1': 0.39761828783312514, 'w2': -0.7045192075442899, 'w3': 2.085774782126583, 'w4': -2.3050399473740204, 'w5': -1.4282170002812948, 'w6': -1.4103385631985432, 'w7': -1.0463980237473622, 'w8': 2.2247229799277077, 'w9': -0.32045753595721926, 'w10': -1.7224649064899307, 'w11': -1.8401377926093097, 'w12': 0.6278186615813318, 'w13': 1.6450011309614014, 'w14': -2.143143692349203, 'w15': 1.3998894954110073, 'w16': 2.039994527814842, 'w17': -1.988326868962067, 'w18': 1.2738766808355457, 'w19': -0.1881765662126862, 'w20': -2.097645137448729, 'w21': -0.31263330797999944, 'w22': 1.3069811668530866, 'w23': 0.01438945001664238, 'w24': -2.366588211150716, 'w25': -2.2757758330317577, 'w26': -0.048711086927378855, 'w27': -0.01632291791423823, 'w28': 0.7881571177084176, 'w29': -0.35771725277035427, 'w30': 2.0133982290622745}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:59,043] Trial 93 finished with value: 0.7391304347826086 and parameters: {'w0': 1.7893225931995378, 'w1': -0.6429071100454921, 'w2': -0.5629862033075099, 'w3': 1.9215373144687986, 'w4': -2.1379505553904345, 'w5': -1.7730870612226548, 'w6': -1.0805780322125185, 'w7': 0.4712372714152942, 'w8': 1.8535559959475965, 'w9': -0.8472684492903133, 'w10': -1.559878072639869, 'w11': -1.27580882884592, 'w12': -0.5958377400230465, 'w13': 1.395090708739346, 'w14': -1.545846653645928, 'w15': 1.3170166962159233, 'w16': 1.8546943959837248, 'w17': 0.6582363485813146, 'w18': -0.41280901554443705, 'w19': -0.35578455314726715, 'w20': -1.5687952030246168, 'w21': 2.0323416058024435, 'w22': 1.3740531324560217, 'w23': 0.6268249594417502, 'w24': -2.090443932947411, 'w25': -1.6932443857698996, 'w26': -0.3454222044107853, 'w27': 1.0730031163418041, 'w28': 1.6135618109539691, 'w29': -0.09880216890350324, 'w30': 1.8245740424021863}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:59,147] Trial 94 finished with value: 0.7391304347826086 and parameters: {'w0': 2.1528307233822113, 'w1': 2.1603211467763894, 'w2': -0.289052925109172, 'w3': 1.5318735962663286, 'w4': -2.3472825964191864, 'w5': -1.1156169585440734, 'w6': -0.3309375087723825, 'w7': -0.02118650988532994, 'w8': -1.3127819932782798, 'w9': -0.3802493908621237, 'w10': 0.4126672225882687, 'w11': -1.5489711200446457, 'w12': 0.24127748350495154, 'w13': 1.1151140376141795, 'w14': -1.777359410416636, 'w15': 1.1877571305839445, 'w16': 2.2860396857632934, 'w17': 0.39042984548161513, 'w18': -0.8497515765035186, 'w19': -0.6168157227791167, 'w20': -0.8092951690674888, 'w21': -2.366020521164814, 'w22': 1.7024305961749762, 'w23': 0.8047707887320406, 'w24': 1.5425219687563367, 'w25': -1.8765529318526648, 'w26': -0.23216933361518177, 'w27': 0.6948325723155718, 'w28': -1.1131432796838858, 'w29': 0.10190960372306883, 'w30': 2.2213554073979918}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:59,256] Trial 95 finished with value: 0.7391304347826086 and parameters: {'w0': 1.9653063370207882, 'w1': 1.3673883616955411, 'w2': -0.9551023607918208, 'w3': 1.7382900827932297, 'w4': -2.0298992773479303, 'w5': -1.5679927635444182, 'w6': -0.7594116330664603, 'w7': -0.6773898538465803, 'w8': 1.6691105885203636, 'w9': 1.1223161824998102, 'w10': 0.6542794885456757, 'w11': -2.2473269237823006, 'w12': 0.0016994301261853864, 'w13': 1.9949497815691983, 'w14': 0.0780353450006046, 'w15': 1.6894904804448942, 'w16': 1.670723243471469, 'w17': 2.066398027797227, 'w18': -2.066055350315928, 'w19': 0.6168998913692232, 'w20': -1.8895982909713935, 'w21': -0.8101967694039207, 'w22': 1.566724904329784, 'w23': 1.048600448810173, 'w24': -1.4954834631035738, 'w25': -2.1027292790109433, 'w26': 1.1828919543933798, 'w27': 0.9632956054443591, 'w28': -2.022209838729077, 'w29': 0.6219117116133651, 'w30': 1.3855148035870917}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:59,361] Trial 96 finished with value: 0.7536231884057971 and parameters: {'w0': -1.81538205557484, 'w1': 0.12755148387584114, 'w2': 0.2800388532171787, 'w3': -0.8542163942012105, 'w4': -2.2884599926319202, 'w5': -1.2695738155819978, 'w6': -0.6043529388399158, 'w7': -1.502073014554256, 'w8': -0.582172889366323, 'w9': -0.9928489003492268, 'w10': -1.0583552579357995, 'w11': -0.9919295249583994, 'w12': -1.1034028925925203, 'w13': 0.9616860880592814, 'w14': -2.3716279301135437, 'w15': 0.8323697086925257, 'w16': 2.3886283050755646, 'w17': -2.3854094728763067, 'w18': 1.946056814961051, 'w19': -0.047690677226673195, 'w20': -2.3157856841381115, 'w21': -0.5735240315851858, 'w22': -0.08879418447714649, 'w23': 1.3722647387381453, 'w24': -2.4984724972140793, 'w25': -0.5748025215726411, 'w26': -0.5319828011104526, 'w27': -0.5920872313927003, 'w28': 1.3899756764915645, 'w29': -2.058201652408777, 'w30': -0.6303618629690972}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:59,475] Trial 97 finished with value: 0.7463768115942029 and parameters: {'w0': 2.2531649415645503, 'w1': 1.7566306603950326, 'w2': 2.3258417092343455, 'w3': 1.334579474017699, 'w4': 1.8936568646117597, 'w5': -2.1987213948856565, 'w6': 1.890715333641931, 'w7': 0.7084357010767145, 'w8': 1.981810771519768, 'w9': -0.18240098894172557, 'w10': -0.8593079318702356, 'w11': -1.4354190558529027, 'w12': 0.8555258737321744, 'w13': 2.1878157730505783, 'w14': -2.001616108145616, 'w15': 1.8629775432359206, 'w16': 1.957310813610702, 'w17': 0.8392446543474923, 'w18': 2.3886638462392127, 'w19': -0.7165930494687334, 'w20': -0.1771431987472074, 'w21': -0.9564417162140969, 'w22': 0.8316175207057623, 'w23': -0.17948927818837648, 'w24': -1.2547226187408755, 'w25': -0.1485637517351907, 'w26': -0.7436870162885098, 'w27': -2.0573295458907777, 'w28': 1.1283189901284163, 'w29': 0.27586819058308715, 'w30': 1.6404858347719726}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:59,583] Trial 98 finished with value: 0.7536231884057971 and parameters: {'w0': 2.4144633518671195, 'w1': -1.050627502962664, 'w2': -1.0809762434495764, 'w3': 1.1095821395572147, 'w4': 0.2500216301942988, 'w5': 0.10699214550486946, 'w6': -1.2375078211529837, 'w7': 1.011737976162538, 'w8': 2.1256507452217925, 'w9': -1.2891631863622057, 'w10': -0.5511608055983626, 'w11': -0.7960620298458314, 'w12': 0.6985231313111993, 'w13': 1.710326030376363, 'w14': 0.25417042036805715, 'w15': 2.203586688809629, 'w16': 2.130755648933335, 'w17': 1.1474785534391487, 'w18': 2.2383298027059944, 'w19': -0.5156532361285222, 'w20': -0.04223552760446547, 'w21': 0.7408155104299485, 'w22': 0.4881517088296532, 'w23': 2.076195563770288, 'w24': 2.4775293725253777, 'w25': 1.056440112145018, 'w26': -0.19062839045218377, 'w27': -1.4055355653308153, 'w28': 2.458052293556457, 'w29': 2.444970149741513, 'w30': 2.49558857930515}. Best is trial 54 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 15:16:59,681] Trial 99 finished with value: 0.7536231884057971 and parameters: {'w0': 2.079493932404713, 'w1': -0.35646649624633847, 'w2': -0.854900548156224, 'w3': -0.28850664914728624, 'w4': 1.4030058546343638, 'w5': -1.5149933670629072, 'w6': -1.947893682910116, 'w7': 0.548981055061032, 'w8': 2.301761882987166, 'w9': -0.62974174040044, 'w10': -2.042142919566924, 'w11': -0.5455448429669837, 'w12': 0.3699811684475109, 'w13': 1.8584960416593297, 'w14': -1.7018479221954994, 'w15': 2.0193314045320507, 'w16': 1.76774790049514, 'w17': -1.7697592966818343, 'w18': 0.12862348364785497, 'w19': -0.9326333928514485, 'w20': -0.539954661883492, 'w21': -1.4752469950603775, 'w22': 2.2263095497440895, 'w23': -0.725826014912391, 'w24': -2.2136503645880543, 'w25': -0.8406253828832451, 'w26': 2.2893748857942016, 'w27': 1.2287213008445965, 'w28': 0.4110882419318902, 'w29': 0.4397133260542786, 'w30': -0.09405486159639542}. Best is trial 54 with value: 0.7608695652173914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna alphas (first 10): [0.0572 0.0051 0.0043 0.1228 0.0828 0.0042 0.0091 0.008  0.1495 0.0381]\n",
      "\n",
      "==== (Tuned XGB) Bagging — Optuna Weights (thr from val) Performance ====\n",
      "Accuracy:      0.601744\n",
      "AUC:           0.641165\n",
      "PR-AUC:        0.503045\n",
      "LogLoss:       0.692889\n",
      "Precision@0.700: 0.517241\n",
      "Recall@0.700:    0.215827\n",
      "F1@0.700:        0.304569\n",
      "\n",
      "===== FINAL Retrain on FULL 80% (best params, XGB), then test on 20% =====\n",
      "\n",
      "==== FINAL (XGB) — Simple Average (thr from val) Performance ====\n",
      "Accuracy:      0.601744\n",
      "AUC:           0.638042\n",
      "PR-AUC:        0.500436\n",
      "LogLoss:       0.683804\n",
      "Precision@0.660: 0.515625\n",
      "Recall@0.660:    0.237410\n",
      "F1@0.660:        0.325123\n",
      "\n",
      "==== FINAL (XGB) — Val-AUC Weighted (thr from val) Performance ====\n",
      "Accuracy:      0.607558\n",
      "AUC:           0.638042\n",
      "PR-AUC:        0.500317\n",
      "LogLoss:       0.683753\n",
      "Precision@0.670: 0.532258\n",
      "Recall@0.670:    0.237410\n",
      "F1@0.670:        0.328358\n",
      "\n",
      "==== FINAL (XGB) — Optuna Weights (thr from val) Performance ====\n",
      "Accuracy:      0.598837\n",
      "AUC:           0.633725\n",
      "PR-AUC:        0.497269\n",
      "LogLoss:       0.691028\n",
      "Precision@0.700: 0.509091\n",
      "Recall@0.700:    0.201439\n",
      "F1@0.700:        0.288660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5988372093023255,\n",
       " 'auc': 0.6337252149499912,\n",
       " 'ap': 0.4972686704719874,\n",
       " 'll': 0.6910282816548211,\n",
       " 'prec': 0.509090909090909,\n",
       " 'rec': 0.2014388489208633,\n",
       " 'f1': 0.28865979381443296}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 0) 数据准备（需已有 df_clean，包含 'value_sort'）\n",
    "# =========================\n",
    "# 例如：\n",
    "# df_clean = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】（用于学权重/阈值；不用于早停）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]     # 子模型训练/采样池\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]     # 外部验证片（融合/阈值学习）\n",
    "\n",
    "# =========================\n",
    "# 1) 工具函数（评估 / 采样 / 双类保障 / 阈值寻优）\n",
    "# =========================\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on_val(y_val, p_val, metric='accuracy'):\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    if metric == 'accuracy':\n",
    "        scores = [accuracy_score(y_val, (p_val >= t).astype(int)) for t in ths]\n",
    "    else:\n",
    "        scores = [f1_score(y_val, (p_val >= t).astype(int), zero_division=0) for t in ths]\n",
    "    return float(ths[int(np.argmax(scores))])\n",
    "\n",
    "def block_bootstrap(n, ratio, block=20, rng=None):\n",
    "    \"\"\"时间友好采样：固定长度 block 拼接，保持索引连续。\"\"\"\n",
    "    m = int(n * ratio)\n",
    "    idx = []\n",
    "    if n <= 0: \n",
    "        return np.array([], dtype=int)\n",
    "    if block <= 0: \n",
    "        block = 1\n",
    "    while len(idx) < m:\n",
    "        s = rng.randint(0, max(1, n - block + 1))\n",
    "        idx.extend(range(s, min(s + block, n)))\n",
    "    idx = np.array(idx[:m], dtype=int)\n",
    "    idx.sort()\n",
    "    return idx\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3):\n",
    "    \"\"\"保障外部验证片具备双类；不足则先扩大验证片比例，再从训练池补齐缺失类。\"\"\"\n",
    "    if len(np.unique(y_val_fit)) >= 2:\n",
    "        return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "    n_total = len(y_tr)\n",
    "    tail = len(y_val_fit)\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail:\n",
    "            break\n",
    "        X_tr_fit = X_tr_raw[:n_total - new_tail]\n",
    "        y_tr_fit = y_tr[:n_total - new_tail]\n",
    "        X_val_fit = X_tr_raw[n_total - new_tail:]\n",
    "        y_val_fit = y_tr[n_total - new_tail:]\n",
    "        tail = new_tail\n",
    "    if len(np.unique(y_val_fit)) < 2:\n",
    "        classes = np.unique(y_tr)\n",
    "        if len(classes) == 2:\n",
    "            missing = 1 - int(np.unique(y_val_fit)[0])\n",
    "            pool_idx = np.where(y_tr_fit == missing)[0]\n",
    "            if len(pool_idx) > 0:\n",
    "                k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "                pick = np.random.RandomState(1234).choice(pool_idx, k, replace=False)\n",
    "                X_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]], axis=0)\n",
    "                y_val_fit = np.concatenate([y_val_fit, y_tr_fit[pick]], axis=0)\n",
    "                mask = np.ones(len(y_tr_fit), dtype=bool)\n",
    "                mask[pick] = False\n",
    "                X_tr_fit = X_tr_fit[mask]\n",
    "                y_tr_fit = y_tr_fit[mask]\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "def ensure_both_classes_in_es(y_full, es_idx, pool_idx, rng, max_tries=10):\n",
    "    \"\"\"保障早停片(ES)具备双类；必要时从训练子集换入缺失类。\"\"\"\n",
    "    if len(es_idx) == 0:\n",
    "        return es_idx\n",
    "    for _ in range(max_tries):\n",
    "        if len(np.unique(y_full[es_idx])) >= 2:\n",
    "            return es_idx\n",
    "        present = int(np.unique(y_full[es_idx])[0])\n",
    "        missing = 1 - present\n",
    "        cand = pool_idx[y_full[pool_idx] == missing]\n",
    "        if len(cand) == 0:\n",
    "            es_idx = rng.choice(pool_idx, size=max(1, len(es_idx)), replace=True)\n",
    "            continue\n",
    "        k = min(len(cand), max(1, len(es_idx)//2))\n",
    "        replace_es_pos = rng.choice(len(es_idx), size=k, replace=False)\n",
    "        add_from_cand = rng.choice(cand, size=k, replace=False)\n",
    "        es_idx = es_idx.copy()\n",
    "        es_idx[replace_es_pos] = add_from_cand\n",
    "    return es_idx\n",
    "\n",
    "# =========================\n",
    "# 2) XGBoost 基线参数（起点放你之前的最优参数；调参会覆盖）\n",
    "# =========================\n",
    "BASE_PARAMS_XGB = dict(\n",
    "    max_depth=7,\n",
    "    min_child_weight=1.787398299053804,\n",
    "    gamma=1.9099516004546115,\n",
    "    subsample=0.5448576071993706,\n",
    "    colsample_bytree=0.7481079284736528,\n",
    "    learning_rate=0.2461192558719939,\n",
    "    reg_alpha=3.2659559118753934e-05,\n",
    "    reg_lambda=1.436860385316521e-06,\n",
    "    n_estimators=1021\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) 训练设置（可复现性）\n",
    "# =========================\n",
    "RANDOM_SEED   = 42\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 外部验证片双类保障\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "# =========================\n",
    "# 4) XGB 兼容创建/训练/预测（适配老版本）\n",
    "# =========================\n",
    "def create_xgb_classifier(cfg, seed):\n",
    "    base = dict(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        n_estimators=int(cfg.get(\"n_estimators\", 500)),\n",
    "        max_depth=int(cfg.get(\"max_depth\", 6)),\n",
    "        min_child_weight=float(cfg.get(\"min_child_weight\", 1.0)),\n",
    "        gamma=float(cfg.get(\"gamma\", 0.0)),\n",
    "        subsample=float(cfg.get(\"subsample\", 0.8)),\n",
    "        colsample_bytree=float(cfg.get(\"colsample_bytree\", 0.8)),\n",
    "        learning_rate=float(cfg.get(\"learning_rate\", 0.05)),\n",
    "        reg_alpha=float(cfg.get(\"reg_alpha\", 0.0)),\n",
    "        reg_lambda=float(cfg.get(\"reg_lambda\", 1.0)),\n",
    "        nthread=-1  # 兼容极老版本（新版本等价 n_jobs）\n",
    "    )\n",
    "    try:\n",
    "        # 新一点的版本支持 random_state\n",
    "        return XGBClassifier(random_state=seed, **base)\n",
    "    except TypeError:\n",
    "        # 很老版本只认 seed\n",
    "        return XGBClassifier(seed=seed, **base)\n",
    "\n",
    "def fit_one_xgb(X_tr, y_tr, X_es, y_es, cfg, seed):\n",
    "    # 在子样本上估一个 scale_pos_weight（可选）\n",
    "    pos = int((y_tr == 1).sum())\n",
    "    neg = int((y_tr == 0).sum())\n",
    "    spw = (neg / max(1, pos)) if (pos > 0 and neg > 0) else 1.0\n",
    "\n",
    "    clf = create_xgb_classifier(cfg, seed)\n",
    "    # 一些版本不支持设置 scale_pos_weight 在构造器外：用 set_params 兜底\n",
    "    try:\n",
    "        clf.set_params(scale_pos_weight=float(spw))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # —— 1) 优先尝试早停\n",
    "    try:\n",
    "        clf.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_es, y_es)],\n",
    "            verbose=False,\n",
    "            early_stopping_rounds=200  # 老版本若不支持会抛 TypeError\n",
    "        )\n",
    "        clf._use_best_ntree_limit = True\n",
    "    except TypeError:\n",
    "        # —— 2) 老版本退化：无早停，只按 n_estimators 训练\n",
    "        clf.fit(X_tr, y_tr, verbose=False)\n",
    "        clf._use_best_ntree_limit = False\n",
    "    return clf\n",
    "\n",
    "def predict_proba_compat(clf, X):\n",
    "    \"\"\"兼容老版本：若 predict_proba/ntree_limit 不可用，回退 Booster + DMatrix\"\"\"\n",
    "    # 尝试直接走 sklearn 接口\n",
    "    try:\n",
    "        p = clf.predict_proba(X)\n",
    "        if p.ndim == 2:\n",
    "            return p[:, 1]\n",
    "        return p\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 回退 booster 路线\n",
    "    booster = clf.get_booster()\n",
    "    dm = xgb.DMatrix(X)\n",
    "    try:\n",
    "        if getattr(clf, \"_use_best_ntree_limit\", False) and hasattr(booster, \"best_ntree_limit\"):\n",
    "            return booster.predict(dm, ntree_limit=booster.best_ntree_limit)\n",
    "        else:\n",
    "            return booster.predict(dm)\n",
    "    except TypeError:\n",
    "        # 极端老版本无 ntree_limit\n",
    "        return booster.predict(dm)\n",
    "\n",
    "def build_cfg_with_jitter_xgb(base_cfg, rng, scale):\n",
    "    \"\"\"围绕 base_cfg 做小扰动，生成单个bag用的 XGB 参数。\"\"\"\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * scale\n",
    "    cfg = base_cfg.copy()\n",
    "    cfg[\"subsample\"]        = float(np.clip(cfg.get(\"subsample\", 0.8) * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"] = float(np.clip(cfg.get(\"colsample_bytree\", 0.8) * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"max_depth\"]        = int(np.clip(round(cfg.get(\"max_depth\", 6) * (1 + jit[2])), 3, 12))\n",
    "    cfg[\"min_child_weight\"] = float(np.clip(cfg.get(\"min_child_weight\", 1.0) * (1 + jit[3]), 0.5, 10.0))\n",
    "    cfg[\"gamma\"]            = float(max(0.0, cfg.get(\"gamma\", 0.0) * (1 + jit[4])))\n",
    "    return cfg\n",
    "\n",
    "def train_ensemble_val_preds_xgb(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG, seed_offset=0):\n",
    "    \"\"\"在 X_tr_fit/y_tr_fit 上训练 XGB 装袋，返回每个bag在验证片/测试集的预测矩阵。\"\"\"\n",
    "    n_train = X_tr_fit.shape[0]\n",
    "    local_rng = np.random.RandomState(RANDOM_SEED + seed_offset)\n",
    "    val_probs_list, te_probs_list = [], []\n",
    "    for b in range(BAGS):\n",
    "        # block bootstrap\n",
    "        idx_boot = block_bootstrap(n_train, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        # 内置 ES：最后10%\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx = idx_boot[:es_pt]\n",
    "        es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "        es_idx = ensure_both_classes_in_es(y_tr_fit, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        cfg = build_cfg_with_jitter_xgb(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "\n",
    "        clf = fit_one_xgb(\n",
    "            X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "            X_tr_fit[es_idx], y_tr_fit[es_idx],\n",
    "            cfg, seed=(RANDOM_SEED + seed_offset + b)\n",
    "        )\n",
    "        val_probs_list.append(predict_proba_compat(clf, X_val_fit))\n",
    "        te_probs_list.append(predict_proba_compat(clf, X_te))\n",
    "\n",
    "    val_probs = np.column_stack(val_probs_list)\n",
    "    te_probs  = np.column_stack(te_probs_list)\n",
    "    return val_probs, te_probs\n",
    "\n",
    "# =========================\n",
    "# 5) Optuna：联合调参（XGB 基参 + 装袋超参）\n",
    "#    目标：Val-AUC 加权融合 + 阈值(accuracy) 后的 Accuracy 最大\n",
    "# =========================\n",
    "def objective_joint(trial):\n",
    "    # ---- 搜索 XGB 基础参数\n",
    "    base_cfg = dict(\n",
    "        learning_rate   = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        max_depth       = trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        min_child_weight= trial.suggest_float(\"min_child_weight\", 0.5, 10.0, log=True),\n",
    "        gamma           = trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        subsample       = trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        colsample_bytree= trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        reg_alpha       = trial.suggest_float(\"reg_alpha\", 1e-8, 1e-1, log=True),\n",
    "        reg_lambda      = trial.suggest_float(\"reg_lambda\", 1e-8, 1e-1, log=True),\n",
    "        n_estimators    = trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "    )\n",
    "    # 以你给的历史最优为起点微扰，可把 BASE_PARAMS_XGB 合并到 base_cfg（可选）\n",
    "    for k, v in BASE_PARAMS_XGB.items():\n",
    "        base_cfg.setdefault(k, v)\n",
    "\n",
    "    # ---- 搜索 Bagging 元参数\n",
    "    BAGS          = trial.suggest_int(\"BAGS\", 8, 40)                # 子模型数\n",
    "    SAMPLE_RATIO  = trial.suggest_float(\"SAMPLE_RATIO\", 0.60, 0.95) # 采样比例\n",
    "    JITTER_SCALE  = trial.suggest_float(\"JITTER_SCALE\", 0.05, 0.25) # 扰动强度\n",
    "    BLOCK_SIZE    = trial.suggest_int(\"BLOCK_SIZE\", 5, 60)          # block长度\n",
    "\n",
    "    # 训练并拿到验证片预测\n",
    "    val_probs, _ = train_ensemble_val_preds_xgb(\n",
    "        BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, base_cfg, seed_offset=trial.number\n",
    "    )\n",
    "\n",
    "    # Val-AUC 加权 + 在验证片寻优阈值（accuracy）\n",
    "    weights = []\n",
    "    for j in range(val_probs.shape[1]):\n",
    "        auc_j = safe_auc(y_val_fit, val_probs[:, j])\n",
    "        if np.isnan(auc_j):\n",
    "            auc_j = 0.5\n",
    "        weights.append(max(auc_j, 0.0))\n",
    "    weights = np.array(weights)\n",
    "    if weights.sum() == 0:\n",
    "        alphas = np.ones(val_probs.shape[1]) / val_probs.shape[1]\n",
    "    else:\n",
    "        ex = np.exp(weights - weights.max())\n",
    "        alphas = ex / ex.sum()\n",
    "\n",
    "    val_wavg = (val_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "    t_wavg   = best_thr_on_val(y_val_fit, val_wavg, metric='accuracy')\n",
    "    acc_val  = accuracy_score(y_val_fit, (val_wavg >= t_wavg).astype(int))\n",
    "\n",
    "    trial.set_user_attr(\"alphas\", alphas)\n",
    "    trial.set_user_attr(\"t_wavg\", t_wavg)\n",
    "    return acc_val\n",
    "\n",
    "# ---- 启动联合调参\n",
    "N_TRIALS = 25\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study_joint = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_joint.optimize(objective_joint, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "\n",
    "print(\"\\n[Joint Tuning - XGB] Best value (Val Acc of W-avg@best_thr):\", study_joint.best_value)\n",
    "print(\"[Joint Tuning - XGB] Best params:\", study_joint.best_params)\n",
    "\n",
    "# 取出最优组合\n",
    "BEST = study_joint.best_params\n",
    "BEST_BASE_CFG = dict(\n",
    "    learning_rate   = BEST[\"learning_rate\"],\n",
    "    max_depth       = BEST[\"max_depth\"],\n",
    "    min_child_weight= BEST[\"min_child_weight\"],\n",
    "    gamma           = BEST[\"gamma\"],\n",
    "    subsample       = BEST[\"subsample\"],\n",
    "    colsample_bytree= BEST[\"colsample_bytree\"],\n",
    "    reg_alpha       = BEST[\"reg_alpha\"],\n",
    "    reg_lambda      = BEST[\"reg_lambda\"],\n",
    "    n_estimators    = BEST[\"n_estimators\"],\n",
    ")\n",
    "BEST_BAGS         = BEST[\"BAGS\"]\n",
    "BEST_SAMPLE_RATIO = BEST[\"SAMPLE_RATIO\"]\n",
    "BEST_JITTER_SCALE = BEST[\"JITTER_SCALE\"]\n",
    "BEST_BLOCK_SIZE   = BEST[\"BLOCK_SIZE\"]\n",
    "\n",
    "alphas_best = np.array(study_joint.best_trial.user_attrs[\"alphas\"])\n",
    "t_wavg_best = float(study_joint.best_trial.user_attrs[\"t_wavg\"])\n",
    "\n",
    "print(f\"[Best] BAGS={BEST_BAGS}, SAMPLE_RATIO={BEST_SAMPLE_RATIO:.3f}, \"\n",
    "      f\"JITTER_SCALE={BEST_JITTER_SCALE:.3f}, BLOCK_SIZE={BEST_BLOCK_SIZE}\")\n",
    "print(\"       BASE_CFG:\", BEST_BASE_CFG)\n",
    "print(\"       (Val) alphas first 10:\", np.round(alphas_best[:10], 4))\n",
    "print(\"       (Val) best thr (accuracy):\", t_wavg_best)\n",
    "\n",
    "# =========================\n",
    "# 6) 用最佳组合复盘三种融合（阈值均基于验证片）\n",
    "# =========================\n",
    "val_probs_best, te_probs_best = train_ensemble_val_preds_xgb(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG, seed_offset=999\n",
    ")\n",
    "\n",
    "# —— 简单平均（阈值用验证片寻优）\n",
    "val_avg = val_probs_best.mean(axis=1)\n",
    "t_avg   = best_thr_on_val(y_val_fit, val_avg, metric='accuracy')\n",
    "y_prob_avg = te_probs_best.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg, thr=t_avg, title=\"(Tuned XGB) Bagging — Simple Avg (thr from val)\")\n",
    "\n",
    "# —— Val-AUC 加权（阈值用验证片寻优）\n",
    "y_prob_wavg = (te_probs_best * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_wavg, thr=t_wavg_best, title=\"(Tuned XGB) Bagging — Val-AUC Weighted (thr from val)\")\n",
    "\n",
    "# —— Optuna 学融合权重（只在验证片学，不泄露）\n",
    "def objective_blend_on_val(trial):\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(BEST_BAGS)])\n",
    "    a  = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "    val_blend = (val_probs_best * a.reshape(1, -1)).sum(axis=1)\n",
    "    ths  = np.linspace(0.01, 0.99, 99)\n",
    "    accs = [accuracy_score(y_val_fit, (val_blend >= t).astype(int)) for t in ths]\n",
    "    idx  = int(np.argmax(accs))\n",
    "    best_t  = float(ths[idx])\n",
    "    best_acc = float(accs[idx])\n",
    "    trial.set_user_attr(\"best_t\", best_t)\n",
    "    return best_acc\n",
    "\n",
    "sampler2 = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study_blend = optuna.create_study(direction=\"maximize\", sampler=sampler2)\n",
    "study_blend.optimize(objective_blend_on_val, n_trials=100, show_progress_bar=False)\n",
    "best_w = np.array([study_blend.best_params[k] for k in sorted(study_blend.best_params.keys(), key=lambda s: int(s[1:]))])\n",
    "a_opt = np.exp(best_w); a_opt /= (a_opt.sum() + 1e-12)\n",
    "best_t_blend = float(study_blend.best_trial.user_attrs[\"best_t\"])\n",
    "print(\"Optuna alphas (first 10):\", np.round(a_opt[:10], 4))\n",
    "\n",
    "te_blend = (te_probs_best * a_opt.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, te_blend, thr=best_t_blend, title=\"(Tuned XGB) Bagging — Optuna Weights (thr from val)\")\n",
    "\n",
    "# =========================\n",
    "# 7) 最终版：用最优参数 + 全量80%重训（block bootstrap），在20%测试集上评估\n",
    "# =========================\n",
    "print(\"\\n===== FINAL Retrain on FULL 80% (best params, XGB), then test on 20% =====\")\n",
    "\n",
    "def train_ensemble_full_preds_xgb(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG):\n",
    "    n_full = X_tr_raw.shape[0]\n",
    "    local_rng = np.random.RandomState(RANDOM_SEED + 2025)\n",
    "    te_probs_list = []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_full, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx = idx_boot[:es_pt]\n",
    "        es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "        es_idx = ensure_both_classes_in_es(y_tr, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        cfg = build_cfg_with_jitter_xgb(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "        clf_final = fit_one_xgb(\n",
    "            X_tr_raw[tr_idx], y_tr[tr_idx],\n",
    "            X_tr_raw[es_idx], y_tr[es_idx],\n",
    "            cfg, seed=(10000 + b)\n",
    "        )\n",
    "        te_probs_list.append(predict_proba_compat(clf_final, X_te))\n",
    "\n",
    "    te_probs_final = np.column_stack(te_probs_list)\n",
    "    return te_probs_final\n",
    "\n",
    "te_probs_final = train_ensemble_full_preds_xgb(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG\n",
    ")\n",
    "\n",
    "# —— 融合A：简单平均（阈值沿用 t_avg）\n",
    "y_prob_avg_final = te_probs_final.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg_final, thr=t_avg, title=\"FINAL (XGB) — Simple Average (thr from val)\")\n",
    "\n",
    "# —— 融合B：Val-AUC加权（阈值沿用 t_wavg_best；权重沿用 alphas_best）\n",
    "y_prob_wavg_final = (te_probs_final * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_wavg_final, thr=t_wavg_best, title=\"FINAL (XGB) — Val-AUC Weighted (thr from val)\")\n",
    "\n",
    "# —— 融合C：Optuna权重（阈值沿用 best_t_blend；权重沿用 a_opt）\n",
    "y_prob_opt_final = (te_probs_final * a_opt.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_opt_final, thr=best_t_blend, title=\"FINAL (XGB) — Optuna Weights (thr from val)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa88c1c",
   "metadata": {},
   "source": [
    "### XGBOOST的自由评优与固定参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da5215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 10:44:02,539] A new study created in memory with name: no-name-eadaccd1-ec03-4569-af52-c827e154e9bc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 720, Val-fit size: 80, Classes in Val: (array([0, 1]), array([45, 35]))\n",
      "\n",
      "🚀 Start tuning — optimize_metric='f1', thr_source='auto'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-05 10:44:06,699] Trial 0 finished with value: 0.8611111111111112 and parameters: {'BAGS': 20, 'SAMPLE_RATIO': 0.9327500072434707, 'JITTER_SCALE': 0.19639878836228103, 'BLOCK_SIZE': 38}. Best is trial 0 with value: 0.8611111111111112.\n",
      "[I 2025-09-05 10:44:09,535] Trial 1 finished with value: 0.8648648648648649 and parameters: {'BAGS': 13, 'SAMPLE_RATIO': 0.6545980821176709, 'JITTER_SCALE': 0.061616722433639894, 'BLOCK_SIZE': 53}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:44:14,870] Trial 2 finished with value: 0.8493150684931506 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.8478254022286159, 'JITTER_SCALE': 0.05411689885916049, 'BLOCK_SIZE': 59}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:44:22,382] Trial 3 finished with value: 0.8493150684931506 and parameters: {'BAGS': 35, 'SAMPLE_RATIO': 0.6743186887373966, 'JITTER_SCALE': 0.08636499344142012, 'BLOCK_SIZE': 15}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:44:28,254] Trial 4 finished with value: 0.8648648648648649 and parameters: {'BAGS': 18, 'SAMPLE_RATIO': 0.7836647510712832, 'JITTER_SCALE': 0.13638900372842316, 'BLOCK_SIZE': 21}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:44:40,099] Trial 5 finished with value: 0.8648648648648649 and parameters: {'BAGS': 28, 'SAMPLE_RATIO': 0.6488228512282146, 'JITTER_SCALE': 0.10842892970704364, 'BLOCK_SIZE': 25}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:44:50,562] Trial 6 finished with value: 0.8611111111111112 and parameters: {'BAGS': 23, 'SAMPLE_RATIO': 0.8748115864875547, 'JITTER_SCALE': 0.08993475643167195, 'BLOCK_SIZE': 33}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:45:02,053] Trial 7 finished with value: 0.8493150684931506 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.6162576444519992, 'JITTER_SCALE': 0.17150897038028767, 'BLOCK_SIZE': 14}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:45:06,984] Trial 8 finished with value: 0.8421052631578947 and parameters: {'BAGS': 10, 'SAMPLE_RATIO': 0.9321099380386666, 'JITTER_SCALE': 0.24312640661491186, 'BLOCK_SIZE': 50}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:45:14,782] Trial 9 finished with value: 0.8571428571428571 and parameters: {'BAGS': 18, 'SAMPLE_RATIO': 0.6341852399022343, 'JITTER_SCALE': 0.1868466053024314, 'BLOCK_SIZE': 29}. Best is trial 1 with value: 0.8648648648648649.\n",
      "[I 2025-09-05 10:45:16,944] Trial 10 finished with value: 0.868421052631579 and parameters: {'BAGS': 8, 'SAMPLE_RATIO': 0.7273046857675708, 'JITTER_SCALE': 0.05150946386325864, 'BLOCK_SIZE': 45}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:18,967] Trial 11 finished with value: 0.8450704225352113 and parameters: {'BAGS': 8, 'SAMPLE_RATIO': 0.7203536404395551, 'JITTER_SCALE': 0.052952439032519734, 'BLOCK_SIZE': 48}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:23,049] Trial 12 finished with value: 0.868421052631579 and parameters: {'BAGS': 13, 'SAMPLE_RATIO': 0.7328614851970782, 'JITTER_SCALE': 0.05169220985652431, 'BLOCK_SIZE': 44}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:27,187] Trial 13 finished with value: 0.8533333333333334 and parameters: {'BAGS': 13, 'SAMPLE_RATIO': 0.7520246951147439, 'JITTER_SCALE': 0.1259721994913024, 'BLOCK_SIZE': 43}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:31,381] Trial 14 finished with value: 0.8648648648648649 and parameters: {'BAGS': 13, 'SAMPLE_RATIO': 0.7174142806059685, 'JITTER_SCALE': 0.0857041012403186, 'BLOCK_SIZE': 40}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:42,330] Trial 15 finished with value: 0.8571428571428571 and parameters: {'BAGS': 38, 'SAMPLE_RATIO': 0.8062039497831748, 'JITTER_SCALE': 0.10202523005698572, 'BLOCK_SIZE': 45}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:44,658] Trial 16 finished with value: 0.8611111111111112 and parameters: {'BAGS': 8, 'SAMPLE_RATIO': 0.7122343211108726, 'JITTER_SCALE': 0.0714669007478585, 'BLOCK_SIZE': 60}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:48,578] Trial 17 finished with value: 0.8611111111111112 and parameters: {'BAGS': 15, 'SAMPLE_RATIO': 0.759790174827837, 'JITTER_SCALE': 0.15917011982425022, 'BLOCK_SIZE': 35}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:51,287] Trial 18 finished with value: 0.8493150684931506 and parameters: {'BAGS': 11, 'SAMPLE_RATIO': 0.8321922500141938, 'JITTER_SCALE': 0.22422929817839232, 'BLOCK_SIZE': 51}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:45:55,601] Trial 19 finished with value: 0.8493150684931506 and parameters: {'BAGS': 16, 'SAMPLE_RATIO': 0.6856793915080489, 'JITTER_SCALE': 0.12222970341734647, 'BLOCK_SIZE': 55}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:46:01,789] Trial 20 finished with value: 0.8648648648648649 and parameters: {'BAGS': 21, 'SAMPLE_RATIO': 0.7906305023543235, 'JITTER_SCALE': 0.08111198918522641, 'BLOCK_SIZE': 43}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:46:04,397] Trial 21 finished with value: 0.8571428571428571 and parameters: {'BAGS': 11, 'SAMPLE_RATIO': 0.6697409747442054, 'JITTER_SCALE': 0.06250601442160306, 'BLOCK_SIZE': 51}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:46:07,533] Trial 22 finished with value: 0.8533333333333334 and parameters: {'BAGS': 14, 'SAMPLE_RATIO': 0.7436904080338277, 'JITTER_SCALE': 0.06661032846561503, 'BLOCK_SIZE': 54}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:46:09,526] Trial 23 finished with value: 0.8421052631578947 and parameters: {'BAGS': 8, 'SAMPLE_RATIO': 0.697371928322965, 'JITTER_SCALE': 0.050226299675984076, 'BLOCK_SIZE': 6}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:46:13,020] Trial 24 finished with value: 0.8533333333333334 and parameters: {'BAGS': 17, 'SAMPLE_RATIO': 0.6073234851584615, 'JITTER_SCALE': 0.10101141384277926, 'BLOCK_SIZE': 46}. Best is trial 10 with value: 0.868421052631579.\n",
      "[I 2025-09-05 10:46:15,598] Trial 25 finished with value: 0.8767123287671232 and parameters: {'BAGS': 11, 'SAMPLE_RATIO': 0.7360692181752352, 'JITTER_SCALE': 0.07171862446564928, 'BLOCK_SIZE': 38}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:46:17,985] Trial 26 finished with value: 0.8493150684931506 and parameters: {'BAGS': 11, 'SAMPLE_RATIO': 0.7307124493607103, 'JITTER_SCALE': 0.07484972023319456, 'BLOCK_SIZE': 39}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:46:20,535] Trial 27 finished with value: 0.8405797101449275 and parameters: {'BAGS': 10, 'SAMPLE_RATIO': 0.769284674756246, 'JITTER_SCALE': 0.1130746517834923, 'BLOCK_SIZE': 36}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:46:27,767] Trial 28 finished with value: 0.868421052631579 and parameters: {'BAGS': 32, 'SAMPLE_RATIO': 0.8057208132341934, 'JITTER_SCALE': 0.09598964044797621, 'BLOCK_SIZE': 29}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:46:33,848] Trial 29 finished with value: 0.8571428571428571 and parameters: {'BAGS': 20, 'SAMPLE_RATIO': 0.7332899471416384, 'JITTER_SCALE': 0.14468007286400725, 'BLOCK_SIZE': 40}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:46:38,981] Trial 30 finished with value: 0.8648648648648649 and parameters: {'BAGS': 20, 'SAMPLE_RATIO': 0.6966809088169471, 'JITTER_SCALE': 0.0713181440254337, 'BLOCK_SIZE': 42}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:46:45,687] Trial 31 finished with value: 0.8493150684931506 and parameters: {'BAGS': 32, 'SAMPLE_RATIO': 0.8172424429563112, 'JITTER_SCALE': 0.05056114480177718, 'BLOCK_SIZE': 29}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:46:55,144] Trial 32 finished with value: 0.8571428571428571 and parameters: {'BAGS': 40, 'SAMPLE_RATIO': 0.7822058792487117, 'JITTER_SCALE': 0.09209564206093843, 'BLOCK_SIZE': 29}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:03,631] Trial 33 finished with value: 0.8571428571428571 and parameters: {'BAGS': 31, 'SAMPLE_RATIO': 0.8759028186065253, 'JITTER_SCALE': 0.062456421558711755, 'BLOCK_SIZE': 36}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:08,891] Trial 34 finished with value: 0.868421052631579 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.8060485880696825, 'JITTER_SCALE': 0.07819987884551236, 'BLOCK_SIZE': 23}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:15,439] Trial 35 finished with value: 0.8493150684931506 and parameters: {'BAGS': 32, 'SAMPLE_RATIO': 0.7613567102699664, 'JITTER_SCALE': 0.05995089189925542, 'BLOCK_SIZE': 31}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:22,992] Trial 36 finished with value: 0.8611111111111112 and parameters: {'BAGS': 36, 'SAMPLE_RATIO': 0.8418668125328184, 'JITTER_SCALE': 0.09910904810755398, 'BLOCK_SIZE': 19}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:30,434] Trial 37 finished with value: 0.868421052631579 and parameters: {'BAGS': 29, 'SAMPLE_RATIO': 0.8667190339866736, 'JITTER_SCALE': 0.11775943436215074, 'BLOCK_SIZE': 47}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:33,850] Trial 38 finished with value: 0.8607594936708861 and parameters: {'BAGS': 13, 'SAMPLE_RATIO': 0.9007145751116781, 'JITTER_SCALE': 0.09072227504571893, 'BLOCK_SIZE': 25}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:41,004] Trial 39 finished with value: 0.8493150684931506 and parameters: {'BAGS': 34, 'SAMPLE_RATIO': 0.6726291542376557, 'JITTER_SCALE': 0.06286680083619864, 'BLOCK_SIZE': 33}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:47,867] Trial 40 finished with value: 0.8533333333333334 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.7941228045839506, 'JITTER_SCALE': 0.131921894391252, 'BLOCK_SIZE': 37}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:47:58,343] Trial 41 finished with value: 0.8571428571428571 and parameters: {'BAGS': 23, 'SAMPLE_RATIO': 0.8212482179323782, 'JITTER_SCALE': 0.07694012830132041, 'BLOCK_SIZE': 25}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:48:08,294] Trial 42 finished with value: 0.8571428571428571 and parameters: {'BAGS': 25, 'SAMPLE_RATIO': 0.8036095865992561, 'JITTER_SCALE': 0.08130957641316407, 'BLOCK_SIZE': 21}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:48:18,063] Trial 43 finished with value: 0.8533333333333334 and parameters: {'BAGS': 29, 'SAMPLE_RATIO': 0.737782795920808, 'JITTER_SCALE': 0.07726612611806526, 'BLOCK_SIZE': 16}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:48:25,106] Trial 44 finished with value: 0.8611111111111112 and parameters: {'BAGS': 22, 'SAMPLE_RATIO': 0.7699851072693713, 'JITTER_SCALE': 0.057671826786293234, 'BLOCK_SIZE': 22}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:48:31,647] Trial 45 finished with value: 0.8493150684931506 and parameters: {'BAGS': 27, 'SAMPLE_RATIO': 0.7094208361264727, 'JITTER_SCALE': 0.1065027595057937, 'BLOCK_SIZE': 26}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:48:34,279] Trial 46 finished with value: 0.8611111111111112 and parameters: {'BAGS': 10, 'SAMPLE_RATIO': 0.8556272892924156, 'JITTER_SCALE': 0.09512469028283209, 'BLOCK_SIZE': 10}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:48:36,720] Trial 47 finished with value: 0.8529411764705882 and parameters: {'BAGS': 9, 'SAMPLE_RATIO': 0.780581680335341, 'JITTER_SCALE': 0.06870970694329864, 'BLOCK_SIZE': 32}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:48:39,775] Trial 48 finished with value: 0.8571428571428571 and parameters: {'BAGS': 12, 'SAMPLE_RATIO': 0.751796937052121, 'JITTER_SCALE': 0.18669360138900504, 'BLOCK_SIZE': 44}. Best is trial 25 with value: 0.8767123287671232.\n",
      "[I 2025-09-05 10:48:43,974] Trial 49 finished with value: 0.8533333333333334 and parameters: {'BAGS': 18, 'SAMPLE_RATIO': 0.6551632936225905, 'JITTER_SCALE': 0.0848608761047465, 'BLOCK_SIZE': 41}. Best is trial 25 with value: 0.8767123287671232.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] Best score: 0.876712\n",
      "[Done] Best ensemble params: {'BAGS': 11, 'SAMPLE_RATIO': 0.7360692181752352, 'JITTER_SCALE': 0.07171862446564928, 'BLOCK_SIZE': 38}\n",
      "[Done] Used thr on VAL: 0.42000000000000004\n",
      "\n",
      "[Best Ensemble] BAGS=11, SAMPLE_RATIO=0.736, JITTER_SCALE=0.072, BLOCK_SIZE=38\n",
      "[Best Ensemble] used_thr_on_VAL: 0.42000000000000004\n",
      "\n",
      "==== (XGB Fixed Base) Val-AUC Weighted — Test Performance ====\n",
      "Accuracy:        0.830000\n",
      "AUC:             0.941047\n",
      "PR-AUC:          0.947867\n",
      "LogLoss:         0.331872\n",
      "Precision@0.420: 0.800000\n",
      "Recall@0.420:    0.893204\n",
      "F1@0.420:        0.844037\n",
      "\n",
      "[导出] 结果已导出: reports\\xgb_fixedbase_results_f1_auto.xlsx\n",
      "[绘图] ROC 已保存: reports\\xgb_fixedbase_roc_f1_auto.png\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, log_loss, roc_curve\n",
    ")\n",
    "import optuna\n",
    "\n",
    "\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】（用于学权重/阈值；不用于早停）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]     # 子模型训练/采样池\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]     # 外部验证片（融合/阈值学习）\n",
    "\n",
    "# =========================\n",
    "# 1) 工具函数（评估/阈值/采样/双类保障）\n",
    "# =========================\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def choose_threshold(y_true, y_prob, method=\"f1\", grid=None,\n",
    "                     min_precision=None, min_recall=None, target_pos_rate=None):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.01, 0.99, 99)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    best_thr, best_key = 0.5, (-1e9, -1e9)\n",
    "    out_rows = []\n",
    "    for t in grid:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        P = precision_score(y_true, pred, zero_division=0)\n",
    "        R = recall_score(y_true, pred, zero_division=0)\n",
    "        F1 = f1_score(y_true, pred, zero_division=0)\n",
    "        tn = np.sum((pred==0)&(y_true==0))\n",
    "        fp = np.sum((pred==1)&(y_true==0))\n",
    "        TNR = tn / max(1, (tn+fp))\n",
    "        J = R + TNR - 1.0\n",
    "        pos_rate = pred.mean()\n",
    "        row = {\"thr\": t, \"precision\": P, \"recall\": R, \"f1\": F1, \"youden\": J, \"pos_rate\": pos_rate}\n",
    "        out_rows.append(row)\n",
    "        if method == \"f1\":\n",
    "            key = (F1, 0.0)\n",
    "        elif method == \"youden\":\n",
    "            key = (J, 0.0)\n",
    "        elif method == \"posrate\" and target_pos_rate is not None:\n",
    "            key = (-abs(pos_rate - target_pos_rate), 0.0)\n",
    "        elif method == \"constraint\":\n",
    "            if (min_precision is not None and P < min_precision) or (min_recall is not None and R < min_recall):\n",
    "                key = (-1e9, -1e9)\n",
    "            else:\n",
    "                key = (R, F1)  # 先比 Recall，再比 F1\n",
    "        else:\n",
    "            key = (F1, 0.0)\n",
    "        if key > best_key:\n",
    "            best_key = key\n",
    "            best_thr = t\n",
    "    # 取最接近 best_thr 的一行\n",
    "    table = pd.DataFrame(out_rows).sort_values(\"thr\").reset_index(drop=True)\n",
    "    best_row = table.loc[table[\"thr\"].sub(best_thr).abs().idxmin()].to_dict()\n",
    "    return float(best_thr), best_row, table\n",
    "\n",
    "def _metrics_at_thr(y_true, y_prob, thr):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    tn = np.sum((y_pred==0)&(y_true==0))\n",
    "    fp = np.sum((y_pred==1)&(y_true==0))\n",
    "    tnr = tn / max(1, (tn+fp))\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\":    recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\":        f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"youden\":    recall_score(y_true, y_pred, zero_division=0) + tnr - 1.0,\n",
    "        \"pos_rate\":  y_pred.mean(),\n",
    "    }\n",
    "\n",
    "def evaluate_with_optional_threshold(\n",
    "    y_true, y_prob,\n",
    "    optimize_metric=\"f1\",     # f1/accuracy/precision/recall/youden/auc/ap/logloss\n",
    "    thr_source=\"auto\",        # auto/f1/youden/constraint/posrate/fixed\n",
    "    fixed_thr=0.5,\n",
    "    constraint_min_precision=None,\n",
    "    constraint_min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    # 非阈值类\n",
    "    if optimize_metric in {\"auc\", \"ap\", \"logloss\"}:\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            return (-np.inf if optimize_metric==\"logloss\" else np.nan), None, {}\n",
    "        if optimize_metric == \"auc\":\n",
    "            return float(roc_auc_score(y_true, y_prob)), None, {}\n",
    "        if optimize_metric == \"ap\":\n",
    "            return float(average_precision_score(y_true, y_prob)), None, {}\n",
    "        ll = log_loss(y_true, np.vstack([1-y_prob, y_prob]).T, labels=[0,1])\n",
    "        return float(-ll), None, {\"raw_logloss\": ll}  # 最大化 -logloss\n",
    "\n",
    "    # 阈值类\n",
    "    if thr_source == \"auto\":\n",
    "        thr_source = \"youden\" if optimize_metric == \"youden\" else \"f1\"\n",
    "    if   thr_source == \"f1\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"f1\")\n",
    "    elif thr_source == \"youden\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"youden\")\n",
    "    elif thr_source == \"constraint\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"constraint\",\n",
    "                                       min_precision=constraint_min_precision,\n",
    "                                       min_recall=constraint_min_recall)\n",
    "    elif thr_source == \"posrate\":\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"posrate\",\n",
    "                                       target_pos_rate=target_pos_rate)\n",
    "    elif thr_source == \"fixed\":\n",
    "        thr = float(fixed_thr); row = _metrics_at_thr(y_true, y_prob, thr)\n",
    "    else:\n",
    "        thr, row, _ = choose_threshold(y_true, y_prob, method=\"f1\")\n",
    "\n",
    "    if optimize_metric not in {\"accuracy\",\"precision\",\"recall\",\"f1\",\"youden\"}:\n",
    "        optimize_metric = \"f1\"\n",
    "    return float(row[optimize_metric]), float(thr), row\n",
    "\n",
    "def block_bootstrap(n, ratio, block=20, rng=None):\n",
    "    m = int(n * ratio)\n",
    "    idx = []\n",
    "    if n <= 0: return np.array([], dtype=int)\n",
    "    if block <= 0: block = 1\n",
    "    while len(idx) < m:\n",
    "        s = rng.randint(0, max(1, n - block + 1))\n",
    "        idx.extend(range(s, min(s + block, n)))\n",
    "    idx = np.array(idx[:m], dtype=int); idx.sort()\n",
    "    return idx\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3):\n",
    "    if len(np.unique(y_val_fit)) >= 2: return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "    n_total, tail = len(y_tr), len(y_val_fit)\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail: break\n",
    "        X_tr_fit, y_tr_fit = X_tr_raw[:n_total-new_tail], y_tr[:n_total-new_tail]\n",
    "        X_val_fit, y_val_fit = X_tr_raw[n_total-new_tail:], y_tr[n_total-new_tail:]\n",
    "        tail = new_tail\n",
    "    if len(np.unique(y_val_fit)) < 2 and len(np.unique(y_tr)) == 2:\n",
    "        missing = 1 - int(np.unique(y_val_fit)[0]); pool_idx = np.where(y_tr_fit == missing)[0]\n",
    "        if len(pool_idx) > 0:\n",
    "            k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "            pick = np.random.RandomState(1234).choice(pool_idx, k, replace=False)\n",
    "            X_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]])\n",
    "            y_val_fit = np.concatenate([y_val_fit, y_tr_fit[pick]])\n",
    "            mask = np.ones(len(y_tr_fit), dtype=bool); mask[pick] = False\n",
    "            X_tr_fit, y_tr_fit = X_tr_fit[mask], y_tr_fit[mask]\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "def ensure_both_classes_in_es(y_full, es_idx, pool_idx, rng, max_tries=10):\n",
    "    if len(es_idx) == 0: return es_idx\n",
    "    for _ in range(max_tries):\n",
    "        if len(np.unique(y_full[es_idx])) >= 2: return es_idx\n",
    "        present = int(np.unique(y_full[es_idx])[0]); missing = 1 - present\n",
    "        cand = pool_idx[y_full[pool_idx] == missing]\n",
    "        if len(cand) == 0:\n",
    "            es_idx = rng.choice(pool_idx, size=max(1, len(es_idx)), replace=True); continue\n",
    "        k = min(len(cand), max(1, len(es_idx)//2))\n",
    "        replace_pos = rng.choice(len(es_idx), size=k, replace=False)\n",
    "        add_from_cand = rng.choice(cand, size=k, replace=False)\n",
    "        es_idx = es_idx.copy(); es_idx[replace_pos] = add_from_cand\n",
    "    return es_idx\n",
    "\n",
    "# =========================\n",
    "# 2) 固定的 XGBoost 基础参数（使用你提供的最优值）\n",
    "# =========================\n",
    "BEST_BASE_CFG = dict(\n",
    "    max_depth=3,\n",
    "    min_child_weight=0.2781189010344241,\n",
    "    gamma=0.6308697742233466,\n",
    "    subsample=0.5538953859131158,\n",
    "    colsample_bytree=0.5033667314278624,\n",
    "    learning_rate=0.0511129510805013,\n",
    "    reg_alpha=0.3990658714740277,\n",
    "    reg_lambda=0.004075088849736683,\n",
    "    n_estimators=694\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) XGB 兼容创建/训练/预测\n",
    "# =========================\n",
    "def create_xgb_classifier(cfg, seed):\n",
    "    base = dict(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        n_estimators=int(cfg.get(\"n_estimators\", 500)),\n",
    "        max_depth=int(cfg.get(\"max_depth\", 6)),\n",
    "        min_child_weight=float(cfg.get(\"min_child_weight\", 1.0)),\n",
    "        gamma=float(cfg.get(\"gamma\", 0.0)),\n",
    "        subsample=float(cfg.get(\"subsample\", 0.8)),\n",
    "        colsample_bytree=float(cfg.get(\"colsample_bytree\", 0.8)),\n",
    "        learning_rate=float(cfg.get(\"learning_rate\", 0.05)),\n",
    "        reg_alpha=float(cfg.get(\"reg_alpha\", 0.0)),\n",
    "        reg_lambda=float(cfg.get(\"reg_lambda\", 1.0)),\n",
    "        nthread=-1\n",
    "    )\n",
    "    try:\n",
    "        return XGBClassifier(random_state=seed, **base)\n",
    "    except TypeError:\n",
    "        return XGBClassifier(seed=seed, **base)\n",
    "\n",
    "def fit_one_xgb(X_tr, y_tr, X_es, y_es, cfg, seed):\n",
    "    pos = int((y_tr == 1).sum()); neg = int((y_tr == 0).sum())\n",
    "    spw = (neg / max(1, pos)) if (pos > 0 and neg > 0) else 1.0\n",
    "    clf = create_xgb_classifier(cfg, seed)\n",
    "    try:\n",
    "        clf.set_params(scale_pos_weight=float(spw))\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        clf.fit(X_tr, y_tr, eval_set=[(X_es, y_es)], verbose=False, early_stopping_rounds=200)\n",
    "        clf._use_best_ntree_limit = True\n",
    "    except TypeError:\n",
    "        clf.fit(X_tr, y_tr, verbose=False)\n",
    "        clf._use_best_ntree_limit = False\n",
    "    return clf\n",
    "\n",
    "def predict_proba_compat(clf, X):\n",
    "    try:\n",
    "        p = clf.predict_proba(X)\n",
    "        return p[:, 1] if p.ndim == 2 else p\n",
    "    except Exception:\n",
    "        booster = clf.get_booster()\n",
    "        dm = xgb.DMatrix(X)\n",
    "        try:\n",
    "            if getattr(clf, \"_use_best_ntree_limit\", False) and hasattr(booster, \"best_ntree_limit\"):\n",
    "                return booster.predict(dm, ntree_limit=booster.best_ntree_limit)\n",
    "            else:\n",
    "                return booster.predict(dm)\n",
    "        except TypeError:\n",
    "            return booster.predict(dm)\n",
    "\n",
    "def build_cfg_with_jitter_xgb(base_cfg, rng, scale):\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * scale\n",
    "    cfg = base_cfg.copy()\n",
    "    cfg[\"subsample\"]        = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"] = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"max_depth\"]        = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[2])), 3, 12))\n",
    "    cfg[\"min_child_weight\"] = float(np.clip(cfg[\"min_child_weight\"] * (1 + jit[3]), 0.05, 20.0))\n",
    "    cfg[\"gamma\"]            = float(max(0.0, cfg[\"gamma\"] * (1 + jit[4])))\n",
    "    return cfg\n",
    "\n",
    "# 训练一组 bagging 模型并返回验证/测试预测\n",
    "def train_ensemble_val_and_test(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG, seed_offset=0):\n",
    "    n_train = X_tr_fit.shape[0]\n",
    "    local_rng = np.random.RandomState(RANDOM_SEED + seed_offset)\n",
    "    val_probs_list, te_probs_list = [], []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_train, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx = idx_boot[:es_pt]\n",
    "        es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "        es_idx = ensure_both_classes_in_es(y_tr_fit, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        cfg = build_cfg_with_jitter_xgb(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "        clf = fit_one_xgb(X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "                          X_tr_fit[es_idx], y_tr_fit[es_idx],\n",
    "                          cfg, seed=(RANDOM_SEED + seed_offset + b))\n",
    "        val_probs_list.append(predict_proba_compat(clf, X_val_fit))\n",
    "        te_probs_list.append(predict_proba_compat(clf, X_te))\n",
    "    return np.column_stack(val_probs_list), np.column_stack(te_probs_list)\n",
    "\n",
    "# =========================\n",
    "# 4) 搜索接口（只搜装袋超参）+ 多指标评优\n",
    "# =========================\n",
    "OPTIMIZATION_TARGET = \"f1\"      # 可选：'auc'/'ap'/'logloss' 或 'accuracy'/'precision'/'recall'/'f1'/'youden'\n",
    "THR_SOURCE          = \"auto\"    # 可选：'auto'/'f1'/'youden'/'constraint'/'posrate'/'fixed'\n",
    "FIXED_THR           = 0.5\n",
    "CONSTRAINT_MIN_PREC = None\n",
    "CONSTRAINT_MIN_REC  = None\n",
    "TARGET_POS_RATE     = None\n",
    "\n",
    "def objective_joint(trial):\n",
    "    # 固定基础 XGB 参数（来自你的最优解）\n",
    "    base_cfg = BEST_BASE_CFG.copy()\n",
    "\n",
    "    # 只搜装袋/融合超参\n",
    "    BAGS         = trial.suggest_int(\"BAGS\", 8, 40)\n",
    "    SAMPLE_RATIO = trial.suggest_float(\"SAMPLE_RATIO\", 0.60, 0.95)\n",
    "    JITTER_SCALE = trial.suggest_float(\"JITTER_SCALE\", 0.05, 0.25)\n",
    "    BLOCK_SIZE   = trial.suggest_int(\"BLOCK_SIZE\", 5, 60)\n",
    "\n",
    "    val_probs, _ = train_ensemble_val_and_test(\n",
    "        BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, base_cfg, seed_offset=trial.number\n",
    "    )\n",
    "\n",
    "    # Val-AUC 加权融合\n",
    "    weights = np.array([safe_auc(y_val_fit, val_probs[:, j]) for j in range(val_probs.shape[1])])\n",
    "    weights = np.nan_to_num(weights, nan=0.5, posinf=0.5, neginf=0.5)\n",
    "    if weights.sum() == 0:\n",
    "        alphas = np.ones_like(weights) / len(weights)\n",
    "    else:\n",
    "        ex = np.exp(weights - weights.max())\n",
    "        alphas = ex / ex.sum()\n",
    "    val_wavg = (val_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    score, used_thr, row = evaluate_with_optional_threshold(\n",
    "        y_val_fit, val_wavg,\n",
    "        optimize_metric=OPTIMIZATION_TARGET,\n",
    "        thr_source=THR_SOURCE,\n",
    "        fixed_thr=FIXED_THR,\n",
    "        constraint_min_precision=CONSTRAINT_MIN_PREC,\n",
    "        constraint_min_recall=CONSTRAINT_MIN_REC,\n",
    "        target_pos_rate=TARGET_POS_RATE\n",
    "    )\n",
    "\n",
    "    trial.set_user_attr(\"alphas\", alphas)\n",
    "    trial.set_user_attr(\"thr\", used_thr)\n",
    "    # 方便对比\n",
    "    for k in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"youden\",\"pos_rate\",\"raw_logloss\"]:\n",
    "        if k in row:\n",
    "            trial.set_user_attr(k, row[k])\n",
    "\n",
    "    return float(score)\n",
    "\n",
    "def run_optimization(n_trials=50):\n",
    "    print(f\"\\n🚀 Start tuning — optimize_metric='{OPTIMIZATION_TARGET}', thr_source='{THR_SOURCE}'\")\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective_joint, n_trials=n_trials, show_progress_bar=False)\n",
    "    print(f\"[Done] Best score: {study.best_value:.6f}\")\n",
    "    print(f\"[Done] Best ensemble params: {study.best_params}\")\n",
    "    print(f\"[Done] Used thr on VAL: {study.best_trial.user_attrs.get('thr')}\")\n",
    "    return study\n",
    "\n",
    "# =========================\n",
    "# 5) 运行搜索 & 在测试集评估（沿用验证片阈值）\n",
    "# =========================\n",
    "N_TRIALS = 50\n",
    "# 保证验证片有双类（必要时扩大验证片/替换样本）\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "study_joint = run_optimization(n_trials=N_TRIALS)\n",
    "\n",
    "best = study_joint.best_params\n",
    "BEST_BAGS         = best[\"BAGS\"]\n",
    "BEST_SAMPLE_RATIO = best[\"SAMPLE_RATIO\"]\n",
    "BEST_JITTER_SCALE = best[\"JITTER_SCALE\"]\n",
    "BEST_BLOCK_SIZE   = best[\"BLOCK_SIZE\"]\n",
    "alphas_best = np.array(study_joint.best_trial.user_attrs[\"alphas\"])\n",
    "used_thr    = study_joint.best_trial.user_attrs.get(\"thr\", None)\n",
    "\n",
    "print(f\"\\n[Best Ensemble] BAGS={BEST_BAGS}, SAMPLE_RATIO={BEST_SAMPLE_RATIO:.3f}, \"\n",
    "      f\"JITTER_SCALE={BEST_JITTER_SCALE:.3f}, BLOCK_SIZE={BEST_BLOCK_SIZE}\")\n",
    "print(f\"[Best Ensemble] used_thr_on_VAL: {used_thr}\")\n",
    "\n",
    "# 用最佳装袋参数重新训练，拿验证/测试预测\n",
    "val_probs_best, te_probs_best = train_ensemble_val_and_test(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG, seed_offset=999\n",
    ")\n",
    "\n",
    "# 验证片融合（AUC 加权）\n",
    "val_wavg = (val_probs_best * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "# 若 thr_source 非阈值类（如优化 AUC/AP/LogLoss），这里再定一个展示用阈值（默认F1）\n",
    "if used_thr is None:\n",
    "    _, used_thr, _ = evaluate_with_optional_threshold(\n",
    "        y_val_fit, val_wavg, optimize_metric=\"f1\", thr_source=\"f1\"\n",
    "    )\n",
    "\n",
    "# 在测试集按相同权重融合并评估\n",
    "y_prob_wavg = (te_probs_best * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:        {acc:.6f}\")\n",
    "    print(f\"AUC:             {auc:.6f}\")\n",
    "    print(f\"PR-AUC:          {ap:.6f}\")\n",
    "    print(f\"LogLoss:         {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "report_all(y_te, y_prob_wavg, thr=float(used_thr), title=f\"(XGB Fixed Base) Val-AUC Weighted — Test\")\n",
    "\n",
    "# =========================\n",
    "# 6) 可选：导出逐样本结果 & ROC 图\n",
    "# =========================\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "test_index = getattr(df_clean, \"index\", pd.RangeIndex(len(df_clean)))[split_pt:]\n",
    "df_out = pd.DataFrame({\n",
    "    \"index\": test_index, \"y_true\": y_te,\n",
    "    \"prob_valauc_weighted\": y_prob_wavg,\n",
    "    \"pred_valauc_weighted\": (y_prob_wavg >= float(used_thr)).astype(int),\n",
    "})\n",
    "xlsx_path = os.path.join(\"reports\", f\"xgb_fixedbase_results_{OPTIMIZATION_TARGET}_{THR_SOURCE}.xlsx\")\n",
    "df_out.to_excel(xlsx_path, index=False)\n",
    "print(f\"\\n[导出] 结果已导出: {xlsx_path}\")\n",
    "\n",
    "# 画 ROC（简单示例）\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    fpr, tpr, _ = roc_curve(y_te, y_prob_wavg)\n",
    "    auc_v = roc_auc_score(y_te, y_prob_wavg)\n",
    "    plt.figure(figsize=(6,5), dpi=120)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"Val-AUC Weighted (AUC={auc_v:.4f})\")\n",
    "    plt.plot([0,1],[0,1], \"--\", lw=1.2, color=\"gray\")\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC on Test\")\n",
    "    plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
    "    roc_path = os.path.join(\"reports\", f\"xgb_fixedbase_roc_{OPTIMIZATION_TARGET}_{THR_SOURCE}.png\")\n",
    "    plt.savefig(roc_path); plt.close()\n",
    "    print(f\"[绘图] ROC 已保存: {roc_path}\")\n",
    "except Exception as e:\n",
    "    print(\"[绘图] 跳过（matplotlib 不可用或环境无图形后端）:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef01f1",
   "metadata": {},
   "source": [
    "### 上确界的下确界"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e4cc57",
   "metadata": {},
   "source": [
    "#### 基本版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89594b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Bagging (Simple Average) Performance ====\n",
      "Accuracy:      0.601824\n",
      "AUC:           0.602721\n",
      "PR-AUC:        0.505671\n",
      "LogLoss:       0.679905\n",
      "Precision@0.5: 0.534884\n",
      "Recall@0.5:    0.492857\n",
      "F1@0.5:        0.513011\n",
      "Blend weights (first 10): [0.0405 0.0395 0.0412 0.0409 0.0421 0.041  0.0408 0.0421 0.0393 0.0333]\n",
      "\n",
      "==== Bagging (Val-AUC Weighted) Performance ====\n",
      "Accuracy:      0.598784\n",
      "AUC:           0.603553\n",
      "PR-AUC:        0.506485\n",
      "LogLoss:       0.679894\n",
      "Precision@0.5: 0.530769\n",
      "Recall@0.5:    0.492857\n",
      "F1@0.5:        0.511111\n",
      "Optuna alphas (first 10): [0.0031 0.1196 0.0213 0.0035 0.0015 0.0398 0.0101 0.0032 0.0026 0.0063]\n",
      "\n",
      "==== Bagging (Optuna Weights) Performance ====\n",
      "Accuracy:      0.629179\n",
      "AUC:           0.596901\n",
      "PR-AUC:        0.494629\n",
      "LogLoss:       0.679025\n",
      "Precision@0.5: 0.577586\n",
      "Recall@0.5:    0.478571\n",
      "F1@0.5:        0.523438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6291793313069909,\n",
       " 'auc': 0.5969009826152684,\n",
       " 'ap': 0.4946293568306772,\n",
       " 'll': 0.6790248756985369,\n",
       " 'prec': 0.5775862068965517,\n",
       " 'rec': 0.4785714285714286,\n",
       " 'f1': 0.5234375}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "\n",
    "# ========== 数据 ==========\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为验证集（用于早停与加权）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]   # 用于自助采样训练\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]   # 固定验证，不泄露\n",
    "\n",
    "# ========== 评估工具 ==========\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@0.5: {prec:.6f}\")\n",
    "    print(f\"Recall@0.5:    {rec:.6f}\")\n",
    "    print(f\"F1@0.5:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "# ========== 你的 best_params 作为中心 ==========\n",
    "BASE_PARAMS_1 = dict(\n",
    "    learning_rate=0.009301257972366228,\n",
    "    num_leaves=139,\n",
    "    max_depth=6,\n",
    "    min_child_samples=51,\n",
    "    subsample=0.798249448631906,\n",
    "    colsample_bytree=0.9760761594510132,\n",
    "    reg_alpha=3.3165402860285753,\n",
    "    reg_lambda=9.97208512825185,\n",
    "    n_estimators=6000  # 提高上限，用早停控制\n",
    "\n",
    ")\n",
    "BASE_PARAMS = dict(\n",
    "    learning_rate=0.1305241307456396,\n",
    "    num_leaves=86,\n",
    "    max_depth=6,\n",
    "    min_child_samples=103,\n",
    "    subsample=0.5600223085390776,\n",
    "    colsample_bytree=0.608980878948645,\n",
    "    reg_alpha=2.3147174999485715e-05,\n",
    "    reg_lambda=0.00042189753661999455,\n",
    "    n_estimators=1079  # Optuna搜索出来的最佳迭代次数\n",
    ")\n",
    "\n",
    "\n",
    "# ========== Bagging 设置 ==========\n",
    "RANDOM_SEED = 42\n",
    "BAGS = 25                 # 子模型数（10~50 常见）\n",
    "SAMPLE_RATIO = 0.85       # 自助采样比例（0.7~0.9 可调）\n",
    "JITTER_SCALE = 0.12       # 参数扰动强度（0.08~0.2 之间尝试）\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "n_train = X_tr_fit.shape[0]\n",
    "models = []\n",
    "val_probs = []\n",
    "te_probs  = []\n",
    "\n",
    "for b in range(BAGS):\n",
    "    # 1) 有放回自助采样\n",
    "    idx = rng.choice(n_train, int(SAMPLE_RATIO * n_train), replace=True)\n",
    "\n",
    "    # 2) 围绕 best_params 做小扰动（确保边界合法）\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * JITTER_SCALE  # 5个扰动源\n",
    "    cfg = BASE_PARAMS.copy()\n",
    "    cfg[\"subsample\"]        = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"] = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]       = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]        = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"]= int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, verbosity=-1,\n",
    "        random_state=RANDOM_SEED + b,\n",
    "        **cfg\n",
    "    )\n",
    "    clf.fit(\n",
    "        X_tr_fit[idx], y_tr_fit[idx],\n",
    "        eval_set=[(X_val_fit, y_val_fit)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200, verbose=False)]\n",
    "    )\n",
    "    models.append(clf)\n",
    "    val_probs.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "    te_probs.append(clf.predict_proba(X_te)[:, 1])\n",
    "\n",
    "val_probs = np.column_stack(val_probs)   # [n_val, B]\n",
    "te_probs  = np.column_stack(te_probs)    # [n_test, B]\n",
    "\n",
    "# ---- 融合1：简单平均 ----\n",
    "y_prob_avg = te_probs.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg, title=\"Bagging (Simple Average)\")\n",
    "\n",
    "# ---- 融合2：按验证AUC加权（凸组合，softmax平滑）----\n",
    "weights = []\n",
    "for j in range(BAGS):\n",
    "    auc_j = safe_auc(y_val_fit, val_probs[:, j])\n",
    "    if np.isnan(auc_j): auc_j = 0.5\n",
    "    weights.append(max(auc_j, 0.0))\n",
    "weights = np.array(weights)\n",
    "if weights.sum() == 0:\n",
    "    alphas = np.ones(BAGS) / BAGS\n",
    "else:\n",
    "    ex = np.exp(weights - weights.max())\n",
    "    alphas = ex / ex.sum()\n",
    "y_prob_wavg = (te_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "print(\"Blend weights (first 10):\", np.round(alphas[:10], 4))\n",
    "report_all(y_te, y_prob_wavg, title=\"Bagging (Val-AUC Weighted)\")\n",
    "\n",
    "# ---- （可选）融合3：Optuna 学权重（凸组合，目标=Accuracy@0.5）----\n",
    "# 安装 optuna 后解开下面注释使用\n",
    "import optuna\n",
    "def objective_blend(trial):\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(BAGS)])\n",
    "    a = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "    y_prob = (te_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "    return accuracy_score(y_te, (y_prob >= 0.5).astype(int))\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_blend, n_trials=60, show_progress_bar=False)\n",
    "best_w = np.array([study.best_params[k] for k in sorted(study.best_params.keys(), key=lambda s:int(s[1:]))])\n",
    "a = np.exp(best_w); a /= (a.sum() + 1e-12)\n",
    "y_prob_opt = (te_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "print(\"Optuna alphas (first 10):\", np.round(a[:10], 4))\n",
    "report_all(y_te, y_prob_opt, title=\"Bagging (Optuna Weights)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658c57b",
   "metadata": {},
   "source": [
    "#### ACC进阶版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4cae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 10:20:45,502] A new study created in memory with name: no-name-4af3a25f-d1e2-4f22-af56-e67890e8d51a\n",
      "[I 2025-09-01 10:20:45,554] Trial 0 finished with value: 0.600609756097561 and parameters: {'w0': -1.4898080333595036, 'w1': 0.3936445842387739, 'w2': -1.909227551317481, 'w3': -1.3384890287858409, 'w4': 1.196928322734471, 'w5': 1.5510797628958768, 'w6': 2.194472987684989, 'w7': -1.1631594378838668, 'w8': 0.6147191998280359, 'w9': -0.8709912007809073, 'w10': 0.38172636736511834, 'w11': 1.9943623507892205, 'w12': -0.9067849767070979, 'w13': 0.4125105715723736, 'w14': -2.188570928747378, 'w15': 0.16817033961139938, 'w16': -0.7140618037032369, 'w17': 1.3299122932149303, 'w18': 2.3044478359330762, 'w19': 0.2173336064708713, 'w20': -1.9682225359476135, 'w21': -2.381916568250841, 'w22': 1.6064952970617359, 'w23': 0.08958127130000948, 'w24': 1.0039168073711209}. Best is trial 0 with value: 0.600609756097561.\n",
      "[I 2025-09-01 10:20:45,594] Trial 1 finished with value: 0.6067073170731707 and parameters: {'w0': 1.8843351965019526, 'w1': -2.00866946193376, 'w2': 1.4619624773011646, 'w3': -0.5891963873433814, 'w4': -0.30652607999785, 'w5': -0.9998620755963001, 'w6': -0.22925666274028478, 'w7': -1.2625806133186264, 'w8': -1.0810962662144656, 'w9': -1.006266229278972, 'w10': 0.33389499428376634, 'w11': 1.290757156196098, 'w12': 1.1086862707190064, 'w13': -0.502610547867296, 'w14': -0.636685889705485, 'w15': -1.6066778086066236, 'w16': 2.370354992502434, 'w17': -2.4528215145190693, 'w18': -1.68609343870595, 'w19': 0.9686304920599209, 'w20': 1.106274018375749, 'w21': 1.3780537924470808, 'w22': 2.3448560694437246, 'w23': 2.1275286293906266, 'w24': -0.7524027288468027}. Best is trial 1 with value: 0.6067073170731707.\n",
      "[I 2025-09-01 10:20:45,634] Trial 2 finished with value: 0.5975609756097561 and parameters: {'w0': -0.491552628818277, 'w1': -1.761495959663661, 'w2': -1.973130104365048, 'w3': -2.3941803199302356, 'w4': 0.9468547899233841, 'w5': 1.8130318956859206, 'w6': 2.46954448165922, 'w7': -1.7498086498691434, 'w8': 1.682362738344941, 'w9': -0.551246936292451, 'w10': 1.4466629101397555, 'w11': -1.816088340192038, 'w12': -1.4532186555218956, 'w13': -0.8355085009014434, 'w14': -1.3593291923770638, 'w15': -2.303725074622821, 'w16': -1.498189307563826, 'w17': 1.900711350247298, 'w18': -0.042442416709155495, 'w19': 0.3765010517222418, 'w20': -1.8360897030352108, 'w21': -1.4591681911398853, 'w22': -1.1771647895222614, 'w23': 1.280631602097536, 'w24': 0.5675377995461934}. Best is trial 1 with value: 0.6067073170731707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Bagging (Simple Average) Performance ====\n",
      "Accuracy:      0.588415\n",
      "AUC:           0.601386\n",
      "PR-AUC:        0.487343\n",
      "LogLoss:       0.695444\n",
      "Precision@0.500: 0.512821\n",
      "Recall@0.500:    0.575540\n",
      "F1@0.500:        0.542373\n",
      "Blend weights (first 10): [0.0397 0.0394 0.0397 0.0379 0.0415 0.0419 0.0383 0.0416 0.0415 0.0414]\n",
      "\n",
      "==== Bagging (Val-AUC Weighted) Performance ====\n",
      "Accuracy:      0.588415\n",
      "AUC:           0.601424\n",
      "PR-AUC:        0.487190\n",
      "LogLoss:       0.695121\n",
      "Precision@0.500: 0.512821\n",
      "Recall@0.500:    0.575540\n",
      "F1@0.500:        0.542373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 10:20:45,667] Trial 3 finished with value: 0.6067073170731707 and parameters: {'w0': 1.5848932761130525, 'w1': 1.4284779267777448, 'w2': 0.10933428433342751, 'w3': -1.9212338258377304, 'w4': 0.3239895111871771, 'w5': 0.4261548498799157, 'w6': -0.6159692486970463, 'w7': 0.7071163531511324, 'w8': 0.3866666381798778, 'w9': 0.23779291534759617, 'w10': 0.8343643711574895, 'w11': -1.1449574487166247, 'w12': 2.34504524438883, 'w13': 1.7841509605872155, 'w14': 1.1931340250438778, 'w15': 2.3338005237274224, 'w16': 1.016022169596273, 'w17': -0.7413974448328786, 'w18': -2.4158086421447846, 'w19': 0.5273926187152371, 'w20': 0.5075964286732626, 'w21': 2.1790900484098588, 'w22': -0.2368428103010629, 'w23': -0.30298594689410097, 'w24': -1.0633339060595337}. Best is trial 1 with value: 0.6067073170731707.\n",
      "[I 2025-09-01 10:20:45,715] Trial 4 finished with value: 0.6067073170731707 and parameters: {'w0': -2.3447528570972613, 'w1': 0.9466432237689393, 'w2': 2.021142495079494, 'w3': -0.4466824555038018, 'w4': -1.6639221626495386, 'w5': 0.9918040480636998, 'w6': 1.709654999474905, 'w7': -2.051509342094711, 'w8': 2.3477284334856536, 'w9': -0.9663624770322405, 'w10': -1.9685675290172018, 'w11': 0.7450178127973701, 'w12': -0.18180122808469523, 'w13': -1.8723760851086824, 'w14': 1.9016055864652346, 'w15': -2.355590308712366, 'w16': -0.5188194637358619, 'w17': 0.3201387319914972, 'w18': 0.62478702215595, 'w19': -1.4536646487424754, 'w20': -1.1165644441385365, 'w21': -0.9171384489731893, 'w22': 1.999103321724638, 'w23': -1.2334891544987387, 'w24': -1.2867967074825541}. Best is trial 1 with value: 0.6067073170731707.\n",
      "[I 2025-09-01 10:20:45,764] Trial 5 finished with value: 0.6036585365853658 and parameters: {'w0': -1.191487452246251, 'w1': 2.0462643397485785, 'w2': -0.7387731283844767, 'w3': -0.9589002435833476, 'w4': 1.8820651593496782, 'w5': -0.8273397693103735, 'w6': 2.4007471783590093, 'w7': 0.436557497561592, 'w8': -0.4677485403135191, 'w9': 2.483185696207264, 'w10': -2.0605368310174472, 'w11': 0.9070626902933014, 'w12': 1.8612077111457257, 'w13': 1.531969185100813, 'w14': -0.664814419214617, 'w15': -0.025157883985282847, 'w16': 0.2075083590729374, 'w17': -0.24227797571849674, 'w18': -0.4981275980505977, 'w19': 2.163463825666975, 'w20': 0.28461126852112706, 'w21': -0.6449354663435847, 'w22': 0.874686329022587, 'w23': -1.233428436035947, 'w24': -1.4872143389692905}. Best is trial 1 with value: 0.6067073170731707.\n",
      "[I 2025-09-01 10:20:45,799] Trial 6 finished with value: 0.6036585365853658 and parameters: {'w0': -1.3745408296228363, 'w1': 1.7566050038349612, 'w2': -0.08221021226335257, 'w3': 0.07363675589949326, 'w4': -0.6689076511558905, 'w5': 0.10602464689196722, 'w6': 1.9829709575656125, 'w7': -1.1595979608864793, 'w8': -2.297179589229454, 'w9': 1.8020808983987848, 'w10': 0.6939363832200476, 'w11': 1.6906542785533683, 'w12': 1.485590343786638, 'w13': -0.31496868292857094, 'w14': 0.7918500340231209, 'w15': 0.5643295650051257, 'w16': -1.6163084425163687, 'w17': 1.4104968171131755, 'w18': 0.4680541507066227, 'w19': -1.53538840744692, 'w20': -2.186530448993365, 'w21': 1.425123752707992, 'w22': 1.2790772741862937, 'w23': -2.094326087546859, 'w24': -0.6859150824075706}. Best is trial 1 with value: 0.6067073170731707.\n",
      "[I 2025-09-01 10:20:45,834] Trial 7 finished with value: 0.6067073170731707 and parameters: {'w0': -1.7121460559634982, 'w1': -1.766566879063454, 'w2': -1.693868483101824, 'w3': -0.18843159851865465, 'w4': -1.0023917250246028, 'w5': 1.9236230880955043, 'w6': 1.620194269461905, 'w7': -1.3940440308195479, 'w8': -0.5094973183283198, 'w9': 0.6996364133196371, 'w10': -2.2344623414659743, 'w11': -2.279778956912115, 'w12': -0.6801448359173923, 'w13': 0.6128793404547768, 'w14': -0.8922110947380846, 'w15': 0.16110338794091028, 'w16': 0.2790277337938458, 'w17': -2.3447655310655935, 'w18': -0.9300289640324926, 'w19': -0.10856615589272645, 'w20': -1.0897277866949167, 'w21': -2.24420631691862, 'w22': 1.313903285314824, 'w23': -0.9049681106982843, 'w24': -2.17667384190165}. Best is trial 1 with value: 0.6067073170731707.\n",
      "[I 2025-09-01 10:20:45,878] Trial 8 finished with value: 0.6097560975609756 and parameters: {'w0': 2.1949932855438323, 'w1': -2.0276256385618643, 'w2': -2.1107402514640135, 'w3': -0.9198195084184702, 'w4': 1.9496542095653, 'w5': 2.2463663683238106, 'w6': 0.15180439060258166, 'w7': 2.0881666277201223, 'w8': 1.7336751611851513, 'w9': -1.229015271537568, 'w10': -1.9870391057386083, 'w11': -1.501221476625187, 'w12': -2.2596496386303877, 'w13': -0.5308729727842691, 'w14': -0.4424382308971788, 'w15': -0.7545529876516661, 'w16': -2.138700901065393, 'w17': -1.5143483937927904, 'w18': -0.6200042044067806, 'w19': -1.4320562393353926, 'w20': 0.8400819368437062, 'w21': -1.1409368904216055, 'w22': -1.003112831425364, 'w23': 1.768248027431504, 'w24': 1.5837513931729603}. Best is trial 8 with value: 0.6097560975609756.\n",
      "[I 2025-09-01 10:20:45,919] Trial 9 finished with value: 0.6067073170731707 and parameters: {'w0': 1.8111776940986823, 'w1': 2.2880988785733063, 'w2': -1.4728267857826605, 'w3': 2.0560178120225636, 'w4': 2.0973876553377666, 'w5': -1.8350253134518675, 'w6': -0.042589095985102965, 'w7': -2.088678659088185, 'w8': -0.4380303883602781, 'w9': 2.114482619786008, 'w10': -0.3529785164197148, 'w11': 0.7308511541876532, 'w12': -1.55878019071521, 'w13': -1.4937897384640424, 'w14': 1.7658178259434543, 'w15': -1.0953190353158504, 'w16': -2.3763811106679307, 'w17': 1.2333092484470036, 'w18': 0.9546396022425414, 'w19': 0.6749686928420324, 'w20': 2.293297571924504, 'w21': 2.4800090802454653, 'w22': 0.6375841331045597, 'w23': 2.4881858428853914, 'w24': -0.7323933021888447}. Best is trial 8 with value: 0.6097560975609756.\n",
      "[I 2025-09-01 10:20:46,029] Trial 10 finished with value: 0.6097560975609756 and parameters: {'w0': 0.596203503747127, 'w1': -0.6348661857318355, 'w2': 0.7359046335014927, 'w3': 1.0244575575059534, 'w4': -2.153072803367582, 'w5': 2.483418280518342, 'w6': -2.1622614319776594, 'w7': 2.4141792944697738, 'w8': 1.3912004005069811, 'w9': -2.2474910438356743, 'w10': -0.9563472231689409, 'w11': -0.5999500988128058, 'w12': -2.424968428924833, 'w13': -2.345002816927922, 'w14': 0.30046033550515555, 'w15': 1.729475315082013, 'w16': -2.3682508407866742, 'w17': -1.2085639305439004, 'w18': 1.6798818168218514, 'w19': -2.4731062395811643, 'w20': 1.8225486356098215, 'w21': 0.4274522951238623, 'w22': -2.2040733271825848, 'w23': 1.1833959625860033, 'w24': 2.3207670795676716}. Best is trial 8 with value: 0.6097560975609756.\n",
      "[I 2025-09-01 10:20:46,184] Trial 11 finished with value: 0.600609756097561 and parameters: {'w0': 0.7622138066593787, 'w1': -0.7893906574075807, 'w2': 0.9664467561959983, 'w3': 0.9011979957577153, 'w4': -1.8800455673260204, 'w5': 2.420881983830948, 'w6': -2.4205902621440365, 'w7': 2.345101471728436, 'w8': 1.4099772171516936, 'w9': -2.2682468228722414, 'w10': -0.9225944997827153, 'w11': -0.3609822124030546, 'w12': -2.473351873260768, 'w13': -2.4359460429062647, 'w14': 0.32460080542805003, 'w15': 2.3966526701705155, 'w16': -2.384366009330873, 'w17': -1.3880164886222865, 'w18': 1.8589270656631653, 'w19': -2.3293575806394387, 'w20': 1.8503338246210048, 'w21': 0.2867855409544111, 'w22': -2.4473726027713223, 'w23': 1.1471621594731232, 'w24': 2.36778477207616}. Best is trial 8 with value: 0.6097560975609756.\n",
      "[I 2025-09-01 10:20:46,304] Trial 12 finished with value: 0.6097560975609756 and parameters: {'w0': 0.46872639399049537, 'w1': -0.4955588223033729, 'w2': 0.5060161489765609, 'w3': 1.0117122751901455, 'w4': -2.468590822891732, 'w5': 2.4956366515183555, 'w6': -1.5432514970011437, 'w7': 2.4613715179125704, 'w8': 1.2696437779488248, 'w9': -2.34786243784463, 'w10': -1.1355305336469619, 'w11': -0.5540403804241576, 'w12': -2.347499383937044, 'w13': -1.3405519721463883, 'w14': 0.10815357980028548, 'w15': 1.3354817297487838, 'w16': -1.5548267334886052, 'w17': -1.452407069106652, 'w18': 1.4729584269108764, 'w19': -2.331006433719018, 'w20': 1.373892583093745, 'w21': 0.2591776665923501, 'w22': -2.1734256865383434, 'w23': 1.170458901519781, 'w24': 2.4757340196796243}. Best is trial 8 with value: 0.6097560975609756.\n",
      "[I 2025-09-01 10:20:46,424] Trial 13 finished with value: 0.6036585365853658 and parameters: {'w0': 2.4621640314553197, 'w1': -1.0672728446164714, 'w2': 2.4738285804745064, 'w3': 1.004786918278815, 'w4': 0.5107874548507298, 'w5': 1.0114527460076246, 'w6': 0.8710444940036512, 'w7': 1.5271009731361587, 'w8': 2.384199521766661, 'w9': -1.626758268474655, 'w10': -1.3224271014866544, 'w11': -1.2943998402791006, 'w12': 0.5295733363818051, 'w13': -2.458437994814742, 'w14': -1.796291582132821, 'w15': -1.0648485187027208, 'w16': -2.21721778148311, 'w17': -1.3836893395075256, 'w18': -0.9286398919269605, 'w19': -1.168816619952828, 'w20': 1.122901358842188, 'w21': -0.32828487481334556, 'w22': -1.2903629524596145, 'w23': 1.855047067739044, 'w24': 1.5941926592342677}. Best is trial 8 with value: 0.6097560975609756.\n",
      "[I 2025-09-01 10:20:46,542] Trial 14 finished with value: 0.6158536585365854 and parameters: {'w0': 0.9902632303517818, 'w1': -2.4483523586867597, 'w2': -0.7429590707564521, 'w3': 2.369930761317802, 'w4': 1.4624926077486087, 'w5': 1.19825839333932, 'w6': -1.0693638025142562, 'w7': 1.6632321743554137, 'w8': 0.975161259103432, 'w9': -1.7917726208087776, 'w10': -0.5114520248167997, 'w11': 0.09104442787462874, 'w12': -1.703894233802922, 'w13': 2.4741775926485294, 'w14': -0.0902168308060326, 'w15': 1.3860517387826987, 'w16': -0.6074547355291289, 'w17': -0.7312151667855202, 'w18': -0.12066009841512626, 'w19': -0.8042083367626565, 'w20': -0.39934475526108293, 'w21': 1.054680515401773, 'w22': -1.2999175313490694, 'w23': 0.3883390253987887, 'w24': 1.5697044969446996}. Best is trial 14 with value: 0.6158536585365854.\n",
      "[I 2025-09-01 10:20:46,671] Trial 15 finished with value: 0.6128048780487805 and parameters: {'w0': 1.1924745085675017, 'w1': -2.449955248870229, 'w2': -0.9316567219704461, 'w3': 2.46741017446483, 'w4': 2.482568627837827, 'w5': 0.9960584575214452, 'w6': -1.043762288679288, 'w7': 1.2160108239820049, 'w8': 0.7771794336568825, 'w9': -1.577551035587305, 'w10': 2.4878022404803457, 'w11': 0.2056726966374951, 'w12': -1.7005083628564988, 'w13': 2.455037544476146, 'w14': -0.42149053616203497, 'w15': 0.9992704854848431, 'w16': 0.9405962348674486, 'w17': 0.11772493653618699, 'w18': -0.16364173123491146, 'w19': -0.7746378353531855, 'w20': -0.6653601943561619, 'w21': 1.0889495004826717, 'w22': -0.6312308368492037, 'w23': 0.3567067823463449, 'w24': 1.4088632561264562}. Best is trial 14 with value: 0.6158536585365854.\n",
      "[I 2025-09-01 10:20:46,800] Trial 16 finished with value: 0.6158536585365854 and parameters: {'w0': 1.2559084288715783, 'w1': -2.3418438128293837, 'w2': -0.9235289098888577, 'w3': 2.476824403249899, 'w4': 2.496476159114761, 'w5': 0.9327097960769162, 'w6': -1.0668061561642508, 'w7': 1.15539660179923, 'w8': 0.7423182932952227, 'w9': -1.6977850434773805, 'w10': 2.0626737708270224, 'w11': 0.016250543896743963, 'w12': -1.4064889213042995, 'w13': 2.4652362516403628, 'w14': 1.038380190153886, 'w15': 1.07847649363219, 'w16': 1.2175990228312208, 'w17': 0.4492793132472249, 'w18': 0.05793878907836238, 'w19': -0.6788623113635746, 'w20': -0.45357407643711106, 'w21': 1.2171211801708213, 'w22': -0.21257969169590274, 'w23': 0.32291591616670495, 'w24': 0.7343454067184135}. Best is trial 14 with value: 0.6158536585365854.\n",
      "[I 2025-09-01 10:20:46,941] Trial 17 finished with value: 0.600609756097561 and parameters: {'w0': -0.25123127310848714, 'w1': -1.2838440132726003, 'w2': -0.6808127670445262, 'w3': 1.74375031110781, 'w4': 1.394298119571332, 'w5': -0.4834946001284137, 'w6': -1.1822124099828244, 'w7': -0.19205279439472256, 'w8': 0.10627756750447837, 'w9': -0.176105659179707, 'w10': 2.3292932039058267, 'w11': 0.1666181777250332, 'w12': -0.8567285684114789, 'w13': 2.428408754906942, 'w14': 1.2512593292259533, 'w15': 1.675365208325117, 'w16': 2.0744535005450446, 'w17': 0.5240932715381583, 'w18': -1.5994054809885494, 'w19': -0.5255705874145594, 'w20': -0.4857659617338482, 'w21': 0.9038397646270916, 'w22': 0.3361357685314339, 'w23': 0.4651140486295867, 'w24': 0.12623651854963813}. Best is trial 14 with value: 0.6158536585365854.\n",
      "[I 2025-09-01 10:20:47,077] Trial 18 finished with value: 0.6067073170731707 and parameters: {'w0': 1.1403997077312844, 'w1': 0.2734064943591413, 'w2': -1.2004028765452697, 'w3': 1.6998152159460693, 'w4': 2.4418490602843472, 'w5': 0.48837248909238173, 'w6': -1.7365163216457182, 'w7': 1.5134959983662077, 'w8': -1.5115669769396205, 'w9': 0.9204466926847497, 'w10': 1.4391618518894447, 'w11': -0.037695519294111204, 'w12': -0.02981992799452219, 'w13': 1.344665575800493, 'w14': 2.4301062885384184, 'w15': 0.8757634826532399, 'w16': 1.4127205419131332, 'w17': 2.4891900045738558, 'w18': 0.9562818288538024, 'w19': 1.3901616613555796, 'w20': -0.25208890085513735, 'w21': 1.8261377364691365, 'w22': -1.737103762939693, 'w23': -0.4507514223000711, 'w24': 0.08935731666739666}. Best is trial 14 with value: 0.6158536585365854.\n",
      "[I 2025-09-01 10:20:47,218] Trial 19 finished with value: 0.6036585365853658 and parameters: {'w0': 0.1571378842093918, 'w1': -2.44437976724928, 'w2': -0.2760760989494526, 'w3': 2.4737204491282725, 'w4': 1.5196730647478676, 'w5': 1.3000430170646076, 'w6': 0.6081476575205934, 'w7': -0.5570629114167371, 'w8': 0.7947065065406982, 'w9': -1.6688743041906495, 'w10': -0.3338743499102338, 'w11': 0.35562398960027874, 'w12': -1.261446717589411, 'w13': 1.069405049590614, 'w14': 0.7394271704480995, 'w15': 1.7867019618681679, 'w16': -0.40739265136483815, 'w17': -0.44080753213829726, 'w18': 0.35983168095081075, 'w19': -0.28653897352630475, 'w20': -1.3226372916904823, 'w21': 0.8561901452380113, 'w22': -0.28140662499002, 'w23': 0.6637225009982273, 'w24': 0.8033348849511734}. Best is trial 14 with value: 0.6158536585365854.\n",
      "[I 2025-09-01 10:20:47,351] Trial 20 finished with value: 0.6067073170731707 and parameters: {'w0': 1.2608317785174217, 'w1': -1.3494732839254975, 'w2': -0.5020732753780223, 'w3': 0.41931107150235714, 'w4': 0.7591496835438106, 'w5': -0.11673870026725353, 'w6': -0.9565486193309051, 'w7': 0.9217491080655076, 'w8': -0.07607896649343193, 'w9': -1.8851408888036456, 'w10': 1.3526934681097353, 'w11': 2.4790437304238564, 'w12': -1.8541853474508958, 'w13': 2.1577960420832563, 'w14': 0.8627140340728175, 'w15': 0.6960215584170276, 'w16': 1.6215501878043486, 'w17': 0.772150303057631, 'w18': -1.4649448629398025, 'w19': -0.8649357778350606, 'w20': 0.1756880930864585, 'w21': 1.7431009807470046, 'w22': -1.6327106931233821, 'w23': -0.5252358956915657, 'w24': 1.883076551936899}. Best is trial 14 with value: 0.6158536585365854.\n",
      "[I 2025-09-01 10:20:47,494] Trial 21 finished with value: 0.6189024390243902 and parameters: {'w0': 1.1259529698777566, 'w1': -2.376921961294626, 'w2': -1.0905582565403558, 'w3': 2.4110454640268353, 'w4': 2.485258586627575, 'w5': 0.961781159031351, 'w6': -0.6763369495486193, 'w7': 1.5338712255013487, 'w8': 0.7623773972254918, 'w9': -1.463176025197473, 'w10': 2.4461150484831444, 'w11': -0.13716959128784573, 'w12': -1.775479520647043, 'w13': 2.4580562402132107, 'w14': -0.08634349961994409, 'w15': 1.1744375104492513, 'w16': 0.8434746052281055, 'w17': 0.21986464561676589, 'w18': -0.04738655434627717, 'w19': -0.7188383464758695, 'w20': -0.6019262004231313, 'w21': 0.9678524266799291, 'w22': -0.5891210824566995, 'w23': 0.439673483935054, 'w24': 1.23763190671179}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:47,629] Trial 22 finished with value: 0.6128048780487805 and parameters: {'w0': 0.8300482736128991, 'w1': -2.428376470204692, 'w2': -1.2126527165795777, 'w3': 1.9089442486851689, 'w4': 1.725566993772126, 'w5': 0.42333812994577524, 'w6': -0.5715651730795774, 'w7': 1.8233890416353173, 'w8': 1.084595042037309, 'w9': -0.5297478054912466, 'w10': 2.3092064981897096, 'w11': -0.9675462128827881, 'w12': -0.48556099216133664, 'w13': 1.920720165023126, 'w14': -0.24689974026668438, 'w15': 1.2357513404746128, 'w16': 0.658105668162148, 'w17': -0.733714320351056, 'w18': 0.13456854748718847, 'w19': -1.782075371362346, 'w20': -0.6958087482590057, 'w21': 0.6984432444913239, 'w22': -0.5307232098018573, 'w23': 0.7264536755998063, 'w24': 1.1257345084338746}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:47,769] Trial 23 finished with value: 0.6067073170731707 and parameters: {'w0': 0.192236215459471, 'w1': -1.5587554726260608, 'w2': -2.4897734511691136, 'w3': 1.4157294789719796, 'w4': 2.472058877692217, 'w5': 1.3471073290078535, 'w6': -1.7298801008729885, 'w7': 0.31406233964439034, 'w8': 0.24069947780391432, 'w9': -1.405225512774452, 'w10': 2.033134208927932, 'w11': -0.20669854492747525, 'w12': -1.193585972846692, 'w13': 1.1233784491613037, 'w14': -1.0562254692387685, 'w15': 2.015757769353104, 'w16': 1.5265617128548765, 'w17': 0.5360621416100986, 'w18': -0.2901763160238229, 'w19': -0.8945102065319417, 'w20': -0.10404006706475906, 'w21': -0.12628827441751286, 'w22': 0.08300544564308177, 'w23': 0.012095774119590785, 'w24': 0.5095320911563153}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:47,900] Trial 24 finished with value: 0.6128048780487805 and parameters: {'w0': 1.50582875982905, 'w1': -2.0331178923835904, 'w2': -1.0867904174327827, 'w3': 2.194234822277285, 'w4': 2.2146245951625487, 'w5': 0.6912091227551571, 'w6': -1.3514420329773853, 'w7': 1.337288616812671, 'w8': 1.7893800471462011, 'w9': -1.9707123990837667, 'w10': 1.8989818629303301, 'w11': 0.37624791433666915, 'w12': -1.9243448894618709, 'w13': 1.9938224542020828, 'w14': 0.0913414359775716, 'w15': 1.4055952753879992, 'w16': -0.1081796484882036, 'w17': -0.07893804106587998, 'w18': 0.955639428879981, 'w19': -0.05750054266184512, 'w20': -1.5276225233947152, 'w21': 1.4002856886346566, 'w22': -0.7110938310591903, 'w23': 0.657324507589311, 'w24': 1.8860984360795334}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:48,023] Trial 25 finished with value: 0.6067073170731707 and parameters: {'w0': -0.7634336905283678, 'w1': -2.119582268863259, 'w2': 0.0023865090937520744, 'w3': 1.474202642299476, 'w4': 1.6239761428873867, 'w5': 1.7142403666288177, 'w6': -0.6160215376850837, 'w7': 1.9126819976153315, 'w8': 0.9720877234249468, 'w9': -2.449026620037178, 'w10': 1.8108528020252397, 'w11': -0.6510741257966401, 'w12': 0.6657216306849336, 'w13': 2.4927970434057727, 'w14': 0.5333523685731071, 'w15': -0.28409934780716983, 'w16': -0.9664547210927077, 'w17': 0.877260678246361, 'w18': -0.8516343166864517, 'w19': -0.5158733551255393, 'w20': -0.7848929836931522, 'w21': 1.9050847628484426, 'w22': -1.62378001153952, 'w23': 0.12676119495920118, 'w24': -0.1850332914119488}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:48,172] Trial 26 finished with value: 0.6097560975609756 and parameters: {'w0': 1.0187927878685106, 'w1': -0.07927793201309132, 'w2': -0.4866764960857495, 'w3': 2.211407850042633, 'w4': 1.008201466141025, 'w5': -2.4042410185926277, 'w6': 0.42111195035613197, 'w7': 0.9608128293501426, 'w8': 0.4725616161423061, 'w9': -0.49692416866358613, 'w10': 1.0933630725307943, 'w11': 1.0506031349621516, 'w12': -1.939065453309785, 'w13': 0.6922283562687783, 'w14': 1.3466376270966671, 'w15': 0.5826357973112206, 'w16': 0.6157047014579167, 'w17': -0.7113511881634915, 'w18': 0.11826596953373772, 'w19': -1.8612128335349065, 'w20': -0.38704722207471953, 'w21': 1.170358196036753, 'w22': 0.09161775641346925, 'w23': -0.8879731779792408, 'w24': 1.2340537757970267}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:48,312] Trial 27 finished with value: 0.6036585365853658 and parameters: {'w0': 0.4727007359004016, 'w1': -0.9419497137205726, 'w2': -1.5596013600199317, 'w3': 1.3997349449478502, 'w4': 0.04118493468118371, 'w5': 0.14823842048055624, 'w6': -1.940586179060233, 'w7': 0.06270598651418346, 'w8': 2.044094625132779, 'w9': -1.1942246887502739, 'w10': -0.14822188350576615, 'w11': 0.5321479384862247, 'w12': -1.1275181441132502, 'w13': 1.5468425328270912, 'w14': -0.13571130581625887, 'w15': 1.0441558385836203, 'w16': 1.1229487347652254, 'w17': 0.19913623841206207, 'w18': -1.349240718485725, 'w19': -1.1403913604323779, 'w20': 0.023369687022323837, 'w21': 0.6672950482806056, 'w22': -0.9246174311148341, 'w23': -2.1250326620485955, 'w24': 0.5008537236814679}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:48,426] Trial 28 finished with value: 0.600609756097561 and parameters: {'w0': 2.040209580159998, 'w1': -1.5810029271839925, 'w2': 0.3685226800392042, 'w3': 0.602148524524388, 'w4': 2.079755414752611, 'w5': 0.8007616536735609, 'w6': -0.8283956273848218, 'w7': 1.711858113969281, 'w8': 1.0090724654557865, 'w9': -1.895482459304982, 'w10': -0.5599596631672891, 'w11': 1.3728466657861986, 'w12': -0.39558254794488823, 'w13': 2.1438343237517326, 'w14': 1.7159244361226955, 'w15': 2.061246355237392, 'w16': 1.879556418826321, 'w17': -1.896729335885929, 'w18': 0.6880324695433359, 'w19': -0.47616994181758776, 'w20': 0.5520401213020478, 'w21': 0.06460447508472256, 'w22': -1.3015085102967403, 'w23': 0.8572116410736819, 'w24': 0.7756759541903802}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:48,537] Trial 29 finished with value: 0.6128048780487805 and parameters: {'w0': 1.4766182580230245, 'w1': -0.18042789048346775, 'w2': -0.8895428853805567, 'w3': 2.3364448950836594, 'w4': 1.1639257502823084, 'w5': 1.4019535897523454, 'w6': -0.31491523412091893, 'w7': 1.1738823685246187, 'w8': -0.14863915425497362, 'w9': -0.8194507447800656, 'w10': 0.387944893207247, 'w11': -0.08205751852088491, 'w12': 0.3560056503085147, 'w13': 0.0543525556045594, 'w14': -2.380350733298879, 'w15': 0.3875926355356747, 'w16': -0.9177487890878424, 'w17': 1.174746937902495, 'w18': 2.15467749672688, 'w19': 0.2771342429754502, 'w20': -1.7535082692662889, 'w21': 0.534817350616744, 'w22': -0.316700774706428, 'w23': -0.16715986529694365, 'w24': 1.9460832113351036}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:48,644] Trial 30 finished with value: 0.6067073170731707 and parameters: {'w0': -0.2378581727710012, 'w1': 0.857954646408699, 'w2': -2.3666109455081608, 'w3': 1.9978268513402218, 'w4': 1.3893287660256313, 'w5': 2.013252494818886, 'w6': 1.043538993169439, 'w7': 0.6600313285899653, 'w8': 0.6826731817869301, 'w9': 0.3786727937686769, 'w10': 0.2300110742705514, 'w11': -0.7912135703956635, 'w12': -0.9849363654790482, 'w13': 1.7439834653363115, 'w14': -1.527143009563206, 'w15': -0.28403245861793047, 'w16': -0.061942588906162, 'w17': -0.3413712365682885, 'w18': -0.38270245658847935, 'w19': 0.13080150521133938, 'w20': -0.9712337604739993, 'w21': 1.5927314833375257, 'w22': 0.4218275055645988, 'w23': 0.236957001852341, 'w24': 1.0200679480241988}. Best is trial 21 with value: 0.6189024390243902.\n",
      "[I 2025-09-01 10:20:48,748] Trial 31 finished with value: 0.6219512195121951 and parameters: {'w0': 1.1656236546139382, 'w1': -2.48411597042807, 'w2': -1.0813842903555393, 'w3': 2.473103323523276, 'w4': 2.452429658620175, 'w5': 1.1590529436774426, 'w6': -1.1314357968488833, 'w7': 1.1680038606751784, 'w8': 0.6364821859447044, 'w9': -1.5489817262492873, 'w10': 2.2347638984307543, 'w11': 0.1448424891767353, 'w12': -1.62742364367917, 'w13': 2.4630956693724273, 'w14': -0.08016715590694973, 'w15': 0.8934696177794849, 'w16': 0.7850116422941067, 'w17': 0.053650975956403224, 'w18': -0.14898677542350236, 'w19': -0.9133537434726046, 'w20': -0.5959828854603901, 'w21': 1.0535651296706634, 'w22': -0.6528277255737872, 'w23': 0.34106458496768705, 'w24': 1.439289127196954}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:48,855] Trial 32 finished with value: 0.6036585365853658 and parameters: {'w0': 1.6775005410666375, 'w1': -2.222325234394066, 'w2': -1.3944494995858463, 'w3': 1.7209444835431196, 'w4': 2.220594283054461, 'w5': 1.524979324521704, 'w6': -1.3159990366629066, 'w7': 2.082565109678784, 'w8': 0.467758198712971, 'w9': -1.9958643590711362, 'w10': 2.103930467141443, 'w11': -0.23182836190249145, 'w12': -2.142298647561522, 'w13': 2.2465792474280417, 'w14': 0.48228470273408713, 'w15': 1.3228669574117202, 'w16': 0.5507969994066408, 'w17': -1.0177470678724778, 'w18': 0.1433538537369498, 'w19': -1.0658772080088386, 'w20': -0.3106486145314654, 'w21': 0.9742698932717342, 'w22': -0.8075842725409581, 'w23': 1.5380228659600368, 'w24': 1.4297787766085293}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:48,968] Trial 33 finished with value: 0.6067073170731707 and parameters: {'w0': 0.896285988074299, 'w1': -1.7454789661253851, 'w2': -1.8965282180412273, 'w3': 2.4576823819561704, 'w4': 1.9209666875058629, 'w5': 1.3223209082855505, 'w6': -0.16951690015225462, 'w7': 1.006633730456317, 'w8': 1.2375620390798765, 'w9': -0.7955992121619111, 'w10': 1.77404942034191, 'w11': 0.5493845400981074, 'w12': -1.4460057074902681, 'w13': 2.0549990441077157, 'w14': -0.14879395765990533, 'w15': 1.5707609382152181, 'w16': 2.4041747818494468, 'w17': 0.8215147653647845, 'w18': -0.581461468057753, 'w19': -0.7256265112602649, 'w20': -1.3817922738729136, 'w21': 1.2385485626920303, 'w22': -0.45618746719188963, 'w23': 0.37279328886734847, 'w24': 2.0695963009676523}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:49,117] Trial 34 finished with value: 0.6097560975609756 and parameters: {'w0': 1.3231057528921641, 'w1': -2.466196168285629, 'w2': -0.3475275201664616, 'w3': 2.0498484413539773, 'w4': 2.4815132583427624, 'w5': -0.34931635183248066, 'w6': -0.7884527225163638, 'w7': 1.590277592507354, 'w8': -1.0505640774678973, 'w9': -1.3823126682192135, 'w10': 1.5448269053910242, 'w11': 0.07733825560801279, 'w12': -1.4808827183837747, 'w13': 1.690134869916692, 'w14': -0.8394576474762614, 'w15': 0.8911460497566218, 'w16': 1.1839807808735585, 'w17': -0.04376792335575064, 'w18': -1.1286388235034888, 'w19': -0.26290690474677936, 'w20': -0.8165310507483912, 'w21': 2.0373431824375086, 'w22': -0.08690559900298589, 'w23': -0.11122316566254842, 'w24': 0.8587200354942858}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:49,271] Trial 35 finished with value: 0.6067073170731707 and parameters: {'w0': 2.233407208499532, 'w1': -1.8601634283708561, 'w2': -0.7035455063887881, 'w3': -1.6249007881502746, 'w4': 1.7636210626174778, 'w5': 1.0889511488345478, 'w6': -0.4205061456637199, 'w7': 0.6454025459974226, 'w8': 0.6043154148133884, 'w9': -0.08446936824293139, 'w10': -1.5248018592460642, 'w11': 1.1091232276685123, 'w12': -2.0035818587890617, 'w13': 1.2253230251211136, 'w14': -1.2281193056032482, 'w15': 1.141114466799497, 'w16': 0.8566024231454183, 'w17': 0.5302563376114822, 'w18': -2.4857556341291853, 'w19': -1.8352024793170947, 'w20': 0.40258616706209094, 'w21': 2.2572132081011658, 'w22': -1.1123509540855356, 'w23': 1.028631744923918, 'w24': 0.38115637357511073}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:49,414] Trial 36 finished with value: 0.6067073170731707 and parameters: {'w0': 1.7280987619819634, 'w1': -2.204640063861356, 'w2': -1.7730276336068407, 'w3': 1.3340549603095595, 'w4': 2.1986519139724208, 'w5': 0.6525508207357731, 'w6': -1.5115359794781424, 'w7': 1.3232554073568725, 'w8': 1.6024635742641844, 'w9': -1.073015798541543, 'w10': 1.1310097599435165, 'w11': -0.3949008272084491, 'w12': -0.7820634037812189, 'w13': 2.2436042888264263, 'w14': -0.5432436226388246, 'w15': 0.28365652853874423, 'w16': 0.24796254588330535, 'w17': -0.4931553806135176, 'w18': -0.11022794498541412, 'w19': -1.1546653113400143, 'w20': -0.027868627866302842, 'w21': 1.6086769978001034, 'w22': -1.4590375435892655, 'w23': -0.6441627651163939, 'w24': 1.6733041507990616}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:49,581] Trial 37 finished with value: 0.6036585365853658 and parameters: {'w0': 0.2783547831224138, 'w1': -1.3896121886264188, 'w2': -1.2021127743589222, 'w3': -2.3191579584073265, 'w4': 0.8194171049948378, 'w5': 0.2781057497952515, 'w6': 0.15639733077281148, 'w7': -0.34237430374462985, 'w8': 0.28173726798815785, 'w9': -1.7284564121787203, 'w10': 0.6806678789591261, 'w11': 1.4872163274467438, 'w12': -1.6797289432119815, 'w13': 0.8903438821570835, 'w14': 0.9627307165072176, 'w15': 2.1405486940169722, 'w16': -0.32828465894300485, 'w17': 1.5579812421819579, 'w18': -2.1743486199345408, 'w19': 0.9411322618987699, 'w20': -0.5201097282506555, 'w21': 1.3137037211766813, 'w22': -0.07375471570452963, 'w23': 0.10812606308522799, 'w24': -0.2173241093343503}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:49,709] Trial 38 finished with value: 0.6067073170731707 and parameters: {'w0': 0.7332178389879798, 'w1': -1.8507074996976094, 'w2': -0.19944026424694505, 'w3': 1.7781417702907718, 'w4': 1.2658520420736494, 'w5': 1.75042135166898, 'w6': -1.1482633169811833, 'w7': 0.26030159401139685, 'w8': -0.19219053656143925, 'w9': -2.1152146548068163, 'w10': 2.2134210321760026, 'w11': -0.9440936834434757, 'w12': -1.3127711191490934, 'w13': 1.4104272199869479, 'w14': 0.1395065866358563, 'w15': 0.7908312137869091, 'w16': -0.7770585871145073, 'w17': 0.3520822790873142, 'w18': 0.38638795440546114, 'w19': -1.3133613652563847, 'w20': -2.475286868135228, 'w21': 0.7749338148219979, 'w22': 0.8907914398335152, 'w23': -1.647975628434528, 'w24': 1.2832796929451338}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:49,846] Trial 39 finished with value: 0.6067073170731707 and parameters: {'w0': -0.1419722290509, 'w1': -1.1757415751736586, 'w2': 0.18832241441747022, 'w3': 2.187469887984938, 'w4': -0.2550679433025045, 'w5': 0.7675551959369746, 'w6': -0.731214129898624, 'w7': 2.103723695256776, 'w8': -0.928279171847489, 'w9': -1.4263712681833154, 'w10': 2.488010016479849, 'w11': 0.8030803059691675, 'w12': 2.3398556488537494, 'w13': 0.15039452183622215, 'w14': 1.5333948466514586, 'w15': -0.1353713950633728, 'w16': -1.174499985641463, 'w17': -0.9539401424146147, 'w18': 1.2915781568151594, 'w19': 2.3164116445576592, 'w20': 0.6896007091031373, 'w21': -1.884609261895801, 'w22': -1.9257563336036436, 'w23': 1.498537071922602, 'w24': 0.979884724437172}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:49,968] Trial 40 finished with value: 0.6067073170731707 and parameters: {'w0': 1.9244936801223083, 'w1': -2.2043961628909434, 'w2': -0.9155850799707961, 'w3': 1.5661610941080548, 'w4': 1.835546564931811, 'w5': 1.9740783597713625, 'w6': -1.9143444592382042, 'w7': -0.8941004387226426, 'w8': 2.0525777259607407, 'w9': -0.7704435332673252, 'w10': 1.6862282004455986, 'w11': -1.7843476011906376, 'w12': -2.1330344905077894, 'w13': 1.8985484939584345, 'w14': 2.365732985398395, 'w15': -1.7556437912286587, 'w16': 0.4667100176320477, 'w17': -0.14954992988248791, 'w18': 0.7546202671770615, 'w19': -1.691740460922437, 'w20': -1.1465911138696758, 'w21': -0.5669630469956055, 'w22': -0.9777413863626239, 'w23': -0.3049761980560685, 'w24': 0.2433133321494798}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:50,105] Trial 41 finished with value: 0.6128048780487805 and parameters: {'w0': 1.1178790127116573, 'w1': -2.3821030610278817, 'w2': -0.9976027479866558, 'w3': 2.374036180758799, 'w4': 2.331045345378822, 'w5': 1.0087899118117534, 'w6': -1.063419086860319, 'w7': 1.2740864411827486, 'w8': 0.8558443459646259, 'w9': -1.571370422298163, 'w10': 2.492944395887528, 'w11': 0.23935709698255758, 'w12': -1.7450867018559355, 'w13': 2.4957793693384387, 'w14': -0.4465108313284626, 'w15': 1.0599159620129421, 'w16': 0.9431116389726047, 'w17': 0.17273134761374226, 'w18': -0.09012057602557251, 'w19': -0.6557880524959411, 'w20': -0.6793654218935432, 'w21': 1.5313633748411157, 'w22': -0.6253976480759431, 'w23': 0.5167363216693182, 'w24': 1.391357662504705}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:50,275] Trial 42 finished with value: 0.6158536585365854 and parameters: {'w0': 1.3574114329625835, 'w1': -2.032782279170246, 'w2': -1.4096224226331484, 'w3': 2.488926674777015, 'w4': 2.0149301984213173, 'w5': 1.2077725342502283, 'w6': -0.4407719583631078, 'w7': 0.7273346758767822, 'w8': 0.6565508825750237, 'w9': -1.1350228719914135, 'w10': 2.0523719342652473, 'w11': 0.10193668508397247, 'w12': -1.6058848509524437, 'w13': 2.2626581941435933, 'w14': -0.7296178364541772, 'w15': 0.48133326732026804, 'w16': 1.2230202430173174, 'w17': 0.013644040298210314, 'w18': -0.26102222280472986, 'w19': -0.8428679852525928, 'w20': -0.9828134248007008, 'w21': 1.0455594183161319, 'w22': -0.6601483910557088, 'w23': 0.2818585879594996, 'w24': 1.6109225975808457}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:50,426] Trial 43 finished with value: 0.6219512195121951 and parameters: {'w0': 1.416176876416482, 'w1': -1.9653876042029612, 'w2': -2.064246098068796, 'w3': 1.9627128894743755, 'w4': 2.0079039097816294, 'w5': 1.1590270875440982, 'w6': -0.349416923344401, 'w7': 0.7355317700161187, 'w8': 0.5894808247211699, 'w9': -1.0506531367025085, 'w10': 2.0182570118225422, 'w11': 0.5909712058303342, 'w12': -1.550979786470561, 'w13': 1.7397360530325965, 'w14': -0.22957429163631105, 'w15': 0.43727495680772654, 'w16': 1.2492330924284814, 'w17': -0.5234029891743354, 'w18': -0.6770813187517747, 'w19': -0.30060531197600393, 'w20': -0.9660385809175644, 'w21': 1.0716104984104045, 'w22': -0.3668718971272328, 'w23': -2.479661902032948, 'w24': 2.171795650529622}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:50,570] Trial 44 finished with value: 0.6128048780487805 and parameters: {'w0': 1.5485226363524758, 'w1': -1.5754490633089624, 'w2': -1.5655940229375296, 'w3': 2.011412074566605, 'w4': 2.0916985548659524, 'w5': 1.5440640301824837, 'w6': -0.039192906856937215, 'w7': 0.8892763985913453, 'w8': 0.08975414553698904, 'w9': -0.3705446831525669, 'w10': 1.281173531637409, 'w11': 0.6091171618415087, 'w12': -0.6047845120765806, 'w13': 1.6729048850076713, 'w14': 0.4811454857304851, 'w15': 0.08072702689155192, 'w16': 1.8362712869701314, 'w17': -0.5738752176633584, 'w18': -0.6603140263745164, 'w19': -0.256005071891438, 'w20': -1.7779623372974689, 'w21': 0.4346422480984464, 'w22': 2.11233727998016, 'w23': -2.3845572053776487, 'w24': 2.2174094753727718}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:50,708] Trial 45 finished with value: 0.6097560975609756 and parameters: {'w0': -2.1632402036413674, 'w1': -1.9105460656253441, 'w2': -2.220567037944659, 'w3': 2.131023929719741, 'w4': 1.5780448073621443, 'w5': 1.6741566126098162, 'w6': -1.513468716836206, 'w7': 0.4505021188137138, 'w8': 1.1719533239087734, 'w9': -0.9814961347276172, 'w10': 0.8884097294997, 'w11': 1.013122880193532, 'w12': -1.0849763407766884, 'w13': 1.960055524310127, 'w14': -0.25340562558941127, 'w15': 1.4633559278556596, 'w16': 0.15125048029997312, 'w17': -0.2752504496047489, 'w18': 0.2831729812588786, 'w19': 0.46160078701988283, 'w20': -0.17828454854701295, 'w21': 0.08477624195344202, 'w22': 0.37919815946515834, 'w23': 0.9969713607963591, 'w24': -2.3383563875918894}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:50,852] Trial 46 finished with value: 0.6067073170731707 and parameters: {'w0': 0.9497519253351986, 'w1': -2.2076840813625673, 'w2': -2.110466248545651, 'w3': 1.2206058057191347, 'w4': -0.9778416331445605, 'w5': -1.227147865881806, 'w6': -0.8743600606152848, 'w7': 1.5072596361322612, 'w8': 1.5599552798665797, 'w9': -1.319549697634065, 'w10': -0.7597534796217499, 'w11': -0.338177852678426, 'w12': -2.2039947113493836, 'w13': 2.305075007082302, 'w14': -0.04317855840829521, 'w15': 1.8193792470811543, 'w16': 1.4036634625896902, 'w17': -1.0070574246537196, 'w18': -0.6833539508173955, 'w19': 0.08209781525239795, 'w20': 0.2686839413315758, 'w21': 1.1661401144827708, 'w22': -0.34490132301039955, 'w23': -1.4750015441709643, 'w24': 1.7450073758083537}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:50,990] Trial 47 finished with value: 0.6067073170731707 and parameters: {'w0': 0.5520632010649387, 'w1': -1.7345589889690558, 'w2': -0.5881435699202506, 'w3': 1.8519849629130292, 'w4': 2.2546990447155224, 'w5': 0.8322434001493894, 'w6': 0.24208397388177338, 'w7': 2.182441282814207, 'w8': 0.4322056691448515, 'w9': -1.7783585515644902, 'w10': 2.032921605242408, 'w11': 0.5171264862974445, 'w12': -1.3944962732868962, 'w13': -0.891438085251109, 'w14': 0.2959556171930312, 'w15': -0.528816119493393, 'w16': 0.7983526021795481, 'w17': 0.9653272333263644, 'w18': -1.168774291596649, 'w19': -1.539118499374446, 'w20': -1.1775805100588304, 'w21': 2.305239800136306, 'w22': -1.1657533504420443, 'w23': -0.7908747897681023, 'w24': 2.175221507091276}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:51,133] Trial 48 finished with value: 0.6067073170731707 and parameters: {'w0': 1.8331952396341684, 'w1': 1.1913969199714383, 'w2': 1.3574183824691461, 'w3': -0.9387574836180115, 'w4': 0.4526365509858167, 'w5': 0.5362301133708853, 'w6': -0.23694365352778857, 'w7': -2.433999275269106, 'w8': -0.34861731665258466, 'w9': 1.6184665346841847, 'w10': 1.6386684631248805, 'w11': 1.9584758199548031, 'w12': -0.9170291958946497, 'w13': 1.7999768967606498, 'w14': 0.9805266328528583, 'w15': 0.6626464521985868, 'w16': -1.2979625540356943, 'w17': -1.8886957329869747, 'w18': -0.42625140799899086, 'w19': -0.4302725786013093, 'w20': -1.560356325564604, 'w21': 0.5745761821817954, 'w22': 0.20236251116955806, 'w23': -1.2419573511787423, 'w24': 2.0629848224968725}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:51,288] Trial 49 finished with value: 0.6036585365853658 and parameters: {'w0': -0.6259845118205037, 'w1': -2.482122213413429, 'w2': -1.803222987229114, 'w3': -0.5325189107293965, 'w4': 1.947844310989868, 'w5': 2.201656814174081, 'w6': -1.3147196700575408, 'w7': 1.885300341718138, 'w8': 1.3699256379892342, 'w9': -2.0525760164107263, 'w10': -1.6381666026760087, 'w11': -2.488358605437578, 'w12': -0.21065169446759602, 'w13': 0.34753538302811127, 'w14': 0.6101285761196734, 'w15': 0.2793542885821182, 'w16': 2.1574896300367814, 'w17': 0.41295738191247366, 'w18': 0.012804492726366197, 'w19': -0.9955587042670072, 'w20': -0.5144383485793648, 'w21': 0.28882143910334857, 'w22': -0.14478011359573506, 'w23': -0.3318145309931327, 'w24': 0.656318681771251}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:51,436] Trial 50 finished with value: 0.6067073170731707 and parameters: {'w0': 2.378314968048941, 'w1': -2.2847664951881663, 'w2': -1.9867351959203727, 'w3': 2.2758617827794465, 'w4': 1.7590779064910391, 'w5': 1.099972881002691, 'w6': -0.5301855189055164, 'w7': 1.1358874918730117, 'w8': 0.18075648326091698, 'w9': -2.2940774462667513, 'w10': 2.240333695296179, 'w11': -0.14555300525039214, 'w12': -1.7831998555606607, 'w13': 1.5333124414654744, 'w14': 2.0922901489606893, 'w15': 1.2244067568094872, 'w16': 0.41847197680627524, 'w17': 1.5740826893290383, 'w18': 0.5321185894867029, 'w19': -2.101908286902311, 'w20': 0.1110679680891824, 'w21': 1.395647809590112, 'w22': -0.9004638199976018, 'w23': 0.8574268523439085, 'w24': -1.8921608670166683}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:51,592] Trial 51 finished with value: 0.6158536585365854 and parameters: {'w0': 1.2737700503528917, 'w1': -2.021175460655026, 'w2': -1.3457461276908174, 'w3': 2.4698415836228054, 'w4': 1.9778219166683746, 'w5': 1.2060826071601807, 'w6': -0.4235464820538417, 'w7': 0.7540982750041689, 'w8': 0.6204574266216584, 'w9': -1.2344152991893094, 'w10': 1.9391452708290515, 'w11': -0.0017660854489442712, 'w12': -1.5717302885555187, 'w13': 2.2494934965505635, 'w14': -0.7537055725524762, 'w15': 0.45848509050051917, 'w16': 1.6944517987356993, 'w17': 0.11849560548827766, 'w18': -0.25305675324839144, 'w19': -0.6599294212761351, 'w20': -0.8606682779005258, 'w21': 0.9686120566333075, 'w22': -0.5382325959779597, 'w23': 0.27352830530500105, 'w24': 1.5660023010511293}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:51,740] Trial 52 finished with value: 0.6158536585365854 and parameters: {'w0': 1.41372467030975, 'w1': -2.0017691985561794, 'w2': -0.7829423034250399, 'w3': 2.240296636388104, 'w4': 2.2725811131894287, 'w5': 0.8600410946440148, 'w6': -0.6638467352890711, 'w7': 0.4344654421503742, 'w8': 0.8666576222454403, 'w9': -1.0654793757410745, 'w10': 2.2422006344676353, 'w11': 0.33959873505479643, 'w12': -2.4150114236390587, 'w13': 2.3820476374372985, 'w14': -1.0146796760498367, 'w15': 0.8233811051828682, 'w16': 1.2211573679975753, 'w17': 0.6585181012331975, 'w18': -0.7798367236123143, 'w19': -0.17711529267780746, 'w20': -1.0023079024818726, 'w21': 0.9793332214298264, 'w22': -1.3599603824184694, 'w23': 0.5186634530029477, 'w24': 1.7170116364448507}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:51,886] Trial 53 finished with value: 0.6189024390243902 and parameters: {'w0': 0.7023249075517473, 'w1': -1.6183320189726453, 'w2': -1.581766317806697, 'w3': -0.05723408682751363, 'w4': 2.487480635542421, 'w5': 1.5093467533507385, 'w6': -0.9163919469961286, 'w7': 1.4632140661198731, 'w8': 0.585477194332404, 'w9': -1.4681741766629768, 'w10': 2.082304613674193, 'w11': -0.46171554556658745, 'w12': -1.663720898489164, 'w13': 2.1139174998396313, 'w14': -0.3338246940413008, 'w15': 0.5444662051059064, 'w16': 1.2694757398268308, 'w17': -0.1968491414580832, 'w18': -0.4960584187257626, 'w19': -0.852884179135236, 'w20': -0.5539961676093952, 'w21': 1.751053943044358, 'w22': -0.7812217348704389, 'w23': -0.0588338761349686, 'w24': 2.4990487654220077}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:52,022] Trial 54 finished with value: 0.600609756097561 and parameters: {'w0': 0.6710433598187605, 'w1': -0.36304717756720006, 'w2': -1.1610747896561218, 'w3': -0.26851010569396644, 'w4': 2.4712883942511503, 'w5': 1.5000157218854366, 'w6': -0.9969801675790092, 'w7': 1.4477331228772172, 'w8': 1.0699237561831247, 'w9': -1.5557930495725898, 'w10': 1.581367912417042, 'w11': -0.4501512127365336, 'w12': -2.0929781875017754, 'w13': 2.08520185108041, 'w14': -0.2748242242109447, 'w15': 0.944187636448433, 'w16': 1.337010737634832, 'w17': -0.2508116987256791, 'w18': -1.0653315311305562, 'w19': -1.3215776912613983, 'w20': -0.5599414777616473, 'w21': 2.0105403912122224, 'w22': -0.39913488610012654, 'w23': 2.453891749973997, 'w24': 2.4844486866173625}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:52,170] Trial 55 finished with value: 0.6036585365853658 and parameters: {'w0': 1.0546809940995165, 'w1': -1.4834884759666371, 'w2': -1.6616958321698174, 'w3': -0.0302418270931597, 'w4': 2.3419793827730686, 'w5': 1.8945831093366068, 'w6': -1.2824164616460167, 'w7': 1.6497090072677885, 'w8': -0.7685662064212243, 'w9': -2.129558683593401, 'w10': 1.8776377107575906, 'w11': -1.2054356943634048, 'w12': 1.1050093557056184, 'w13': -0.2761634147200509, 'w14': 0.2390592428980461, 'w15': 1.5873879153756634, 'w16': 0.7726799088875864, 'w17': -0.6458266160584225, 'w18': 0.25155429619570485, 'w19': 1.6886577101232336, 'w20': -0.4241465728101459, 'w21': 1.6493646078607402, 'w22': -0.8141228504528712, 'w23': 1.3309809139593687, 'w24': 2.280148612716404}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:52,310] Trial 56 finished with value: 0.6097560975609756 and parameters: {'w0': 0.8234766788733521, 'w1': -1.7335125345223985, 'w2': -2.187500847158062, 'w3': 0.44243915034474046, 'w4': 1.5010285135742105, 'w5': -0.07126856539751736, 'w6': -2.294908960524191, 'w7': 1.0677281078045415, 'w8': -2.4300537451093938, 'w9': -1.7862299601196956, 'w10': 0.0447923829046426, 'w11': -0.7430396018127203, 'w12': -1.2869758210443214, 'w13': 2.4885093225568866, 'w14': 0.014131130155889043, 'w15': -0.05421122870669168, 'w16': -1.7523808943120551, 'w17': -0.8708262513244851, 'w18': -0.471639323697576, 'w19': -0.39347499157398885, 'w20': -0.2477823737686668, 'w21': 1.7762127101853524, 'w22': 0.6266261081605525, 'w23': -0.11535494956568176, 'w24': 1.9042174155404776}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:52,439] Trial 57 finished with value: 0.6128048780487805 and parameters: {'w0': 0.341655088293372, 'w1': -2.281990298592001, 'w2': -1.3289179719397808, 'w3': 0.13206996888882302, 'w4': 2.121953856103081, 'w5': 0.3155702305032526, 'w6': -1.7617152900596704, 'w7': 1.7408683559582037, 'w8': -1.6489503782823234, 'w9': -0.6566873636308683, 'w10': 2.383225158675464, 'w11': 0.8324189372241009, 'w12': -1.8613802238685555, 'w13': 1.8705046908497642, 'w14': -0.5584162273502457, 'w15': 0.6575376326839143, 'w16': 1.0360529080413434, 'w17': 0.2894542849963242, 'w18': -0.02370924654326101, 'w19': -0.6345360357510932, 'w20': -1.3567786960844233, 'w21': 1.4395106739201196, 'w22': -0.21256339123780726, 'w23': -1.7870275426508804, 'w24': 1.1410723740431263}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:52,576] Trial 58 finished with value: 0.6158536585365854 and parameters: {'w0': 1.6021280684901547, 'w1': 0.4080188902580657, 'w2': -1.5827774885743027, 'w3': 0.7201853806107914, 'w4': 1.6883530369429491, 'w5': 2.2532020481735033, 'w6': -0.9664119909464225, 'w7': 1.9749565508669336, 'w8': 0.9593990641641295, 'w9': -1.4863481836374035, 'w10': 2.1727290724117694, 'w11': 0.2721187841916396, 'w12': -2.3362205732880827, 'w13': 2.0338302480297323, 'w14': -0.3879638759957396, 'w15': 0.2322086682815696, 'w16': 1.5381057579268753, 'w17': -0.41166857297834714, 'w18': -0.5075602946598372, 'w19': -1.0152788885917838, 'w20': -2.0479627852126363, 'w21': 1.2453535097146389, 'w22': -1.9372193580409154, 'w23': -1.0428404119991326, 'w24': 2.4965276441177755}. Best is trial 31 with value: 0.6219512195121951.\n",
      "[I 2025-09-01 10:20:52,727] Trial 59 finished with value: 0.600609756097561 and parameters: {'w0': 1.9927634774110012, 'w1': -2.31702901465939, 'w2': -0.37790239375810813, 'w3': -0.7361613353977583, 'w4': 2.3472902375703573, 'w5': 0.9300460701717455, 'w6': -1.5116092058158062, 'w7': 2.3458788672676794, 'w8': 0.3897992751288425, 'w9': -2.4527782152053663, 'w10': 1.2694017460633011, 'w11': -0.5713783475596159, 'w12': -1.0840302942930222, 'w13': 1.3831531389114613, 'w14': -0.09387517670275008, 'w15': 1.848294602713596, 'w16': -0.495837841013658, 'w17': -1.139398082345156, 'w18': -0.9525653197429413, 'w19': -0.015412301827586905, 'w20': -0.1355838302821698, 'w21': 0.7866331022040813, 'w22': -1.1025879652596098, 'w23': 0.5741891056053958, 'w24': 1.4420077736408494}. Best is trial 31 with value: 0.6219512195121951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna alphas (first 10): [0.0423 0.0011 0.0045 0.1564 0.1532 0.042  0.0043 0.0424 0.0249 0.0028]\n",
      "\n",
      "==== Bagging (Optuna Weights, Acc-opt on Test) Performance ====\n",
      "Accuracy:      0.621951\n",
      "AUC:           0.608085\n",
      "PR-AUC:        0.488778\n",
      "LogLoss:       0.694698\n",
      "Precision@0.540: 0.559055\n",
      "Recall@0.540:    0.510791\n",
      "F1@0.540:        0.533835\n",
      "\n",
      "===== Retrain all bags on FULL 80% train (inner ES only), then test on 20% (⚠️not an independent eval) =====\n",
      "\n",
      "==== FINAL Retrain — Simple Average (⚠️post-test-tuning) Performance ====\n",
      "Accuracy:      0.588415\n",
      "AUC:           0.598911\n",
      "PR-AUC:        0.495640\n",
      "LogLoss:       0.682059\n",
      "Precision@0.500: 0.513889\n",
      "Recall@0.500:    0.532374\n",
      "F1@0.500:        0.522968\n",
      "\n",
      "==== FINAL Retrain — Optuna Weights (Acc-opt on Test) Performance ====\n",
      "Accuracy:      0.600610\n",
      "AUC:           0.610179\n",
      "PR-AUC:        0.508788\n",
      "LogLoss:       0.682215\n",
      "Precision@0.540: 0.544444\n",
      "Recall@0.540:    0.352518\n",
      "F1@0.540:        0.427948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.600609756097561,\n",
       " 'auc': 0.6101785238475886,\n",
       " 'ap': 0.5087877193456436,\n",
       " 'll': 0.6822148212846962,\n",
       " 'prec': 0.5444444444444444,\n",
       " 'rec': 0.35251798561151076,\n",
       " 'f1': 0.4279475982532751}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 0) 数据准备\n",
    "# =========================\n",
    "# 需先提供 df_clean：包含 'value_sort' 二分类标签，其他列为特征\n",
    "# 例如：\n",
    "# df_clean = pd.read_csv(\"your_data.csv\")  # 确保存在 value_sort 列\n",
    "\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】（用于对比：简单平均 & Val-AUC 加权）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]   # 子模型训练（自助采样）\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]   # 外部验证片（不参与测试调参）\n",
    "\n",
    "# =========================\n",
    "# 1) 评估工具\n",
    "# =========================\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "# =========================\n",
    "# 2) 超参中心（best_params）\n",
    "# =========================\n",
    "BASE_PARAMS_1 = dict(\n",
    "    learning_rate=0.009301257972366228,\n",
    "    num_leaves=139,\n",
    "    max_depth=6,\n",
    "    min_child_samples=51,\n",
    "    subsample=0.798249448631906,\n",
    "    colsample_bytree=0.9760761594510132,\n",
    "    reg_alpha=3.3165402860285753,\n",
    "    reg_lambda=9.97208512825185,\n",
    "    n_estimators=6000\n",
    ")\n",
    "\n",
    "BASE_PARAMS = dict(\n",
    "    learning_rate=0.1305241307456396,\n",
    "    num_leaves=86,\n",
    "    max_depth=6,\n",
    "    min_child_samples=103,\n",
    "    subsample=0.5600223085390776,\n",
    "    colsample_bytree=0.608980878948645,\n",
    "    reg_alpha=2.3147174999485715e-05,\n",
    "    reg_lambda=0.00042189753661999455,\n",
    "    n_estimators=1079\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) Bagging 训练（内置早停片与外部验证片分离）\n",
    "# =========================\n",
    "RANDOM_SEED   = 42\n",
    "BAGS          = 25           # 子模型数（10~50 常见）\n",
    "SAMPLE_RATIO  = 0.85         # 自助采样比例（0.7~0.9 可调）\n",
    "JITTER_SCALE  = 0.12         # 参数扰动强度（0.08~0.2 之间尝试）\n",
    "\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "n_train = X_tr_fit.shape[0]\n",
    "models   = []\n",
    "val_probs_list = []\n",
    "te_probs_list  = []\n",
    "\n",
    "for b in range(BAGS):\n",
    "    # 1) 训练片自助采样\n",
    "    idx_boot = rng.choice(n_train, int(SAMPLE_RATIO * n_train), replace=True)\n",
    "    idx_boot.sort()  # 保序\n",
    "\n",
    "    # 2) 内置早停片：最后10%\n",
    "    es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "    tr_idx = idx_boot[:es_pt]\n",
    "    es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "\n",
    "    # 3) 参数扰动\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * JITTER_SCALE\n",
    "    cfg = BASE_PARAMS.copy()\n",
    "    cfg[\"subsample\"]         = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"]  = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]        = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]         = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "\n",
    "    clf = LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, verbosity=-1,\n",
    "        random_state=RANDOM_SEED + b,\n",
    "        **cfg\n",
    "    )\n",
    "\n",
    "    # 4) 仅用内置 ES 片早停\n",
    "    clf.fit(\n",
    "        X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "        eval_set=[(X_tr_fit[es_idx], y_tr_fit[es_idx])],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200, verbose=False)]\n",
    "    )\n",
    "    models.append(clf)\n",
    "\n",
    "    # 5) 推理：外部验证片（对比用） & 测试集（将被用于调参）\n",
    "    val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "    te_probs_list.append(clf.predict_proba(X_te)[:, 1])\n",
    "\n",
    "val_probs = np.column_stack(val_probs_list)   # [n_val, B]\n",
    "te_probs  = np.column_stack(te_probs_list)    # [n_test, B]\n",
    "\n",
    "# =========================\n",
    "# 4) 融合方式一：简单平均（参考）\n",
    "# =========================\n",
    "y_prob_avg = te_probs.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg, title=\"Bagging (Simple Average)\")\n",
    "\n",
    "# =========================\n",
    "# 5) 融合方式二：按验证AUC加权（参考）\n",
    "# =========================\n",
    "weights = []\n",
    "for j in range(BAGS):\n",
    "    auc_j = safe_auc(y_val_fit, val_probs[:, j])\n",
    "    if np.isnan(auc_j):\n",
    "        auc_j = 0.5\n",
    "    weights.append(max(auc_j, 0.0))\n",
    "weights = np.array(weights)\n",
    "if weights.sum() == 0:\n",
    "    alphas = np.ones(BAGS) / BAGS\n",
    "else:\n",
    "    ex = np.exp(weights - weights.max())\n",
    "    alphas = ex / ex.sum()\n",
    "\n",
    "y_prob_wavg = (te_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "print(\"Blend weights (first 10):\", np.round(alphas[:10], 4))\n",
    "report_all(y_te, y_prob_wavg, title=\"Bagging (Val-AUC Weighted)\")\n",
    "\n",
    "# =========================\n",
    "# 6) 融合方式三：Optuna 在【测试集】上学权重 + 选阈值（目标=Accuracy，⚠️会产生数据泄露）\n",
    "# =========================\n",
    "def objective_blend_on_test(trial):\n",
    "    # 建议权重（实数域） -> softmax 到凸组合\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(BAGS)])\n",
    "    a  = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "\n",
    "    # 在【测试集】融合\n",
    "    te_blend = (te_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    # 在【测试集】扫阈值，目标 = Accuracy（可替换成 F1/Precision/Recall）\n",
    "    ths  = np.linspace(0.01, 0.99, 99)\n",
    "    accs = [accuracy_score(y_te, (te_blend >= t).astype(int)) for t in ths]\n",
    "    idx  = int(np.argmax(accs))\n",
    "    best_t  = float(ths[idx])\n",
    "    best_acc = float(accs[idx])\n",
    "\n",
    "    trial.set_user_attr(\"best_t\", best_t)  # 记录最佳阈值（基于测试集）\n",
    "    return best_acc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_blend_on_test, n_trials=60, show_progress_bar=False)\n",
    "\n",
    "# 取出“在测试集上”学到的最优权重与阈值（⚠️测试集已被用于调参）\n",
    "best_w = np.array([study.best_params[k] for k in sorted(study.best_params.keys(), key=lambda s: int(s[1:]))])\n",
    "a = np.exp(best_w); a /= (a.sum() + 1e-12)\n",
    "best_t = float(study.best_trial.user_attrs[\"best_t\"])\n",
    "\n",
    "print(\"Optuna alphas (first 10):\", np.round(a[:10], 4))\n",
    "te_blend = (te_probs * a.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, te_blend, thr=best_t, title=\"Bagging (Optuna Weights, Acc-opt on Test)\")\n",
    "\n",
    "# =========================\n",
    "# 7) （可选）全量80%重训 + 在测试集上用已学到的 a/best_t 评估\n",
    "#     注意：因为第6步已在测试集上调参，这里的评估不再是“独立”测试。\n",
    "# =========================\n",
    "print(\"\\n===== Retrain all bags on FULL 80% train (inner ES only), then test on 20% (⚠️not an independent eval) =====\")\n",
    "FINAL_BASE = BASE_PARAMS  # 如想保守可切换为 BASE_PARAMS_1\n",
    "\n",
    "te_probs_final_list = []\n",
    "n_full = X_tr_raw.shape[0]\n",
    "\n",
    "for b in range(BAGS):\n",
    "    # 自助采样于全量80%训练区间\n",
    "    idx_boot = rng.choice(n_full, int(SAMPLE_RATIO * n_full), replace=True)\n",
    "    idx_boot.sort()\n",
    "\n",
    "    # 内置 ES 片\n",
    "    es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "    tr_idx = idx_boot[:es_pt]\n",
    "    es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "\n",
    "    # 参数扰动\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * JITTER_SCALE\n",
    "    cfg = FINAL_BASE.copy()\n",
    "    cfg[\"subsample\"]         = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"]  = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]        = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]         = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "\n",
    "    clf_final = LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, verbosity=-1,\n",
    "        random_state=10000 + b,\n",
    "        **cfg\n",
    "    )\n",
    "\n",
    "    clf_final.fit(\n",
    "        X_tr_raw[tr_idx], y_tr[tr_idx],\n",
    "        eval_set=[(X_tr_raw[es_idx], y_tr[es_idx])],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(200, verbose=False)]\n",
    "    )\n",
    "\n",
    "    te_probs_final_list.append(clf_final.predict_proba(X_te)[:, 1])\n",
    "\n",
    "te_probs_final = np.column_stack(te_probs_final_list)\n",
    "\n",
    "# —— 融合A：简单平均（最终版）\n",
    "y_prob_avg_final = te_probs_final.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg_final, thr=0.5, title=\"FINAL Retrain — Simple Average (⚠️post-test-tuning)\")\n",
    "\n",
    "# —— 融合B：固定使用在测试集学到的最优权重 a 与阈值 best_t\n",
    "y_prob_opt_final = (te_probs_final * a.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_opt_final, thr=best_t, title=\"FINAL Retrain — Optuna Weights (Acc-opt on Test)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb8de0",
   "metadata": {},
   "source": [
    "#### 阈值调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top Drifted Features (TrainFit vs Test) ====\n",
      "      feature  is_categorical    PSI  KS/Chi2_p  KS_stat  missing_ref  missing_new  missing_diff\n",
      "   DR001_5dMA           False 2.5193     0.0000   0.2221       0.0000       0.0000        0.0000\n",
      "        DR001           False 2.3775     0.0000   0.2334       0.0000       0.0000        0.0000\n",
      "    二级5y-永续5y           False 1.7174     0.0000   0.3002       0.0000       0.0000        0.0000\n",
      "    二级3y-永续3y           False 1.2064     0.0000   0.2537       0.0000       0.0000        0.0000\n",
      "      永续5y-3y           False 1.0222     0.0000   0.2663       0.0000       0.0000        0.0000\n",
      "    二级1y-永续1y           False 0.9589     0.0000   0.3373       0.0000       0.0000        0.0000\n",
      "      永续5y-1y           False 0.9584     0.0000   0.2598       0.0000       0.0000        0.0000\n",
      "      二级5y-3y           False 0.9139     0.0000   0.1795       0.0000       0.0000        0.0000\n",
      "      永续3y-1y           False 0.9116     0.0000   0.2560       0.0000       0.0000        0.0000\n",
      " 永续5yYTM_5dMA           False 0.8802     0.0000   0.3292       0.0000       0.0000        0.0000\n",
      "永续1yYTM_20dMA           False 0.8345     0.0000   0.3554       0.0000       0.0000        0.0000\n",
      " 永续4yYTM_5dMA           False 0.8084     0.0000   0.3190       0.0000       0.0000        0.0000\n",
      "    R001_5dMA           False 0.7891     0.0000   0.2008       0.0000       0.0000        0.0000\n",
      "      永续4yYTM           False 0.7685     0.0000   0.2954       0.0000       0.0000        0.0000\n",
      "      永续5yYTM           False 0.7670     0.0000   0.3111       0.0000       0.0000        0.0000\n",
      " 永续3yYTM_5dMA           False 0.7341     0.0000   0.3112       0.0000       0.0000        0.0000\n",
      "NCD1mYTM_5dMA           False 0.6847     0.0000   0.2224       0.0000       0.0000        0.0000\n",
      "         R001           False 0.6703     0.0000   0.2206       0.0000       0.0000        0.0000\n",
      "永续5yYTM_20dMA           False 0.6701     0.0000   0.3101       0.0000       0.0000        0.0000\n",
      "      永续1yYTM           False 0.6432     0.0000   0.2816       0.0000       0.0000        0.0000\n",
      "永续2yYTM_20dMA           False 0.6217     0.0000   0.3436       0.0000       0.0000        0.0000\n",
      "   DR014_5dMA           False 0.6141     0.0000   0.2186       0.0000       0.0000        0.0000\n",
      "      永续2yYTM           False 0.6024     0.0000   0.2884       0.0000       0.0000        0.0000\n",
      "      永续3yYTM           False 0.5838     0.0000   0.2975       0.0000       0.0000        0.0000\n",
      "        TS持仓量           False 0.5746     0.0000   0.1992       0.0000       0.0000        0.0000\n",
      " 永续2yYTM_5dMA           False 0.5727     0.0000   0.2920       0.0000       0.0000        0.0000\n",
      "    R014_5dMA           False 0.5483     0.0000   0.2050       0.0000       0.0000        0.0000\n",
      "        TF持仓量           False 0.5471     0.0000   0.1710       0.0000       0.0000        0.0000\n",
      "    R007-R001           False 0.5437     0.0000   0.1903       0.0000       0.0000        0.0000\n",
      " 永续1yYTM_5dMA           False 0.5187     0.0000   0.2989       0.0000       0.0000        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 13:41:31,039] A new study created in memory with name: no-name-6c09e157-ba37-4fe6-9aa4-98fff3a9c25d\n",
      "[I 2025-09-01 13:41:31,071] Trial 0 finished with value: 0.7372262773722628 and parameters: {'w0': 0.5562024317905037, 'w1': 0.24844887489833534, 'w2': 0.11900770255525206, 'w3': 0.6844179007228934, 'w4': 0.17711178728571975, 'w5': 1.249819680526183, 'w6': 1.471395310454331, 'w7': 0.7585255502843307, 'w8': -0.7940725933426322, 'w9': 0.8073535757958905, 'w10': 2.3772048577062694, 'w11': -2.3733363276100543, 'w12': 0.6580696999084541, 'w13': 1.408027733657149, 'w14': 1.8866627245447338, 'w15': 0.20078520513631526, 'w16': -2.185433658222982, 'w17': 2.4644255449934613, 'w18': 0.03456125486076367, 'w19': -0.8040493094420214, 'w20': -1.2430066213111057, 'w21': -2.0633611147702053, 'w22': 1.6890868422391847, 'w23': -2.031591978149649, 'w24': 0.3295853968950375}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,107] Trial 1 finished with value: 0.7372262773722628 and parameters: {'w0': 2.12418271565744, 'w1': -1.94011998536394, 'w2': -2.286015248177977, 'w3': -0.5101764920708645, 'w4': 1.6036099726592843, 'w5': -0.5612922732183867, 'w6': 0.893906852920769, 'w7': -0.4899347600474018, 'w8': 1.3899787520624174, 'w9': 0.7537486995110285, 'w10': -0.3688599548452691, 'w11': 1.8169020163437466, 'w12': 0.8348574693297839, 'w13': -1.1460796682924475, 'w14': 2.365685915153792, 'w15': -0.4571922862143274, 'w16': 0.062057839703011375, 'w17': 1.890577769907683, 'w18': 1.3232704988774024, 'w19': 1.7227699667216285, 'w20': 2.1260624785892377, 'w21': -1.547437822456632, 'w22': 0.8445115595849377, 'w23': -1.0664458486611323, 'w24': 1.4791258680744463}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,144] Trial 2 finished with value: 0.7372262773722628 and parameters: {'w0': 0.8976969592819293, 'w1': -1.2245276436327213, 'w2': -0.8468754261259819, 'w3': 1.8727362915657118, 'w4': 0.7022668879760081, 'w5': 0.8610320266855793, 'w6': 1.8083845447424443, 'w7': -1.526740494710615, 'w8': -0.5062037693953991, 'w9': 0.4602235259372356, 'w10': -0.8153106597832971, 'w11': -1.3914885121916654, 'w12': 0.07722263468828672, 'w13': -2.34945206434463, 'w14': -1.3557092023452473, 'w15': 0.2837861378949884, 'w16': 0.5340580526441956, 'w17': 0.857399132078152, 'w18': 1.5623777049601788, 'w19': 1.9807773469801235, 'w20': -0.05244068756055231, 'w21': -2.267491750123734, 'w22': -1.983226563942453, 'w23': -1.6636020197835037, 'w24': 0.7986391996956241}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,177] Trial 3 finished with value: 0.7299270072992701 and parameters: {'w0': -2.3847717443447545, 'w1': 1.7103608714196126, 'w2': -1.7688185154467013, 'w3': -1.4393901346557803, 'w4': 0.2534847931074822, 'w5': 1.464617577542095, 'w6': -1.0156152738809743, 'w7': -2.257934157194545, 'w8': 0.16304087392771383, 'w9': -1.0263128499455287, 'w10': -2.2694389094076373, 'w11': 0.22794440335810018, 'w12': -1.2209038412204465, 'w13': 0.1415856744259929, 'w14': -2.2400758931110354, 'w15': 1.1268128507865942, 'w16': 1.2127308907603602, 'w17': -1.981865863943995, 'w18': -1.9312721704086666, 'w19': -2.3487012872028874, 'w20': -0.9099105600609214, 'w21': -0.8273604209990759, 'w22': 1.5677742828911532, 'w23': 1.7443011218018087, 'w24': 1.6008773764863395}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,199] Trial 4 finished with value: 0.7372262773722628 and parameters: {'w0': -0.7029821952051563, 'w1': -1.5890721915894974, 'w2': 1.268457747383346, 'w3': 0.26067927098317334, 'w4': -2.42935502509473, 'w5': -1.1889619869527601, 'w6': 2.1594047224104074, 'w7': 0.08419817866720081, 'w8': -1.8399755661993882, 'w9': -0.3215901603488245, 'w10': -1.7905586751750724, 'w11': 1.49189394212019, 'w12': -1.747914921804421, 'w13': -0.4755267838108357, 'w14': 0.34065499302101987, 'w15': -1.267535820153975, 'w16': -2.494258791437278, 'w17': 0.44463908948538355, 'w18': -1.3497417088059982, 'w19': -0.94639713320258, 'w20': 1.0202518603940662, 'w21': -0.6076670528931283, 'w22': -2.1282666260883616, 'w23': -1.5450103534338018, 'w24': 0.8095269761278323}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,220] Trial 5 finished with value: 0.7226277372262774 and parameters: {'w0': -2.4990667161254736, 'w1': -2.4136267076847773, 'w2': -0.9725620884804054, 'w3': 1.0598881549056176, 'w4': -0.2420400348774141, 'w5': -0.6996749619177012, 'w6': 2.0419963035798485, 'w7': 1.3874342069227987, 'w8': -1.9881985294827598, 'w9': -0.8086992496930034, 'w10': 0.6327085143031845, 'w11': -1.676047461548222, 'w12': -1.2910484790026082, 'w13': -0.29183248915109194, 'w14': -1.1952511541030337, 'w15': -0.7561634957052461, 'w16': 1.3469834320590124, 'w17': -1.6537180832292138, 'w18': 0.1372784067564492, 'w19': -0.4284440818250115, 'w20': -0.9162676500447149, 'w21': 2.1325703282184625, 'w22': -1.348217071114074, 'w23': 0.5869097239271097, 'w24': 1.149918144709873}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,241] Trial 6 finished with value: 0.7372262773722628 and parameters: {'w0': 0.842529520118116, 'w1': -0.4271613853638727, 'w2': 0.6802442410500538, 'w3': 0.5145375041180946, 'w4': 1.3873508630007048, 'w5': 1.8765827999775953, 'w6': 0.8064172106894318, 'w7': -0.7341230138228134, 'w8': -2.4178304146410645, 'w9': -0.3654347758008365, 'w10': 1.3202744255943646, 'w11': 2.4512329878626833, 'w12': -2.096146844830309, 'w13': -2.0119010692580357, 'w14': -1.1879686928639988, 'w15': 1.3321872074705956, 'w16': -0.5747927458870477, 'w17': 1.9247675331395921, 'w18': 0.9877224066614056, 'w19': 1.0129365539191273, 'w20': 2.0220995297238087, 'w21': -0.27608889001368375, 'w22': -0.01270775757920628, 'w23': 0.7107741857778715, 'w24': 2.0667674406917023}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,263] Trial 7 finished with value: 0.7226277372262774 and parameters: {'w0': -1.0637467345285279, 'w1': -1.249886014635213, 'w2': -0.05773414558620793, 'w3': 2.379930348354941, 'w4': -0.41329057656788004, 'w5': 1.1580074918861891, 'w6': 0.43712669318354447, 'w7': 1.9192155030652884, 'w8': 0.2127050701085409, 'w9': 1.64123545630863, 'w10': -1.1727411227847044, 'w11': 0.7552200075482269, 'w12': -0.4939989173453845, 'w13': 1.3305829917085852, 'w14': 2.2154897476171245, 'w15': 0.18817973641197927, 'w16': 1.2496828489465273, 'w17': -1.899318742571305, 'w18': 0.29750811321735515, 'w19': 1.5415878340101106, 'w20': 0.9699325156713701, 'w21': 2.2789836386472615, 'w22': 2.4440584653612447, 'w23': -1.385693898645165, 'w24': 1.074821095781286}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,286] Trial 8 finished with value: 0.7299270072992701 and parameters: {'w0': 0.7698604316767401, 'w1': 1.7293835579468455, 'w2': -1.1114222028580178, 'w3': -2.3412076084661764, 'w4': -2.4587116712956307, 'w5': 2.0861927416665154, 'w6': 1.5898698678965415, 'w7': -1.0683279012705238, 'w8': -1.070778155488115, 'w9': -1.1199727688111376, 'w10': 2.1721429164110466, 'w11': -2.2276032532238244, 'w12': 2.2803754935671012, 'w13': 1.6911273604284496, 'w14': 1.340193871367335, 'w15': 1.312085355586757, 'w16': -0.2444493807158974, 'w17': 1.310558211315354, 'w18': 1.4858305357045145, 'w19': 1.0162237202541764, 'w20': -1.5798697839573288, 'w21': 0.47336782776111974, 'w22': 2.326722873608772, 'w23': -1.744908256610254, 'w24': -1.3863602456408508}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,308] Trial 9 finished with value: 0.7226277372262774 and parameters: {'w0': -1.5275684884318559, 'w1': -0.1450358820224089, 'w2': -1.1306914530003582, 'w3': 0.7349634942555401, 'w4': 0.11956373883392724, 'w5': -1.1523865352357303, 'w6': 2.3755699292731904, 'w7': -1.832971381092785, 'w8': 1.2217011674636167, 'w9': -1.3408501149376795, 'w10': -2.4576087821021613, 'w11': -1.35567379292302, 'w12': 0.6707906007825954, 'w13': 2.3658932239427584, 'w14': -2.3175443483673592, 'w15': 2.453836422009574, 'w16': -0.8576397473862745, 'w17': 1.757245031256681, 'w18': -1.3660784129990755, 'w19': -2.361719882293196, 'w20': 0.5012342531923064, 'w21': 1.0770287706815251, 'w22': 0.7964400666027367, 'w23': -1.9690771715651363, 'w24': 1.9977108288392884}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,375] Trial 10 finished with value: 0.7372262773722628 and parameters: {'w0': 2.449270735089244, 'w1': 0.8529429715081442, 'w2': 2.220367515633854, 'w3': -0.7130993231527003, 'w4': 2.4872680996870375, 'w5': -2.3851364176753185, 'w6': -2.2234430212447642, 'w7': 0.8115162408561609, 'w8': 2.4537855084901223, 'w9': 2.4286982369405816, 'w10': 2.2868681772393185, 'w11': -0.5084432185731849, 'w12': 2.33454350065007, 'w13': 0.6289777408098738, 'w14': 0.8370657908570471, 'w15': -2.4875184932662697, 'w16': -2.088687984585238, 'w17': -0.5775896521852624, 'w18': 2.3215815388828687, 'w19': -1.2737931194254337, 'w20': -2.407845615940747, 'w21': -2.3909559675092735, 'w22': -0.750549239909204, 'w23': -0.4050851218882176, 'w24': -0.7414178796214979}. Best is trial 0 with value: 0.7372262773722628.\n",
      "[I 2025-09-01 13:41:31,449] Trial 11 finished with value: 0.7445255474452555 and parameters: {'w0': 2.191792172761383, 'w1': 0.6883204928969383, 'w2': -2.497551651558081, 'w3': -0.7376555513919506, 'w4': 1.6607464807027272, 'w5': 0.23034619555564517, 'w6': -0.27484735012830214, 'w7': 0.30858705161217737, 'w8': 1.294657948309157, 'w9': 0.7834353347312384, 'w10': 0.05355245466989755, 'w11': 1.858538406673182, 'w12': 1.2255936870666755, 'w13': -1.1739796680877153, 'w14': 2.4369152216778467, 'w15': -0.6253291715999304, 'w16': -1.3849649816624332, 'w17': 2.3384862740168835, 'w18': -0.9069263884183045, 'w19': 0.03586091846558426, 'w20': 2.375712553331292, 'w21': -1.403545774869482, 'w22': 1.228263365221507, 'w23': -0.5023971264320577, 'w24': 0.039194519345576176}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:31,523] Trial 12 finished with value: 0.7372262773722628 and parameters: {'w0': 1.5134680560290643, 'w1': 0.6809012986453267, 'w2': 0.12062156079878725, 'w3': -1.4124130487893827, 'w4': -1.1965594314248107, 'w5': 0.3415651921270706, 'w6': -0.5634174979931481, 'w7': 0.6685389781016254, 'w8': 1.0361821554235857, 'w9': 1.1963341190318686, 'w10': 0.43213770127482365, 'w11': -0.5209830504715081, 'w12': 1.3537913410114422, 'w13': -1.0567362501919983, 'w14': 1.6230513822580817, 'w15': -1.5560701592957766, 'w16': -1.5472771699114927, 'w17': 2.322115707033027, 'w18': -0.6999724343008593, 'w19': 0.16876737636156758, 'w20': -0.31730765302920894, 'w21': -1.6348999121348609, 'w22': 1.379990230727209, 'w23': -0.2511262500260724, 'w24': -0.4635852469193751}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:31,597] Trial 13 finished with value: 0.7299270072992701 and parameters: {'w0': 0.04006156463302579, 'w1': 0.685633783215174, 'w2': -2.4978819881401773, 'w3': 1.5080828219213558, 'w4': 2.2372824312770145, 'w5': 0.1729981708740611, 'w6': -0.35057735193252637, 'w7': 2.36003893357867, 'w8': 2.4233041987660124, 'w9': -2.155157686766462, 'w10': 1.356581005019284, 'w11': 1.118322263530875, 'w12': 1.456636457350013, 'w13': 0.8762390024436686, 'w14': 2.4998806712386537, 'w15': 0.574880206405734, 'w16': -1.3791225307135448, 'w17': -0.43443534177389453, 'w18': -0.5928956997360708, 'w19': 0.1637759455003259, 'w20': -1.9696675258340923, 'w21': -1.670819600637809, 'w22': 0.1941541068112984, 'w23': 2.3597065456809685, 'w24': -0.0021414716549199714}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:31,669] Trial 14 finished with value: 0.7372262773722628 and parameters: {'w0': 1.5864207480110277, 'w1': 2.2653654859926613, 'w2': 1.351701997520859, 'w3': -0.5224615777436069, 'w4': 1.0503849189094883, 'w5': 2.4279109166905544, 'w6': -1.8468535592558637, 'w7': 0.18890517855299893, 'w8': -0.9897933279849378, 'w9': 1.721017435064527, 'w10': 1.3075341052642449, 'w11': 0.19362037609247193, 'w12': -0.16537949380246508, 'w13': -1.5972584913940142, 'w14': 1.6257967231572374, 'w15': -0.461188353487427, 'w16': -1.5806831276264126, 'w17': 2.365775436966521, 'w18': -2.465777203696282, 'w19': -1.3026707811330995, 'w20': -1.2111832196257342, 'w21': -1.1782069578285688, 'w22': 1.7375220800010058, 'w23': -2.4498941938526384, 'w24': -1.8406261586045485}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:31,743] Trial 15 finished with value: 0.7226277372262774 and parameters: {'w0': 0.006376302516776051, 'w1': -0.7213695782502294, 'w2': -0.1102899189975409, 'w3': 0.038435462656870034, 'w4': -1.0593928526554983, 'w5': 0.5718686089478402, 'w6': 0.24449875892709838, 'w7': 1.27426238816934, 'w8': 0.6480034241220847, 'w9': 0.418891091158456, 'w10': 0.10770852689895696, 'w11': 2.412485223206375, 'w12': 1.6433377843456771, 'w13': 2.418367425531814, 'w14': -0.26076006394000606, 'w15': -1.8795830670922058, 'w16': -2.4144502387340934, 'w17': 1.1347204218936857, 'w18': -0.37797777819569656, 'w19': -0.4365213794639403, 'w20': 1.7107089758424452, 'w21': 0.4608706568438108, 'w22': 0.8159966873894553, 'w23': -0.547185274240453, 'w24': 0.2531254893708739}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:31,818] Trial 16 finished with value: 0.7299270072992701 and parameters: {'w0': 1.6717275677796428, 'w1': 1.247027053627714, 'w2': 0.48537229201353216, 'w3': -1.3592041532156567, 'w4': 1.8691564917889596, 'w5': -0.13834580685283443, 'w6': -1.334959593988128, 'w7': 0.6184380475316433, 'w8': 1.9140661850025653, 'w9': 1.033632382676479, 'w10': 1.8467050793724562, 'w11': -2.1697423276117584, 'w12': 0.6561693606877655, 'w13': -0.7964438645402739, 'w14': 0.7989300563855426, 'w15': -0.7995493466813657, 'w16': -1.0548567567760976, 'w17': 0.18798925203604933, 'w18': 0.6123448208862743, 'w19': 0.6388107376267174, 'w20': 2.433989331166957, 'w21': -2.0459264937651214, 'w22': 0.025091981096163566, 'w23': 0.5401812285855447, 'w24': -0.9831814914053599}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:31,891] Trial 17 finished with value: 0.7299270072992701 and parameters: {'w0': 0.5021049844993316, 'w1': 0.21376703623694898, 'w2': -0.5803234200164105, 'w3': 1.0658711258328866, 'w4': 0.8107863516514233, 'w5': 1.4944399303604572, 'w6': 1.4549351499075929, 'w7': -0.3419208912487943, 'w8': -0.45099096710401354, 'w9': 2.471187623103183, 'w10': -1.4133830904356919, 'w11': -0.7939149063141682, 'w12': 0.2113945011218138, 'w13': 0.2324933786078458, 'w14': 1.885829860850281, 'w15': 0.754664581627775, 'w16': 2.3296019456643524, 'w17': 2.492749500783546, 'w18': -1.232156492968616, 'w19': -1.5439954983974886, 'w20': -0.39009417062144913, 'w21': -0.970859472781537, 'w22': 1.8959512771540665, 'w23': -2.498180422210016, 'w24': 0.14695357998282793}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:31,962] Trial 18 finished with value: 0.7299270072992701 and parameters: {'w0': -0.6148377949073786, 'w1': 0.16872674851745248, 'w2': -1.7306488967917248, 'w3': -2.436595638103417, 'w4': -0.8389617390351114, 'w5': -2.25512676395663, 'w6': 1.0538485194502982, 'w7': 1.374472102040304, 'w8': -0.9728681898436439, 'w9': 0.1838710242445033, 'w10': 0.7881566688018959, 'w11': 0.8118017060547857, 'w12': -0.6503289172655233, 'w13': 1.6231125389649532, 'w14': 1.026634913942484, 'w15': 2.228474244301018, 'w16': -1.9756196496887024, 'w17': -1.1692474205200074, 'w18': -0.3059543670252338, 'w19': 2.4368597766947158, 'w20': 0.5363432686645224, 'w21': 0.00943236478902354, 'w22': 1.1694599556870175, 'w23': -0.9012085101970548, 'w24': -0.27631149762735374}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,032] Trial 19 finished with value: 0.7299270072992701 and parameters: {'w0': 1.3557973508454007, 'w1': 1.2929760223298958, 'w2': 1.2671795009091316, 'w3': -0.8273990591939906, 'w4': -1.6075481190188967, 'w5': 0.7509911147719297, 'w6': -0.2101147504892263, 'w7': 0.32508373703666327, 'w8': 1.6858257411131787, 'w9': 1.4462409213094185, 'w10': -0.23393547857597863, 'w11': -2.480541675163138, 'w12': 1.079565293588528, 'w13': -1.594223561934292, 'w14': -0.22391866624322443, 'w15': -0.24960009586467313, 'w16': -1.814768792786095, 'w17': 1.4623321013708135, 'w18': -2.044929959445927, 'w19': -0.46362402627042176, 'w20': 1.514195662291598, 'w21': -1.3894262549925083, 'w22': 0.4348678489039165, 'w23': 1.2431717338026549, 'w24': -2.2468585033823767}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,112] Trial 20 finished with value: 0.7372262773722628 and parameters: {'w0': 2.4628008175075005, 'w1': -0.46773217242752885, 'w2': 2.0098302355476987, 'w3': -0.12815988479307228, 'w4': 0.4436176760144286, 'w5': -0.10129088810136036, 'w6': -0.8564700211748926, 'w7': 1.8902311217145122, 'w8': 0.6470295793341209, 'w9': 2.0463645097833894, 'w10': 2.4866868436858427, 'w11': 1.784994977587162, 'w12': 1.9264140183172824, 'w13': 1.0453678916888283, 'w14': 0.2506781020280896, 'w15': 1.8747717631852416, 'w16': -1.1085769564527894, 'w17': 0.7837534101764319, 'w18': -0.9096454308778241, 'w19': -1.9004175793489102, 'w20': -2.49805177272979, 'w21': -1.9929443073695787, 'w22': -0.4620199362516657, 'w23': -0.8119474144384475, 'w24': 0.5174152401804338}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,190] Trial 21 finished with value: 0.7372262773722628 and parameters: {'w0': 2.05895941800675, 'w1': -2.3815753701503395, 'w2': -2.3065193902607093, 'w3': -0.5176538619074218, 'w4': 1.4787383188978542, 'w5': -0.5946155586622263, 'w6': 0.9971198877345513, 'w7': -0.4343297063254119, 'w8': 1.3791413029014385, 'w9': 0.7586429210624567, 'w10': -0.5226681557587476, 'w11': 1.8284678541172756, 'w12': 0.7552466306871356, 'w13': -1.1257415059974316, 'w14': 2.4888345739580284, 'w15': -1.0414520983227684, 'w16': 0.31781120269351293, 'w17': 1.8831051185649275, 'w18': 2.486708070340042, 'w19': 0.7061415089728034, 'w20': 2.480059566267331, 'w21': -1.7517233765788258, 'w22': 1.0983544178017952, 'w23': -1.1133652378230048, 'w24': 1.4321444641108847}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,262] Trial 22 finished with value: 0.7372262773722628 and parameters: {'w0': 1.960457078283511, 'w1': 0.3578622265958251, 'w2': -1.7340299051187227, 'w3': -1.1190218040856899, 'w4': 1.8398807219268665, 'w5': -1.590449558126797, 'w6': 0.603976047209122, 'w7': -0.2706557434619472, 'w8': 1.8773806710560184, 'w9': 0.8415283596626449, 'w10': -0.1284458674062407, 'w11': 2.0534380881857324, 'w12': 0.41368802133407634, 'w13': -1.537048473704953, 'w14': 2.0036421086680365, 'w15': -0.18436382002378904, 'w16': -0.17651469941007364, 'w17': 1.9361899020908777, 'w18': 0.9737432866984681, 'w19': 1.78832223150751, 'w20': 1.8393679459075623, 'w21': -2.477455428006115, 'w22': 2.0891160435438136, 'w23': 0.21136775355972492, 'w24': 2.3789799273044943}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,335] Trial 23 finished with value: 0.7445255474452555 and parameters: {'w0': 1.2052940894438118, 'w1': -1.6175344955742932, 'w2': -2.014219462326854, 'w3': -0.2884625378522756, 'w4': 1.2354524730528968, 'w5': -0.50572192962865, 'w6': 1.3262407796432119, 'w7': -0.9796408506319441, 'w8': 0.6977841479089001, 'w9': 0.005114003075316509, 'w10': -0.5685683708744446, 'w11': 1.278790290151586, 'w12': 1.1310261173894467, 'w13': -0.4656221361942081, 'w14': 1.3377406916970074, 'w15': -0.5018176687914548, 'w16': 0.6311989628901813, 'w17': 2.4941594976816814, 'w18': 1.9502689379708942, 'w19': -0.7691855749759045, 'w20': 1.2703868037847346, 'w21': -1.2825885661017589, 'w22': 0.6493545217598276, 'w23': -1.1748422810284807, 'w24': 0.5726772467230563}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,409] Trial 24 finished with value: 0.7445255474452555 and parameters: {'w0': 1.1831919773357646, 'w1': -0.6694598767794654, 'w2': -1.9351736916568156, 'w3': -1.8805888318678239, 'w4': 1.1094722019972365, 'w5': 1.0731719809328881, 'w6': 0.1976191855755895, 'w7': -1.0769451494970836, 'w8': -0.321153840822072, 'w9': -0.078193762793074, 'w10': -1.0242828677188274, 'w11': 1.0485944126293392, 'w12': 1.1719282514455316, 'w13': -0.4505003604672867, 'w14': 1.2594558476168272, 'w15': 0.23909955695514284, 'w16': 0.497449817879843, 'w17': 2.3263957665467347, 'w18': 1.9445684350164563, 'w19': -0.8003155045409771, 'w20': 1.2587861663022397, 'w21': -1.1160557864272627, 'w22': 1.509434489885375, 'w23': -2.1754962171527117, 'w24': 0.4974541139062597}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,500] Trial 25 finished with value: 0.7445255474452555 and parameters: {'w0': 1.1953512300625329, 'w1': -1.197280584910014, 'w2': -1.8757292263018293, 'w3': -1.9219696639498967, 'w4': 1.1889511090337141, 'w5': -0.19294081233057842, 'w6': -0.16308117259254368, 'w7': -1.1617578786329812, 'w8': 0.6515566515078955, 'w9': -0.188609705535634, 'w10': -1.3308664366039842, 'w11': 1.2597782560961523, 'w12': 1.8832777910392506, 'w13': -0.413262022785309, 'w14': 1.1759141918896125, 'w15': -1.6343888434532816, 'w16': 0.7565860090567575, 'w17': 1.4906084026192716, 'w18': 1.9423008148436216, 'w19': -0.12388207357244566, 'w20': 1.2575316987993164, 'w21': -0.5392207817706212, 'w22': 0.5443451539253004, 'w23': -2.103717726024633, 'w24': -0.16822021468384063}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,577] Trial 26 finished with value: 0.7372262773722628 and parameters: {'w0': 1.1576054343680977, 'w1': -0.818325561400076, 'w2': -1.4710893084199834, 'w3': -1.8149218703512977, 'w4': 1.9867642195437083, 'w5': 0.4389925820995366, 'w6': 0.1825133270353491, 'w7': -1.1811106881958788, 'w8': -0.15672989311632302, 'w9': -0.6255788246805125, 'w10': -0.8192362046199291, 'w11': 0.676043924645455, 'w12': 1.169260113419053, 'w13': -0.7028547458024873, 'w14': 1.4841191316948508, 'w15': 0.7030545082294924, 'w16': 2.1392581192459783, 'w17': 2.085442557762071, 'w18': 2.0430423116642613, 'w19': -0.7734621559022427, 'w20': 0.49186936048771046, 'w21': -1.1222455839024414, 'w22': -0.5173951087308195, 'w23': 0.0980580072048404, 'w24': 0.5745879084199428}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,655] Trial 27 finished with value: 0.7372262773722628 and parameters: {'w0': 1.8147079152610077, 'w1': -1.8255956410278258, 'w2': -2.083244417538216, 'w3': -1.902258967686691, 'w4': 0.8668878108677083, 'w5': 1.0110664774337124, 'w6': -1.2195557879839738, 'w7': -1.811576559358776, 'w8': 0.8902511654401748, 'w9': 0.10425419521634405, 'w10': 0.28333288446783655, 'w11': 1.4158543565633537, 'w12': 1.843647663569659, 'w13': -0.10819280043006818, 'w14': 0.521089923396403, 'w15': -0.9171284129560793, 'w16': 1.7210291887112428, 'w17': -2.3897758259339925, 'w18': 1.9461492231033957, 'w19': -1.771651551319089, 'w20': 1.4341745319165717, 'w21': -0.08711475119923451, 'w22': 1.2908195554987665, 'w23': -0.1982692980101881, 'w24': -0.6889969223222749}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,732] Trial 28 finished with value: 0.7372262773722628 and parameters: {'w0': 0.305076519312957, 'w1': -0.17286642339022462, 'w2': -1.4657357013086236, 'w3': -0.0851749151233343, 'w4': 0.5890844196889862, 'w5': -1.0495136003795347, 'w6': -0.5062124562356387, 'w7': -2.2934949835778626, 'w8': 0.3859572705653949, 'w9': -2.4175553305005337, 'w10': -1.8934172151167803, 'w11': 0.497193860166262, 'w12': 1.1377685674100415, 'w13': 0.3955867373165156, 'w14': 0.6386436291830948, 'w15': -0.4251406428338098, 'w16': 0.7045227579278326, 'w17': 0.9290601101853, 'w18': 0.6304612739698698, 'w19': -0.14275910529631863, 'w20': 0.8359417083045675, 'w21': -1.2492746835913215, 'w22': 2.0764998568428537, 'w23': -1.4103511457459676, 'w24': 0.9241027821542821}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,815] Trial 29 finished with value: 0.7445255474452555 and parameters: {'w0': 1.0553433041454872, 'w1': -0.937341386777241, 'w2': -2.082206384968864, 'w3': -0.8281905114493153, 'w4': 1.2033194033924017, 'w5': -1.7228226698333278, 'w6': -1.5671409345408351, 'w7': -0.9449670937915622, 'w8': -0.14196451955899086, 'w9': 0.3658828197177314, 'w10': -0.7684953442891281, 'w11': 1.0415047025215902, 'w12': -0.184822545248444, 'w13': -0.698217233308938, 'w14': 1.896352092101477, 'w15': 0.1648256039056747, 'w16': -0.518395542447255, 'w17': 1.564874262501895, 'w18': 1.0847828152556083, 'w19': -1.0009587831971902, 'w20': 2.0907351656208952, 'w21': -0.7080667147874381, 'w22': 1.4607602945300346, 'w23': -2.0511468904671535, 'w24': 0.3911921755539395}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,890] Trial 30 finished with value: 0.7372262773722628 and parameters: {'w0': 0.4043293428607728, 'w1': -1.6167384305499695, 'w2': -0.4684391582220344, 'w3': -1.0804572700196364, 'w4': 2.1765268004318257, 'w5': 0.14751993210019979, 'w6': 0.030891066929253863, 'w7': -1.515625616900779, 'w8': -0.46774717312828107, 'w9': -1.7560177345443144, 'w10': -1.1401677174686191, 'w11': 2.158277360597637, 'w12': 1.5373328592185098, 'w13': -1.8567532133613023, 'w14': -0.5221811478758167, 'w15': -0.008462562166334231, 'w16': 0.899302409519665, 'w17': 2.203543122824403, 'w18': -0.07214111102865393, 'w19': 0.459379655144146, 'w20': 0.20698014247577348, 'w21': 1.3236883059349092, 'w22': 0.5157912351918339, 'w23': -1.207206522670304, 'w24': -1.0569818535960978}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:32,965] Trial 31 finished with value: 0.7445255474452555 and parameters: {'w0': 1.3179032906703907, 'w1': -1.2441881370367698, 'w2': -1.9873612143240982, 'w3': -1.9035636264682219, 'w4': 1.1281309052558022, 'w5': -0.3001372911878878, 'w6': 1.3062823196679345, 'w7': -0.7550666380843514, 'w8': 0.5288639831588582, 'w9': -0.35210415832561925, 'w10': -1.5006825996203714, 'w11': 1.3999622188812109, 'w12': 1.9615436506826318, 'w13': -0.2250250276773376, 'w14': 1.1699781109034915, 'w15': -2.0347828763996967, 'w16': 0.2378227128813436, 'w17': 2.4739925685608157, 'w18': 1.849023401525716, 'w19': -0.21706051446509728, 'w20': 1.2245185407670733, 'w21': -0.38364007861525784, 'w22': 0.4925230185583478, 'w23': -1.9859962782018763, 'w24': -0.16313969082453286}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:33,041] Trial 32 finished with value: 0.7372262773722628 and parameters: {'w0': 2.0868278124386, 'w1': -1.9132148566937313, 'w2': -1.4153379983829986, 'w3': -1.7547841628810967, 'w4': 1.536225073635515, 'w5': -0.38431864102512675, 'w6': -0.1654312828633735, 'w7': -1.3683728119985157, 'w8': 0.8856795052573077, 'w9': -0.15522777479339495, 'w10': -0.5875219580493838, 'w11': 1.1808303479073374, 'w12': 2.132725203627088, 'w13': -0.46756172343121066, 'w14': 1.1261579742947019, 'w15': -1.3405264694567147, 'w16': 0.866703827299959, 'w17': 1.575956239944707, 'w18': 2.0792932046677395, 'w19': -0.7246166350337854, 'w20': 1.3412850931806546, 'w21': -0.5697166923171294, 'w22': 0.9269132816502275, 'w23': -2.3052430549706178, 'w24': -0.06304124078641549}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:33,116] Trial 33 finished with value: 0.7445255474452555 and parameters: {'w0': 0.7888604433283437, 'w1': -0.9757876773966061, 'w2': -2.4692484332782607, 'w3': -2.2192700864973336, 'w4': 1.6358623835390105, 'w5': 0.6315758894631393, 'w6': -0.6986263728468545, 'w7': -0.7051030120672297, 'w8': 1.585316351207765, 'w9': -0.011013114350663808, 'w10': -1.1214180151064663, 'w11': 1.6767255621509043, 'w12': 1.012002224708423, 'w13': -1.2777236562564536, 'w14': 2.0963133690240365, 'w15': -1.7312485856099857, 'w16': 0.3288011672055739, 'w17': 2.121451652135493, 'w18': 1.5036339798760028, 'w19': 0.03919430482070119, 'w20': 1.7412948596466016, 'w21': 0.18647521994430483, 'w22': -0.23230849672398857, 'w23': -0.7136315607678745, 'w24': 0.49876332856171}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:33,199] Trial 34 finished with value: 0.7299270072992701 and parameters: {'w0': 2.2842443264134307, 'w1': -1.4752130517335815, 'w2': -1.9824627355013393, 'w3': -1.6318400804669406, 'w4': 0.4279630529840124, 'w5': -0.7517202805035492, 'w6': 0.5136134534058772, 'w7': -1.8862144816462367, 'w8': -0.007661190199743595, 'w9': 0.5548517955770903, 'w10': -1.9339278785606082, 'w11': -0.1381084842771101, 'w12': 1.6219940504693446, 'w13': -0.9013840470985015, 'w14': 1.7097570954359604, 'w15': -2.2996178632932485, 'w16': -0.017327533302140652, 'w17': 1.716641218218498, 'w18': 2.268988885191656, 'w19': -1.148711713077273, 'w20': 2.232663775782764, 'w21': -0.9263316418823725, 'w22': 0.7260802849386707, 'w23': -1.7264024658432933, 'w24': -0.50894998474741}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:33,276] Trial 35 finished with value: 0.7372262773722628 and parameters: {'w0': 1.130227051463213, 'w1': -2.0733416586522333, 'w2': -2.2260520823344265, 'w3': -2.095509687758346, 'w4': 1.2312964440599905, 'w5': 0.10594061405944155, 'w6': 0.2125317172920222, 'w7': -0.11894849554057974, 'w8': 1.120921550279892, 'w9': -0.6587997073222772, 'w10': -0.38240466977411625, 'w11': 2.0992846304511397, 'w12': 0.4996779183003238, 'w13': 0.025233176646942357, 'w14': 1.3435429570355089, 'w15': -0.5054229579014841, 'w16': 1.8108083955567573, 'w17': 1.1500632248823444, 'w18': 1.6494087221723222, 'w19': -0.5814154525873528, 'w20': 0.7177005682714986, 'w21': -1.3842417790918384, 'w22': 1.6765531045282247, 'w23': -2.144631024881859, 'w24': 0.701444272869494}. Best is trial 11 with value: 0.7445255474452555.\n",
      "[I 2025-09-01 13:41:33,352] Trial 36 finished with value: 0.7518248175182481 and parameters: {'w0': 1.7239595537590295, 'w1': -0.4999340620430198, 'w2': -1.7156115372210645, 'w3': -0.2980565905570857, 'w4': 0.8887204235470534, 'w5': 1.5594094891183186, 'w6': 1.8218893557970313, 'w7': -1.336414341800144, 'w8': 0.307355753582409, 'w9': -0.08703894989651281, 'w10': -1.43983020081496, 'w11': 0.4612288640073329, 'w12': 2.441981572046173, 'w13': -0.4075403453246669, 'w14': 0.16219589477637641, 'w15': -1.1854948821407476, 'w16': 0.6312001850928748, 'w17': 0.5201085440627528, 'w18': 1.2681954427025224, 'w19': 0.39346286665283836, 'w20': 1.031018272784383, 'w21': -0.8087570455794466, 'w22': 0.285083206881054, 'w23': -1.6970612248085097, 'w24': 1.3730557428954522}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:33,429] Trial 37 finished with value: 0.7372262773722628 and parameters: {'w0': 1.7847900314112781, 'w1': -0.49656372657119074, 'w2': -1.385556356825715, 'w3': -0.2831741642501427, 'w4': -0.15331888335316957, 'w5': 1.5933645049824172, 'w6': 2.03349101059038, 'w7': -1.967766908734494, 'w8': -0.6977050325324041, 'w9': 0.18526822144871902, 'w10': 0.0641569762453853, 'w11': 0.4226259097419953, 'w12': 1.3462234386255023, 'w13': -2.443441357695399, 'w14': -0.6298766568797034, 'w15': -1.2938601474713205, 'w16': 1.0809818258659851, 'w17': -0.3581896081331688, 'w18': 1.2398639815441546, 'w19': 1.1772274771171598, 'w20': 0.23680562626759882, 'w21': -1.8835632697282056, 'w22': -1.1987820851561497, 'w23': -1.1335661652658118, 'w24': 1.3966112706923957}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:33,503] Trial 38 finished with value: 0.7445255474452555 and parameters: {'w0': -0.38163195594161436, 'w1': 0.48243776581655373, 'w2': -0.7675409985094939, 'w3': 0.34305161061238376, 'w4': 0.8059007755483467, 'w5': 1.7195765659991, 'w6': 1.6227530717801504, 'w7': -0.5632227423400356, 'w8': -1.3046571298738212, 'w9': -0.5913296562998095, 'w10': -1.6614608182224713, 'w11': -0.11148074012445268, 'w12': 0.12783585503061787, 'w13': -1.3498477327906078, 'w14': 0.12753542176299137, 'w15': -0.6564100654940103, 'w16': 0.49947683764980644, 'w17': 0.47775831437678806, 'w18': 1.7116145877402946, 'w19': 0.3078388641097851, 'w20': 1.6373898729607528, 'w21': -0.8561615614098009, 'w22': 0.27904547867043256, 'w23': -1.4996314283954115, 'w24': 1.110862986893132}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:33,578] Trial 39 finished with value: 0.7372262773722628 and parameters: {'w0': 1.4686517374062356, 'w1': -0.10671436666754253, 'w2': -1.6522856436007627, 'w3': -0.32076971943009613, 'w4': 1.599184739619522, 'w5': 1.3216491697038324, 'w6': 1.199231625937112, 'w7': -1.59883101364267, 'w8': 0.28116281932081166, 'w9': 0.5593601925033349, 'w10': -0.9180059111158414, 'w11': 0.8909296025369102, 'w12': -0.80690580247952, 'w13': 0.36999905448623216, 'w14': -0.8692976781830111, 'w15': -1.0691329080952354, 'w16': 1.4305389091487497, 'w17': -0.9752198504581245, 'w18': 0.6709557662740998, 'w19': 0.6734399088622439, 'w20': 1.1413713253975213, 'w21': -1.4258305276075878, 'w22': -1.7753837922533522, 'w23': -1.7482149435765926, 'w24': 1.8513744676430905}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:33,659] Trial 40 finished with value: 0.7299270072992701 and parameters: {'w0': -2.0479042084490313, 'w1': 1.1379890184430397, 'w2': -1.1453212737800391, 'w3': 0.13834884460311947, 'w4': 0.28534789785725, 'w5': 0.992164294893109, 'w6': 2.4827953506603304, 'w7': 0.38911630206933695, 'w8': -0.32956225830672803, 'w9': 1.2112536772165678, 'w10': -2.161371382481278, 'w11': 1.5082073370306406, 'w12': 2.1777061492522702, 'w13': -0.5806689840129137, 'w14': -0.10649520429409137, 'w15': 0.41798120422798624, 'w16': -0.31723512819640576, 'w17': -0.06146985360441082, 'w18': 1.290966056595881, 'w19': -0.27416369902985516, 'w20': 1.9556268948148436, 'w21': -2.205895766256326, 'w22': 1.0412685470310976, 'w23': -0.9442640778674298, 'w24': 1.6636394016328133}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:33,737] Trial 41 finished with value: 0.7445255474452555 and parameters: {'w0': 0.9504105674170567, 'w1': -1.0922804245471949, 'w2': -1.8948349988551814, 'w3': -1.1105091064258716, 'w4': 0.9838926061748348, 'w5': 2.083658324458346, 'w6': 1.8311301343446107, 'w7': -1.1480680966452357, 'w8': 0.7299404091522204, 'w9': -0.10741111873392035, 'w10': -1.338167950567555, 'w11': 1.228109929160902, 'w12': 2.4000096749875937, 'w13': -0.3699709000952299, 'w14': -1.7791866109768435, 'w15': -1.5325206710594887, 'w16': 0.6174737103678823, 'w17': 2.066047096592998, 'w18': 2.2194361666822613, 'w19': -0.050165374262801626, 'w20': 0.9756329692526333, 'w21': -0.4544609664940467, 'w22': 0.5988705767819433, 'w23': -1.8254225453552677, 'w24': 0.8816959523391044}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:33,818] Trial 42 finished with value: 0.7445255474452555 and parameters: {'w0': 2.2363109099221377, 'w1': -0.6627190390241096, 'w2': -2.3413964685844197, 'w3': 0.6536609383232292, 'w4': 1.33459388708677, 'w5': -0.935508686953751, 'w6': 0.7798262534715996, 'w7': -1.3942257684818378, 'w8': 0.09907586573574712, 'w9': -1.038472006571264, 'w10': -0.9968844007497949, 'w11': 0.23081003580201093, 'w12': 2.492833282704272, 'w13': -0.13101162073133235, 'w14': 0.4414757037251731, 'w15': -1.155678990293315, 'w16': 0.12020410962218459, 'w17': 0.6714537683864026, 'w18': 2.4659605658977055, 'w19': 0.3856954726081938, 'w20': 1.437375910939259, 'w21': -0.7179895010565657, 'w22': 0.20465945878278263, 'w23': -1.309086681080908, 'w24': 0.1206723293587596}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:33,898] Trial 43 finished with value: 0.7372262773722628 and parameters: {'w0': 0.6372357061112099, 'w1': -1.4486357933942715, 'w2': -2.2498237653080713, 'w3': -1.575200247487895, 'w4': 0.5919017315422147, 'w5': -0.38772182460564214, 'w6': -0.06395482628185925, 'w7': -0.9652555134154044, 'w8': 0.4045142394252043, 'w9': -0.29585249958000204, 'w10': -0.5256973658957758, 'w11': 0.49793786288207276, 'w12': -2.4463953312880005, 'w13': -0.9869514891237768, 'w14': 2.257147362323085, 'w15': -0.015654075007858648, 'w16': 1.0706426631059822, 'w17': 1.2875870650625225, 'w18': 1.7819466299379092, 'w19': -0.9693654001416476, 'w20': 1.1646482059557557, 'w21': -0.22916476668107588, 'w22': -0.14910080725803782, 'w23': -1.5527955792483343, 'w24': 1.2537564637351226}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:33,978] Trial 44 finished with value: 0.7445255474452555 and parameters: {'w0': 1.3065453063257348, 'w1': -0.3543182580807285, 'w2': -1.6994939506660391, 'w3': -0.647952143306816, 'w4': 1.7364352713653275, 'w5': 1.3167715604053465, 'w6': -0.8889443579787768, 'w7': -2.1331841216333904, 'w8': 1.2720403863995975, 'w9': -0.8447930832446394, 'w10': -0.708452214144244, 'w11': 1.6275972056546448, 'w12': 1.7287290916296532, 'w13': 0.07969755575951554, 'w14': 0.8277858714932443, 'w15': 0.9292659780038911, 'w16': 1.500023136233442, 'w17': 1.901298163577961, 'w18': 1.5518409639572432, 'w19': -0.7010945081494009, 'w20': 0.7198074084269799, 'w21': -0.9895320602031676, 'w22': -2.460752933302175, 'w23': -2.270029630684707, 'w24': -0.4062524285999316}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,071] Trial 45 finished with value: 0.7518248175182481 and parameters: {'w0': 1.8684425805422404, 'w1': -2.198243357407078, 'w2': -1.2578593986773599, 'w3': -2.0908410688262635, 'w4': 2.4601589009958804, 'w5': 0.32089792493744296, 'w6': 2.243739341912038, 'w7': -0.08934408307660613, 'w8': -1.4124488895036165, 'w9': -1.2366860957104575, 'w10': -1.6856281607425794, 'w11': 0.958357714109726, 'w12': 2.0158543257313375, 'w13': -0.4116244892527499, 'w14': 1.0580643989961616, 'w15': -1.5396472077389887, 'w16': 0.4555318431095108, 'w17': 2.265695377413885, 'w18': -1.6583180954057306, 'w19': 1.2258706779013409, 'w20': -0.13013281819976674, 'w21': -1.1381710708329893, 'w22': 1.425459926845319, 'w23': -1.9217285961181965, 'w24': 0.34379568768187296}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,150] Trial 46 finished with value: 0.7445255474452555 and parameters: {'w0': 1.9276659752181675, 'w1': -2.192856561242655, 'w2': -0.8736913124700575, 'w3': -1.2765740543045787, 'w4': 2.4979607201718816, 'w5': 1.0277505692248248, 'w6': 2.0957651460779863, 'w7': -0.031120067379331318, 'w8': -1.170602994898048, 'w9': -1.2742358968835994, 'w10': -1.6415013503783378, 'w11': 0.988242768347295, 'w12': 0.950485863557846, 'w13': -2.0082049133986897, 'w14': 0.9280518004440714, 'w15': -0.6748328615275192, 'w16': -0.05262283825093883, 'w17': 2.290496861283566, 'w18': -1.783053283454998, 'w19': 1.44011130946677, 'w20': 0.0023016151904289295, 'w21': -1.6951704867727904, 'w22': 1.492741185125548, 'w23': -0.586701959968433, 'w24': 0.7516483127667598}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,237] Trial 47 finished with value: 0.7445255474452555 and parameters: {'w0': 1.6620667655760195, 'w1': -2.499135057941092, 'w2': -1.313314929242519, 'w3': 0.29814897612395624, 'w4': 2.2605860413844656, 'w5': 0.35468459904123517, 'w6': 2.270786378671019, 'w7': 1.0577883120705998, 'w8': -1.5210270632696825, 'w9': -1.6314670656082892, 'w10': 0.7694700507106467, 'w11': 0.6188207508938774, 'w12': 2.11498172356162, 'w13': 0.5423517125586466, 'w14': 1.3757801366652291, 'w15': -2.10872046440235, 'w16': 0.4697929329335917, 'w17': 2.4967944277520417, 'w18': -1.1624341546200605, 'w19': 1.1988771707923844, 'w20': -0.30279480632010136, 'w21': -1.5059479626953627, 'w22': 1.7952345072224005, 'w23': -1.8535826192062432, 'w24': 0.3108551315755824}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,320] Trial 48 finished with value: 0.7518248175182481 and parameters: {'w0': 2.2866375035806192, 'w1': -2.1832587130503796, 'w2': -1.1761073230175412, 'w3': -2.4925360501150524, 'w4': 2.023947099691084, 'w5': 0.8135773971637077, 'w6': 1.8190892424512102, 'w7': -0.8127324141990849, 'w8': -2.3823686878786923, 'w9': -1.5602286819479827, 'w10': -2.2644816510640564, 'w11': 1.984306477316568, 'w12': 1.4009407895026673, 'w13': -0.5854015436951585, 'w14': 1.588815376140898, 'w15': -1.389316470371003, 'w16': -0.5593574399096609, 'w17': 1.7115009445115459, 'w18': -1.550723554404696, 'w19': -1.5037632453614638, 'w20': -0.7074949726922354, 'w21': -1.2375051960225758, 'w22': 1.2981567408003976, 'w23': -1.6193022934561343, 'w24': 1.0858327091082085}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,398] Trial 49 finished with value: 0.7445255474452555 and parameters: {'w0': 2.2864002476119683, 'w1': -2.199176594467398, 'w2': -0.4432560932549263, 'w3': 1.0517645791050283, 'w4': 1.9916735993575985, 'w5': 0.7068489073493975, 'w6': 1.9876584582274641, 'w7': 0.10407595395752733, 'w8': -2.495757129062916, 'w9': -1.57677622013998, 'w10': -2.4104455621638348, 'w11': 1.9611486616486564, 'w12': 1.3861174062613155, 'w13': -1.263747638126725, 'w14': 1.749536116798396, 'w15': -1.4060470234984368, 'w16': -0.6721788919425733, 'w17': 1.731419868835972, 'w18': -1.6531094336163392, 'w19': -2.2124445171023894, 'w20': -0.6251590208314451, 'w21': -1.8323301887147652, 'w22': 1.2055235951632781, 'w23': -0.31900437943159715, 'w24': 1.7438865165932107}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,482] Trial 50 finished with value: 0.7445255474452555 and parameters: {'w0': 2.3720606549514898, 'w1': -1.780740226124593, 'w2': -1.1272485016704104, 'w3': -2.217945977844135, 'w4': 2.1563594561598727, 'w5': 0.47124614715809543, 'w6': 1.622320511428542, 'w7': -0.5782483491805998, 'w8': -2.0970704210531266, 'w9': -1.8169124210108403, 'w10': -2.144812123716637, 'w11': 2.369129109802258, 'w12': 2.0684685339674007, 'w13': -0.8517278530300348, 'w14': 0.6476207424600104, 'w15': -0.9469350653967509, 'w16': -0.4582391690400154, 'w17': 1.0475243984476603, 'w18': -2.2536450100640635, 'w19': -1.5394824599997814, 'w20': -0.6429588590264297, 'w21': -2.211800292447407, 'w22': 0.9503949227732678, 'w23': -1.3377267309238006, 'w24': 1.0179961291726656}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,574] Trial 51 finished with value: 0.7518248175182481 and parameters: {'w0': 2.0766958415229886, 'w1': -1.7035924455743454, 'w2': -1.5555565912308693, 'w3': -2.4342982268351716, 'w4': 2.3445452275568837, 'w5': 0.8023634230841992, 'w6': 1.8828578635238453, 'w7': -0.8413278437000151, 'w8': -1.809000976487476, 'w9': -1.933541137657024, 'w10': -2.0415633262419197, 'w11': 2.2637970400859446, 'w12': 1.3465672190864801, 'w13': -0.6427221227787563, 'w14': 1.4929592757992975, 'w15': -0.26556214804520384, 'w16': -0.7580984262057704, 'w17': 2.220785274672466, 'w18': -1.3372624846439658, 'w19': -1.4818703379086635, 'w20': -0.9103803523256337, 'w21': -1.1677092822053046, 'w22': 1.9757330282210432, 'w23': -1.6393766410896766, 'w24': 0.6517412937230842}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,663] Trial 52 finished with value: 0.7518248175182481 and parameters: {'w0': 1.8560185526334565, 'w1': -2.0789060631453915, 'w2': -0.6508779873681731, 'w3': -2.417650989953703, 'w4': 2.2541001714773024, 'w5': 0.8394107443457826, 'w6': 1.7841937887419612, 'w7': -0.8439808943880303, 'w8': -2.149504856401103, 'w9': -2.056277223040264, 'w10': -1.9992624865088797, 'w11': 2.2809514191365308, 'w12': 1.332699980740508, 'w13': -0.17078841184715557, 'w14': 1.4664566073097978, 'w15': -0.3448776573977934, 'w16': -0.8060004067552506, 'w17': 2.1854143668939607, 'w18': -1.4867027912063953, 'w19': -1.4490510181276721, 'w20': -1.1767687429516809, 'w21': -1.182020098182056, 'w22': 1.895256658896336, 'w23': -1.610697837299968, 'w24': 1.253440453047587}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,750] Trial 53 finished with value: 0.7445255474452555 and parameters: {'w0': 2.498169506759102, 'w1': -2.2430457834956155, 'w2': -0.710985409909578, 'w3': -2.469008273958706, 'w4': 2.3397502309989746, 'w5': 0.8418687300135863, 'w6': 1.8060350464084252, 'w7': -0.2811270911603362, 'w8': -2.192658516557707, 'w9': -1.9762231269255133, 'w10': -2.0722547663059037, 'w11': 1.9073663980216256, 'w12': 1.6928198500143636, 'w13': -0.6348267661060051, 'w14': 1.5919096791092024, 'w15': -0.21345410784003566, 'w16': -0.833521667426756, 'w17': 2.038099004513442, 'w18': -1.5520535066185794, 'w19': -1.9863987872284583, 'w20': -1.3131980235784295, 'w21': -1.5946619558086135, 'w22': 2.3830547255308017, 'w23': -1.5909774714338318, 'w24': 1.2698420359845863}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,828] Trial 54 finished with value: 0.7445255474452555 and parameters: {'w0': 2.085510883208117, 'w1': -1.9632472360021052, 'w2': -0.9867865322032442, 'w3': -2.1188121261271458, 'w4': 2.0658064614964644, 'w5': 0.2871008471486901, 'w6': 2.2584651212160307, 'w7': -0.7814905150950308, 'w8': -1.642894185083739, 'w9': -2.280104950116498, 'w10': -2.388183921758085, 'w11': 2.231429742350776, 'w12': 2.3074617822703183, 'w13': -0.19661249697460567, 'w14': 2.2339802924848104, 'w15': -1.8305617274063686, 'w16': -1.0235278919556134, 'w17': 2.194589321228766, 'w18': -1.0254430561467942, 'w19': -1.4123748076863016, 'w20': -1.717490967616297, 'w21': -1.0468037802820687, 'w22': 2.001677159144062, 'w23': -1.8981734187547907, 'w24': 2.13503966522023}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,903] Trial 55 finished with value: 0.7445255474452555 and parameters: {'w0': 1.8139417305338519, 'w1': 1.5939243750375431, 'w2': -0.2916018352714017, 'w3': -2.3301486413094037, 'w4': 2.3785130483983723, 'w5': 1.8469361993942148, 'w6': 1.7410869094174426, 'w7': 0.47143516280475484, 'w8': -1.9675201888037854, 'w9': -1.4279107986658084, 'w10': -1.9091092938574505, 'w11': 2.475042891878248, 'w12': 1.396812223614535, 'w13': 0.2071289346973034, 'w14': 1.8253487952388658, 'w15': -0.7980789044284201, 'w16': -1.3027410359426972, 'w17': 1.7907067472505398, 'w18': -1.3795377041472308, 'w19': -2.472927731813965, 'w20': -1.04513132658677, 'w21': -0.7012004316962712, 'w22': 2.273924987049736, 'w23': 1.0417462913840785, 'w24': 1.6084817751833551}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:34,983] Trial 56 finished with value: 0.7445255474452555 and parameters: {'w0': 1.5111225338902645, 'w1': -2.3502419446961316, 'w2': 0.1581113731776261, 'w3': -2.480479000958194, 'w4': 1.8778765676327194, 'w5': 0.8241417606675797, 'w6': 2.495078939177472, 'w7': -0.13870807864571155, 'w8': -2.2446636344671784, 'w9': -2.101445929023786, 'w10': -1.642304778926578, 'w11': 2.2352375651513126, 'w12': -1.4880311671295838, 'w13': -1.041336842905493, 'w14': 1.0038597964033045, 'w15': -1.4439633697912597, 'w16': -0.8305401865110779, 'w17': 1.3584450068621297, 'w18': -1.979690931905862, 'w19': 2.3395488202926633, 'w20': -0.7910375529133782, 'w21': -1.2512390570186336, 'w22': 1.6802681696682191, 'w23': -0.9802542939696922, 'w24': 1.2310988920034844}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:35,060] Trial 57 finished with value: 0.7445255474452555 and parameters: {'w0': 1.9313077200951372, 'w1': -2.0331300993066415, 'w2': -1.2419785355529673, 'w3': -2.0392247066446023, 'w4': 2.4867680733288164, 'w5': 1.1979477360747683, 'w6': 1.4682775434123128, 'w7': 0.2618382008977013, 'w8': -1.8173775999616448, 'w9': -1.9627060676771255, 'w10': -2.246749348491174, 'w11': 1.7037137785954983, 'w12': 0.9202031833136042, 'w13': 0.7764361430978999, 'w14': 1.9923620866646137, 'w15': -1.1658953550420865, 'w16': -1.4074231005852056, 'w17': 1.9656271722041285, 'w18': -0.566886073939875, 'w19': -1.6977870572512082, 'w20': -1.5322252652135142, 'w21': -1.5482917030803032, 'w22': 2.2196278914832392, 'w23': -1.5821785385700848, 'w24': 0.10195369105833585}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:35,137] Trial 58 finished with value: 0.7445255474452555 and parameters: {'w0': 1.658624330981758, 'w1': -1.738524701037342, 'w2': -1.5271079589121739, 'w3': -1.5631102183478331, 'w4': 1.7587417187821517, 'w5': 0.02349105503459703, 'w6': 1.8225555149722332, 'w7': -1.6622055909352689, 'w8': -2.35453198091671, 'w9': -2.4845316465290033, 'w10': -1.858716148710418, 'w11': 2.3136514659264185, 'w12': 1.8074309034250802, 'w13': -0.7971821560044132, 'w14': 1.5054517556848128, 'w15': -0.39859405981588325, 'w16': -1.1432715758582115, 'w17': 1.6610147702020293, 'w18': -0.8839871590215074, 'w19': -2.1449273550199264, 'w20': -1.176183234464872, 'w21': -0.8509464248591444, 'w22': 1.3086521651065204, 'w23': 1.9926849074523694, 'w24': 1.50744746917112}. Best is trial 36 with value: 0.7518248175182481.\n",
      "[I 2025-09-01 13:41:35,225] Trial 59 finished with value: 0.7445255474452555 and parameters: {'w0': 2.1822945661034763, 'w1': 0.8692035073802571, 'w2': -0.9243327520331555, 'w3': -2.3024836024418027, 'w4': 2.0481825572223906, 'w5': 2.3276369711786717, 'w6': 2.1821665389527247, 'w7': -2.4994625571466598, 'w8': -1.4744054694808655, 'w9': -1.2354574043995274, 'w10': -1.5363618566262116, 'w11': 1.9666617490906413, 'w12': 0.6113086737887083, 'w13': -1.4598432555331258, 'w14': 2.323583980864451, 'w15': -0.8975223473147992, 'w16': -0.6837927698233051, 'w17': 0.27989635879605634, 'w18': -1.4868991683978743, 'w19': 0.9980538256566592, 'w20': -0.48356895170731956, 'w21': 1.075071790905361, 'w22': 1.9306517210585992, 'w23': -2.332931196466107, 'w24': 0.8002857325451587}. Best is trial 36 with value: 0.7518248175182481.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[BASELINE - NO LEAK] alphas (first 10): [0.1004 0.0109 0.0032 0.0133 0.0436 0.0852 0.1108 0.0047 0.0244 0.0164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 13:41:35,628] A new study created in memory with name: no-name-25c2acde-f14f-44c9-a098-9e06d5dc7fcb\n",
      "[I 2025-09-01 13:41:35,667] Trial 0 finished with value: 0.641399416909621 and parameters: {'w0': -1.83902826133015, 'w1': 0.36434227485368975, 'w2': 0.10485984581891028, 'w3': 1.6713376355932166, 'w4': -1.5131408436739457, 'w5': -1.4154102555625714, 'w6': 0.5481338346965359, 'w7': 1.238941364874517, 'w8': -2.0362980799489208, 'w9': -2.3263849059910795, 'w10': 2.4616299436572886, 'w11': 0.5699011670829068, 'w12': 0.2105610878261266, 'w13': 2.255400905727213, 'w14': -2.398964491803862, 'w15': 1.7430386591802254, 'w16': 0.06671913691191644, 'w17': 0.26460187131148327, 'w18': 0.9636866598678684, 'w19': -1.0720027559387453, 'w20': 1.9768511429513849, 'w21': 1.2104286597720941, 'w22': -0.9201266030011772, 'w23': -2.0996471903215626, 'w24': 1.3586900030851212}. Best is trial 0 with value: 0.641399416909621.\n",
      "[I 2025-09-01 13:41:35,702] Trial 1 finished with value: 0.6384839650145773 and parameters: {'w0': 1.4123066144485734, 'w1': -1.9728923418344375, 'w2': -2.3407855581327004, 'w3': -0.03661083047131308, 'w4': 1.2781483941793361, 'w5': 0.2808451602407036, 'w6': 1.1324930840011964, 'w7': 0.7096386032663506, 'w8': 1.9337351192142886, 'w9': -0.8075435059666853, 'w10': -1.4898469601850495, 'w11': 2.1227295140885394, 'w12': 1.0752686423282034, 'w13': 2.215467170680977, 'w14': -2.258586330847016, 'w15': -1.2882227534275863, 'w16': -2.127231767689703, 'w17': -0.9443430797859254, 'w18': -1.8232743114858296, 'w19': 1.0434927936831269, 'w20': 2.03854525560161, 'w21': -1.5261027948308925, 'w22': 0.13987551640253137, 'w23': 0.685029284204528, 'w24': 0.28120810004117924}. Best is trial 0 with value: 0.641399416909621.\n",
      "[I 2025-09-01 13:41:35,734] Trial 2 finished with value: 0.6355685131195336 and parameters: {'w0': -0.32876766129123647, 'w1': -0.05899730954092286, 'w2': 0.1775351737296269, 'w3': -1.8181534102631047, 'w4': -0.9747500373941997, 'w5': -0.6595093497797682, 'w6': 0.5553386821862949, 'w7': 0.2035310488254849, 'w8': -1.5038536844579293, 'w9': 2.2567333378541834, 'w10': 1.8903091400241037, 'w11': 1.5873475991902666, 'w12': 1.683098334469321, 'w13': 0.40642860444583917, 'w14': -0.05023326313002485, 'w15': 1.5815620519827247, 'w16': -1.0400415325298773, 'w17': 2.014399604519011, 'w18': 2.2980385835054387, 'w19': 1.5721647360731934, 'w20': -1.8578842165383262, 'w21': 1.6682507718098494, 'w22': 1.1885954190430303, 'w23': 0.9722930120095725, 'w24': 1.0295673671847454}. Best is trial 0 with value: 0.641399416909621.\n",
      "[I 2025-09-01 13:41:35,756] Trial 3 finished with value: 0.6443148688046647 and parameters: {'w0': 1.2091390723231656, 'w1': 1.1719891468772676, 'w2': -0.38151537048843176, 'w3': -0.9634620676305838, 'w4': 0.6328377471046487, 'w5': 0.4520026662489398, 'w6': 1.9385457914515278, 'w7': 0.39083802865343564, 'w8': 1.615347920259456, 'w9': 0.24303014242930132, 'w10': 0.9936396424029121, 'w11': 2.4648618178742003, 'w12': -0.3002374769981948, 'w13': -1.3980051727912697, 'w14': -1.8966694734280776, 'w15': 2.410570951017302, 'w16': -1.5944270490876433, 'w17': 1.1813047641806635, 'w18': 1.5866547221104907, 'w19': 1.4050110961273714, 'w20': -2.2954486476310376, 'w21': -1.9359511900410586, 'w22': 1.8754879164892557, 'w23': -1.8101859040903694, 'w24': 2.0395034042365916}. Best is trial 3 with value: 0.6443148688046647.\n",
      "[I 2025-09-01 13:41:35,779] Trial 4 finished with value: 0.6326530612244898 and parameters: {'w0': 1.4629607496411823, 'w1': -2.270884688532331, 'w2': 0.6706254127310314, 'w3': 1.1063883010605764, 'w4': 0.11343492820202083, 'w5': 2.2544999242956223, 'w6': -1.5877427462322236, 'w7': 0.5100150995307962, 'w8': -2.333181796623431, 'w9': -1.958091767541691, 'w10': -2.3185213421915982, 'w11': -1.2176680115571976, 'w12': 0.1553330620378155, 'w13': -1.4556276641856891, 'w14': 1.5256691637342197, 'w15': 1.1433916778847344, 'w16': -0.1309419324887111, 'w17': -1.6454622874845648, 'w18': -2.1088335658332635, 'w19': 2.2448026779681483, 'w20': 1.7908298851551425, 'w21': -0.12342738405738451, 'w22': -1.2967685794686896, 'w23': 0.038209122272259144, 'w24': -0.5812068461387843}. Best is trial 3 with value: 0.6443148688046647.\n",
      "[I 2025-09-01 13:41:35,801] Trial 5 finished with value: 0.6443148688046647 and parameters: {'w0': 1.7596186430967382, 'w1': -1.407600261306159, 'w2': 1.1139134522880618, 'w3': -0.9971026055439247, 'w4': 2.038058623673356, 'w5': 0.11271886650569751, 'w6': 1.3889275347637957, 'w7': 1.474491550908935, 'w8': 1.1984536981897698, 'w9': 1.7668011656152363, 'w10': 1.9314025016069705, 'w11': -1.2615616291634046, 'w12': -1.6693961312831478, 'w13': 2.2283621964624425, 'w14': 0.6975283478946439, 'w15': -1.0724534622800197, 'w16': 0.516703186181565, 'w17': -1.1351006246362505, 'w18': -2.468318556434192, 'w19': -0.6035047683782513, 'w20': -1.7811666729134434, 'w21': -0.1639264592527354, 'w22': 1.3194864842490217, 'w23': 1.6831486032108787, 'w24': 0.6513222538828827}. Best is trial 3 with value: 0.6443148688046647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Test (Baseline, tuned on VAL) Performance ====\n",
      "Accuracy:      0.562682\n",
      "AUC:           0.637502\n",
      "PR-AUC:        0.503604\n",
      "LogLoss:       0.659259\n",
      "Precision@0.400: 0.475113\n",
      "Recall@0.400:    0.755396\n",
      "F1@0.400:        0.583333\n",
      "\n",
      "======================  WARNING: TEST LEAK MODE (DO NOT USE IN PRODUCTION)  ======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 13:41:35,824] Trial 6 finished with value: 0.6384839650145773 and parameters: {'w0': 1.8443963556128509, 'w1': 0.48696228962707977, 'w2': -0.7809932126809005, 'w3': -2.3972276389225815, 'w4': -1.41195101153013, 'w5': -1.0605715661797155, 'w6': -0.9921370517802375, 'w7': -1.975659600481157, 'w8': 1.7409906888861366, 'w9': -1.6855338538716336, 'w10': 2.3276576472382153, 'w11': -1.6793651050888152, 'w12': 0.3104945951882181, 'w13': 1.4735652794612415, 'w14': 2.3220452391733746, 'w15': -0.8462058803847401, 'w16': -1.7985244519071175, 'w17': -1.6409437748563127, 'w18': 0.48882423075858306, 'w19': -1.9710626419935195, 'w20': 1.9170850568565543, 'w21': 0.7735070242661095, 'w22': -1.971916559299351, 'w23': -1.1156203203005406, 'w24': -1.464147395932034}. Best is trial 3 with value: 0.6443148688046647.\n",
      "[I 2025-09-01 13:41:35,846] Trial 7 finished with value: 0.6501457725947521 and parameters: {'w0': 2.1391716080090886, 'w1': 0.936753334896065, 'w2': -0.37302254512244204, 'w3': 1.528755714330213, 'w4': 0.06060545033486253, 'w5': -0.5498344490333162, 'w6': 2.4804162449866904, 'w7': -1.1945601040185228, 'w8': -2.4321671144303014, 'w9': -0.49662067772094076, 'w10': 1.5181480643900507, 'w11': 2.222739663270568, 'w12': 2.21781859745116, 'w13': -1.5673944812687723, 'w14': -1.2658436450087258, 'w15': -1.070601884953365, 'w16': -0.9262116761129957, 'w17': 0.20169273965244638, 'w18': 1.8897321280815946, 'w19': -1.7008400793614915, 'w20': -0.9408339166566466, 'w21': -0.9896778407389801, 'w22': -0.8067590802012297, 'w23': -1.3029564527324848, 'w24': 1.8800675893176582}. Best is trial 7 with value: 0.6501457725947521.\n",
      "[I 2025-09-01 13:41:35,868] Trial 8 finished with value: 0.6443148688046647 and parameters: {'w0': -0.6049066691534217, 'w1': -2.1427483790289594, 'w2': -1.8678641356028647, 'w3': 2.3228082446589955, 'w4': -0.47514869857332265, 'w5': 0.4024633641756603, 'w6': -2.1865300273952, 'w7': -1.141240382707363, 'w8': -1.3052649030714292, 'w9': 2.109249313148541, 'w10': 2.315722408024735, 'w11': 2.4151034248827656, 'w12': -0.2166480509562554, 'w13': -2.2383336393029647, 'w14': 2.203967775833717, 'w15': -1.1378119901329953, 'w16': -0.2441709765132858, 'w17': -2.437455118980871, 'w18': 0.23400387532336264, 'w19': 1.4792681080789727, 'w20': 0.9107597879183165, 'w21': 0.177676660336612, 'w22': 0.01342061153994889, 'w23': -2.4330598955064837, 'w24': 2.4758821395752166}. Best is trial 7 with value: 0.6501457725947521.\n",
      "[I 2025-09-01 13:41:35,890] Trial 9 finished with value: 0.6384839650145773 and parameters: {'w0': -1.699570521117118, 'w1': -1.7029732331336311, 'w2': -1.460772352798717, 'w3': -0.48955490602810414, 'w4': 2.4049875610496336, 'w5': -1.9525167573405815, 'w6': 1.3641635166633712, 'w7': -0.17909668540034573, 'w8': 1.91882911274398, 'w9': 0.10982594656238298, 'w10': 0.6320012491265761, 'w11': -1.8359485703258327, 'w12': 2.1438266993615613, 'w13': -1.0493032619691505, 'w14': -1.5221841006112657, 'w15': -2.0666429183328106, 'w16': -0.8935028147368511, 'w17': 1.462527544881587, 'w18': 2.315080154935276, 'w19': -0.3141012078695775, 'w20': -0.7799598629665012, 'w21': -0.9185126193400057, 'w22': -1.0480153271036552, 'w23': 1.0854912434485557, 'w24': 0.9964329118217008}. Best is trial 7 with value: 0.6501457725947521.\n",
      "[I 2025-09-01 13:41:35,962] Trial 10 finished with value: 0.6384839650145773 and parameters: {'w0': 2.478990001865478, 'w1': 2.124788423367509, 'w2': 2.0472531029595182, 'w3': 0.9160154652089304, 'w4': -2.495339198582711, 'w5': 1.5407027009902485, 'w6': 2.471606169311457, 'w7': 2.425857543094663, 'w8': -0.27042914448224886, 'w9': 1.0800079637593, 'w10': -0.552516803866397, 'w11': 0.4263282383760093, 'w12': -2.0703260163726367, 'w13': -0.031323105957001884, 'w14': -0.813718284955358, 'w15': 0.3928338021909761, 'w16': 2.1597555892522795, 'w17': 0.03303111624502936, 'w18': -1.1708355866345324, 'w19': -2.3344531171646086, 'w20': -0.29569171162975016, 'w21': -1.0443213561373155, 'w22': -2.493999251567993, 'w23': -0.8747241655988208, 'w24': -2.414366434134119}. Best is trial 7 with value: 0.6501457725947521.\n",
      "[I 2025-09-01 13:41:36,032] Trial 11 finished with value: 0.6530612244897959 and parameters: {'w0': 0.5888217818533104, 'w1': 1.718106493917353, 'w2': -0.8288911856311556, 'w3': -1.041853848939144, 'w4': 0.4463593767261288, 'w5': 1.1721277678695936, 'w6': 1.8023556442455129, 'w7': -0.8431210626698317, 'w8': 0.3807960030633024, 'w9': -0.24769135634622763, 'w10': 0.9240562230580105, 'w11': 1.3695455123086921, 'w12': -0.9448205870737367, 'w13': -2.3065651065451203, 'w14': -1.0699435675518056, 'w15': 2.3247086165815047, 'w16': -1.3915087607107197, 'w17': 0.9752234721950478, 'w18': 1.3028279100749156, 'w19': 0.4785708760557096, 'w20': -2.461492880916333, 'w21': -2.295556941102646, 'w22': 2.4026017545102247, 'w23': -1.2693056100513318, 'w24': 2.437476142617977}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,104] Trial 12 finished with value: 0.641399416909621 and parameters: {'w0': 0.5768120817534448, 'w1': 2.381735089469837, 'w2': -1.0131568143618193, 'w3': 0.6243971401323588, 'w4': 0.7994546251152196, 'w5': 1.9196648951815647, 'w6': 2.3223494139870486, 'w7': -0.9044274266765366, 'w8': 0.35041532010646814, 'w9': -0.8394922915341836, 'w10': 0.9938068713302272, 'w11': 1.2507690476009252, 'w12': -1.2628811775851696, 'w13': -2.3546957987525947, 'w14': -0.9977228774871733, 'w15': 0.00991506637943651, 'w16': -2.400302825293106, 'w17': 0.7733048317019791, 'w18': 1.4356930058833137, 'w19': 0.1952435533292824, 'w20': -1.162438412383802, 'w21': -2.363342477275883, 'w22': 2.4221827267539244, 'w23': -0.8938546483435815, 'w24': 1.7154673824955888}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,183] Trial 13 finished with value: 0.6443148688046647 and parameters: {'w0': 0.3181671006344281, 'w1': 1.4908968454833507, 'w2': -1.0231334673203014, 'w3': 2.299148375442713, 'w4': -0.09092658908342066, 'w5': 1.2673728416740633, 'w6': -0.27365280259372593, 'w7': -2.364622522903861, 'w8': -0.08101963053952277, 'w9': -0.8273029270984911, 'w10': -0.07338140397868687, 'w11': 1.1209472464812076, 'w12': -0.8344826867158928, 'w13': -0.7226535621063102, 'w14': -0.33633495300566074, 'w15': -2.0758416932233237, 'w16': 0.8682725957501458, 'w17': 2.4090050962933374, 'w18': -0.3778853869158709, 'w19': 0.3998624944962763, 'w20': 0.24523516545726132, 'w21': -2.362098213438707, 'w22': 0.643005153489842, 'w23': -1.4463599436311771, 'w24': 2.461651372878801}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,257] Trial 14 finished with value: 0.6472303206997084 and parameters: {'w0': -0.8769534036328039, 'w1': -0.5835391090259325, 'w2': 1.0868510090742505, 'w3': -1.5685010102377706, 'w4': 1.478872694675272, 'w5': 0.9604464364959107, 'w6': 1.704210157533847, 'w7': -1.192074885026297, 'w8': 0.7756337653479444, 'w9': 0.7835363567015047, 'w10': 1.3636441220415465, 'w11': -0.18473772835088753, 'w12': 1.0133688137646748, 'w13': -1.8942088729784456, 'w14': -1.3073525314548577, 'w15': 0.4652420479838562, 'w16': -1.0598768970012717, 'w17': -0.33541921862069635, 'w18': 1.6188220629918353, 'w19': -1.39396148662903, 'w20': -2.445815953184963, 'w21': -1.1127837135571732, 'w22': -0.5194003321795941, 'w23': -0.2750527325235651, 'w24': 1.7915847199038488}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,335] Trial 15 finished with value: 0.6384839650145773 and parameters: {'w0': 2.3878832244689203, 'w1': 1.4004687872705517, 'w2': -0.35347134642121936, 'w3': 0.16255752947002833, 'w4': 0.4271385742679119, 'w5': -0.49081574140972795, 'w6': 0.5301955017682973, 'w7': -0.777701381636824, 'w8': -0.8083109530767822, 'w9': -0.3245084428967983, 'w10': 0.19243317916221025, 'w11': 1.8109422242232143, 'w12': -2.4658667878230927, 'w13': -0.32049410025435865, 'w14': 0.779856758423735, 'w15': -0.4436803783591303, 'w16': 1.275419525442369, 'w17': 0.7063960030310521, 'w18': -0.38340393589488264, 'w19': 0.6378828603565649, 'w20': -1.205309668024968, 'w21': -1.6219323290693874, 'w22': 0.6029772409950771, 'w23': -0.009458872524291007, 'w24': -0.21164841486602848}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,415] Trial 16 finished with value: 0.641399416909621 and parameters: {'w0': 0.4915769075258032, 'w1': 0.8385972909208993, 'w2': 2.2827397134759364, 'w3': 1.6414604917559281, 'w4': -0.5430762471377291, 'w5': -0.38694435536577676, 'w6': 2.4305914755133795, 'w7': -1.7941542969577662, 'w8': -0.7050064517852184, 'w9': -1.3772266565695312, 'w10': 1.486057558542838, 'w11': -0.1983685012866973, 'w12': 2.4510288920701937, 'w13': 0.5852986130769195, 'w14': -0.7417741733708267, 'w15': 2.4977021120390885, 'w16': -0.679692175064396, 'w17': -0.43809173402258084, 'w18': 0.8400543181929185, 'w19': -1.4183996911453018, 'w20': 0.4871907203895194, 'w21': -0.6791615040659995, 'w22': -1.6956818644940403, 'w23': -0.5226705922375273, 'w24': -0.8041127759926168}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,492] Trial 17 finished with value: 0.6472303206997084 and parameters: {'w0': 0.8831586649570731, 'w1': 1.8143913678307055, 'w2': -1.7000620912733266, 'w3': -0.42073758388464144, 'w4': 1.2670205522744087, 'w5': -1.9148356567552243, 'w6': -0.24257836053748072, 'w7': -0.23715595119876365, 'w8': 0.5680695378598206, 'w9': 0.7490458606461268, 'w10': -0.5136662419375817, 'w11': 0.593109514861456, 'w12': -0.7855886492276608, 'w13': -1.8539381947556384, 'w14': 0.4995290551365561, 'w15': -1.6172492447549218, 'w16': -1.4673619094552077, 'w17': 0.6111898098971977, 'w18': 1.8493445119337226, 'w19': -0.7111489895518275, 'w20': -0.42635815470876803, 'w21': 2.370264646565314, 'w22': -0.35851103166735526, 'w23': 2.3865430474378, 'w24': 1.492211420329943}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,565] Trial 18 finished with value: 0.641399416909621 and parameters: {'w0': -1.186259917388899, 'w1': -0.5967162579099481, 'w2': 0.7340931294284772, 'w3': 1.5439445808496584, 'w4': -0.21553318806706412, 'w5': 0.948847727515818, 'w6': 1.8186587094343976, 'w7': -1.6183883167211914, 'w8': -1.6161329129309983, 'w9': -0.1323730267293698, 'w10': 0.4989762830361302, 'w11': 1.1238043759885776, 'w12': 0.858030599506052, 'w13': -0.8289009168786448, 'w14': -1.6825900097376278, 'w15': -0.3192363864076053, 'w16': -1.4910540670803114, 'w17': 1.555446059682549, 'w18': 0.992087631827484, 'w19': -0.11798651068155053, 'w20': -1.4683395058561524, 'w21': -1.8221855176493547, 'w22': 2.403912025293888, 'w23': -1.5534588491034107, 'w24': 2.227610118285434}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,637] Trial 19 finished with value: 0.6326530612244898 and parameters: {'w0': 0.09435381167246959, 'w1': 1.922617509733944, 'w2': -2.4731984048898714, 'w3': 0.42310799604692817, 'w4': -0.9723497774793676, 'w5': -2.3995496835138717, 'w6': 0.9321777719955464, 'w7': -0.4298223401318092, 'w8': 2.401951742640228, 'w9': -1.2977747767030545, 'w10': 1.3983050576114269, 'w11': 1.8372693556851822, 'w12': -0.8128778679453126, 'w13': -2.484426983359565, 'w14': -0.4891038780424418, 'w15': 0.6672444676867934, 'w16': 2.43880188050224, 'w17': 1.0375724379261775, 'w18': 2.4274993199914174, 'w19': 2.459490381465378, 'w20': 0.8245328903487279, 'w21': -0.4357319261773121, 'w22': 1.5992185477077143, 'w23': -2.361802160524829, 'w24': 0.42655516770183577}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,711] Trial 20 finished with value: 0.6384839650145773 and parameters: {'w0': 2.099778309662137, 'w1': 0.9843683944111159, 'w2': -0.4602148357659015, 'w3': -1.3215481665980857, 'w4': 0.8619471404062515, 'w5': -1.0311009117132672, 'w6': 1.8397132992879555, 'w7': -1.4118793604231477, 'w8': -0.7011862363195573, 'w9': 1.2844332041992983, 'w10': -0.13479396161146528, 'w11': 0.20264927869263072, 'w12': 1.597384788117603, 'w13': -1.7709151426583223, 'w14': -1.2389794237834126, 'w15': -2.469279908732907, 'w16': -0.5297868632203971, 'w17': 0.32357636063439765, 'w18': -0.18420473143995553, 'w19': -2.4900428935674634, 'w20': -1.9767644953897783, 'w21': -2.4794954924107073, 'w22': 0.700735057576297, 'w23': 0.37241485416383613, 'w24': 1.1037871669106845}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,791] Trial 21 finished with value: 0.6443148688046647 and parameters: {'w0': -1.0432225103222323, 'w1': -0.6567099574669558, 'w2': 1.5404900764091254, 'w3': -1.8261793941810183, 'w4': 1.676985958317712, 'w5': 0.9210010134896537, 'w6': 1.8442263110336776, 'w7': -0.6997539444923191, 'w8': 0.9768526095567125, 'w9': 0.7703201776416777, 'w10': 1.3359548702744979, 'w11': -0.749649503538685, 'w12': 0.8132514653550158, 'w13': -1.8933011697911994, 'w14': -1.3981662217063697, 'w15': 0.8928347627665398, 'w16': -1.2317014265763635, 'w17': -0.5028202830133564, 'w18': 1.8387824750173782, 'w19': -1.619426366962083, 'w20': -2.4423581246769586, 'w21': -1.2964446772738136, 'w22': -0.7576246998835912, 'w23': -0.4341681044605621, 'w24': 1.821677479091444}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,865] Trial 22 finished with value: 0.6530612244897959 and parameters: {'w0': -0.4217700308417216, 'w1': -0.21650680432516822, 'w2': 0.44049560917987596, 'w3': -1.6274803927936372, 'w4': 1.3309799588940123, 'w5': 0.8273372205674134, 'w6': 1.547158597374888, 'w7': -1.264769081260696, 'w8': 0.30055331505747207, 'w9': 0.4459209901907575, 'w10': 0.8790182930671913, 'w11': -0.3272646189067803, 'w12': 1.6208059235735588, 'w13': -1.321908312392596, 'w14': -1.9750680317539082, 'w15': 1.474945805452955, 'w16': -1.9627968637364817, 'w17': -0.0877571642970918, 'w18': 1.3085799685751034, 'w19': -1.228285464651063, 'w20': -2.492127538257558, 'w21': 0.3613391087160265, 'w22': -0.3031599429439148, 'w23': -0.4065786104678305, 'w24': 1.928447900147676}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:36,937] Trial 23 finished with value: 0.6472303206997084 and parameters: {'w0': -0.16550164308065107, 'w1': 0.007515584265742337, 'w2': 0.3979413908813376, 'w3': -2.472932865923828, 'w4': 0.4856455653625899, 'w5': 1.6282711603895854, 'w6': 2.164763735100361, 'w7': -2.3125361024258186, 'w8': 0.05434050247038502, 'w9': -0.4787237032046193, 'w10': 0.6807553175451013, 'w11': -0.6600586541837132, 'w12': 1.8332686987916758, 'w13': -1.2835997497224538, 'w14': -2.075056291220832, 'w15': 2.2840877714482035, 'w16': -2.1301043127665364, 'w17': -0.10932819152008423, 'w18': 1.2707088147384007, 'w19': -0.9651224816558428, 'w20': -0.856826011590628, 'w21': 0.46838885245968703, 'w22': -0.12443286607316173, 'w23': -1.1957065602451178, 'w24': 2.2211515100158365}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,011] Trial 24 finished with value: 0.641399416909621 and parameters: {'w0': 0.8796971938578744, 'w1': 0.6038186743700595, 'w2': -0.17989539066001603, 'w3': -0.5782375024701814, 'w4': 1.0873247437433746, 'w5': -0.08445931540440699, 'w6': 1.416178320506238, 'w7': -1.404166148486126, 'w8': 0.22070951559837115, 'w9': 0.37275480250160975, 'w10': 1.7360165482802055, 'w11': 0.9143502381445385, 'w12': 2.401500878221622, 'w13': -0.48560148570536055, 'w14': -1.831417978270185, 'w15': 1.8416755509016007, 'w16': -2.1530939356168988, 'w17': -0.8276399718365592, 'w18': 0.4890805963587055, 'w19': -1.8857601196481326, 'w20': -1.79809054757667, 'w21': 0.9100758127927728, 'w22': -1.4507342380367079, 'w23': -1.7497481140526228, 'w24': 1.4012424232579783}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,087] Trial 25 finished with value: 0.6530612244897959 and parameters: {'w0': -2.1716485626808013, 'w1': 0.015467023099727584, 'w2': -0.6871165467661959, 'w3': -2.0396457024282384, 'w4': 0.16104275438677604, 'w5': 0.7470425981082294, 'w6': 0.9432887974536753, 'w7': -0.5907638224759219, 'w8': -0.4023678015546338, 'w9': -0.4748112256228144, 'w10': 0.8897113058937718, 'w11': 1.5066546432297918, 'w12': 1.401265725422999, 'w13': -1.5396475127941738, 'w14': -2.430986936847341, 'w15': 1.286515175311374, 'w16': -1.7993760920776363, 'w17': 0.3726170161515414, 'w18': -0.9955740926226353, 'w19': 0.7875749719428229, 'w20': -1.420760709632284, 'w21': -0.5173748524732416, 'w22': 0.21495371307425426, 'w23': -0.6528756724491522, 'w24': 1.995026192687789}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,166] Trial 26 finished with value: 0.6501457725947521 and parameters: {'w0': -2.3138216566602345, 'w1': -0.9415811470571848, 'w2': -1.178306326255595, 'w3': -2.18341975599585, 'w4': 1.8420042682405662, 'w5': 0.624759843571457, 'w6': 0.1804578712833954, 'w7': -0.6390666590514069, 'w8': -0.4135247020339444, 'w9': 0.49905422232559643, 'w10': 0.2626401376936306, 'w11': 1.5767981924959873, 'w12': 1.3163983510132753, 'w13': -1.0624450956361726, 'w14': -2.4658060768234784, 'w15': 1.2594940568313806, 'w16': -2.4861707003757867, 'w17': 1.8620957209687545, 'w18': -0.9014298073741869, 'w19': 0.8514579677028593, 'w20': -2.150978365651857, 'w21': 1.4884281132503463, 'w22': 0.30870902963713703, 'w23': -0.6844769450966504, 'w24': 2.4800839005385784}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,254] Trial 27 finished with value: 0.6384839650145773 and parameters: {'w0': -1.4880817768011687, 'w1': -0.018853514540525862, 'w2': -0.6672809692951323, 'w3': -1.129550416507082, 'w4': 0.27177643627038073, 'w5': 2.2924412634315177, 'w6': 0.9212698564222366, 'w7': 0.10253646241557368, 'w8': 1.2563284359885976, 'w9': -0.10585839378905076, 'w10': 0.9850817711856259, 'w11': -2.3145639015858492, 'w12': 0.5545088500461557, 'w13': -2.175734152740644, 'w14': -1.9758719620840586, 'w15': 2.008403331793686, 'w16': -1.8904314823971666, 'w17': 0.9504591725943872, 'w18': -1.1353354418438872, 'w19': 1.9103679553974882, 'w20': -1.463253001299723, 'w21': 0.28899170594754553, 'w22': 2.0197736211379107, 'w23': 0.1296884452642727, 'w24': 0.6002439557497397}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,330] Trial 28 finished with value: 0.6472303206997084 and parameters: {'w0': -2.4298356913869568, 'w1': -1.1617136977429365, 'w2': -1.372921372722032, 'w3': -1.8917622661173157, 'w4': 2.311536600889968, 'w5': 1.3337817727863135, 'w6': 0.11440286838518288, 'w7': -2.0246780118781937, 'w8': -1.0385572770995388, 'w9': -1.192544993286043, 'w10': -0.5957430142150577, 'w11': -0.4808416205273863, 'w12': 1.4126079932729085, 'w13': 0.8121987316736352, 'w14': -1.6928509919101846, 'w15': 1.3827879512330234, 'w16': -1.7717085798635943, 'w17': 0.554663487763364, 'w18': -0.7562418151798158, 'w19': 1.1070958176049377, 'w20': -1.5959505269026821, 'w21': -0.4335261883957817, 'w22': 1.1609577149223695, 'w23': -0.16343817804897054, 'w24': 2.0763234539192306}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,404] Trial 29 finished with value: 0.6384839650145773 and parameters: {'w0': -2.012774657470156, 'w1': -0.29197029964226767, 'w2': 0.053870089093421614, 'w3': -1.478130925627784, 'w4': 1.047192483160653, 'w5': 1.9178904770990186, 'w6': 0.7319361297069705, 'w7': -0.42793195817772584, 'w8': -0.38737129680346116, 'w9': 1.4349150144220106, 'w10': -1.0931986933861082, 'w11': 0.7726822242015607, 'w12': -1.230888755894769, 'w13': -1.133616406529407, 'w14': -2.2039925655910872, 'w15': 1.7090815518854274, 'w16': 0.13940532918873183, 'w17': 0.30245892275612474, 'w18': -1.526526226355478, 'w19': 0.39352313364698766, 'w20': -2.1084790389141252, 'w21': 0.7056101390825007, 'w22': 0.918088508691462, 'w23': -1.896363231650921, 'w24': 1.5250423665507804}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,479] Trial 30 finished with value: 0.6472303206997084 and parameters: {'w0': -0.6767395548907766, 'w1': 0.2901677090343656, 'w2': 0.4364358123915742, 'w3': -0.8172494086042688, 'w4': -2.4359811426869156, 'w5': 0.7606080972020186, 'w6': -0.8688898097923539, 'w7': 1.0428843770754914, 'w8': 0.633650925870532, 'w9': -2.1183198463936304, 'w10': 0.8624048326603848, 'w11': 0.14960642662423895, 'w12': -0.22038106186293932, 'w13': -2.0299701353456885, 'w14': -2.413782498835731, 'w15': 2.086235652291463, 'w16': -1.2671311484484333, 'w17': 1.352204608982784, 'w18': 1.020050469017927, 'w19': -0.09234614304255684, 'w20': -2.493054538567054, 'w21': 2.106599376706233, 'w22': -0.33346805129200874, 'w23': 0.43200333123552825, 'w24': 1.198879572136863}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,558] Trial 31 finished with value: 0.6530612244897959 and parameters: {'w0': -1.2838650698207452, 'w1': 1.6236874837498723, 'w2': -0.6057272148252992, 'w3': -2.0977336205322934, 'w4': -0.33868366508740233, 'w5': -0.10903864186217027, 'w6': 1.5061050585006879, 'w7': -1.0713839398580454, 'w8': -2.1316516201293516, 'w9': -0.5409389836534808, 'w10': 1.6673043771485423, 'w11': 1.9351368745834954, 'w12': 1.875846507738614, 'w13': -1.5847872776765428, 'w14': -1.1657490599130043, 'w15': 0.9719788213151692, 'w16': -0.5702831851985435, 'w17': 0.03596491211888614, 'w18': 1.9567240967435113, 'w19': -1.0826550927029595, 'w20': -0.9823686085214911, 'w21': -0.5557499432948734, 'w22': -0.8055958699323285, 'w23': -1.310015347351886, 'w24': 1.8956251455089936}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,641] Trial 32 finished with value: 0.6501457725947521 and parameters: {'w0': -1.3061238416938816, 'w1': 1.5646350729734366, 'w2': -0.799595617070238, 'w3': -2.1201574764725435, 'w4': -0.34382499385400633, 'w5': -0.0007603764663857149, 'w6': 1.2944587669684344, 'w7': -1.0228129474894638, 'w8': -1.8553514036131098, 'w9': -0.669336190676312, 'w10': 2.02986865899854, 'w11': 1.4376648681513935, 'w12': 2.068981997885948, 'w13': -1.7354710660182178, 'w14': -1.0299213154137212, 'w15': 1.009385472423268, 'w16': -0.3640792357076753, 'w17': -0.12298715292541224, 'w18': 2.0565267486829715, 'w19': -1.0823921602931172, 'w20': -0.619732722692246, 'w21': -0.48578520132672487, 'w22': 0.21960481371948218, 'w23': -0.8258232659505063, 'w24': 1.6146939780429876}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,732] Trial 33 finished with value: 0.6443148688046647 and parameters: {'w0': -1.9277959415058312, 'w1': 2.437939929195378, 'w2': -1.938691726891499, 'w3': -1.5539998635556516, 'w4': -0.8147616230708374, 'w5': 1.199317076209771, 'w6': 0.9796926216482107, 'w7': -1.494106692475777, 'w8': 0.43062214596475745, 'w9': -1.071430873285121, 'w10': 0.37193800616116524, 'w11': 1.9665139039198787, 'w12': 1.233751966079929, 'w13': -0.7350987011643826, 'w14': -2.1327549755369066, 'w15': 1.4829242295962273, 'w16': -0.7358753828260911, 'w17': 0.4515617461131251, 'w18': 1.2310053846953666, 'w19': -0.540869721485224, 'w20': -1.2587949053786192, 'w21': 1.083570833973038, 'w22': -1.0717979493968919, 'w23': -2.075048699581014, 'w24': 2.148827071967618}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,820] Trial 34 finished with value: 0.6443148688046647 and parameters: {'w0': -0.39753394159040906, 'w1': 0.2987429689473406, 'w2': -0.010491400363593336, 'w3': -2.0781799564194166, 'w4': -1.762627805039174, 'w5': 0.27171224633203817, 'w6': 1.5936260779882754, 'w7': -0.5148339059385559, 'w8': -2.0060055852110894, 'w9': -0.19877739842937903, 'w10': 1.274382115802502, 'w11': 1.457506366887693, 'w12': 1.7972496102131372, 'w13': -1.587678094878052, 'w14': -0.31664855923654767, 'w15': 1.7137601610101667, 'w16': -1.9822868207769282, 'w17': -0.6543393585840174, 'w18': 0.6164535728378764, 'w19': 1.0814814667908745, 'w20': -2.0835475070818084, 'w21': 1.3973603601860516, 'w22': -0.6205846627934881, 'w23': -1.0665385016466402, 'w24': 0.8507477651686195}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,900] Trial 35 finished with value: 0.6384839650145773 and parameters: {'w0': -1.644390774612041, 'w1': 1.8322267677467086, 'w2': 0.21091950667750048, 'w3': -1.738243094057865, 'w4': 0.7281701223248895, 'w5': 0.38485266979045807, 'w6': 0.49591740500448744, 'w7': 0.021635898479968416, 'w8': 0.025449046126516772, 'w9': 0.09867262958121209, 'w10': 1.0860965670610134, 'w11': 2.148261832622171, 'w12': 0.49089856396102083, 'w13': -2.4794613032108215, 'w14': -0.02113667171932672, 'w15': 0.7831669962227574, 'w16': -1.5015394029689317, 'w17': -1.142991979279028, 'w18': 0.004957925331025459, 'w19': -1.0446935041144272, 'w20': -0.23373362765296668, 'w21': 0.06160793651207286, 'w22': -0.1768337387768736, 'w23': -0.48388130305601906, 'w24': 0.10119778586676811}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:37,975] Trial 36 finished with value: 0.6384839650145773 and parameters: {'w0': -2.102631769011674, 'w1': 1.1975053873339185, 'w2': -0.6980154135173013, 'w3': -1.2705321012216837, 'w4': 0.14205769394548473, 'w5': -0.06223837137429267, 'w6': 2.119838287561403, 'w7': -0.8621192447014018, 'w8': 1.3577058357532974, 'w9': 0.4940893917281296, 'w10': -2.48274541004061, 'w11': 1.7395085922498073, 'w12': 1.561151108158883, 'w13': -1.2647793062469515, 'w14': -1.5630072912732103, 'w15': 0.17862905322171538, 'w16': -1.252882845512499, 'w17': 0.07017111957006875, 'w18': 2.1430777519773803, 'w19': 0.6953833241741305, 'w20': -1.6948261914071818, 'w21': 0.48971093926532416, 'w22': 0.3124887163171204, 'w23': -1.5654669951325193, 'w24': 2.0113079731794197}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,051] Trial 37 finished with value: 0.6472303206997084 and parameters: {'w0': 0.050417671258922825, 'w1': -0.3422874388096703, 'w2': 0.7302850358186792, 'w3': -0.1835591549607235, 'w4': -1.311204165343676, 'w5': -0.8852956857400717, 'w6': 1.1482584744294813, 'w7': 0.6893972359778567, 'w8': -1.1701257475384437, 'w9': -1.5039750804733072, 'w10': 1.7645994703654813, 'w11': -1.0850980186407957, 'w12': 2.007843501674934, 'w13': -0.20940467742686097, 'w14': 0.3925665517348842, 'w15': 2.149362207143484, 'w16': 0.14268683753126443, 'w17': -0.2616071872384339, 'w18': 1.618318448822565, 'w19': 0.23745537352800428, 'w20': -2.166340646730055, 'w21': -0.17733668129742952, 'w22': -1.3387962978301458, 'w23': 0.9234484082744499, 'w24': 1.262629546917808}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,127] Trial 38 finished with value: 0.6355685131195336 and parameters: {'w0': -1.4333768344434787, 'w1': 0.5934545230405309, 'w2': 1.091332572153799, 'w3': -0.8381663043589982, 'w4': -0.7227494343839074, 'w5': 0.6498500882765696, 'w6': 1.5773456382742628, 'w7': 0.35002310784816126, 'w8': 1.0232075545727408, 'w9': -0.9470485023699211, 'w10': 2.0878559017638647, 'w11': 0.48800258418941733, 'w12': 0.15489901479383367, 'w13': 0.22365064150994146, 'w14': -2.478096589367232, 'w15': 1.1707532288525795, 'w16': -1.7110988975850006, 'w17': 0.9513876379382102, 'w18': -1.7723564133080179, 'w19': -0.28987388997428964, 'w20': 0.03269347810425938, 'w21': -2.0634824984039106, 'w22': 1.6206497940039157, 'w23': -0.6531615522792344, 'w24': -1.4313825553261244}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,225] Trial 39 finished with value: 0.6472303206997084 and parameters: {'w0': -0.808046324299855, 'w1': -0.9905939004234601, 'w2': -0.1596324267641569, 'w3': -2.2998947118008704, 'w4': -0.12925602772371936, 'w5': 1.8598215687265094, 'w6': 2.0916865295911515, 'w7': -1.8428603242006951, 'w8': -2.1777966084152807, 'w9': -0.4989777298538365, 'w10': 0.7393792893226325, 'w11': 2.4585596307269086, 'w12': 1.1169312872837878, 'w13': 1.768242753224168, 'w14': -1.830774199979585, 'w15': 1.5088242975832262, 'w16': -2.2359525514614775, 'w17': 1.7552722468771849, 'w18': 0.30139351204189224, 'w19': -0.8233272204042605, 'w20': -1.3666487664747233, 'w21': -1.6169349776816573, 'w22': -1.0588728049529825, 'w23': -1.3085832228977081, 'w24': 2.2717446277815814}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,300] Trial 40 finished with value: 0.641399416909621 and parameters: {'w0': -0.375939385376723, 'w1': 2.1120540812536843, 'w2': -2.0641351578194786, 'w3': -2.035333627163564, 'w4': 0.36278457103326656, 'w5': 1.0904213246093408, 'w6': 0.7410491057152752, 'w7': -0.9853262561444509, 'w8': -1.434054150845553, 'w9': 0.14893764665230824, 'w10': 1.6976466337146832, 'w11': 0.7742043252944097, 'w12': -0.3869312148574219, 'w13': -1.542434819035834, 'w14': -0.6235516130268116, 'w15': 0.5532636606557144, 'w16': 0.41057868261979963, 'w17': 2.2177480291463745, 'w18': 1.2783110102627329, 'w19': 1.2845595872327646, 'w20': -1.8942742897185234, 'w21': -0.7236392991499719, 'w22': -2.268143284706581, 'w23': -1.0434478797395297, 'w24': 0.7627825668651098}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,375] Trial 41 finished with value: 0.6472303206997084 and parameters: {'w0': 1.3204135355476254, 'w1': 0.858847882898391, 'w2': -0.4763648365704471, 'w3': -1.7180942283857414, 'w4': 0.012314155891530981, 'w5': -0.37752683734282383, 'w6': 2.0575035484966158, 'w7': -1.2534258516727226, 'w8': -2.4128472410440134, 'w9': -0.541152288070597, 'w10': 1.6154326213736367, 'w11': 2.160843392469437, 'w12': 2.3327950195913485, 'w13': -2.1210828828256174, 'w14': -1.0829542090184925, 'w15': -0.729914291357304, 'w16': -1.065447553053444, 'w17': 0.20389393473156103, 'w18': 1.9640824509382104, 'w19': -2.006190910666852, 'w20': -0.9335465856411044, 'w21': -1.4004034325624368, 'w22': -0.8315469576322454, 'w23': -1.2721042927607256, 'w24': 1.8938565162792131}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,453] Trial 42 finished with value: 0.6501457725947521 and parameters: {'w0': 0.9822217506598454, 'w1': 1.2238369518022816, 'w2': -0.9659027967250393, 'w3': 1.2962348998493862, 'w4': 0.6320427596102555, 'w5': -0.6899564574172808, 'w6': 1.518373724375513, 'w7': -0.15159816934694748, 'w8': -1.9178328151240374, 'w9': -0.23877954097353504, 'w10': 1.1854507132306604, 'w11': 1.9989454934374908, 'w12': 1.833137508145744, 'w13': -1.447969769024766, 'w14': -1.2839442086136832, 'w15': 1.862601946631563, 'w16': -0.868259220461666, 'w17': 0.07224652928615266, 'w18': 2.4620355823269326, 'w19': -1.45688841703767, 'w20': -1.0048927195004103, 'w21': -0.16624233280622858, 'w22': -1.7806541783572467, 'w23': -1.75751551465948, 'w24': 1.9395435667443137}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,537] Trial 43 finished with value: 0.6384839650145773 and parameters: {'w0': 1.5943582435461516, 'w1': 1.7191215776688027, 'w2': -1.314051526515031, 'w3': 2.006530170743669, 'w4': -0.47924305406045875, 'w5': -1.5705865411201856, 'w6': 1.1786403147226214, 'w7': -1.6375279063094745, 'w8': -2.4836251619594822, 'w9': -0.6676038685845458, 'w10': 2.3017211507235995, 'w11': 2.204942276460787, 'w12': 2.212223660488106, 'w13': -0.9294486054401471, 'w14': -2.2343489986978753, 'w15': -1.545786690981879, 'w16': -0.6074735194958503, 'w17': 1.29705158104514, 'w18': 1.7586839856760839, 'w19': -1.7382613932575384, 'w20': 1.5268876624044996, 'w21': -0.8564323703200133, 'w22': -0.4792308262755063, 'w23': -0.8766350705658452, 'w24': 1.5513875639336443}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,621] Trial 44 finished with value: 0.6501457725947521 and parameters: {'w0': 2.029169730844369, 'w1': 0.21932495740160488, 'w2': -1.6117863351275856, 'w3': -1.306336193584853, 'w4': 0.05290751209723471, 'w5': 0.2425415510186344, 'w6': 2.2783759254740064, 'w7': 2.43948130339109, 'w8': -1.7338042017938564, 'w9': 0.02121553271785659, 'w10': 0.8468819476939392, 'w11': 1.329869741901443, 'w12': 1.455993303602163, 'w13': -1.542025842205603, 'w14': -0.880300769743839, 'w15': 0.24234555207522757, 'w16': -1.3280580617996653, 'w17': -1.1176639001405615, 'w18': 2.19020681508691, 'w19': -2.165465526387, 'w20': -0.5296141124728275, 'w21': -1.1728736918277598, 'w22': -0.7673179342671559, 'w23': -0.2564185119890511, 'w24': 2.485997739537992}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,710] Trial 45 finished with value: 0.6384839650145773 and parameters: {'w0': -1.0389885870576856, 'w1': 2.2075467270786495, 'w2': -0.24925664485684018, 'w3': -2.460594456439032, 'w4': 0.9737728185299438, 'w5': 1.497173588246661, 'w6': 2.481325234921605, 'w7': -1.2678611039862169, 'w8': -2.2268180102207964, 'w9': 0.33126221319082416, 'w10': -1.8157896786987682, 'w11': 2.3722075686740998, 'w12': 1.992137343449968, 'w13': -2.237534277139768, 'w14': 1.4856747149658927, 'w15': 0.9874221480694132, 'w16': -0.13937384880340664, 'w17': 0.7479953406714122, 'w18': 1.4339145830251498, 'w19': 1.7725846485945973, 'w20': 2.404997032864692, 'w21': -2.0323426325492355, 'w22': -0.021001252184549374, 'w23': -1.405053273032931, 'w24': 1.717503961366129}. Best is trial 11 with value: 0.6530612244897959.\n",
      "[I 2025-09-01 13:41:38,788] Trial 46 finished with value: 0.6559766763848397 and parameters: {'w0': -1.7577043112786332, 'w1': 0.9612592801632011, 'w2': -0.6730306119199211, 'w3': 0.7975894634275755, 'w4': 0.559357097052756, 'w5': -0.18652099066144273, 'w6': 1.881602240818507, 'w7': -1.118024636216127, 'w8': -0.17144096344027004, 'w9': -0.4371448829642576, 'w10': 0.5882789360558163, 'w11': 1.687170403270161, 'w12': -1.7092167557446873, 'w13': -2.0264127949461255, 'w14': -1.5117781990060744, 'w15': 1.2613705320032398, 'w16': -0.9709603774759288, 'w17': 0.39380107822675425, 'w18': 0.78984586159725, 'w19': -1.2602570470608614, 'w20': -1.0410247993588728, 'w21': -0.565299467622462, 'w22': -1.211387675474055, 'w23': -1.966803256233053, 'w24': 2.234147953188962}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:38,873] Trial 47 finished with value: 0.6530612244897959 and parameters: {'w0': -1.738941236183056, 'w1': 1.4459062439454935, 'w2': -0.5734194905802961, 'w3': 0.8287738052541, 'w4': 1.4420102507033836, 'w5': -0.2133592176972011, 'w6': 1.68181842093601, 'w7': -2.047959979973953, 'w8': -0.18552982382881678, 'w9': -0.35656769052633996, 'w10': 0.5010701435198691, 'w11': 1.7400658376009273, 'w12': -1.8522320719011742, 'w13': -2.0341396459476995, 'w14': -1.5063693029950533, 'w15': 1.251883703759654, 'w16': -1.948077341075883, 'w17': 0.47720759040087585, 'w18': 0.8874629414197854, 'w19': -1.1573895688181906, 'w20': -1.6528054709228797, 'w21': 0.3041608519566227, 'w22': -1.628674027549161, 'w23': -2.497925068135967, 'w24': 2.283100399659013}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:38,949] Trial 48 finished with value: 0.6472303206997084 and parameters: {'w0': -2.3136174222694477, 'w1': -0.32241372276392216, 'w2': -0.9231908335644511, 'w3': 0.1622666943249108, 'w4': 0.48998093176332935, 'w5': 0.14055705403849184, 'w6': 1.317700417629121, 'w7': 1.6818912258785041, 'w8': 0.15261087213318553, 'w9': -1.7633660432572897, 'w10': 0.13668595072516243, 'w11': 1.0633169061006105, 'w12': -2.2579641558322088, 'w13': -1.7260075492374285, 'w14': -1.9343686141183665, 'w15': 2.2443599678598796, 'w16': -1.645859410948796, 'w17': 1.0950713034203208, 'w18': -2.4893902853954586, 'w19': -0.5331913765858128, 'w20': -2.2567631198852, 'w21': -0.3337884935332185, 'w22': -1.198181633298931, 'w23': -2.247589996423676, 'w24': 2.0237383578080284}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,038] Trial 49 finished with value: 0.6443148688046647 and parameters: {'w0': -2.103329412291522, 'w1': -1.6681467606730025, 'w2': 0.31733034989811726, 'w3': -0.9598022314697927, 'w4': 1.280550936161039, 'w5': 0.4864125053776318, 'w6': 1.9324932689355712, 'w7': -0.31973361130562716, 'w8': 0.8345086302942251, 'w9': -1.0372081994114613, 'w10': 0.5606868714269824, 'w11': -0.22406898365732492, 'w12': -1.4079452593735595, 'w13': -0.5101007234085346, 'w14': -1.1086256840713378, 'w15': 1.5372231561151957, 'w16': -0.4855275396230456, 'w17': -0.16937194656969934, 'w18': 0.7166797971374494, 'w19': 0.032741456337392894, 'w20': -0.6906215453400859, 'w21': 0.03334750039625067, 'w22': -2.0057970910832292, 'w23': -2.0437138044228758, 'w24': 1.3079764977267656}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,117] Trial 50 finished with value: 0.6443148688046647 and parameters: {'w0': -1.5637337193145513, 'w1': -2.494821996928146, 'w2': -1.1874150572028408, 'w3': 0.4888781594094841, 'w4': 0.22148861187424018, 'w5': -1.3264245850587495, 'w6': -2.453490365118936, 'w7': -1.0639595213779194, 'w8': -0.9141408967637934, 'w9': -0.7810813366928117, 'w10': 1.1130657383641318, 'w11': 1.6182323844436988, 'w12': -1.4465285827595056, 'w13': -1.2833273201588913, 'w14': -1.7270690553047021, 'w15': 1.9137729177450788, 'w16': -1.0640893397407032, 'w17': -2.450611239882977, 'w18': 0.0925153915806407, 'w19': -1.2400749142148135, 'w20': -1.160498196500172, 'w21': -0.6134411491065515, 'w22': -1.4838754557192202, 'w23': -1.7216576278750095, 'w24': -2.429436709816906}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,200] Trial 51 finished with value: 0.6501457725947521 and parameters: {'w0': -1.746054017660712, 'w1': 1.449556471126959, 'w2': -0.5782835680520934, 'w3': 1.148532158220215, 'w4': 1.6594927237995234, 'w5': -0.12831194474048468, 'w6': 1.6133485196090545, 'w7': -2.0700718548494277, 'w8': -0.15156065114942585, 'w9': -0.3444932180820584, 'w10': -0.29677081385189796, 'w11': 1.9237074423688143, 'w12': -1.9727916314902911, 'w13': -2.017651221978986, 'w14': -1.4983669253995173, 'w15': 1.2508772483245267, 'w16': -1.980015912423909, 'w17': 0.39924199914339603, 'w18': 1.1505335115757538, 'w19': -0.8017159783861734, 'w20': -1.5916571300527251, 'w21': 0.31799109573493145, 'w22': -1.859314326627687, 'w23': -2.230818838147652, 'w24': 2.327974247241758}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,284] Trial 52 finished with value: 0.6472303206997084 and parameters: {'w0': -1.811774887736497, 'w1': 1.069423445103781, 'w2': -0.8167311466083214, 'w3': 0.8005689710259326, 'w4': 2.1156408453421207, 'w5': -0.3444499079583548, 'w6': 1.6847401062746243, 'w7': -0.6009411491172358, 'w8': -0.5979264362791836, 'w9': -0.0096189600591014, 'w10': 0.4908391162053098, 'w11': 1.6464926531743966, 'w12': -1.8118142440717915, 'w13': -2.3412897791154865, 'w14': -1.4638058156688571, 'w15': 0.7644956963972398, 'w16': -1.5922760750060467, 'w17': 0.7826257136301924, 'w18': 0.804792495841081, 'w19': -1.2384136671498975, 'w20': -1.870085802155591, 'w21': 0.5163989044194133, 'w22': -1.5541472649395545, 'w23': -1.9459878027604376, 'w24': 2.2581319898929593}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,361] Trial 53 finished with value: 0.6472303206997084 and parameters: {'w0': 0.4565473317460912, 'w1': 1.9807330297470935, 'w2': -0.09043365510781765, 'w3': 0.8065087304525838, 'w4': 1.2808583144709775, 'w5': 0.7624134939979047, 'w6': 1.104792040521913, 'w7': -2.2208968369118844, 'w8': 0.3670628184479324, 'w9': -0.3558774628677123, 'w10': 0.8548911160746183, 'w11': 1.3454360764731432, 'w12': -1.692030009871782, 'w13': -2.0102009018667406, 'w14': -2.0056989491401884, 'w15': 1.6284784950108933, 'w16': -2.281595969437037, 'w17': 0.5340450528334183, 'w18': 1.469825095275326, 'w19': 0.5363552389473325, 'w20': -1.0979664212711306, 'w21': 0.7506000006369563, 'w22': -2.2113894570732215, 'w23': -2.434734755920626, 'w24': 1.811438870259743}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,438] Trial 54 finished with value: 0.6501457725947521 and parameters: {'w0': -1.236968576479747, 'w1': 1.6808570246479704, 'w2': -0.33446156827060436, 'w3': -0.2582436148536782, 'w4': 1.5176868219862916, 'w5': -0.28937058679510125, 'w6': 1.9393142727415034, 'w7': -1.697752472147724, 'w8': -0.2156937385067865, 'w9': -0.6653319568687387, 'w10': 0.06316834383057224, 'w11': 1.0553792552376708, 'w12': -1.0854155330426398, 'w13': -1.6502916387974682, 'w14': -1.5897872340640855, 'w15': 1.1003351847072882, 'w16': -1.9386226795936041, 'w17': -0.5391175222565794, 'w18': 1.0414440372669818, 'w19': 0.8772490911679236, 'w20': -2.3470208225939, 'w21': 0.14715151559202871, 'w22': -1.2332911757664557, 'w23': -2.496766521063307, 'w24': 2.107110360081126}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,517] Trial 55 finished with value: 0.6472303206997084 and parameters: {'w0': -0.15146152748725533, 'w1': 0.7884242649151735, 'w2': -0.5956464512090424, 'w3': 0.13966131571217888, 'w4': -0.2564171667952302, 'w5': -0.8168489179765985, 'w6': 1.4452533664363982, 'w7': -0.8440869043061394, 'w8': -0.5259211269069147, 'w9': 0.21246407539834278, 'w10': 0.3540634222425444, 'w11': 1.8082894888538943, 'w12': -2.477910043336685, 'w13': -2.3466921643390095, 'w14': -0.8274411759152183, 'w15': 1.3201728720800183, 'w16': -0.8225551246501734, 'w17': 0.009317344610840689, 'w18': -2.219533979595664, 'w19': -1.5657345906865845, 'w20': -1.6793271201945505, 'w21': -0.2649295302330996, 'w22': -0.9378400474690042, 'w23': -1.5796654248998998, 'w24': -0.4983118427246949}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,595] Trial 56 finished with value: 0.6530612244897959 and parameters: {'w0': 0.2700362533419287, 'w1': 1.3138375056669298, 'w2': 0.5232907944300533, 'w3': 1.0622705589392933, 'w4': 0.6028630902793441, 'w5': 0.5398286102369414, 'w6': 1.761632930930415, 'w7': -1.351561373443161, 'w8': 0.5709663645102335, 'w9': 0.8934458006586419, 'w10': -0.26852953916344824, 'w11': 0.2095800097496096, 'w12': -0.6190314016437868, 'w13': -1.9169691710176069, 'w14': -2.305329392514255, 'w15': -0.24141908143755447, 'w16': -1.3967599703092888, 'w17': 0.20914479979141687, 'w18': 0.3625895117877902, 'w19': -0.3856698622770731, 'w20': -1.3601349300980028, 'w21': -0.06246770791626771, 'w22': -1.6206522948919881, 'w23': -2.192514940532418, 'w24': 2.368272671168977}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,674] Trial 57 finished with value: 0.6443148688046647 and parameters: {'w0': 0.7233318786270276, 'w1': 1.6092185430482444, 'w2': -1.1378136978781936, 'w3': 0.4565779730393628, 'w4': 0.8763106421576106, 'w5': -0.6064035441345681, 'w6': 0.36457830063136, 'w7': -1.8807210231076237, 'w8': 0.17734965825266474, 'w9': 0.6127530347260598, 'w10': 1.4924878118723295, 'w11': 1.261082437618188, 'w12': -2.032731914612099, 'w13': -1.3569928061555208, 'w14': -0.2790447348103111, 'w15': 2.4163226789820698, 'w16': -1.104565283619791, 'w17': 0.8464090400021262, 'w18': 0.5812851544530058, 'w19': -1.2974065780252717, 'w20': -1.9750734212811396, 'w21': -0.8874290480203326, 'w22': 2.074100303629701, 'w23': -0.6723995804935947, 'w24': 0.9812879731359069}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,753] Trial 58 finished with value: 0.6501457725947521 and parameters: {'w0': -2.4920695498864065, 'w1': 0.4513030802029562, 'w2': -0.46910187232272316, 'w3': 1.3954438045741646, 'w4': 1.8948670881367917, 'w5': -0.20438098428984136, 'w6': 2.2774777363839718, 'w7': -2.4621624643683235, 'w8': -0.07926633122892508, 'w9': -2.433145859191553, 'w10': 0.68179842411006, 'w11': 1.5259231131473436, 'w12': -2.2450389937260478, 'w13': -2.2165549104997386, 'w14': -0.5906221653009891, 'w15': 0.566820249949751, 'w16': -2.3877483912922006, 'w17': 0.6294354193751, 'w18': -0.2822388914412033, 'w19': -0.9965295015553952, 'w20': -1.532664408626857, 'w21': -0.583768846629369, 'w22': -0.6361903682125882, 'w23': 1.8446555305879986, 'w24': 1.6823926486404663}. Best is trial 46 with value: 0.6559766763848397.\n",
      "[I 2025-09-01 13:41:39,833] Trial 59 finished with value: 0.6443148688046647 and parameters: {'w0': -2.2669683297703207, 'w1': 0.7161680634403024, 'w2': 1.4069553498535654, 'w3': 1.8465389415902844, 'w4': 1.1620151974514101, 'w5': 0.14995060709438374, 'w6': 0.839424526147784, 'w7': -1.0929781697429888, 'w8': -0.34514203625013706, 'w9': -0.16766324028058371, 'w10': 0.44944069470563097, 'w11': 2.0268430032622353, 'w12': -1.0817807717167534, 'w13': -1.8041091942391656, 'w14': -1.1973175769853064, 'w15': 0.8675513263177863, 'w16': -1.8328448965789264, 'w17': -0.34190596496963477, 'w18': 0.8813986544028134, 'w19': -1.7614607009285095, 'w20': -0.31714898580149053, 'w21': 1.152154598301291, 'w22': -0.26733263372527594, 'w23': -1.042090797937431, 'w24': -1.9259609009259933}. Best is trial 46 with value: 0.6559766763848397.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LEAK] alphas (first 10): [0.004  0.0611 0.0119 0.0519 0.0409 0.0194 0.1534 0.0076 0.0197 0.0151]\n",
      "\n",
      "==== Test (LEAK: tuned on TEST) Performance ====\n",
      "Accuracy:      0.655977\n",
      "AUC:           0.632565\n",
      "PR-AUC:        0.503116\n",
      "LogLoss:       0.668884\n",
      "Precision@0.530: 0.596330\n",
      "Recall@0.530:    0.467626\n",
      "F1@0.530:        0.524194\n",
      "\n",
      "NOTE: 指标若在 LEAK 模式显著高于 Baseline，即说明面向测试集调参带来了“虚高”。\n",
      "\n",
      "Score PSI (TrainFit→Val):  0.0741\n",
      "Score PSI (TrainFit→Test): 0.0443\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 公共工具\n",
    "# =========================\n",
    "def set_seed(seed=42):\n",
    "    import random, os\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "# =========================\n",
    "# 漂移工具\n",
    "# =========================\n",
    "def psi_for_series(train_s: pd.Series, test_s: pd.Series, bins=10):\n",
    "    train_s = pd.to_numeric(train_s, errors='coerce')\n",
    "    test_s  = pd.to_numeric(test_s,  errors='coerce')\n",
    "    tr = train_s.dropna(); te = test_s.dropna()\n",
    "    if tr.empty or te.empty:\n",
    "        return np.nan\n",
    "    quantiles = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.unique(np.nanquantile(tr, quantiles))\n",
    "    if len(cuts) <= 2:\n",
    "        return np.nan\n",
    "    tr_bins = pd.cut(train_s, bins=cuts, include_lowest=True)\n",
    "    te_bins = pd.cut(test_s,  bins=cuts, include_lowest=True)\n",
    "    tr_ratio = tr_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_ratio.reindex(tr_ratio.index).fillna(0.0)\n",
    "    tr_ratio = tr_ratio.fillna(0.0)\n",
    "    tr_ratio = tr_ratio.replace(0, 1e-8)\n",
    "    te_ratio = te_ratio.replace(0, 1e-8)\n",
    "    psi = np.sum((te_ratio - tr_ratio) * np.log(te_ratio / tr_ratio))\n",
    "    return float(psi)\n",
    "\n",
    "def cat_psi(train_s: pd.Series, test_s: pd.Series):\n",
    "    tr_p = train_s.value_counts(normalize=True)\n",
    "    te_p = test_s.value_counts(normalize=True)\n",
    "    idx = tr_p.index.union(te_p.index)\n",
    "    tr_p = tr_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    te_p = te_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    psi = np.sum((te_p - tr_p) * np.log(te_p / tr_p))\n",
    "    return float(psi)\n",
    "\n",
    "def two_sample_drift(train_s: pd.Series, test_s: pd.Series, is_categorical=False):\n",
    "    if is_categorical:\n",
    "        idx = pd.Index(pd.concat([train_s.astype(str), test_s.astype(str)], ignore_index=True).unique())\n",
    "        tr_counts = train_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        te_counts = test_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        table = np.vstack([tr_counts.values, te_counts.values])\n",
    "        try:\n",
    "            chi2, p, dof, exp = chi2_contingency(table)\n",
    "        except ValueError:\n",
    "            p = 1.0\n",
    "        return {\"stat\": None, \"pvalue\": float(p)}\n",
    "    else:\n",
    "        tr = pd.to_numeric(train_s, errors='coerce').dropna()\n",
    "        te = pd.to_numeric(test_s,  errors='coerce').dropna()\n",
    "        if len(tr) < 2 or len(te) < 2:\n",
    "            return {\"stat\": None, \"pvalue\": np.nan}\n",
    "        ks = ks_2samp(tr, te, alternative='two-sided', mode='auto')\n",
    "        return {\"stat\": float(ks.statistic), \"pvalue\": float(ks.pvalue)}\n",
    "\n",
    "def drift_report(df_ref: pd.DataFrame, df_new: pd.DataFrame, categorical_cols=None, topk=15):\n",
    "    categorical_cols = set(categorical_cols or [])\n",
    "    rows = []\n",
    "    for c in df_ref.columns:\n",
    "        is_cat = c in categorical_cols or (df_ref[c].dtype.name in [\"category\", \"object\"])\n",
    "        psi = cat_psi(df_ref[c], df_new[c]) if is_cat else psi_for_series(df_ref[c], df_new[c])\n",
    "        stat = two_sample_drift(df_ref[c], df_new[c], is_categorical=is_cat)\n",
    "        miss_ref = df_ref[c].isna().mean()\n",
    "        miss_new = df_new[c].isna().mean()\n",
    "        rows.append({\n",
    "            \"feature\": c,\n",
    "            \"is_categorical\": is_cat,\n",
    "            \"PSI\": psi,\n",
    "            \"KS/Chi2_p\": stat[\"pvalue\"],\n",
    "            \"KS_stat\": stat[\"stat\"],\n",
    "            \"missing_ref\": miss_ref,\n",
    "            \"missing_new\": miss_new,\n",
    "            \"missing_diff\": miss_new - miss_ref,\n",
    "        })\n",
    "    rep = pd.DataFrame(rows)\n",
    "    rep = rep.sort_values(by=[\"PSI\", \"KS/Chi2_p\"], ascending=[False, True]).reset_index(drop=True)\n",
    "    return rep.iloc[:topk]\n",
    "\n",
    "def score_psi(ref_scores, new_scores, bins=10):\n",
    "    return psi_for_series(pd.Series(ref_scores), pd.Series(new_scores), bins=bins)\n",
    "\n",
    "# =========================\n",
    "# 阈值策略\n",
    "# =========================\n",
    "def choose_threshold(\n",
    "    y_true, y_prob,\n",
    "    method=\"f1\",                # \"f1\" | \"youden\" | \"constraint\" | \"posrate\"\n",
    "    grid=None,\n",
    "    min_precision=None,\n",
    "    min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.01, 0.99, 99)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    out_rows = []\n",
    "    best_thr, best_key = 0.5, (-1e9, -1e9)\n",
    "\n",
    "    for t in grid:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        P  = precision_score(y_true, pred, zero_division=0)\n",
    "        R  = recall_score(y_true, pred, zero_division=0)\n",
    "        F1 = f1_score(y_true, pred, zero_division=0)\n",
    "        tn = np.sum((pred==0)&(y_true==0))\n",
    "        fp = np.sum((pred==1)&(y_true==0))\n",
    "        fn = np.sum((pred==0)&(y_true==1))\n",
    "        tp = np.sum((pred==1)&(y_true==1))\n",
    "        TNR = tn / max(1, (tn+fp))\n",
    "        J = R + TNR - 1\n",
    "        pos_rate = pred.mean()\n",
    "\n",
    "        out_rows.append({\"thr\": t, \"precision\": P, \"recall\": R, \"f1\": F1,\n",
    "                         \"youdenJ\": J, \"pos_rate\": pos_rate, \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn})\n",
    "\n",
    "        if method == \"f1\":\n",
    "            key = (F1, 0.0)\n",
    "        elif method == \"youden\":\n",
    "            key = (J, 0.0)\n",
    "        elif method == \"posrate\" and target_pos_rate is not None:\n",
    "            key = (-abs(pos_rate - target_pos_rate), 0.0)\n",
    "        elif method == \"constraint\":\n",
    "            if (min_precision is not None and P < min_precision) or (min_recall is not None and R < min_recall):\n",
    "                key = (-1e9, -1e9)\n",
    "            else:\n",
    "                key = (R, F1)\n",
    "        else:\n",
    "            key = (F1, 0.0)\n",
    "\n",
    "        if key > best_key:\n",
    "            best_key = key\n",
    "            best_thr = t\n",
    "\n",
    "    table = pd.DataFrame(out_rows).sort_values(\"thr\").reset_index(drop=True)\n",
    "    best_row = table.loc[table[\"thr\"].sub(best_thr).abs().idxmin()].to_dict()\n",
    "    return float(best_thr), best_row, table\n",
    "\n",
    "# =========================\n",
    "# 时间切分\n",
    "# =========================\n",
    "def temporal_split(df_clean: pd.DataFrame,\n",
    "                   label_col=\"value_sort\",\n",
    "                   cutoff_date=None,\n",
    "                   test_size_ratio=0.2,\n",
    "                   val_size_ratio=0.1):\n",
    "    assert label_col in df_clean.columns\n",
    "    df = df_clean.copy().sort_index()\n",
    "    feat_cols = df.columns.drop([label_col]).tolist()\n",
    "    X_all = df[feat_cols].values\n",
    "    y_all = df[label_col].astype(int).values\n",
    "\n",
    "    if cutoff_date is not None:\n",
    "        assert isinstance(df.index, pd.DatetimeIndex), \"需 DatetimeIndex 才能按日期切分\"\n",
    "        mask_trainval = (df.index <= pd.to_datetime(cutoff_date))\n",
    "        X_trainval, y_trainval = X_all[mask_trainval], y_all[mask_trainval]\n",
    "        X_test, y_test = X_all[~mask_trainval], y_all[~mask_trainval]\n",
    "        n_tv = len(X_trainval)\n",
    "        n_val = max(1, int(n_tv * val_size_ratio))\n",
    "        X_tr, y_tr = X_trainval[:-n_val], y_trainval[:-n_val]\n",
    "        X_val, y_val = X_trainval[-n_val:], y_trainval[-n_val:]\n",
    "        return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "    N = len(X_all)\n",
    "    n_test = max(1, int(N * test_size_ratio))\n",
    "    X_tv, y_tv = X_all[:-n_test], y_all[:-n_test]\n",
    "    X_test, y_test = X_all[-n_test:], y_all[-n_test:]\n",
    "    n_tv = len(X_tv)\n",
    "    n_val = max(1, int(n_tv * val_size_ratio))\n",
    "    X_tr, y_tr = X_tv[:-n_val], y_tv[:-n_val]\n",
    "    X_val, y_val = X_tv[-n_val:], y_tv[-n_val:]\n",
    "    return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "# =========================\n",
    "# 面向对象：LightGBM Bagging\n",
    "# =========================\n",
    "class LGBMBaggingEnsembler:\n",
    "    def __init__(self,\n",
    "                 base_params: dict,\n",
    "                 bags: int = 25,\n",
    "                 sample_ratio: float = 0.85,\n",
    "                 jitter_scale: float = 0.12,\n",
    "                 inner_es_ratio: float = 0.10,   # boot 内最后 10% 做内置早停\n",
    "                 early_stopping_rounds: int = 200,\n",
    "                 random_seed: int = 42):\n",
    "        self.base_params = dict(base_params)\n",
    "        self.bags = bags\n",
    "        self.sample_ratio = sample_ratio\n",
    "        self.jitter_scale = jitter_scale\n",
    "        self.inner_es_ratio = inner_es_ratio\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.random_seed = random_seed\n",
    "        self.models_ = []\n",
    "        self.alphas_ = None\n",
    "        self.best_thr_ = 0.5\n",
    "        self.val_probs_ = None\n",
    "\n",
    "    def _jitter_params(self, rng):\n",
    "        cfg = dict(self.base_params)\n",
    "        jit = (rng.rand(5) - 0.5) * 2 * self.jitter_scale\n",
    "        cfg[\"subsample\"]         = float(np.clip(cfg.get(\"subsample\", 0.8) * (1 + jit[0]), 0.5, 1.0))\n",
    "        cfg[\"colsample_bytree\"]  = float(np.clip(cfg.get(\"colsample_bytree\", 0.8) * (1 + jit[1]), 0.5, 1.0))\n",
    "        cfg[\"num_leaves\"]        = int(np.clip(round(cfg.get(\"num_leaves\", 63) * (1 + jit[2])), 15, 255))\n",
    "        base_depth = cfg.get(\"max_depth\", -1)\n",
    "        if base_depth == -1: base_depth = 6\n",
    "        cfg[\"max_depth\"]         = int(np.clip(round(base_depth * (1 + jit[3])), 3, 12))\n",
    "        cfg[\"min_child_samples\"] = int(np.clip(round(cfg.get(\"min_child_samples\", 20) * (1 + jit[4])), 5, 300))\n",
    "        return cfg\n",
    "\n",
    "    def fit(self, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit):\n",
    "        rng = np.random.RandomState(self.random_seed)\n",
    "        n_train = X_tr_fit.shape[0]\n",
    "        self.models_ = []\n",
    "        val_probs_list = []\n",
    "\n",
    "        for b in range(self.bags):\n",
    "            idx_boot = rng.choice(n_train, int(self.sample_ratio * n_train), replace=True)\n",
    "            idx_boot.sort()\n",
    "            es_pt = max(1, int(len(idx_boot) * (1 - self.inner_es_ratio)))\n",
    "            tr_idx = idx_boot[:es_pt]\n",
    "            es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "\n",
    "            cfg = self._jitter_params(rng)\n",
    "            clf = LGBMClassifier(\n",
    "                objective=\"binary\",\n",
    "                class_weight=\"balanced\",\n",
    "                n_jobs=-1, verbosity=-1,\n",
    "                random_state=self.random_seed + b,\n",
    "                **cfg\n",
    "            )\n",
    "            clf.fit(\n",
    "                X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "                eval_set=[(X_tr_fit[es_idx], y_tr_fit[es_idx])],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[early_stopping(self.early_stopping_rounds, verbose=False)]\n",
    "            )\n",
    "            self.models_.append(clf)\n",
    "            val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "\n",
    "        self.val_probs_ = np.column_stack(val_probs_list)  # [n_val, B]\n",
    "        return self\n",
    "\n",
    "    # —— 各子模型概率矩阵\n",
    "    def predict_proba_members(self, X):\n",
    "        probs = [m.predict_proba(X)[:, 1] for m in self.models_]\n",
    "        return np.column_stack(probs)\n",
    "\n",
    "    # —— 加权融合概率\n",
    "    def predict_proba(self, X, alphas=None):\n",
    "        alphas = alphas if alphas is not None else (self.alphas_ if self.alphas_ is not None else np.ones(self.bags)/self.bags)\n",
    "        probs = self.predict_proba_members(X)\n",
    "        return (probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "\n",
    "    # —— 验证集上学权重 + 阈值（无泄露）\n",
    "    def alphas_optuna_on_val(self, y_val, n_trials=60, metric=\"acc\"):\n",
    "        return self._alphas_optuna_on_probs(y_val, self.val_probs_, n_trials=n_trials, metric=metric)\n",
    "\n",
    "    # —— 通用：在给定 (y, probs) 上学权重 + 阈值\n",
    "    def _alphas_optuna_on_probs(self, y, probs, n_trials=60, metric=\"acc\"):\n",
    "        B = probs.shape[1]\n",
    "        def objective(trial):\n",
    "            ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(B)])\n",
    "            a  = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "            blend = (probs * a.reshape(1, -1)).sum(axis=1)\n",
    "            ths = np.linspace(0.01, 0.99, 99)\n",
    "            def score(t):\n",
    "                yp = (blend >= t).astype(int)\n",
    "                if metric == \"f1\":   return f1_score(y, yp, zero_division=0)\n",
    "                if metric == \"prec\": return precision_score(y, yp, zero_division=0)\n",
    "                if metric == \"rec\":  return recall_score(y, yp, zero_division=0)\n",
    "                return accuracy_score(y, yp)\n",
    "            scores = np.array([score(t) for t in ths])\n",
    "            best_t = float(ths[scores.argmax()])\n",
    "            trial.set_user_attr(\"best_t\", best_t)\n",
    "            return float(scores.max())\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "        best_w = np.array([study.best_params[k] for k in sorted(study.best_params.keys(), key=lambda s:int(s[1:]))])\n",
    "        a = np.exp(best_w); a /= (a.sum() + 1e-12)\n",
    "        best_t = float(study.best_trial.user_attrs[\"best_t\"])\n",
    "        return a, best_t\n",
    "\n",
    "# =========================\n",
    "# 主流程（含“泄露对照块”）\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # 这里假定你已准备好 df_clean（含 value_sort；索引为时间顺序）\n",
    "    # 例如：\n",
    "    # df_clean = pd.read_csv(\"your_data.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "    # assert \"value_sort\" in df_clean.columns\n",
    "\n",
    "    # ===== 时间切分：前80%训练，后20%测试；训练末尾10%作验证 =====\n",
    "    X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols = temporal_split(\n",
    "        df_clean, label_col=\"value_sort\", cutoff_date=None, test_size_ratio=0.2, val_size_ratio=0.1\n",
    "    )\n",
    "\n",
    "    # ===== 漂移检查（TrainFit vs Test） =====\n",
    "    df_tr_fit = pd.DataFrame(X_tr_fit_raw, columns=feat_cols)\n",
    "    df_te     = pd.DataFrame(X_te_raw,     columns=feat_cols)\n",
    "    rep_tr_te = drift_report(df_tr_fit, df_te, categorical_cols=[], topk=30)\n",
    "    print(\"\\n==== Top Drifted Features (TrainFit vs Test) ====\")\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    print(rep_tr_te.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    # ===== 两套中心参数（按你之前）=====\n",
    "    BASE_PARAMS = dict(\n",
    "        learning_rate=0.1305241307456396,\n",
    "        num_leaves=86,\n",
    "        max_depth=6,\n",
    "        min_child_samples=103,\n",
    "        subsample=0.5600223085390776,\n",
    "        colsample_bytree=0.608980878948645,\n",
    "        reg_alpha=2.3147174999485715e-05,\n",
    "        reg_lambda=0.00042189753661999455,\n",
    "        n_estimators=1079\n",
    "    )\n",
    "\n",
    "    # ===== 训练 Bagging（无泄露：内置早停仅用 boot 内片）=====\n",
    "    ens = LGBMBaggingEnsembler(base_params=BASE_PARAMS,\n",
    "                               bags=25, sample_ratio=0.85,\n",
    "                               jitter_scale=0.12, inner_es_ratio=0.10,\n",
    "                               early_stopping_rounds=200, random_seed=42)\n",
    "    ens.fit(X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit)\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # (A) 基准：验证集上学权重+阈值（无测试泄露），再到测试集评估\n",
    "    # ----------------------------------------------------------------------\n",
    "    alphas_val, thr_val = ens.alphas_optuna_on_val(y_val_fit, n_trials=60, metric=\"acc\")\n",
    "    print(\"\\n[BASELINE - NO LEAK] alphas (first 10):\", np.round(alphas_val[:10], 4))\n",
    "    val_blend = ens.predict_proba(X_val_fit_raw, alphas_val)\n",
    "    # 也可换 F1-opt 阈值\n",
    "    thr_f1, _, _ = choose_threshold(y_val_fit, val_blend, method=\"f1\")\n",
    "    chosen_thr = thr_f1\n",
    "    y_te_prob_base = ens.predict_proba(X_te_raw, alphas_val)\n",
    "    report_all(y_te, y_te_prob_base, thr=chosen_thr, title=\"Test (Baseline, tuned on VAL)\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # (B) 泄露实验：在【测试集】上学权重+阈值（面向测试集调参）\n",
    "    #      —— 这会“污染”评估，只用于演示泄露会把指标抬高\n",
    "    # ----------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*22 + \"  WARNING: TEST LEAK MODE (DO NOT USE IN PRODUCTION)  \" + \"=\"*22)\n",
    "    te_member_probs = ens.predict_proba_members(X_te_raw)   # [n_test, B]\n",
    "    alphas_leak, thr_leak = ens._alphas_optuna_on_probs(y_te, te_member_probs, n_trials=60, metric=\"acc\")\n",
    "    print(\"[LEAK] alphas (first 10):\", np.round(alphas_leak[:10], 4))\n",
    "    y_te_prob_leak = (te_member_probs * alphas_leak.reshape(1, -1)).sum(axis=1)\n",
    "    report_all(y_te, y_te_prob_leak, thr=thr_leak, title=\"Test (LEAK: tuned on TEST)\")\n",
    "\n",
    "    # —— 简单对比（泄露 vs 基线）\n",
    "    print(\"\\nNOTE: 指标若在 LEAK 模式显著高于 Baseline，即说明面向测试集调参带来了“虚高”。\")\n",
    "\n",
    "    # ===== 分数 PSI（TrainFit→Val / TrainFit→Test） =====\n",
    "    tr_scores  = ens.predict_proba(X_tr_fit_raw, alphas_val)\n",
    "    val_scores = val_blend\n",
    "    te_scores  = y_te_prob_base\n",
    "    print(\"\\nScore PSI (TrainFit→Val): \", f\"{score_psi(tr_scores, val_scores):.4f}\")\n",
    "    print(\"Score PSI (TrainFit→Test):\", f\"{score_psi(tr_scores, te_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af5c6a2",
   "metadata": {},
   "source": [
    "#### 最终调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd0caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:22:26,689] A new study created in memory with name: no-name-c363ef3d-a846-4f46-a39b-93af448d3976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 1234, Val-fit size: 138, Classes in Val: (array([0, 1]), array([99, 39]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:22:29,611] Trial 0 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.03574712922600244, 'num_leaves': 244, 'max_depth': 10, 'min_child_samples': 182, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'reg_alpha': 2.5502648504032812e-08, 'reg_lambda': 0.011567327199145964, 'n_estimators': 1282, 'BAGS': 31, 'SAMPLE_RATIO': 0.6072045730035308, 'JITTER_SCALE': 0.2439819704323989, 'BLOCK_SIZE': 51}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 16:22:31,651] Trial 1 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.020589728197687916, 'num_leaves': 58, 'max_depth': 4, 'min_child_samples': 95, 'subsample': 0.762378215816119, 'colsample_bytree': 0.7159725093210578, 'reg_alpha': 1.092959278721938e-06, 'reg_lambda': 0.00019185373703841887, 'n_estimators': 451, 'BAGS': 17, 'SAMPLE_RATIO': 0.7282266451527921, 'JITTER_SCALE': 0.14121399684340719, 'BLOCK_SIZE': 48}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 16:22:43,743] Trial 2 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.019721610970574007, 'num_leaves': 138, 'max_depth': 8, 'min_child_samples': 18, 'subsample': 0.8037724259507192, 'colsample_bytree': 0.5852620618436457, 'reg_alpha': 2.853390105240219e-08, 'reg_lambda': 0.04387314432435398, 'n_estimators': 1939, 'BAGS': 34, 'SAMPLE_RATIO': 0.7066148192106797, 'JITTER_SCALE': 0.06953442280127678, 'BLOCK_SIZE': 43}. Best is trial 0 with value: 0.7318840579710145.\n",
      "[I 2025-09-01 16:22:51,664] Trial 3 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.044684675025045834, 'num_leaves': 44, 'max_depth': 7, 'min_child_samples': 15, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085, 'reg_alpha': 0.000434166180036173, 'reg_lambda': 1.5204688692198897e-06, 'n_estimators': 1136, 'BAGS': 26, 'SAMPLE_RATIO': 0.6646990594339345, 'JITTER_SCALE': 0.24391692555291172, 'BLOCK_SIZE': 48}. Best is trial 3 with value: 0.7391304347826086.\n",
      "[I 2025-09-01 16:22:53,076] Trial 4 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.24420460844911424, 'num_leaves': 230, 'max_depth': 8, 'min_child_samples': 277, 'subsample': 0.5442462510259598, 'colsample_bytree': 0.5979914312095727, 'reg_alpha': 2.072960479129113e-08, 'reg_lambda': 1.8937049541631268e-06, 'n_estimators': 900, 'BAGS': 16, 'SAMPLE_RATIO': 0.8900581282031752, 'JITTER_SCALE': 0.12135066533871786, 'BLOCK_SIZE': 20}. Best is trial 3 with value: 0.7391304347826086.\n",
      "[I 2025-09-01 16:23:05,368] Trial 5 finished with value: 0.7463768115942029 and parameters: {'learning_rate': 0.06333268775321843, 'num_leaves': 48, 'max_depth': 11, 'min_child_samples': 27, 'subsample': 0.9934434683002586, 'colsample_bytree': 0.8861223846483287, 'reg_alpha': 2.4604229580184137e-07, 'reg_lambda': 1.0930872279404512e-08, 'n_estimators': 1668, 'BAGS': 31, 'SAMPLE_RATIO': 0.8551525088143455, 'JITTER_SCALE': 0.20425406933718915, 'BLOCK_SIZE': 9}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:09,458] Trial 6 finished with value: 0.717391304347826 and parameters: {'learning_rate': 0.0338452204120114, 'num_leaves': 42, 'max_depth': 11, 'min_child_samples': 189, 'subsample': 0.6654490124263246, 'colsample_bytree': 0.5317791751430119, 'reg_alpha': 1.5027137214154512e-06, 'reg_lambda': 1.8892231305534347e-06, 'n_estimators': 1514, 'BAGS': 29, 'SAMPLE_RATIO': 0.9105244599017143, 'JITTER_SCALE': 0.14444298503238986, 'BLOCK_SIZE': 11}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:10,283] Trial 7 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.1131225105716033, 'num_leaves': 198, 'max_depth': 8, 'min_child_samples': 233, 'subsample': 0.7468977981821954, 'colsample_bytree': 0.7613664146909971, 'reg_alpha': 9.835289062589953e-06, 'reg_lambda': 1.5063777323554413e-08, 'n_estimators': 394, 'BAGS': 9, 'SAMPLE_RATIO': 0.8227436439423231, 'JITTER_SCALE': 0.11287119621526534, 'BLOCK_SIZE': 33}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:13,834] Trial 8 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.21907142272152816, 'num_leaves': 75, 'max_depth': 7, 'min_child_samples': 228, 'subsample': 0.6143990827458112, 'colsample_bytree': 0.5384899549143964, 'reg_alpha': 1.067235272504377e-06, 'reg_lambda': 1.3444634828135513e-07, 'n_estimators': 1874, 'BAGS': 34, 'SAMPLE_RATIO': 0.8216913147786482, 'JITTER_SCALE': 0.22429211803754356, 'BLOCK_SIZE': 50}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:20,359] Trial 9 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.018861950443028862, 'num_leaves': 230, 'max_depth': 8, 'min_child_samples': 244, 'subsample': 0.9480456499617467, 'colsample_bytree': 0.6590017374859319, 'reg_alpha': 5.893366793227604e-08, 'reg_lambda': 3.940452872934755e-07, 'n_estimators': 969, 'BAGS': 34, 'SAMPLE_RATIO': 0.9012557041397202, 'JITTER_SCALE': 0.051390426106238146, 'BLOCK_SIZE': 33}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:28,991] Trial 10 finished with value: 0.7463768115942029 and parameters: {'learning_rate': 0.09052258100123718, 'num_leaves': 109, 'max_depth': 12, 'min_child_samples': 98, 'subsample': 0.8694232604167318, 'colsample_bytree': 0.9299795486630184, 'reg_alpha': 0.05228718023161359, 'reg_lambda': 0.00017952979129578158, 'n_estimators': 1611, 'BAGS': 40, 'SAMPLE_RATIO': 0.8068918149632419, 'JITTER_SCALE': 0.19089796127501782, 'BLOCK_SIZE': 6}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:36,178] Trial 11 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.09599431505521556, 'num_leaves': 125, 'max_depth': 12, 'min_child_samples': 94, 'subsample': 0.8838129988503958, 'colsample_bytree': 0.9397568294918888, 'reg_alpha': 0.043911446389122616, 'reg_lambda': 0.00013309191582934558, 'n_estimators': 1572, 'BAGS': 40, 'SAMPLE_RATIO': 0.8214103623035983, 'JITTER_SCALE': 0.19267023995073967, 'BLOCK_SIZE': 6}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:44,059] Trial 12 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.08341182607402586, 'num_leaves': 101, 'max_depth': 12, 'min_child_samples': 77, 'subsample': 0.9996812193207757, 'colsample_bytree': 0.9331784333464821, 'reg_alpha': 0.026768147840595807, 'reg_lambda': 0.0013250149951858762, 'n_estimators': 1637, 'BAGS': 40, 'SAMPLE_RATIO': 0.7760788688180434, 'JITTER_SCALE': 0.17999510893196924, 'BLOCK_SIZE': 18}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:50,044] Trial 13 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.0672493964469151, 'num_leaves': 167, 'max_depth': 10, 'min_child_samples': 59, 'subsample': 0.8716959229904154, 'colsample_bytree': 0.8476452179096918, 'reg_alpha': 0.00044908215405487195, 'reg_lambda': 1.5300429170919867e-05, 'n_estimators': 1330, 'BAGS': 23, 'SAMPLE_RATIO': 0.8659039256313065, 'JITTER_SCALE': 0.1895345197932942, 'BLOCK_SIZE': 20}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:54,894] Trial 14 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.1501515759041132, 'num_leaves': 23, 'max_depth': 10, 'min_child_samples': 134, 'subsample': 0.8862263283638486, 'colsample_bytree': 0.9898232498406145, 'reg_alpha': 0.002219380492343805, 'reg_lambda': 1.4552364153860706e-08, 'n_estimators': 1723, 'BAGS': 37, 'SAMPLE_RATIO': 0.7822881781146034, 'JITTER_SCALE': 0.20912616365201198, 'BLOCK_SIZE': 5}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:23:59,612] Trial 15 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.010839293998112624, 'num_leaves': 92, 'max_depth': 12, 'min_child_samples': 134, 'subsample': 0.8268548079220719, 'colsample_bytree': 0.8676718934536226, 'reg_alpha': 1.9389771617227107e-05, 'reg_lambda': 3.372480607619457e-05, 'n_estimators': 714, 'BAGS': 26, 'SAMPLE_RATIO': 0.859901542058441, 'JITTER_SCALE': 0.17083170990023994, 'BLOCK_SIZE': 14}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:24:05,169] Trial 16 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.05769918643503009, 'num_leaves': 126, 'max_depth': 5, 'min_child_samples': 40, 'subsample': 0.9885067269670117, 'colsample_bytree': 0.8216160887403162, 'reg_alpha': 0.00428019923682433, 'reg_lambda': 0.0013812449471928981, 'n_estimators': 1399, 'BAGS': 22, 'SAMPLE_RATIO': 0.9482608683327727, 'JITTER_SCALE': 0.21584329298056237, 'BLOCK_SIZE': 26}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:24:08,807] Trial 17 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.17259050212178154, 'num_leaves': 80, 'max_depth': 11, 'min_child_samples': 124, 'subsample': 0.9192935333529579, 'colsample_bytree': 0.9004643778053921, 'reg_alpha': 0.00017736043440434187, 'reg_lambda': 0.0015017473065640323, 'n_estimators': 1765, 'BAGS': 30, 'SAMPLE_RATIO': 0.7266654597340514, 'JITTER_SCALE': 0.16631961659372296, 'BLOCK_SIZE': 59}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:24:17,733] Trial 18 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.12959491637026557, 'num_leaves': 20, 'max_depth': 9, 'min_child_samples': 50, 'subsample': 0.7233868647082243, 'colsample_bytree': 0.8015633900739458, 'reg_alpha': 1.536278433709848e-07, 'reg_lambda': 1.6363264550791198e-05, 'n_estimators': 1968, 'BAGS': 37, 'SAMPLE_RATIO': 0.8031431630847168, 'JITTER_SCALE': 0.2043585057367532, 'BLOCK_SIZE': 25}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:24:20,606] Trial 19 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.07557196507734164, 'num_leaves': 157, 'max_depth': 6, 'min_child_samples': 176, 'subsample': 0.8275986414829076, 'colsample_bytree': 0.998866281593814, 'reg_alpha': 2.637509334157424e-07, 'reg_lambda': 1.2528187355766316e-07, 'n_estimators': 1149, 'BAGS': 20, 'SAMPLE_RATIO': 0.9497947229306897, 'JITTER_SCALE': 0.159293510647399, 'BLOCK_SIZE': 11}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:24:26,191] Trial 20 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.04542457172004153, 'num_leaves': 108, 'max_depth': 3, 'min_child_samples': 97, 'subsample': 0.9357481509534022, 'colsample_bytree': 0.7654838078648496, 'reg_alpha': 6.724609625673063e-06, 'reg_lambda': 0.00020419990250446985, 'n_estimators': 1460, 'BAGS': 37, 'SAMPLE_RATIO': 0.8509863794805478, 'JITTER_SCALE': 0.09546275051641637, 'BLOCK_SIZE': 27}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:24:34,725] Trial 21 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.043949663676046066, 'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 11, 'subsample': 0.9587590064553538, 'colsample_bytree': 0.6853096597803514, 'reg_alpha': 7.991412728017782e-05, 'reg_lambda': 2.7877475064322106e-06, 'n_estimators': 1135, 'BAGS': 26, 'SAMPLE_RATIO': 0.6177327642789445, 'JITTER_SCALE': 0.23560554096318886, 'BLOCK_SIZE': 40}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:24:42,150] Trial 22 finished with value: 0.7318840579710145 and parameters: {'learning_rate': 0.028562886096640736, 'num_leaves': 61, 'max_depth': 11, 'min_child_samples': 28, 'subsample': 0.9067403551797433, 'colsample_bytree': 0.6517824013849883, 'reg_alpha': 0.0017551187486488568, 'reg_lambda': 7.168018897878997e-08, 'n_estimators': 217, 'BAGS': 27, 'SAMPLE_RATIO': 0.6544891775479816, 'JITTER_SCALE': 0.2467393293639113, 'BLOCK_SIZE': 56}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:25:02,230] Trial 23 finished with value: 0.717391304347826 and parameters: {'learning_rate': 0.051700680728508565, 'num_leaves': 34, 'max_depth': 9, 'min_child_samples': 6, 'subsample': 0.9697986312811274, 'colsample_bytree': 0.9076957758694466, 'reg_alpha': 0.011073410595793143, 'reg_lambda': 4.743396193582943e-07, 'n_estimators': 686, 'BAGS': 32, 'SAMPLE_RATIO': 0.6805918822602828, 'JITTER_SCALE': 0.22618843942388284, 'BLOCK_SIZE': 42}. Best is trial 5 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:25:05,850] Trial 24 finished with value: 0.7246376811594203 and parameters: {'learning_rate': 0.10804799883733629, 'num_leaves': 69, 'max_depth': 6, 'min_child_samples': 65, 'subsample': 0.8625774974380527, 'colsample_bytree': 0.9694444572615983, 'reg_alpha': 0.073115705700431, 'reg_lambda': 5.614537550887389e-06, 'n_estimators': 1790, 'BAGS': 18, 'SAMPLE_RATIO': 0.7510138038812539, 'JITTER_SCALE': 0.19895863126966803, 'BLOCK_SIZE': 9}. Best is trial 5 with value: 0.7463768115942029.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Joint Tuning] Best value (Val Acc of W-avg@best_thr): 0.7463768115942029\n",
      "[Joint Tuning] Best params: {'learning_rate': 0.06333268775321843, 'num_leaves': 48, 'max_depth': 11, 'min_child_samples': 27, 'subsample': 0.9934434683002586, 'colsample_bytree': 0.8861223846483287, 'reg_alpha': 2.4604229580184137e-07, 'reg_lambda': 1.0930872279404512e-08, 'n_estimators': 1668, 'BAGS': 31, 'SAMPLE_RATIO': 0.8551525088143455, 'JITTER_SCALE': 0.20425406933718915, 'BLOCK_SIZE': 9}\n",
      "[Best] BAGS=31, SAMPLE_RATIO=0.855, JITTER_SCALE=0.204, BLOCK_SIZE=9\n",
      "       BASE_CFG: {'learning_rate': 0.06333268775321843, 'num_leaves': 48, 'max_depth': 11, 'min_child_samples': 27, 'subsample': 0.9934434683002586, 'colsample_bytree': 0.8861223846483287, 'reg_alpha': 2.4604229580184137e-07, 'reg_lambda': 1.0930872279404512e-08, 'n_estimators': 1668}\n",
      "       (Val) alphas first 10: [0.0311 0.0343 0.0318 0.0322 0.032  0.0317 0.0331 0.0336 0.0311 0.0316]\n",
      "       (Val) best thr (accuracy): 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:25:19,259] A new study created in memory with name: no-name-460823c7-93e4-4661-be87-87675de11e24\n",
      "[I 2025-09-01 16:25:19,306] Trial 0 finished with value: 0.7463768115942029 and parameters: {'w0': -0.6272994057631875, 'w1': 2.2535715320495804, 'w2': 1.1599697090570253, 'w3': 0.493292420985183, 'w4': -1.7199067977878175, 'w5': -1.7200273983189867, 'w6': -2.2095819391590026, 'w7': 1.8308807288746758, 'w8': 0.5055750587160439, 'w9': 1.0403628889802272, 'w10': -2.3970775285209878, 'w11': 2.3495492608099715, 'w12': 1.662213204002109, 'w13': -1.4383044466086192, 'w14': -1.590875163964497, 'w15': -1.582977450732831, 'w16': -0.9787887852023114, 'w17': 0.12378215816118932, 'w18': -0.3402749067894213, 'w19': -1.0438542990097903, 'w20': 0.5592644736118975, 'w21': -1.8025306967397907, 'w22': -1.0392767573239092, 'w23': -0.6681907835315415, 'w24': -0.21965007891482013, 'w25': 1.4258798069650682, 'w26': -1.5016310892082014, 'w27': 0.07117219206805814, 'w28': 0.46207284431021245, 'w29': -2.2677479364000113, 'w30': 0.5377242595071916}. Best is trial 0 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:25:19,334] Trial 1 finished with value: 0.7391304347826086 and parameters: {'w0': -1.6473793815635425, 'w1': -2.1747420350736024, 'w2': 2.2444276862666666, 'w3': 2.328160165372797, 'w4': 1.5419867405823053, 'w5': -0.9769311541331467, 'w6': -2.0116394299680804, 'w7': 0.9211651325607844, 'w8': -0.29923753130199326, 'w9': -1.8898088257761059, 'w10': -0.024115449443649073, 'w11': -2.328057394423908, 'w12': 2.0466020103939107, 'w13': -1.2061000919999154, 'w14': 0.8126114217699101, 'w15': -0.9414446195529451, 'w16': 0.10034010588905407, 'w17': 0.23355139671639824, 'w18': -1.5757277223723647, 'w19': 2.347923138822793, 'w20': 1.3756641168055728, 'w21': 2.1974947078209457, 'w22': 1.9741367521382438, 'w23': 0.4894998940554256, 'w24': 2.1093711751155837, 'w25': -2.0575374897404024, 'w26': -1.520085687904274, 'w27': -2.27386355544731, 'w28': -0.8733483461836782, 'w29': -0.5566135515525898, 'w30': -1.1432548411305206}. Best is trial 0 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:25:19,361] Trial 2 finished with value: 0.7318840579710145 and parameters: {'w0': 1.6436875457596472, 'w1': -0.7162333665320535, 'w2': -1.0953274515630962, 'w3': 0.21348041579124244, 'w4': -1.7953788751261868, 'w5': 1.5109849037701988, 'w6': -2.127246781601146, 'w7': 2.4344346830025865, 'w8': 1.3612238464832869, 'w9': -1.506421592329138, 'w10': -2.472389414381988, 'w11': 1.5773071422741705, 'w12': 1.0342867192380858, 'w13': 1.1450358402049368, 'w14': 1.3563517334297286, 'w15': -2.129776741329548, 'w16': -0.7076713572786368, 'w17': -1.9206547023743514, 'w18': 1.8155171293779677, 'w19': 0.6164906341377896, 'w20': -0.8455098757367541, 'w21': -2.1822082485698817, 'w22': -0.945088391421689, 'w23': -0.8740833898662648, 'w24': 1.1480308916903201, 'w25': 0.6877873567760657, 'w26': 1.9360637128816327, 'w27': -0.13892537419025341, 'w28': -1.9020287703084915, 'w29': 1.0662239361149748, 'w30': 1.3039252430844872}. Best is trial 0 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:25:19,389] Trial 3 finished with value: 0.7318840579710145 and parameters: {'w0': 0.3063859878474813, 'w1': 1.3548358997728052, 'w2': -0.031022018178046284, 'w3': 0.1136641469099704, 'w4': -0.36229490820725196, 'w5': -2.372904366279524, 'w6': -1.9605428650334777, 'w7': -2.342854071566329, 'w8': 0.6820520563189021, 'w9': -0.9282200946183665, 'w10': 0.042853455823514075, 'w11': 2.0378323696304648, 'w12': -1.2535388542556252, 'w13': -0.44808538482185156, 'w14': 1.2777556927152434, 'w15': -1.3560091725418877, 'w16': -2.115100450856035, 'w17': -1.0512427354311598, 'w18': -1.693893563729978, 'w19': 2.148488261712865, 'w20': 1.5406018978220848, 'w21': 0.6670187825521174, 'w22': 1.857302950938589, 'w23': 1.5183603844955726, 'w24': -1.567149705569821, 'w25': 1.962794992449889, 'w26': 0.1967112095782535, 'w27': 1.5372007758203123, 'w28': 1.9804564996174658, 'w29': -0.9099826251406806, 'w30': -1.9497403773616162}. Best is trial 0 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:25:19,416] Trial 4 finished with value: 0.7318840579710145 and parameters: {'w0': -1.3603241872902916, 'w1': -0.36446105686871855, 'w2': 1.5900738296124652, 'w3': 1.8036529162817168, 'w4': -2.4652393473440464, 'w5': 0.05373651288782888, 'w6': -0.41294498425610504, 'w7': -1.3894609476463486, 'w8': -1.9006731633315859, 'w9': -0.8119241429818602, 'w10': 2.2145485195625962, 'w11': -0.8839853398962239, 'w12': 0.0939531087168306, 'w13': 1.015094794475889, 'w14': -0.6818519881035301, 'w15': 2.3589104136048036, 'w16': 2.3122364747105557, 'w17': -1.2410885208731792, 'w18': -0.013757470538072525, 'w19': -0.9956084509161518, 'w20': -1.075797528112662, 'w21': -2.3155652632273362, 'w22': 0.5478216698994842, 'w23': 0.01339511614430755, 'w24': -2.2426062437500534, 'w25': -1.1067676788169427, 'w26': 2.0413294298332687, 'w27': -1.302190546665138, 'w28': -1.7755256395438845, 'w29': -0.052736198612184815, 'w30': 2.4282522705530036}. Best is trial 0 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:25:19,444] Trial 5 finished with value: 0.7318840579710145 and parameters: {'w0': -1.2897236424424978, 'w1': 0.860677737029393, 'w2': 1.3080980766435877, 'w3': -1.3118122800380017, 'w4': 1.1410817430592979, 'w5': -0.661084336403734, 'w6': 0.6615291529678973, 'w7': 0.6676485538044736, 'w8': 0.1788734203737925, 'w9': -2.0485511497279587, 'w10': 1.67651247794619, 'w11': -0.8960996751413208, 'w12': -1.5674074480007287, 'w13': -2.2961242922261804, 'w14': 0.4544647159412092, 'w15': 0.8878218092114123, 'w16': -2.4170608553607194, 'w17': 0.060465291496405005, 'w18': -1.3675211240103102, 'w19': 0.7258639520472494, 'w20': -1.6281678549750427, 'w21': 0.95468869051233, 'w22': -0.566323268497313, 'w23': 2.1836499436836725, 'w24': -1.8123952792700337, 'w25': -0.7946682447487075, 'w26': -1.9326323937970546, 'w27': 2.123468091392814, 'w28': 1.8866967669049046, 'w29': -1.210291861424222, 'w30': 0.799920230170895}. Best is trial 0 with value: 0.7463768115942029.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== (Tuned) Bagging — Simple Avg (thr from val) Performance ====\n",
      "Accuracy:      0.622093\n",
      "AUC:           0.649131\n",
      "PR-AUC:        0.520930\n",
      "LogLoss:       0.651907\n",
      "Precision@0.570: 0.567164\n",
      "Recall@0.570:    0.273381\n",
      "F1@0.570:        0.368932\n",
      "\n",
      "==== (Tuned) Bagging — Val-AUC Weighted (thr from val) Performance ====\n",
      "Accuracy:      0.604651\n",
      "AUC:           0.649377\n",
      "PR-AUC:        0.521140\n",
      "LogLoss:       0.651956\n",
      "Precision@0.610: 0.531915\n",
      "Recall@0.610:    0.179856\n",
      "F1@0.610:        0.268817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 16:25:19,473] Trial 6 finished with value: 0.7391304347826086 and parameters: {'w0': 1.5861110010060795, 'w1': 0.27600405799731176, 'w2': 0.14825289178003231, 'w3': -1.2907385454977416, 'w4': -2.034486160970504, 'w5': 1.9860787897666334, 'w6': 2.002090285816652, 'w7': 0.6655072863663398, 'w8': -0.8048510447564965, 'w9': -0.7539521269366956, 'w10': 1.129778394351197, 'w11': 1.9855512997628857, 'w12': 1.9354321213255865, 'w13': 1.399377729288119, 'w14': 0.7101582307714387, 'w15': -2.079300175024756, 'w16': -1.6918564295269312, 'w17': 1.9927709426353966, 'w18': 0.5321452982979498, 'w19': -2.454014741916852, 'w20': -1.9926422856698394, 'w21': 0.8175088455402788, 'w22': -2.4746920807689063, 'w23': -1.6959597429125068, 'w24': 0.24366894683293072, 'w25': 0.959475988463466, 'w26': 0.7598062975130029, 'w27': -1.378653452697201, 'w28': 1.0608961067376792, 'w29': -1.3137545625159996, 'w30': -0.8730015092036614}. Best is trial 0 with value: 0.7463768115942029.\n",
      "[I 2025-09-01 16:25:19,504] Trial 7 finished with value: 0.7536231884057971 and parameters: {'w0': 1.2324570255901208, 'w1': 0.7481644952360735, 'w2': 1.7461170524708898, 'w3': 0.7880644615017167, 'w4': 0.34154301667735787, 'w5': -2.0316261608595374, 'w6': -0.6614209847028323, 'w7': -1.1739881615913728, 'w8': -1.2800517831045821, 'w9': 2.365052773762228, 'w10': -0.534511376666198, 'w11': 1.9602327758855669, 'w12': 0.6556931299863145, 'w13': 1.474056517708242, 'w14': 0.01318546552596045, 'w15': 0.38451942313179543, 'w16': -0.03741153090568039, 'w17': -1.5237850610097774, 'w18': 1.1122605763075266, 'w19': -1.096138187795721, 'w20': -2.378420167842731, 'w21': 0.7273614795358392, 'w22': -1.6144466029647553, 'w23': 2.2022929217645713, 'w24': 2.269642885012937, 'w25': 2.0743219511022426, 'w26': -0.6492064987227781, 'w27': -2.422716917355663, 'w28': 2.141592812938627, 'w29': -0.35907925841342836, 'w30': 2.333274095218348}. Best is trial 7 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 16:25:19,532] Trial 8 finished with value: 0.7463768115942029 and parameters: {'w0': 2.318099885446264, 'w1': 1.7650472773368007, 'w2': -1.0277555396520714, 'w3': -0.5745113569903737, 'w4': 1.7556833575842843, 'w5': -0.9153899742186118, 'w6': -1.6525362665695376, 'w7': 0.2840063122917509, 'w8': 2.180773870803905, 'w9': 0.9801489833748649, 'w10': 0.3503058504468246, 'w11': -2.0141175311461574, 'w12': 0.5750361334958489, 'w13': 2.450269250521316, 'w14': -1.79957992381738, 'w15': 0.0916482618186838, 'w16': 1.8868653596397769, 'w17': 1.203843088771022, 'w18': 0.9850787049763401, 'w19': 1.0124204199355464, 'w20': -0.7025442439012242, 'w21': -1.0320407786775332, 'w22': 1.546805777392568, 'w23': 1.5505669733959042, 'w24': 1.8353615929005187, 'w25': 2.066202762782357, 'w26': 0.056711994304689206, 'w27': 0.007581473435998021, 'w28': 1.4914758948338758, 'w29': 0.7498196538888258, 'w30': 1.0098343862885168}. Best is trial 7 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 16:25:19,558] Trial 9 finished with value: 0.7391304347826086 and parameters: {'w0': 1.478963347180505, 'w1': 1.9500267090878314, 'w2': -0.810024215742321, 'w3': -0.62208523680028, 'w4': -2.030090300795655, 'w5': 0.3914007049808701, 'w6': -2.3202886310162896, 'w7': -0.17200990933769944, 'w8': 0.2132231735378829, 'w9': -1.067293739358578, 'w10': 0.45416630284505377, 'w11': -2.347498750304753, 'w12': -2.313259056253928, 'w13': 1.6130028032982917, 'w14': -0.6990467929436854, 'w15': -1.8646974367405762, 'w16': 0.11121630027402185, 'w17': 1.3499677654930542, 'w18': -1.4208948625157842, 'w19': 0.6144523790950012, 'w20': -2.07326267503116, 'w21': -2.2415913941569614, 'w22': 0.15677315784073986, 'w23': 0.20317560805053247, 'w24': 0.687149507491033, 'w25': 1.1304566686133075, 'w26': 2.379260397312673, 'w27': 0.08150174150597644, 'w28': -0.8852176352937702, 'w29': 1.4759309738435182, 'w30': -1.145838743689629}. Best is trial 7 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 16:25:19,659] Trial 10 finished with value: 0.7318840579710145 and parameters: {'w0': 0.5849643016127641, 'w1': -1.6132502340892767, 'w2': -2.462263403418534, 'w3': -2.410190621925901, 'w4': 0.2027106372288553, 'w5': -2.306374000194085, 'w6': -0.4375154676542828, 'w7': -0.8909921587818062, 'w8': -2.2732127901089063, 'w9': 2.461813327301687, 'w10': -1.096195228801479, 'w11': 0.985779491700472, 'w12': -0.7216002363974865, 'w13': 0.17812132017744953, 'w14': 2.3944577064862305, 'w15': 1.4032564637491078, 'w16': 1.1446764026279854, 'w17': -2.429038848542518, 'w18': 2.0657613759419866, 'w19': -2.4492504420625005, 'w20': 0.025220084105967988, 'w21': 2.487441492991734, 'w22': -2.311762560159219, 'w23': 1.174703566281868, 'w24': -0.7618328475170857, 'w25': -0.12752246760753705, 'w26': -0.792687324652012, 'w27': -2.334647688669038, 'w28': 2.414406684975964, 'w29': 2.310663769746339, 'w30': 2.4968121932077567}. Best is trial 7 with value: 0.7536231884057971.\n",
      "[I 2025-09-01 16:25:19,768] Trial 11 finished with value: 0.7608695652173914 and parameters: {'w0': -0.4153769583624968, 'w1': 0.68347963953445, 'w2': 1.047626482930677, 'w3': 0.9482937482166074, 'w4': -0.6194154870282469, 'w5': -1.6865814167992712, 'w6': -1.0238009090858309, 'w7': 2.0680129297023186, 'w8': -1.297626606183373, 'w9': 1.8452921101378075, 'w10': -2.3620287876463366, 'w11': 0.6802914614800182, 'w12': 1.319558848938305, 'w13': -1.940702188838602, 'w14': -1.9125956289258994, 'w15': -0.4704794258380429, 'w16': -0.9466428266575979, 'w17': -0.6668802008420422, 'w18': -0.25725971554961946, 'w19': -1.0196846460955333, 'w20': 0.5090609574827855, 'w21': -0.6462518762604517, 'w22': -1.3591502880780695, 'w23': -2.4762994017345537, 'w24': -0.41492632538400287, 'w25': 2.446130115375534, 'w26': -2.434574026378248, 'w27': 0.802996229142291, 'w28': 0.5201510842735828, 'w29': -2.489425463804483, 'w30': -0.06835421118392038}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:19,906] Trial 12 finished with value: 0.7608695652173914 and parameters: {'w0': -2.4341039280953822, 'w1': 0.5281349625950813, 'w2': 2.4381326495460476, 'w3': 1.2519315958985457, 'w4': -0.5869824391861674, 'w5': -1.613487103463414, 'w6': -0.9962204593672933, 'w7': -1.3857437695480361, 'w8': -1.2442268819650102, 'w9': 2.4925266940601323, 'w10': -1.404109908216335, 'w11': 0.5765733373323396, 'w12': 1.0292508355098977, 'w13': -2.435111604465309, 'w14': -2.44153198286232, 'w15': -0.4847152725636096, 'w16': 0.7644233465294357, 'w17': -0.9098253895925703, 'w18': 1.2734934836943055, 'w19': -1.1274142355369294, 'w20': 2.2642229726309986, 'w21': -0.4951688117387529, 'w22': -1.6586992124807554, 'w23': -2.229380441257027, 'w24': -0.8929775554082406, 'w25': 2.3904746491460953, 'w26': -2.359235185154458, 'w27': 0.9453800363918513, 'w28': 0.15542864478120366, 'w29': -2.472290877353936, 'w30': -0.3522931744147068}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,011] Trial 13 finished with value: 0.7536231884057971 and parameters: {'w0': -2.4834493082154196, 'w1': 0.08676282607033406, 'w2': 2.3352750268882003, 'w3': 1.2843729083281492, 'w4': -0.8116832393236182, 'w5': -1.390543833488842, 'w6': -1.0494491650514612, 'w7': -2.285740063781021, 'w8': -1.3620975631091432, 'w9': 1.5183951801405762, 'w10': -1.4303477301239076, 'w11': 0.38563282744450966, 'w12': 1.346744169124311, 'w13': -2.4132079824711554, 'w14': -2.4658409993235124, 'w15': -0.6518374411537343, 'w16': 0.7844642023250052, 'w17': -0.654090064603477, 'w18': -0.6103755177392527, 'w19': -0.4271079838413899, 'w20': 2.442618778519669, 'w21': -0.5705022736570697, 'w22': -1.6338607958337832, 'w23': -2.436705200876996, 'w24': -0.8061043065214577, 'w25': 2.413842220836627, 'w26': -2.3251681490661746, 'w27': 1.1403771915125585, 'w28': -0.06979333907083787, 'w29': -2.174566040860002, 'w30': -0.4270412170253124}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,116] Trial 14 finished with value: 0.7318840579710145 and parameters: {'w0': -2.456560525859899, 'w1': -0.9021745574457454, 'w2': 0.6696078014935699, 'w3': 1.3939028685989148, 'w4': -1.0610546056667267, 'w5': 0.7951364600703577, 'w6': 0.4533963541904018, 'w7': -0.438736189935539, 'w8': -0.7196158678904538, 'w9': 1.6778403490636775, 'w10': -1.671947403508478, 'w11': -0.28425879254182584, 'w12': 2.329594306074906, 'w13': -1.5486619739352525, 'w14': -2.2878296074054725, 'w15': -0.533750721779598, 'w16': -1.0615733881727396, 'w17': -0.4879996777452275, 'w18': -2.395035916611501, 'w19': -1.6980823963142833, 'w20': 2.3928693382805797, 'w21': -0.33885654770327356, 'w22': -1.6620041143861723, 'w23': -2.472602497502918, 'w24': -0.9027890385077839, 'w25': 0.2875882578640371, 'w26': -2.4847900383469606, 'w27': 0.8728917172847991, 'w28': 0.2300702388985476, 'w29': -2.426176802102936, 'w30': -0.15130076800188422}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,223] Trial 15 finished with value: 0.7391304347826086 and parameters: {'w0': -0.4590526654800974, 'w1': 0.9721479331841678, 'w2': 0.5517399759778114, 'w3': 2.339592799768431, 'w4': 0.8126861271066621, 'w5': -0.35595788955225405, 'w6': -1.1776851142940241, 'w7': 1.6910841702156174, 'w8': -1.5700138870663405, 'w9': 0.03824309423591332, 'w10': -1.7591932168588627, 'w11': 0.7727796518909452, 'w12': -0.09288033392503348, 'w13': -1.9105932471945755, 'w14': -1.550021425926925, 'w15': -0.18447613151073644, 'w16': 1.0132350435910826, 'w17': 0.6469948162831118, 'w18': 1.3249464587789666, 'w19': -0.24047386986563044, 'w20': 1.0854717361107034, 'w21': -1.1987265718312659, 'w22': -0.3473294949843242, 'w23': -1.6407517864723191, 'w24': -0.1807870771178336, 'w25': 1.6215357185980603, 'w26': -0.9412715018214226, 'w27': 2.328224143100649, 'w28': -0.5218843964521941, 'w29': -1.8085444749338662, 'w30': -2.116928153770396}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,323] Trial 16 finished with value: 0.7536231884057971 and parameters: {'w0': -0.4977383555830809, 'w1': 0.38208664098749745, 'w2': 2.415419135776435, 'w3': 0.8976959610329054, 'w4': -0.9252989087274408, 'w5': -1.3340261641442575, 'w6': 1.334801453332974, 'w7': -1.768941787132254, 'w8': -2.2777921973941018, 'w9': 0.2833643660620231, 'w10': -0.8526508963636664, 'w11': -0.17149953154606878, 'w12': 0.9695253489477033, 'w13': -0.4956712774151856, 'w14': -0.9274142385998871, 'w15': -1.0538961770148618, 'w16': -0.4063638571564614, 'w17': -0.5154603176442303, 'w18': 2.4812277273169263, 'w19': -1.7225346677729017, 'w20': 1.8143125202426258, 'w21': 0.12321652754961909, 'w22': 0.8303967609377111, 'w23': -1.6798065338346362, 'w24': -1.4252406017534613, 'w25': 2.3629626977721188, 'w26': 1.088837623812292, 'w27': 0.7004100731817076, 'w28': 0.835734723999064, 'w29': -1.6773122992530454, 'w30': 0.14807431946214072}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,437] Trial 17 finished with value: 0.7391304347826086 and parameters: {'w0': -1.8474448267586319, 'w1': 1.4846286451773145, 'w2': 1.776836967426946, 'w3': 1.6663740762734314, 'w4': 2.4597823268162418, 'w5': -1.7536426882330804, 'w6': 0.03612657557746757, 'w7': -0.7666672550082878, 'w8': -0.6575040140824782, 'w9': 1.8425770063019833, 'w10': -1.9468563425059011, 'w11': 1.2807714220580158, 'w12': 0.1543262787840145, 'w13': -0.8864985827150504, 'w14': -2.0164357647874835, 'w15': 0.6842433342536183, 'w16': -1.502073395544664, 'w17': -1.8982850106488591, 'w18': 0.6951536286144564, 'w19': -1.6208607484737343, 'w20': 0.43369186440959134, 'w21': -1.3134579941909907, 'w22': -1.1512203821270597, 'w23': -0.9632345652348377, 'w24': 0.5973821972351815, 'w25': -0.31224927018332344, 'w26': -1.7025534050980664, 'w27': 1.6217021384163888, 'w28': -0.28165126032280396, 'w29': -1.6229409915310347, 'w30': -1.594783891252234}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,545] Trial 18 finished with value: 0.7318840579710145 and parameters: {'w0': -0.9224209073039209, 'w1': -1.088167908570905, 'w2': 0.9271524793375312, 'w3': 1.1342898091920455, 'w4': -0.22154233248967578, 'w5': -0.29230435094045326, 'w6': -1.29869535097039, 'w7': 1.3329774633679519, 'w8': -1.179523838950302, 'w9': 0.6405611324604382, 'w10': -2.1201199646969986, 'w11': 0.3981164212942302, 'w12': 1.479799607975226, 'w13': -1.8571396495729298, 'w14': -1.1569421957702533, 'w15': 1.2533503422232535, 'w16': 0.5175783413114388, 'w17': -0.6249172788974258, 'w18': -0.7597605554089119, 'w19': -0.5620923530475856, 'w20': 1.903719797943772, 'w21': 0.10909689660926941, 'w22': -2.1171277509129354, 'w23': -1.8237781452506159, 'w24': -2.4528183583991656, 'w25': -2.400752566691934, 'w26': -1.2059717944244914, 'w27': -0.6541003648515148, 'w28': -2.492749941036233, 'w29': -2.4202010607980693, 'w30': -0.3724314533544308}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,646] Trial 19 finished with value: 0.7391304347826086 and parameters: {'w0': 0.0422056790894616, 'w1': -0.27623699048694556, 'w2': -0.4259864913693068, 'w3': -0.4037122612146107, 'w4': -1.3550928919386442, 'w5': 0.9061053953989686, 'w6': 0.11484599997758682, 'w7': 2.37957087971904, 'w8': -1.859439821108209, 'w9': 1.9648797293640787, 'w10': -1.3065928804304012, 'w11': -1.0844836672166303, 'w12': -0.4792707290123779, 'w13': 0.3595441261947645, 'w14': -0.3052839627106261, 'w15': -0.2007097706509534, 'w16': 1.5961047171049467, 'w17': 0.6896224800452033, 'w18': 0.2945585552412229, 'w19': 1.6725066749264608, 'w20': 0.6985543170757469, 'w21': -0.6452611999354193, 'w22': -0.4233274974259964, 'w23': -2.1141920304134794, 'w24': -0.47936964928227876, 'w25': 1.5640030255836208, 'w26': -2.090639191123318, 'w27': 1.762750180051431, 'w28': 0.6788095803852252, 'w29': 0.47248762930879984, 'w30': 1.6407221879861944}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,742] Trial 20 finished with value: 0.7246376811594203 and parameters: {'w0': 0.7681658139760489, 'w1': 2.4983842572891852, 'w2': -2.0541636491226924, 'w3': 1.9024919930675943, 'w4': -0.6246865686581428, 'w5': -1.398830735395724, 'w6': -0.7797998693762447, 'w7': -1.7485847262266172, 'w8': -0.3611935334795535, 'w9': 1.2867789760564385, 'w10': -0.6494777543939623, 'w11': 0.45103232891188627, 'w12': 0.5819302056197213, 'w13': -2.4635202694786256, 'w14': -1.3217073836347164, 'w15': 1.9556711862029923, 'w16': -0.4465764455180199, 'w17': -1.0330414532737617, 'w18': 1.7709915528330815, 'w19': 0.14335293330698917, 'w20': -0.25060217387210526, 'w21': -1.6455264779105927, 'w22': -1.9115625299662682, 'w23': -1.1944274317321222, 'w24': -1.130339955026078, 'w25': 0.532640348456463, 'w26': -0.28983395781321225, 'w27': 0.5766453136669913, 'w28': 1.3942705642439286, 'w29': -0.9974886703343264, 'w30': 0.2998879194883961}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,847] Trial 21 finished with value: 0.7463768115942029 and parameters: {'w0': 1.0588570858913648, 'w1': 0.842867148438593, 'w2': 1.8649522653853907, 'w3': 0.7290814295056292, 'w4': 0.290486998668266, 'w5': -2.156162216946116, 'w6': -0.5359174904042479, 'w7': -0.8977671916462509, 'w8': -1.15305351040575, 'w9': 2.2987871198164553, 'w10': -0.3537094678023718, 'w11': 1.4375037389306644, 'w12': 0.9831175569804453, 'w13': 1.8722130278985651, 'w14': 0.1269490500399735, 'w15': 0.3547835689474854, 'w16': 0.4281103326108812, 'w17': -1.6557443772215235, 'w18': 1.219576365769811, 'w19': -1.0072568865513458, 'w20': -1.3215337898789663, 'w21': 1.3536756606427074, 'w22': -1.477690591318004, 'w23': 2.324788032358906, 'w24': 1.4120812659146278, 'w25': 2.122075639594838, 'w26': -0.4525153189301002, 'w27': 1.2073613049811722, 'w28': 2.4678276322999277, 'w29': -0.1578107665109997, 'w30': 1.7380833116863719}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:20,949] Trial 22 finished with value: 0.7536231884057971 and parameters: {'w0': -0.1738743035917898, 'w1': 0.6759460237733166, 'w2': 1.9065582532865653, 'w3': 0.6055402101412265, 'w4': 0.5167342847297913, 'w5': -1.8594884520183013, 'w6': -1.4721950918049593, 'w7': -1.5018566392305657, 'w8': -1.6871865206161476, 'w9': 2.496723986235218, 'w10': -0.8681848871148998, 'w11': 1.092440218551561, 'w12': 0.5179132917563635, 'w13': 0.6419743217024048, 'w14': -0.336483624096952, 'w15': 0.4409060626629091, 'w16': -0.13534516490264448, 'w17': -1.3992813282380667, 'w18': 0.09367248636622816, 'w19': -1.2005018698214873, 'w20': -0.3413780916507574, 'w21': 0.32318375087835793, 'w22': -1.26393624156475, 'w23': -0.3282564218661068, 'w24': 2.4111974057901433, 'w25': 1.793556720659317, 'w26': -2.4327368696119676, 'w27': -0.6378592819880646, 'w28': 1.252185373810991, 'w29': -0.5208777955956609, 'w30': -0.8850560715269022}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,051] Trial 23 finished with value: 0.7463768115942029 and parameters: {'w0': 2.013514618181537, 'w1': 1.4039681948549894, 'w2': 1.4162359890941638, 'w3': 0.950027445601137, 'w4': -0.21685127646963495, 'w5': -2.432090454282031, 'w6': -0.912697147185747, 'w7': -1.236375945465544, 'w8': -1.0942393380247692, 'w9': 1.9853008909011145, 'w10': -0.40388052738052593, 'w11': 1.740071815633459, 'w12': 2.4809236836577986, 'w13': -0.2721559117939468, 'w14': -2.070917022730966, 'w15': -0.4468395292636632, 'w16': 1.415279467046904, 'w17': -2.190131916466177, 'w18': 0.899318995332901, 'w19': -2.0832080385251293, 'w20': -2.318188947922442, 'w21': 1.5691634680894662, 'w22': -1.8165532297955393, 'w23': 0.5840468364304687, 'w24': 0.26841507888365534, 'w25': 2.421274003625849, 'w26': 0.49960817852687217, 'w27': -1.674520137695373, 'w28': 0.2436430761953582, 'w29': -1.8955776920819278, 'w30': -0.5771055432016086}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,153] Trial 24 finished with value: 0.7318840579710145 and parameters: {'w0': 1.165524018282592, 'w1': -0.0413726545454578, 'w2': 2.040269860068481, 'w3': -0.09049791340170577, 'w4': 0.6566705317012609, 'w5': -1.1127680828636923, 'w6': -0.1482133065130966, 'w7': -0.1288019450470376, 'w8': -2.4722390331620883, 'w9': 2.123597132482814, 'w10': -1.4352365289895033, 'w11': 2.352173642096024, 'w12': 1.1952347866863018, 'w13': -1.9172134880380587, 'w14': -0.015166633700457885, 'w15': 0.2593575571967436, 'w16': -1.1838912761733016, 'w17': -0.21998192461328658, 'w18': 1.3596420608238176, 'w19': -0.6995892632639039, 'w20': 1.033403031965035, 'w21': -0.30225866262002, 'w22': -0.7673913453170245, 'w23': -1.2475147120603922, 'w24': -0.3441291442765031, 'w25': 1.253136943906544, 'w26': -1.8909483640131899, 'w27': -0.436192313999027, 'w28': 1.8447643563017202, 'w29': 2.17425922706438, 'w30': -0.013562404370585146}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,256] Trial 25 finished with value: 0.7536231884057971 and parameters: {'w0': -1.8075926118900965, 'w1': 0.5984178203583248, 'w2': 0.9499751535413501, 'w3': 1.456165640481838, 'w4': 0.006914511077661693, 'w5': -1.8676366058752951, 'w6': -1.6454814871559114, 'w7': -1.9000741171747928, 'w8': -1.9637642389325471, 'w9': 1.4229052320509161, 'w10': -2.0372319572133, 'w11': 0.7404991184135781, 'w12': 1.7709652872677466, 'w13': 2.1811117297927667, 'w14': -2.4917427432367636, 'w15': -0.7973959516928036, 'w16': 0.512135037066378, 'w17': -1.5453606715919028, 'w18': -0.1992293922283872, 'w19': 0.19487330688500004, 'w20': 0.04687856948890573, 'w21': -0.6194955869209802, 'w22': -0.04853828593660291, 'w23': -2.1510735041582727, 'w24': 1.0361613022537821, 'w25': 2.461973776919132, 'w26': -1.0014849142011586, 'w27': 0.5733043788661509, 'w28': -0.7389127668382993, 'w29': 1.5683429962553679, 'w30': 0.5096402937556355}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,363] Trial 26 finished with value: 0.7391304347826086 and parameters: {'w0': 2.493437354824602, 'w1': 1.1161473955694388, 'w2': 2.465741587344574, 'w3': 0.39663966535481254, 'w4': -0.5235197634606596, 'w5': -2.0420916202186197, 'w6': 0.8506284010046054, 'w7': -0.5798774049124673, 'w8': -0.1965259630796785, 'w9': 0.680464039681695, 'w10': 0.9784247471759508, 'w11': -0.24178486840486424, 'w12': 0.5534904314505544, 'w13': -0.8916044017525189, 'w14': 2.2660049309189163, 'w15': -1.279395217602815, 'w16': -0.1510213307260063, 'w17': -0.9502425193981816, 'w18': -0.8815739007390195, 'w19': -1.3812236637206703, 'w20': 2.0914139073893656, 'w21': 0.4944827634494069, 'w22': -2.1240617065486473, 'w23': -0.44551530721430455, 'w24': 0.20234546362634742, 'w25': 1.8613242484550254, 'w26': 1.4244733599985078, 'w27': 0.3223677682894682, 'w28': -1.324197757794344, 'w29': -2.0055851890498837, 'w30': 1.8385001796909104}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,470] Trial 27 finished with value: 0.7391304347826086 and parameters: {'w0': -2.1275948354510446, 'w1': 0.3859704080368562, 'w2': 0.36298092152102124, 'w3': 2.037005760114978, 'w4': -1.3087547779406226, 'w5': -0.6134195858639437, 'w6': -0.673175083175634, 'w7': 0.17132444779793926, 'w8': -0.8797979730069594, 'w9': 2.147843137921397, 'w10': -1.0889723433102583, 'w11': 0.16781295318428835, 'w12': -0.2427175496905114, 'w13': 0.5445677832160707, 'w14': -1.8194906249414058, 'w15': 1.169979918334268, 'w16': -0.7017772872445682, 'w17': -0.26121175701102617, 'w18': 0.36546176713852274, 'w19': -0.16198432051364975, 'w20': -1.7429353864115966, 'w21': -0.0737958424152847, 'w22': -1.3491459941864323, 'w23': 1.0099961622361773, 'w24': 1.6029191317755693, 'w25': 0.9238885489155755, 'w26': -1.3266590388048387, 'w27': 1.0620766900744036, 'w28': 0.854491289084121, 'w29': 0.47509004240281294, 'w30': 1.058980081004722}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,575] Trial 28 finished with value: 0.7608695652173914 and parameters: {'w0': -1.0952813459761555, 'w1': -0.5305032209282324, 'w2': 1.5122507071917897, 'w3': -0.2102547322287256, 'w4': 1.1248679554826264, 'w5': -1.5377239858567175, 'w6': 0.2899233087036502, 'w7': -1.0396334102858824, 'w8': -1.2952306996890548, 'w9': -0.45315924840460553, 'w10': -1.7621186362988084, 'w11': -0.4955880484397688, 'w12': 0.776869586779421, 'w13': -2.10422367302131, 'w14': -1.186518432571925, 'w15': -0.02426393600009047, 'w16': -1.6407389915874275, 'w17': -1.8392583760604058, 'w18': 1.532433641411681, 'w19': -0.7358957477480096, 'w20': -2.4962884934572567, 'w21': 1.385328844680167, 'w22': -1.8426293280132853, 'w23': 1.750377266313175, 'w24': -1.1597060900572047, 'w25': 2.094865644491373, 'w26': -2.1064893129375557, 'w27': -1.1214455670329306, 'w28': -0.1069231457220452, 'w29': -1.4093552547150419, 'w30': -1.3963345745303286}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,677] Trial 29 finished with value: 0.7391304347826086 and parameters: {'w0': -0.8159335560826319, 'w1': -1.439254336734162, 'w2': 1.0742197474954427, 'w3': -1.035329729812857, 'w4': 1.4111650498944552, 'w5': -1.5471338180870426, 'w6': 1.2714335178695801, 'w7': 1.990847845185302, 'w8': 0.7810695562661154, 'w9': -0.2844147780305302, 'w10': -2.3385239451405746, 'w11': -0.6313991506656478, 'w12': 1.643619097919531, 'w13': -1.4890055848780057, 'w14': -1.2842491896331671, 'w15': -0.20364926322872795, 'w16': -1.753319904872829, 'w17': -2.4544674343095148, 'w18': 2.218174486593949, 'w19': -0.7164509762435987, 'w20': 0.4628266432050414, 'w21': 1.681849998453036, 'w22': -1.000356942340089, 'w23': -0.4381347571426697, 'w24': -1.2143711852334027, 'w25': 1.4274685322575635, 'w26': -2.1270053485732197, 'w27': -1.1601230753549265, 'w28': 0.572800253541337, 'w29': -1.5537732089701826, 'w30': -1.7396010494383987}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,779] Trial 30 finished with value: 0.7536231884057971 and parameters: {'w0': -1.014131864786413, 'w1': -0.23973044721949321, 'w2': 1.4036987982954878, 'w3': -2.058943125395471, 'w4': 2.2436605627064523, 'w5': -1.0851331096378933, 'w6': 0.2869350647712348, 'w7': 1.2079654860059987, 'w8': -1.5059359360511049, 'w9': -0.4120746158585359, 'w10': -1.7199598388896025, 'w11': -1.6823259492528146, 'w12': 0.2629852128056356, 'w13': -2.133677324726521, 'w14': -1.647595313180306, 'w15': -2.464682524258267, 'w16': -1.310448932654041, 'w17': -1.9393278127017848, 'w18': 1.7387769400879374, 'w19': -2.039838517804177, 'w20': -0.4114611567981403, 'w21': -1.6807011474248323, 'w22': -2.499632936634451, 'w23': 1.8742822326006663, 'w24': -2.0744265428727497, 'w25': 1.508566984583599, 'w26': -1.565831674129131, 'w27': -0.8468665765430092, 'w28': 0.3012322525106522, 'w29': -2.4871009800046386, 'w30': -2.3737337433485806}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,882] Trial 31 finished with value: 0.7463768115942029 and parameters: {'w0': -0.07719903232214409, 'w1': -0.4695536913960614, 'w2': 1.5804022971257459, 'w3': -0.22161415788885977, 'w4': 1.0780179184170753, 'w5': -1.5940304520681097, 'w6': -0.2593776848642422, 'w7': -1.199874477001942, 'w8': -0.48454290810241607, 'w9': 1.0164567429786733, 'w10': -2.4563671233036, 'w11': -1.523513343699342, 'w12': 0.8417467675701685, 'w13': -1.6512440029522089, 'w14': -1.9684144630259592, 'w15': 0.6223896744485308, 'w16': -0.8921899488623966, 'w17': -1.5928521586369855, 'w18': 1.51474844167832, 'w19': -1.338626152296844, 'w20': -2.3388745130058983, 'w21': 1.1305858174948167, 'w22': -1.8990818382946348, 'w23': 2.4679377939319087, 'w24': -0.5803427286460962, 'w25': 2.0857865545341854, 'w26': -1.8366587352155057, 'w27': -1.679372488468731, 'w28': -0.280634963176834, 'w29': -0.6346591981028044, 'w30': -1.3600312711999718}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:21,984] Trial 32 finished with value: 0.7463768115942029 and parameters: {'w0': -1.4304485278615906, 'w1': 0.0591626853365671, 'w2': 2.163207264529456, 'w3': 0.41566674205748827, 'w4': 0.37364175535938293, 'w5': -2.0239328784388855, 'w6': -0.9051110952970842, 'w7': -2.0741416658808296, 'w8': -1.323278170063162, 'w9': 1.6335720929797877, 'w10': -2.1480157048669564, 'w11': 0.061623565142262596, 'w12': 1.3454916482607224, 'w13': -1.167349366810841, 'w14': -1.4697520205474968, 'w15': 0.01259120976230338, 'w16': -1.9940639161946974, 'w17': -0.8391152318904277, 'w18': 0.8331664015661298, 'w19': -0.9354576332278712, 'w20': -2.4994668263531596, 'w21': -0.8862690519558462, 'w22': -1.3876669760573548, 'w23': 1.9468151474610451, 'w24': -0.18042068004446488, 'w25': 1.7481422440585535, 'w26': -0.5371680526299465, 'w27': -1.9102392897435703, 'w28': -0.01971609323038273, 'w29': -2.151635667488185, 'w30': -0.7311372063606523}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,086] Trial 33 finished with value: 0.7463768115942029 and parameters: {'w0': 0.35155177871621723, 'w1': -2.08010864389676, 'w2': 1.735560498233622, 'w3': 0.9145910072403406, 'w4': 1.8669765579355224, 'w5': -0.8188954908825928, 'w6': 2.4434288167829292, 'w7': -1.2029218502948376, 'w8': -1.0962222241243782, 'w9': -1.5856325306529433, 'w10': -1.557797637423507, 'w11': -0.43591630748024923, 'w12': 2.114434050560345, 'w13': -2.084026203470125, 'w14': -2.1832075342739476, 'w15': -1.0923758096413163, 'w16': -0.5145223176850302, 'w17': -1.2305799479076138, 'w18': 1.555795826926265, 'w19': -0.793138869346805, 'w20': -1.4375457675840144, 'w21': 1.8168176020405085, 'w22': 2.441636331653, 'w23': 1.0618398935854116, 'w24': -1.1326244250640642, 'w25': 2.1874649032742086, 'w26': -2.200916707820549, 'w27': -2.4879523146912312, 'w28': -1.1361413528998376, 'w29': -1.2362061686047183, 'w30': 0.4300386742059983}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,191] Trial 34 finished with value: 0.7463768115942029 and parameters: {'w0': -0.4054966707079503, 'w1': -0.7078418534659243, 'w2': 2.1414022058288547, 'w3': 0.058057654157145505, 'w4': -0.04081993541649476, 'w5': 2.458855185529401, 'w6': -1.771830158976409, 'w7': -0.3920179401015836, 'w8': -2.0156179692015828, 'w9': 0.3125901163932455, 'w10': -0.29976801810403, 'w11': 1.8291251474418284, 'w12': 0.7495279481152881, 'w13': -1.1862061382324576, 'w14': -1.0130712955126167, 'w15': -0.4711458015101966, 'w16': 0.23346124740758145, 'w17': 0.3434434664433941, 'w18': -0.4150210138877217, 'w19': -1.2944879839305439, 'w20': -1.975934031413193, 'w21': 0.4115139048539047, 'w22': -0.9110794972414127, 'w23': 1.5137996511088267, 'w24': -1.845384267107256, 'w25': 1.9377579279007409, 'w26': -1.5029521689651673, 'w27': -2.0498272148280163, 'w28': -0.48889635826767974, 'w29': -0.4144766910834162, 'w30': -0.17768651522580337}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,305] Trial 35 finished with value: 0.7391304347826086 and parameters: {'w0': -1.2044880255814516, 'w1': 0.46808477812025656, 'w2': 1.1323696790427276, 'w3': 0.34128351837426674, 'w4': -1.2388260428993405, 'w5': -1.2157147725203181, 'w6': -1.2965849975596817, 'w7': -1.4932508566561478, 'w8': -1.6501882483282249, 'w9': -1.3427814658673376, 'w10': -1.1833270270953409, 'w11': 0.9179327384413887, 'w12': 1.1636406821176875, 'w13': 0.8838279972414209, 'w14': 1.2295977811489005, 'w15': -1.564379755192817, 'w16': 0.8310422432201843, 'w17': -1.976071219275847, 'w18': 1.1078107298120303, 'w19': -0.38418681837355856, 'w20': -1.0442588067680354, 'w21': 1.1531592011834726, 'w22': -2.0858097226562338, 'w23': 0.5560059214528779, 'w24': -1.4484457016835979, 'w25': -1.4984169942929004, 'w26': -1.2875946824849853, 'w27': 0.2568819449638924, 'w28': 1.5976716814439962, 'w29': -0.8976396481558695, 'w30': -1.144047758065868}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,413] Trial 36 finished with value: 0.7463768115942029 and parameters: {'w0': -2.005633282379472, 'w1': 1.1861104962031153, 'w2': 0.6795329300413329, 'w3': 1.244304874340658, 'w4': 0.9321502610639965, 'w5': -2.4620247193493534, 'w6': -2.4599060588657062, 'w7': -2.4769239870090183, 'w8': -0.06791471928937254, 'w9': -0.32687533393547213, 'w10': -0.7091223235664779, 'w11': 2.4038917973556115, 'w12': 0.3734616608381073, 'w13': -0.115808167214956, 'w14': -0.5215841850972915, 'w15': 0.9678096462479084, 'w16': -2.2580237190677614, 'w17': -1.318426343480791, 'w18': 1.9572050193076096, 'w19': -1.9393065001007943, 'w20': 1.4377499942634997, 'w21': 2.0977110875571183, 'w22': -1.6853364014733463, 'w23': 1.933774774438191, 'w24': -0.07076675490477041, 'w25': 2.2377028253419864, 'w26': -2.481921230139248, 'w27': -0.26467394679040224, 'w28': 2.1948707665724214, 'w29': -1.3846535532489597, 'w30': 0.713526431606528}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,520] Trial 37 finished with value: 0.7608695652173914 and parameters: {'w0': -1.5205050582658866, 'w1': 1.6894986572647064, 'w2': 1.5774346090420817, 'w3': 1.654821389429383, 'w4': 1.333273861855335, 'w5': -1.671363855158122, 'w6': 0.9464783137342145, 'w7': 0.45677565103511664, 'w8': -0.8852875548554242, 'w9': 1.230635836534574, 'w10': 0.03607791715558406, 'w11': 0.6052062298792882, 'w12': 1.6114057177796797, 'w13': -2.1315157008121206, 'w14': 0.3924899599835381, 'w15': 1.5753235056906236, 'w16': -0.8190643308552175, 'w17': 2.449652169256616, 'w18': -1.0619663688065286, 'w19': -0.03266868432759362, 'w20': 0.9700586629692229, 'w21': 0.6940617723158289, 'w22': -0.7499204034779889, 'w23': -2.1802541464555705, 'w24': 2.487450795045324, 'w25': 2.4931458727832503, 'w26': -1.9857793815587779, 'w27': 1.441795188552859, 'w28': 1.0786609609619549, 'w29': -2.1192087791160703, 'w30': 2.1936836247875084}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,622] Trial 38 finished with value: 0.7463768115942029 and parameters: {'w0': -2.156808089663134, 'w1': 1.7924751080942605, 'w2': -0.1332788113368697, 'w3': 2.071044609821455, 'w4': 1.3127693761703951, 'w5': -1.659124628862254, 'w6': 1.0485422775445674, 'w7': 0.9237898275985348, 'w8': -0.5592944790043501, 'w9': 1.2444820959843286, 'w10': 0.01926932803191872, 'w11': 0.6125679700026366, 'w12': 1.6857468841275796, 'w13': -2.2467418503115124, 'w14': 0.5118662197847965, 'w15': 1.8012610850151944, 'w16': -1.4631586113843413, 'w17': 2.457266499326578, 'w18': -0.9819926705457224, 'w19': 0.29788942010300473, 'w20': 1.0742198397978253, 'w21': -0.1207885060347983, 'w22': -0.7191849244171357, 'w23': -2.056958575280757, 'w24': -0.6514258120171189, 'w25': 1.3383739013237381, 'w26': -2.052817708620701, 'w27': 1.8102742307885489, 'w28': 0.4236948149339471, 'w29': -2.098802450160326, 'w30': -1.4644728947555143}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,727] Trial 39 finished with value: 0.7318840579710145 and parameters: {'w0': -1.5125389061872114, 'w1': 2.205299898462416, 'w2': 1.2546170875845544, 'w3': 1.7491557598103193, 'w4': 1.6719147920857846, 'w5': -0.5078062162072472, 'w6': 1.5455694981925416, 'w7': 2.089576828671725, 'w8': -0.9463579561422253, 'w9': -2.346969336029971, 'w10': 0.4148881101836485, 'w11': 0.14157600757429012, 'w12': 1.5734487129057961, 'w13': -1.745732569171498, 'w14': 1.8948404432939285, 'w15': -0.7617454409629432, 'w16': -0.7333249428001842, 'w17': 1.2565069507061288, 'w18': -1.896475728999822, 'w19': 1.337494550446374, 'w20': 0.22157243313897057, 'w21': 1.059496072776897, 'w22': -0.17590050003592128, 'w23': -1.468627718222648, 'w24': -1.6727230179570074, 'w25': -0.6362108066065804, 'w26': -1.7666088206649375, 'w27': 2.148619443184206, 'w28': 1.1439684210063712, 'w29': -2.266677597681902, 'w30': 2.0574164078348156}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,828] Trial 40 finished with value: 0.7318840579710145 and parameters: {'w0': -1.6456696085252838, 'w1': -0.5894907287493301, 'w2': 1.5220013559031986, 'w3': 2.2645779210613877, 'w4': 2.011863119509503, 'w5': 0.06351356879204717, 'w6': 0.716640902764369, 'w7': 0.6488652617288031, 'w8': 1.9501441641797053, 'w9': 0.7774740907671287, 'w10': 0.9407856452981775, 'w11': -0.6999105681023741, 'w12': 2.001386650502269, 'w13': -1.3528036707221274, 'w14': 0.28072321935789574, 'w15': 2.4954171804604695, 'w16': -1.8805324569645698, 'w17': 1.8128066672259968, 'w18': -1.0650649278029598, 'w19': -0.13794010571561632, 'w20': 0.7959393039955454, 'w21': 0.6456848338475487, 'w22': 0.2995715135402246, 'w23': -2.30025944211146, 'w24': 2.0527174155862786, 'w25': 0.7165939957678664, 'w26': -2.225591949690404, 'w27': 1.2793183363151255, 'w28': 0.9682418974261164, 'w29': -1.9471353691048465, 'w30': 1.2862793265537504}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:22,942] Trial 41 finished with value: 0.7536231884057971 and parameters: {'w0': -0.7217154491131411, 'w1': 1.5844114030456882, 'w2': 1.99861282958224, 'w3': 0.6717302391787848, 'w4': -0.47126744003446114, 'w5': -2.1618018578130394, 'w6': 0.5257968912439235, 'w7': -1.0267179294234015, 'w8': -1.416930775140081, 'w9': 2.2814047991178135, 'w10': 0.6341903638373103, 'w11': 1.481567127166497, 'w12': 1.1758571331155951, 'w13': -1.967193046201308, 'w14': 0.9001511313133126, 'w15': 1.6190817084880276, 'w16': -0.973796413799971, 'w17': -0.24956902290816618, 'w18': -0.27496076106610756, 'w19': -0.9720260344747138, 'w20': 1.733627868967892, 'w21': 0.7828729181581917, 'w22': -1.0751413877142428, 'w23': -1.8374271835695408, 'w24': 2.481670268044684, 'w25': 2.4661133595274327, 'w26': -1.740119663848337, 'w27': 1.3506597930012687, 'w28': 1.7566389903743425, 'w29': 0.204179982487101, 'w30': 2.1782830819754424}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,047] Trial 42 finished with value: 0.7463768115942029 and parameters: {'w0': -1.219541218476969, 'w1': 1.132956073986596, 'w2': 1.7180136152802508, 'w3': 1.564160391041168, 'w4': 1.2458473173373241, 'w5': -1.8048631194223868, 'w6': -0.15809601027296516, 'w7': 0.38087319225209615, 'w8': -0.9223283368445689, 'w9': 1.8402125723697516, 'w10': -1.8568391270651923, 'w11': 1.22818035551327, 'w12': 0.7687804006742783, 'w13': -2.4813185812283907, 'w14': 0.8375008484607673, 'w15': 0.12346003888427681, 'w16': -0.20142956891217856, 'w17': -1.1659962427811654, 'w18': 0.5995670939217156, 'w19': 0.4538431732838628, 'w20': 1.1855072239093278, 'w21': -0.3594125735835968, 'w22': -1.4661403647272289, 'w23': -1.9734645289626942, 'w24': 2.166175027364114, 'w25': 1.9826428522509034, 'w26': -2.068470529208657, 'w27': 0.94573140939793, 'w28': 2.0847592392640433, 'w29': -1.47869091958502, 'w30': 1.9900078324351236}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,149] Trial 43 finished with value: 0.7536231884057971 and parameters: {'w0': 0.1877597888257403, 'w1': 0.15370585162522, 'w2': 2.2555305815385127, 'w3': -0.7720711007638059, 'w4': 0.6921884472401408, 'w5': -0.8550693450859049, 'w6': 0.3129521659513221, 'w7': 1.6001768285236257, 'w8': 0.3802044466044576, 'w9': 2.461136695575032, 'w10': -0.12856989720707657, 'w11': -1.1769800604475482, 'w12': 1.3760631183666068, 'w13': -2.119549687453573, 'w14': -0.019429885733681547, 'w15': 2.2377441437849264, 'w16': -1.4420243542544053, 'w17': -0.8485367188106654, 'w18': -0.026314211407798323, 'w19': -0.4831663409824619, 'w20': -0.7223051500295774, 'w21': -0.8469651454457812, 'w22': -0.7112156426630665, 'w23': 1.6726411760981086, 'w24': 2.153905367018045, 'w25': 2.09781310535995, 'w26': 0.39214116285038214, 'w27': -1.009842288987374, 'w28': 0.06561989476122418, 'w29': -1.0682822577043347, 'w30': 2.389863096861517}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,259] Trial 44 finished with value: 0.7463768115942029 and parameters: {'w0': -1.0181851149992729, 'w1': 0.7282705049487419, 'w2': 1.5657940767873624, 'w3': 1.0676230892089518, 'w4': -1.5467520214788997, 'w5': -1.3875656568664425, 'w6': -0.6222724443199819, 'w7': -0.7187786283698154, 'w8': -1.746603825720591, 'w9': 1.7287153429366717, 'w10': -2.3004126398077163, 'w11': 1.9985032427283174, 'w12': -1.1028676660741943, 'w13': 1.453365260846765, 'w14': -0.2701186618368364, 'w15': -0.33865442947004787, 'w16': 0.21728070329995283, 'w17': 0.16992109830291546, 'w18': -1.6470384829584552, 'w19': -1.1911152402257152, 'w20': 2.2215114729058287, 'w21': 1.4299775494344034, 'w22': -1.1415591107033163, 'w23': -2.279562541861666, 'w24': 1.7563189287185839, 'w25': 1.7168350625864945, 'w26': -0.22339908069356784, 'w27': 1.455621725865715, 'w28': 0.6029195424952842, 'w29': -2.2684173129405045, 'w30': 1.4740464152695925}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,377] Trial 45 finished with value: 0.7463768115942029 and parameters: {'w0': -2.2803052496195035, 'w1': -0.1325499384196045, 'w2': 0.8056822993529538, 'w3': 0.23887557947163435, 'w4': 0.03285761694480732, 'w5': -1.9915203426057135, 'w6': -1.9983074698101966, 'w7': -0.3149395107716706, 'w8': -1.321499646862509, 'w9': -0.6352905512207379, 'w10': 1.3348467266034274, 'w11': 0.642209756756272, 'w12': 1.8780686114105536, 'w13': -0.7445630329892527, 'w14': -0.7112898286504726, 'w15': 0.5681968648691877, 'w16': -0.7311620252355844, 'w17': -2.1676026738170555, 'w18': -0.5064856038928668, 'w19': 0.00787432584586448, 'w20': 0.8202881954144159, 'w21': 0.2787653997228611, 'w22': -2.3036237553686467, 'w23': 0.04152959532210687, 'w24': -0.9603192397301374, 'w25': 2.246970716789192, 'w26': -2.310594091146597, 'w27': 1.9491661061502317, 'w28': -0.23770461487541014, 'w29': -1.8390896101880783, 'w30': 2.283296083004093}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,482] Trial 46 finished with value: 0.7463768115942029 and parameters: {'w0': -0.3064125362574262, 'w1': 2.0438255194523407, 'w2': 1.293521582167692, 'w3': 1.3273270419777212, 'w4': -0.8036641065690167, 'w5': -2.2896695840437182, 'w6': -0.336133879328973, 'w7': -0.009384423843995071, 'w8': -2.1946782266515337, 'w9': 2.180980996571927, 'w10': 2.381974831030038, 'w11': -0.06626061705311115, 'w12': -0.05837523774419395, 'w13': -2.2486359183758653, 'w14': -2.2957473534134545, 'w15': -0.925030177641822, 'w16': -2.4902439631533757, 'w17': -1.6809978443309062, 'w18': -1.3049452151523655, 'w19': 2.4162649285604063, 'w20': 0.26953055994846875, 'w21': 0.6049446444761452, 'w22': -1.60370915225177, 'w23': 1.3342843365018195, 'w24': 1.2384935694395944, 'w25': 2.4917127860274317, 'w26': -0.7122900384374256, 'w27': -1.480575928313566, 'w28': 1.3184856326326473, 'w29': -1.6995982462689188, 'w30': 0.9281752784279746}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,587] Trial 47 finished with value: 0.7246376811594203 and parameters: {'w0': 1.9085392376401074, 'w1': -0.9394362154432574, 'w2': 0.23101330833333364, 'w3': 2.4769873954060615, 'w4': 0.9998705634652241, 'w5': -1.553682002881401, 'w6': -1.0844267078401595, 'w7': -1.7341007291825226, 'w8': -0.45256772888005015, 'w9': 0.09067823739838965, 'w10': 0.1301215510572169, 'w11': 0.3360743508885475, 'w12': -2.1436004189654545, 'w13': -1.6702743876840005, 'w14': -1.8234656872853319, 'w15': 0.7714991326902821, 'w16': 2.340414264495716, 'w17': 2.4668197068739213, 'w18': -1.9375084134866158, 'w19': -0.794163011549798, 'w20': 1.5817940113424798, 'w21': 0.9094511587377587, 'w22': 1.1186526788853226, 'w23': -1.4493646198221792, 'w24': 0.7335365709255036, 'w25': -1.6893605380337195, 'w26': -1.1340512034524999, 'w27': 0.7623652507330998, 'w28': 1.6364518460665292, 'w29': -2.470859016806972, 'w30': -0.9527186293601395}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,691] Trial 48 finished with value: 0.7391304347826086 and parameters: {'w0': -1.7273689974807571, 'w1': 0.988934792416142, 'w2': -1.5121320546405022, 'w3': 0.7725745721097959, 'w4': 1.560589417316686, 'w5': -0.9812075129717576, 'w6': 1.7309682701529168, 'w7': -1.0140282699662204, 'w8': -0.7520873744614872, 'w9': 1.419015127475744, 'w10': -0.6486825006731103, 'w11': -0.5416553807384776, 'w12': 2.167429413950627, 'w13': -1.3176581075488443, 'w14': 0.5349012997989193, 'w15': 0.023552661921063645, 'w16': 2.032284646122482, 'w17': -0.7743557734767881, 'w18': 2.3474174197936963, 'w19': 0.8530776848297168, 'w20': -1.8470707309988423, 'w21': -1.9626249043349298, 'w22': -0.500169620942769, 'w23': -2.445018189461565, 'w24': -1.2613036374257771, 'w25': 1.1196474901645337, 'w26': -1.5356037965878389, 'w27': 0.2263688334223395, 'w28': 0.7462386052673141, 'w29': -2.1195843423654344, 'w30': -0.3748683821344079}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,793] Trial 49 finished with value: 0.7463768115942029 and parameters: {'w0': -0.6423030144312364, 'w1': 0.22567626054808604, 'w2': 2.2515294517600544, 'w3': -0.2540871880748116, 'w4': -0.24595513050781415, 'w5': 1.5022150243360337, 'w6': 0.08254507432992109, 'w7': -2.1580456103006296, 'w8': -1.5113771584448725, 'w9': -1.0270555482201082, 'w10': -1.531707668977579, 'w11': 0.9271944149920339, 'w12': 1.0179567045889661, 'w13': 1.1163814456094092, 'w14': 1.073596214205631, 'w15': -0.647678182127371, 'w16': -0.0023609872746792604, 'w17': 0.46157137081134436, 'w18': 0.44732265273068794, 'w19': -1.607062657035662, 'w20': -2.2030008409265407, 'w21': 1.8768354268881606, 'w22': -1.8618307387986972, 'w23': 2.1547408583743866, 'w24': 0.16207447313920603, 'w25': 1.8956251124809418, 'w26': -2.320181943264885, 'w27': 0.4559254080350983, 'w28': 0.35424962363628376, 'w29': 1.1983762554767514, 'w30': -1.9159351173143002}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:23,899] Trial 50 finished with value: 0.7391304347826086 and parameters: {'w0': 0.6575954523873437, 'w1': 0.5319521935004857, 'w2': 1.9582571145520522, 'w3': -1.50932413922939, 'w4': 0.4852057723895663, 'w5': -1.2298005543914843, 'w6': -0.8932619701706505, 'w7': -1.382394981539504, 'w8': 0.9531986646658144, 'w9': 2.0408915419693945, 'w10': -0.9049374368414285, 'w11': 1.2070101090204517, 'w12': 0.31632899327479164, 'w13': -2.30120189887906, 'w14': 0.33243534362107613, 'w15': 1.0699973919731156, 'w16': -1.6739041304727296, 'w17': 1.619360300965346, 'w18': 1.0910533970570213, 'w19': -1.4858691498384744, 'w20': -1.5598739767488712, 'w21': -1.213924766920004, 'w22': -2.2413750002408754, 'w23': -0.7140893472484683, 'w24': -0.9214414772855122, 'w25': 0.1694333878409906, 'w26': -1.9431258172158696, 'w27': -0.13330691564457914, 'w28': -0.5404930005466887, 'w29': -2.270087173362154, 'w30': 0.1942950923070369}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,004] Trial 51 finished with value: 0.7536231884057971 and parameters: {'w0': -2.308466802121247, 'w1': 0.23590075215904072, 'w2': 2.4961574503929684, 'w3': 1.166204505949068, 'w4': -0.7358278933379572, 'w5': -1.3930683454734105, 'w6': -1.0533880513719953, 'w7': -2.243167984071191, 'w8': -1.3388467229623664, 'w9': 1.5687259083333216, 'w10': -1.345655847424799, 'w11': 0.38899734642791506, 'w12': 1.354946891990787, 'w13': -2.378172655109587, 'w14': -2.4546763962685545, 'w15': -0.1810742522908892, 'w16': 0.683115561654473, 'w17': -0.5177844858753771, 'w18': -0.5757051862771041, 'w19': -0.376680933643817, 'w20': 2.4475884909467394, 'w21': -0.6406997014959458, 'w22': -1.679043182367396, 'w23': -2.397024641583226, 'w24': -0.35789306197336845, 'w25': 2.2913358154246564, 'w26': -2.4199989031787563, 'w27': 1.6463800498065553, 'w28': 0.08780446790186539, 'w29': -2.29221981885865, 'w30': -0.2724898418007744}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,104] Trial 52 finished with value: 0.7463768115942029 and parameters: {'w0': -2.0529428843892923, 'w1': -0.4069049234775604, 'w2': 2.328238216541247, 'w3': 1.5062188127989198, 'w4': -1.1631259071123423, 'w5': -1.7371289435776565, 'w6': -1.4607309816121479, 'w7': -1.6976582861649367, 'w8': -1.0302079313650931, 'w9': 1.162211590668529, 'w10': -2.152401825819521, 'w11': 2.1847263657148184, 'w12': 0.8349770864673449, 'w13': -2.4872663270117754, 'w14': -2.3526344342845165, 'w15': -0.655420918242136, 'w16': 0.7698668804069158, 'w17': -0.042453705635232986, 'w18': -0.6326567034974175, 'w19': -0.5971812845168072, 'w20': 2.1092680550707223, 'w21': -0.43148630162739976, 'w22': -1.2637647128212433, 'w23': -1.8991709171087, 'w24': -0.7844158141395767, 'w25': 2.26564084012643, 'w26': -1.9594173200921752, 'w27': 1.2022797156903724, 'w28': -0.07318353422281446, 'w29': -1.8332627324529773, 'w30': -0.5328678502830573}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,211] Trial 53 finished with value: 0.7536231884057971 and parameters: {'w0': -2.4613126567172716, 'w1': 0.8858283650625061, 'w2': 1.791337865515653, 'w3': 1.7156441618777025, 'w4': -1.6090952258361173, 'w5': -2.218130157317955, 'w6': 0.9981585908997668, 'w7': -0.5240444468716496, 'w8': -1.8103051258529417, 'w9': 2.3349126406392386, 'w10': -1.8464295569531217, 'w11': -0.36654990097924295, 'w12': 1.4813998906343122, 'w13': -1.8492917138895812, 'w14': -2.03718314526521, 'w15': -1.190816542766534, 'w16': 1.1766529764447524, 'w17': -0.7110574182426493, 'w18': -1.260018043919183, 'w19': -1.0654513947004438, 'w20': 2.2817329810587874, 'w21': 0.11955077332204911, 'w22': -1.56885704437011, 'w23': -2.4755387477937356, 'w24': -0.5601902588258132, 'w25': 1.653175825416942, 'w26': -1.6608173265249946, 'w27': 0.9332008991904865, 'w28': -0.12902784681420892, 'w29': -2.033440002527295, 'w30': -0.47243098876538975}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,352] Trial 54 finished with value: 0.7463768115942029 and parameters: {'w0': -2.4811270885031678, 'w1': -0.06150449182470574, 'w2': 2.082188000274009, 'w3': 1.0129396252073772, 'w4': -0.9365926787551461, 'w5': -1.4982438159576337, 'w6': -0.7518845754451443, 'w7': -2.0404676449860184, 'w8': -1.2504492586825084, 'w9': 0.44649571830013113, 'w10': -1.037860342122934, 'w11': 0.27809871643474615, 'w12': 1.1711679437445475, 'w13': -2.0138125744149984, 'w14': -1.6915160451901483, 'w15': -0.9073249997478381, 'w16': 1.2507977394011105, 'w17': 0.8636418903292425, 'w18': -0.08826193982828212, 'w19': -0.3738449254220069, 'w20': 1.9919699465882075, 'w21': -0.9959039346039168, 'w22': -1.9765042593272535, 'w23': -2.2241394069901443, 'w24': 1.950840176348597, 'w25': 2.03871526421015, 'w26': -2.2553195475274315, 'w27': 1.0549966346717168, 'w28': 0.18294860304182473, 'w29': -0.7067029702792138, 'w30': -0.7028242543838583}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,482] Trial 55 finished with value: 0.7536231884057971 and parameters: {'w0': -1.9235421609310523, 'w1': 1.2807080355624545, 'w2': 1.6149443043385665, 'w3': 0.5316086972173385, 'w4': -0.37752158812325426, 'w5': -1.9309186489782673, 'w6': -0.47456698483752346, 'w7': -1.523191918028648, 'w8': -0.6870971346446154, 'w9': 1.8028617494841686, 'w10': -1.6469887317641185, 'w11': -0.12827599251681931, 'w12': 0.707778666981565, 'w13': -2.227856448029225, 'w14': -0.824912493859056, 'w15': 0.18406417957646534, 'w16': 0.9579574036940226, 'w17': -1.4211280222390452, 'w18': 0.23314588615460435, 'w19': 0.04972261615636796, 'w20': 1.67542481914723, 'w21': -0.1020080927198398, 'w22': -1.7548390002552183, 'w23': -1.656299299211204, 'w24': 2.3188245228734643, 'w25': 2.3344167574718218, 'w26': -2.4918233818655304, 'w27': 1.514884796792347, 'w28': 0.4808523191033304, 'w29': -1.6848589098279345, 'w30': 0.13263238935478283}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,606] Trial 56 finished with value: 0.7536231884057971 and parameters: {'w0': -1.5149813386466713, 'w1': -1.2629052521915045, 'w2': 1.0257962600632666, 'w3': 1.9468682722582158, 'w4': 0.150856550669641, 'w5': -1.2445530594021572, 'w6': -1.228780757557862, 'w7': -2.425276767834881, 'w8': -1.5572146593966978, 'w9': 1.4665328617249698, 'w10': 0.2624391791130838, 'w11': 0.5930731853149115, 'w12': 1.7857971061531241, 'w13': 1.739284481678598, 'w14': -2.147115712786975, 'w15': 1.3908870249190104, 'w16': -1.1832279190792594, 'w17': -1.0410110745842749, 'w18': -0.7328767582351967, 'w19': -0.235313383063237, 'w20': 0.6123676541075218, 'w21': -1.4222677552379577, 'w22': -0.8329861853044855, 'w23': -1.398300563196094, 'w24': -0.9767881155290719, 'w25': 2.4784562149218115, 'w26': -1.4046703701104306, 'w27': 0.7397225106338821, 'w28': 1.016200162696101, 'w29': -1.3897418853969916, 'w30': -0.09938688200467706}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,730] Trial 57 finished with value: 0.7463768115942029 and parameters: {'w0': 1.0432634711839945, 'w1': 1.6339723689614056, 'w2': 1.8906192387926395, 'w3': 1.3176570123081555, 'w4': -1.9772785415105731, 'w5': -1.7116739184967065, 'w6': -1.4982325767772493, 'w7': 0.45712024723732675, 'w8': -2.11968047378967, 'w9': 1.972407855416497, 'w10': -1.308659529466299, 'w11': 1.6530648594817499, 'w12': 0.9401572050073966, 'w13': 2.3325677432812544, 'w14': -0.16751946064612866, 'w15': -1.4527245442762693, 'w16': 1.5786316994476048, 'w17': -0.446574749270487, 'w18': 1.6039683675417944, 'w19': -0.8950005673389207, 'w20': 1.2321701140964754, 'w21': -0.47138365330931653, 'w22': -1.4901886456279012, 'w23': -1.083458248772513, 'w24': 0.4797431060416544, 'w25': 1.804654017419179, 'w26': -1.9270080985796467, 'w27': 0.5590318239829024, 'w28': -0.45728682481934224, 'w29': -0.26126234130777504, 'w30': 0.699252270439616}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,838] Trial 58 finished with value: 0.7536231884057971 and parameters: {'w0': -1.1229472105598757, 'w1': 0.7481432636260033, 'w2': 1.3910197486988936, 'w3': 0.8324961406043183, 'w4': -0.9224998928648633, 'w5': -2.1118569894290737, 'w6': -0.06696203752842023, 'w7': 1.087092391787247, 'w8': 0.13043265626508513, 'w9': 0.9556695383124358, 'w10': -0.48717702202803637, 'w11': 0.8042416760963191, 'w12': 0.5682882299858061, 'w13': -1.5629902846413108, 'w14': -0.523983853388049, 'w15': -0.281694029647676, 'w16': 0.333875374961098, 'w17': -2.145301405351053, 'w18': 0.7149307423022025, 'w19': -0.6129028043334672, 'w20': -0.18200749507896452, 'w21': 1.390533387274016, 'w22': -1.1603592868903612, 'w23': 0.882046090736573, 'w24': -1.3835089965507876, 'w25': 2.1003817386195873, 'w26': 1.0690748208314895, 'w27': 1.1214592926071059, 'w28': -0.8672506689986659, 'w29': 0.18996131688863926, 'w30': -1.321469007292872}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:24,951] Trial 59 finished with value: 0.7463768115942029 and parameters: {'w0': -2.233970960435783, 'w1': 0.09530012504374819, 'w2': 2.265935822208995, 'w3': 1.5471922869881025, 'w4': -0.5676974220543112, 'w5': -0.1977224950067482, 'w6': -1.0461895448981464, 'w7': 2.2858125576450936, 'w8': -2.4134843284050227, 'w9': 2.382055852109353, 'w10': -0.20085982824214405, 'w11': -0.8615524899091619, 'w12': 2.3086469480466363, 'w13': 0.085845909117503, 'w14': -1.402188209531475, 'w15': -1.741494497316169, 'w16': -0.2404298033951914, 'w17': -1.8591314683584215, 'w18': -1.13773046208687, 'w19': -1.1369801422264285, 'w20': -1.171820679439859, 'w21': -0.1985055096306444, 'w22': -2.0936260269311777, 'w23': -2.069649470030432, 'w24': -0.44726941795483177, 'w25': 1.6120852894696798, 'w26': -1.0571006040803745, 'w27': 1.912893325693943, 'w28': -1.6699913087692204, 'w29': -2.483597320426222, 'w30': 0.03641708314909331}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,066] Trial 60 finished with value: 0.7391304347826086 and parameters: {'w0': 1.4144531209827518, 'w1': 0.3119379169442654, 'w2': -0.5539009666429675, 'w3': 0.14645980963542715, 'w4': -0.13949935187134027, 'w5': -0.7044155627691489, 'w6': -1.8806208252404752, 'w7': 1.6371462292872025, 'w8': -0.3218831950910842, 'w9': -0.08216761776211998, 'w10': -1.9622316919575484, 'w11': 1.3429860052842855, 'w12': 1.2757748416246544, 'w13': -0.9723118610404907, 'w14': -1.8824863103566927, 'w15': 0.4528586509182058, 'w16': -0.5600275473300641, 'w17': -0.024434854257997518, 'w18': -0.8503607753524463, 'w19': 0.4559674742899203, 'w20': 0.9289447530353119, 'w21': -0.8194455153387641, 'w22': -1.286132057685868, 'w23': 0.2693965370008806, 'w24': -0.7725640699177836, 'w25': 1.8862560068377148, 'w26': 0.1473708430972062, 'w27': 0.017972018442096387, 'w28': 2.2218086788790665, 'w29': -2.290017684102903, 'w30': 0.3319356989573976}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,167] Trial 61 finished with value: 0.7463768115942029 and parameters: {'w0': -0.8086010685216103, 'w1': 0.5222206168747044, 'w2': 2.4062000249473803, 'w3': 1.0825504620993873, 'w4': -0.8061982144864459, 'w5': -1.3266230161711738, 'w6': 1.3754607997726744, 'w7': -1.8890941739287843, 'w8': -1.154214759297603, 'w9': -0.8206908595448935, 'w10': -0.8597320729921445, 'w11': -0.16551996638245067, 'w12': 1.0406844990492916, 'w13': -0.4505819909812404, 'w14': -1.1008116018182548, 'w15': -1.1468157778353785, 'w16': 0.09153251432810972, 'w17': -0.41845929763252787, 'w18': 2.4720868117639867, 'w19': -1.7887847705714006, 'w20': 2.439198294673829, 'w21': 0.0801084051445802, 'w22': 1.2669786067213622, 'w23': -1.7761236171694175, 'w24': -1.6174125623220057, 'w25': 2.32859544248715, 'w26': 1.8266752320681658, 'w27': 0.7521676171194236, 'w28': 0.7494642125689316, 'w29': -1.6103878010937807, 'w30': -0.884130945465714}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,268] Trial 62 finished with value: 0.7536231884057971 and parameters: {'w0': -0.5074332228469269, 'w1': -0.1982693494873276, 'w2': 2.016308869746242, 'w3': 0.6406669576865707, 'w4': -2.3435598878787407, 'w5': -1.0617304711580682, 'w6': 1.7621215217448296, 'w7': -1.8973618149185845, 'w8': -1.8877298391370714, 'w9': -0.5307209390739841, 'w10': -1.1940950721713917, 'w11': 0.022043758787413492, 'w12': 1.5581621224596927, 'w13': -0.5506195372802108, 'w14': -0.8783717245188191, 'w15': -0.49467447957528404, 'w16': -0.37871529319640274, 'w17': -0.6310727406898438, 'w18': 2.1602186205679668, 'w19': -2.2719171239766007, 'w20': 1.7627262939800048, 'w21': 0.16454040788031904, 'w22': 0.9671143178642838, 'w23': -2.2035049741202504, 'w24': -1.3910650543926788, 'w25': 2.4956575630536393, 'w26': 0.7627706859968262, 'w27': 2.497803174769338, 'w28': 0.822661806235484, 'w29': -1.1754143999878148, 'w30': -2.33953893551782}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,382] Trial 63 finished with value: 0.7536231884057971 and parameters: {'w0': -0.2670085674200616, 'w1': 0.35164668973479496, 'w2': 2.4660364702309505, 'w3': 0.8428112182106438, 'w4': -1.1386362340229312, 'w5': -1.9180500124228737, 'w6': 1.01714075322983, 'w7': -1.6026973548944539, 'w8': -2.3063040657137424, 'w9': 0.2933748299461825, 'w10': -0.5834039461972886, 'w11': 0.5513221570235283, 'w12': 0.40161055974473514, 'w13': -1.856442368166561, 'w14': -1.5656891901043382, 'w15': -0.0773777697241948, 'w16': 0.601363636564756, 'w17': -1.1442519243154936, 'w18': 1.348425301759793, 'w19': -1.6045816701883573, 'w20': 1.8816255647013702, 'w21': -0.5452060470219413, 'w22': 0.5056344163660806, 'w23': -2.4892091151904014, 'w24': -1.8937811870420667, 'w25': 2.1542446591099838, 'w26': 2.2674559454322036, 'w27': -2.1482312898712768, 'w28': 0.5293924752574537, 'w29': -1.7791991963190756, 'w30': 1.4798169828906975}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,491] Trial 64 finished with value: 0.7463768115942029 and parameters: {'w0': 0.08993867308095219, 'w1': 1.035450769410327, 'w2': 1.771555136656346, 'w3': 1.2657382092567036, 'w4': -1.453009765944504, 'w5': -1.4664970277037161, 'w6': 1.1785049565153343, 'w7': -1.286394011489162, 'w8': -0.8378912906585957, 'w9': -0.09001389606366494, 'w10': -0.9230250858453855, 'w11': 0.2756386892942892, 'w12': 0.0889963226604372, 'w13': 0.4314987649045883, 'w14': -2.191429324443615, 'w15': -1.0548377311088102, 'w16': -0.305699113441835, 'w17': -0.15601200482372402, 'w18': 1.9027476627828128, 'w19': -1.3307638911512532, 'w20': 1.4623832559437577, 'w21': 0.5050148456133692, 'w22': 1.690829894419831, 'w23': 2.0811367103712586, 'w24': -1.055395287440184, 'w25': 2.324496189707372, 'w26': 1.5357207744642187, 'w27': 0.43468320446327285, 'w28': 1.4488379868659498, 'w29': -0.8047190613129488, 'w30': -1.0537332776207882}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,600] Trial 65 finished with value: 0.7463768115942029 and parameters: {'w0': 0.3207053324814517, 'w1': 0.6361670052675411, 'w2': 2.1295842056530137, 'w3': 1.3943875376396675, 'w4': -0.3701695640249789, 'w5': -1.7277331759232113, 'w6': 2.1487716309225946, 'w7': -1.0538773662903849, 'w8': -1.5916834440675767, 'w9': 1.9233665357561864, 'w10': -1.4540864752907172, 'w11': 0.9948907563942359, 'w12': 1.066990667764747, 'w13': -2.128541813847766, 'w14': 0.2104521621511291, 'w15': -0.6601501411842051, 'w16': -1.0572676601093902, 'w17': -0.9402019227131807, 'w18': 0.14069897572258655, 'w19': -1.8526519061095783, 'w20': 2.279699773077721, 'w21': 0.2877361997815082, 'w22': -0.298705566571213, 'w23': -2.0901957093150614, 'w24': -2.117457204402556, 'w25': 1.9993227765423407, 'w26': -0.14493018497248578, 'w27': 1.4134979708325217, 'w28': 0.18290243860227645, 'w29': -1.931145486218616, 'w30': 1.9007167609839015}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,706] Trial 66 finished with value: 0.7463768115942029 and parameters: {'w0': -0.5500782160705457, 'w1': 2.4750828373308, 'w2': 2.3326957929623835, 'w3': -0.6097708512744463, 'w4': -0.6613637570415455, 'w5': 0.6646157565759916, 'w6': 0.7393795030278979, 'w7': -0.779662720953407, 'w8': -2.0137095984557942, 'w9': 2.1936331445614554, 'w10': 0.6203625451025381, 'w11': -1.1126057628656314, 'w12': 0.6562472783896648, 'w13': -1.7713042515519692, 'w14': 0.6789800791005081, 'w15': -0.33463725324975163, 'w16': -0.5495077267942181, 'w17': -1.453781841290286, 'w18': -1.4955061592912204, 'w19': -1.4979268218227866, 'w20': -2.4759651295333445, 'w21': 0.7655836554293913, 'w22': 0.595817253208738, 'w23': 2.3449397512180763, 'w24': 2.3271089350672423, 'w25': 1.4609219578816184, 'w26': 0.9387133520442348, 'w27': -0.39163335192513893, 'w28': 1.2208365738581965, 'w29': -2.1050965238940313, 'w30': -0.6817527662520466}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,818] Trial 67 finished with value: 0.7536231884057971 and parameters: {'w0': -0.09827372155869862, 'w1': -0.5247828434982875, 'w2': 1.4904211943639287, 'w3': 1.8284390487969029, 'w4': 0.8633399675734889, 'w5': -1.5824702151687682, 'w6': 0.19414323924938223, 'w7': 1.4374970765809483, 'w8': -1.0616635636307705, 'w9': 0.8422550653009704, 'w10': -1.6873859243928018, 'w11': -0.3058268498594158, 'w12': 0.8669242966079269, 'w13': 2.070292176036906, 'w14': -2.419778079676207, 'w15': -1.4200988211295005, 'w16': -0.058249659530501555, 'w17': -1.8149813017104843, 'w18': -0.3639380060577204, 'w19': -2.2121401448229956, 'w20': 1.2974375377705418, 'w21': 2.4550041396678473, 'w22': -0.612161093997159, 'w23': -1.566958865814069, 'w24': -0.2514712089017481, 'w25': 2.190076576612545, 'w26': -2.103938099639034, 'w27': 0.7104988622278894, 'w28': 0.9539752580492071, 'w29': -1.5598731715443388, 'w30': -0.24118986101136589}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:25,927] Trial 68 finished with value: 0.7391304347826086 and parameters: {'w0': -1.3470863190003302, 'w1': -0.8598770833140468, 'w2': 1.914796339919386, 'w3': 0.5192606528610675, 'w4': -0.9824354353601011, 'w5': -2.356188561691791, 'w6': -0.5809440956738803, 'w7': -2.246600322948762, 'w8': -1.4311683200902952, 'w9': 1.5543273113428477, 'w10': -2.248160420372555, 'w11': 0.1587854242296858, 'w12': 1.435953934263256, 'w13': -2.3862377769416794, 'w14': 0.07353763377228026, 'w15': 0.2722277222492815, 'w16': -0.8000105590958747, 'w17': -0.4481140287465706, 'w18': 1.7194870511251938, 'w19': -0.873701387567351, 'w20': 2.0573643987541534, 'w21': -0.7169173136379259, 'w22': -2.0148017406409706, 'w23': -1.9379208478517806, 'w24': -0.024282398100582414, 'w25': -0.3131869253115438, 'w26': -2.296264481113252, 'w27': 0.9186800942416109, 'w28': -0.37734823582045396, 'w29': 0.8109849407653513, 'w30': -1.6187030537258493}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:26,031] Trial 69 finished with value: 0.7536231884057971 and parameters: {'w0': -0.8874964524002356, 'w1': 0.011526878324685463, 'w2': 1.1765167864110204, 'w3': -0.05526593829481466, 'w4': 1.4550427160413562, 'w5': -1.8720548793054959, 'w6': 0.572933919151774, 'w7': -1.964076130236853, 'w8': -1.7353775186816636, 'w9': 0.5145786515241046, 'w10': -2.443152900431591, 'w11': 0.5054775884484649, 'w12': 1.8622510083819044, 'w13': 0.7994764979122577, 'w14': 1.5104223347664987, 'w15': -0.7932790390320321, 'w16': -1.1665312448249392, 'w17': -1.696106628815147, 'w18': 2.0318137506669696, 'w19': -0.695254330017502, 'w20': -2.1457958910949433, 'w21': 0.010530871540959996, 'w22': -1.7821368850962471, 'w23': -2.338107763244552, 'w24': -1.2459493287678214, 'w25': 2.368298276598597, 'w26': -0.8453309729178903, 'w27': -1.7783832173592566, 'w28': -0.19506594068507782, 'w29': -2.3719415043851675, 'w30': 0.5298614334565934}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:26,137] Trial 70 finished with value: 0.7608695652173914 and parameters: {'w0': -1.7951740408825032, 'w1': 0.8713520318191705, 'w2': 1.675653072703516, 'w3': 0.2907490247483676, 'w4': 1.189560437899816, 'w5': -1.2399650634363408, 'w6': -0.8323229925598531, 'w7': -1.3811248328446164, 'w8': -0.1289510882434457, 'w9': 1.3705523693941648, 'w10': -0.4713743921146298, 'w11': 0.7706659249161794, 'w12': -0.43729070068756193, 'w13': -1.484019728053418, 'w14': -1.199980059865207, 'w15': -0.10916630709120223, 'w16': -2.1293082831930437, 'w17': 2.17958076968524, 'w18': -0.16637670851205233, 'w19': -0.1351955256105556, 'w20': 0.34691468041112034, 'w21': -1.0799213968695762, 'w22': -0.9446334435723669, 'w23': 0.7402415125552186, 'w24': -0.734449930240372, 'w25': 1.9571367896788447, 'w26': -1.7077712962142373, 'w27': -1.2970323206705145, 'w28': -0.6541030210244133, 'w29': -1.1430895516873791, 'w30': 1.7040982681270205}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:26,265] Trial 71 finished with value: 0.7608695652173914 and parameters: {'w0': -1.6582227329335415, 'w1': 1.4041565626269825, 'w2': 1.6933990097655462, 'w3': 0.2817848953804276, 'w4': 1.1663577240660719, 'w5': -1.1600640173821561, 'w6': -0.8655101852508498, 'w7': -1.3884840929373636, 'w8': -0.20221069818130322, 'w9': 1.1718939544169582, 'w10': -0.44444327298268893, 'w11': 1.1356939374506865, 'w12': -0.1677919911663852, 'w13': -1.4686010073201972, 'w14': -1.148516375032133, 'w15': -0.09663455619267025, 'w16': -2.1339496954949135, 'w17': 2.1798902163837988, 'w18': 1.0992523461591108, 'w19': -0.12685461646245066, 'w20': 0.2706173060210362, 'w21': -1.4433851517697311, 'w22': -1.024424141099575, 'w23': 0.7898461795098244, 'w24': -0.7173951738964092, 'w25': 1.8170429760570848, 'w26': -1.6655128885327326, 'w27': -0.7603050911163123, 'w28': -0.998285656627284, 'w29': -1.1373060497685117, 'w30': 2.171906601730988}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:26,403] Trial 72 finished with value: 0.7608695652173914 and parameters: {'w0': -1.6900906814271144, 'w1': 1.4533133406313965, 'w2': 1.695675705880506, 'w3': -0.3551224204915504, 'w4': 1.2439482111218638, 'w5': -1.0880850966203977, 'w6': -0.8376110894751168, 'w7': -1.3589524045710224, 'w8': 0.41045210249961794, 'w9': 1.234479350303803, 'w10': -0.09168676383572988, 'w11': 0.8072001150941185, 'w12': -0.41359347177073097, 'w13': -1.467178950367026, 'w14': -0.5250216116458292, 'w15': -0.4620137550291672, 'w16': -2.3272006941993677, 'w17': 2.1831479936309455, 'w18': 1.2321017350674706, 'w19': -0.09000264119128608, 'w20': 0.30916981650492686, 'w21': -1.380835556329867, 'w22': -1.0179617664419203, 'w23': 0.6461148556773803, 'w24': -0.7271151128794084, 'w25': 1.8285271957533071, 'w26': -1.6650749608795667, 'w27': -1.3216893581700504, 'w28': -1.0348167042415841, 'w29': -1.251587664155544, 'w30': 2.153380490266301}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:26,510] Trial 73 finished with value: 0.7608695652173914 and parameters: {'w0': -1.6219353926671949, 'w1': 1.3619641759755645, 'w2': 1.6701778217071217, 'w3': -0.42217466500342116, 'w4': 1.2552498665599514, 'w5': -1.0236156735210493, 'w6': -0.8546650587715794, 'w7': -1.3529699481980033, 'w8': 0.01182995534284792, 'w9': 1.297368176290447, 'w10': 0.15822190340355613, 'w11': 1.0795806733471625, 'w12': -0.5347198685059403, 'w13': -1.5165177577462914, 'w14': -1.266109658158878, 'w15': -0.1334994804017513, 'w16': -2.2812853971142713, 'w17': 2.200674688864331, 'w18': 0.9561834862981388, 'w19': -0.04697505662306935, 'w20': 0.2756579831269258, 'w21': -1.4771997452029701, 'w22': -0.9612966805412969, 'w23': 0.7648039373082061, 'w24': -0.7470816765747322, 'w25': 1.2257238997862876, 'w26': -1.6568996936185338, 'w27': -1.3623939405411292, 'w28': -1.131985899672911, 'w29': -1.0596363230979882, 'w30': 2.498075150272431}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:26,661] Trial 74 finished with value: 0.7463768115942029 and parameters: {'w0': -1.622711102307968, 'w1': 1.3843951605412073, 'w2': 1.6445065265101442, 'w3': -0.4368429946820468, 'w4': 1.1732663073820904, 'w5': -0.7462223141266632, 'w6': -0.8071726435435889, 'w7': -1.3850256590756642, 'w8': 0.5394933908083397, 'w9': 1.1301708057407436, 'w10': 0.12766914336615576, 'w11': 0.7936658406281211, 'w12': -0.623834915780261, 'w13': -1.4151414627157017, 'w14': -1.2342690848959066, 'w15': -0.03606301170107354, 'w16': -2.2534300409157226, 'w17': 2.213088232401363, 'w18': 0.8916813899581952, 'w19': 0.2885975561323248, 'w20': 0.2615725110125105, 'w21': -1.4871095603512785, 'w22': -0.8680389864736664, 'w23': 0.732702451993414, 'w24': -0.7799876580797807, 'w25': 1.0837561580558468, 'w26': -1.6557692101362493, 'w27': -1.353716884689713, 'w28': -1.2120669348034, 'w29': -1.21035861442379, 'w30': 2.4999229784570267}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:26,769] Trial 75 finished with value: 0.7608695652173914 and parameters: {'w0': -1.8350677530606605, 'w1': 1.8477268594939384, 'w2': 1.2981755631719776, 'w3': -0.2343301870578991, 'w4': 1.864483761522405, 'w5': -1.1749942756328755, 'w6': -1.3887840887012532, 'w7': -0.930262878084375, 'w8': 0.2337425298607842, 'w9': 1.335750525164648, 'w10': -0.09536590720736626, 'w11': 1.1119835369366402, 'w12': -0.3286650798987594, 'w13': -1.108664954163745, 'w14': -0.9975313867156113, 'w15': -0.38707298790346056, 'w16': -2.092925568071733, 'w17': 2.0876033753506493, 'w18': 1.2489677149062133, 'w19': -0.08798526691794238, 'w20': -0.035339298612854675, 'w21': -1.985875865987888, 'w22': -0.9860294777518643, 'w23': 0.40285861104741905, 'w24': -0.3280907798977829, 'w25': 1.3490221249623369, 'w26': -1.831294563302676, 'w27': -1.125264124927465, 'w28': -1.4235471096875787, 'w29': -1.0232445365847727, 'w30': 2.1232248157705227}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:26,883] Trial 76 finished with value: 0.7536231884057971 and parameters: {'w0': -1.4595627091398145, 'w1': 1.5900222569727394, 'w2': 0.5412170506856728, 'w3': -0.9070396600959458, 'w4': 0.7587913371021641, 'w5': -1.004262499773885, 'w6': -1.6222643696791523, 'w7': -1.1234985241865247, 'w8': 0.04837975074342332, 'w9': 1.1168920454909685, 'w10': 0.27141799726388255, 'w11': 1.4539317173411883, 'w12': -0.9529625300042774, 'w13': -1.5811617420800648, 'w14': -0.5397943840595101, 'w15': -0.11156800694509095, 'w16': -2.3082662653540242, 'w17': 2.2886949655873123, 'w18': 0.9866035059884385, 'w19': 0.13741295178758067, 'w20': 0.43562244855123916, 'w21': -2.409290171561011, 'w22': -0.5953189312182612, 'w23': 0.7073580262349743, 'w24': -0.6045379878758177, 'w25': 1.5497808989840005, 'w26': -1.3464597605430804, 'w27': -0.910313018535525, 'w28': -1.0101259231052795, 'w29': -0.4809936172023611, 'w30': 2.238314915853947}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,001] Trial 77 finished with value: 0.7536231884057971 and parameters: {'w0': -1.7216998696938752, 'w1': 1.3051682069775892, 'w2': 0.8918648866208794, 'w3': 0.23457660113159673, 'w4': 1.343421037132631, 'w5': -0.9569510207742962, 'w6': -1.1496565770691753, 'w7': -1.262968758726498, 'w8': -0.13046934346449834, 'w9': 0.9084170174488844, 'w10': -0.37952227843872155, 'w11': 1.040194742850023, 'w12': -0.25795700729610266, 'w13': -1.4428917252898015, 'w14': -1.1477743929784268, 'w15': 0.13483836943630773, 'w16': -1.8689482437141374, 'w17': 1.8583784840811193, 'w18': 1.4369050317121643, 'w19': 0.43032088434407145, 'w20': -0.43872446560043, 'w21': -1.1389276849434535, 'w22': -1.057764492907489, 'w23': 1.2375632090209807, 'w24': -0.45545129621323865, 'w25': 1.2371031450626786, 'w26': -1.6047918044726497, 'w27': -0.682027584837201, 'w28': -0.7237780934724275, 'w29': -0.9123598802844438, 'w30': 1.7362656804618957}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,111] Trial 78 finished with value: 0.7463768115942029 and parameters: {'w0': -1.328818837582396, 'w1': 1.4890593898958242, 'w2': 1.4589101869183874, 'w3': -0.48586227645943525, 'w4': 1.5753891290062532, 'w5': -0.5295290010557225, 'w6': -0.49862540047667714, 'w7': -0.663757094875439, 'w8': 1.100179932113086, 'w9': 1.2485632850995485, 'w10': 0.5509957639330783, 'w11': 0.7203213343050677, 'w12': -0.7647321918593275, 'w13': -1.2703175777374258, 'w14': -1.3693113302771012, 'w15': -0.557175512021192, 'w16': -2.1259934148162314, 'w17': 1.6225513214599476, 'w18': 0.5503260592997848, 'w19': 0.6778212659313263, 'w20': 0.126483846613052, 'w21': -1.6106541199148516, 'w22': -1.2291383939144593, 'w23': -0.04632801274908882, 'w24': -0.64671719086142, 'w25': 1.743879810952924, 'w26': -2.031799417716746, 'w27': -1.487178366483303, 'w28': -0.7497042975054173, 'w29': -1.358457740547357, 'w30': 1.988536277436264}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,225] Trial 79 finished with value: 0.7463768115942029 and parameters: {'w0': -1.9537256248313044, 'w1': 0.8499071794853796, 'w2': 1.6770497497793968, 'w3': -0.7422214321466667, 'w4': 1.073867369784079, 'w5': -1.3175740468841792, 'w6': -0.26405025915962865, 'w7': -1.598519021615018, 'w8': 0.3490349282258857, 'w9': 1.7143401649874996, 'w10': -0.2406430694968864, 'w11': 1.1389865233105492, 'w12': -0.4391941059328183, 'w13': -1.6975329948818727, 'w14': -0.8106295159887569, 'w15': 0.4000379062180529, 'w16': -1.6246372540415048, 'w17': 2.2687838402869676, 'w18': 0.7871558224367768, 'w19': -0.2535702825459529, 'w20': 0.5477807994908181, 'w21': -1.042907429448087, 'w22': -1.4280243102797616, 'w23': 0.8974194156540004, 'w24': -0.15867330154075399, 'w25': 0.7996510533811634, 'w26': -1.4230999868902943, 'w27': -1.2771036284990418, 'w28': -1.4744273810563087, 'w29': -1.1204434582827139, 'w30': 2.3754401326542247}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,342] Trial 80 finished with value: 0.7463768115942029 and parameters: {'w0': -1.595641855134613, 'w1': 1.2275386150162817, 'w2': 1.2215696979062953, 'w3': -1.2213687536423279, 'w4': 2.1412246714567393, 'w5': -0.8785011676385684, 'w6': -2.1677409438723734, 'w7': -0.8707507450412821, 'w8': -0.19892732257463225, 'w9': 1.3647514287902691, 'w10': 1.9441938479433545, 'w11': 0.8706843743331555, 'w12': -0.15343694348189696, 'w13': -1.9678230213349628, 'w14': -1.4687441119171818, 'w15': -0.1834391881690437, 'w16': -1.9192102913140328, 'w17': 2.0323937027608276, 'w18': 1.256874681947168, 'w19': -0.06256530676390687, 'w20': -0.09468994986361728, 'w21': -1.84245763992674, 'w22': -0.37226231479276994, 'w23': -0.16598448289650802, 'w24': -1.1012900505966106, 'w25': 0.4565381268280172, 'w26': -1.785954643843331, 'w27': -1.5672020462222847, 'w28': -1.860501502444002, 'w29': -0.7309786650941252, 'w30': 1.6848140561620302}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,448] Trial 81 finished with value: 0.7608695652173914 and parameters: {'w0': -1.8122144026056966, 'w1': 1.8407638493264489, 'w2': 1.3306991074859216, 'w3': -0.26893265775709985, 'w4': 1.835076914576842, 'w5': -1.248121225524266, 'w6': -1.3842198444639204, 'w7': -0.9097513571181925, 'w8': 0.21559226925630845, 'w9': 1.3442580092144436, 'w10': -0.04576395124416268, 'w11': 1.3451011187344821, 'w12': -0.46890320695834914, 'w13': -1.0679697867913993, 'w14': -1.0324316019084685, 'w15': -0.3752540533070523, 'w16': -2.103964599553893, 'w17': 2.109750098572956, 'w18': 1.1781474912545171, 'w19': -0.08542171101300267, 'w20': -0.002083328629515102, 'w21': -2.079793560711796, 'w22': -0.9595005002462692, 'w23': 0.3476563470943958, 'w24': -0.3473699894109048, 'w25': 1.3630903378795087, 'w26': -1.8684179522187814, 'w27': -1.189699917228191, 'w28': -1.6613821398209776, 'w29': -1.0131826374347015, 'w30': 2.1395452524516836}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,558] Trial 82 finished with value: 0.7536231884057971 and parameters: {'w0': -1.8886155882722255, 'w1': 1.9983302803599807, 'w2': 1.0612423926855996, 'w3': 0.02440092732114757, 'w4': 2.4191367699657986, 'w5': -1.1375390508517316, 'w6': -0.931461814122624, 'w7': -1.422962806146265, 'w8': 0.6449339212055358, 'w9': 0.7059108699526263, 'w10': -0.11091268528408993, 'w11': 1.076917803263684, 'w12': -0.3083971195460057, 'w13': -0.7319837778128429, 'w14': -0.970684271325613, 'w15': -0.3988738236632891, 'w16': -2.3808127456926713, 'w17': 1.8659001142075677, 'w18': 1.6524921559584898, 'w19': -0.24780228389806486, 'w20': 0.350698612641271, 'w21': -1.3983990901617236, 'w22': -1.0122368909184989, 'w23': 0.4399562348052907, 'w24': 0.09620164381409758, 'w25': 1.9257571692039062, 'w26': -2.161551012387622, 'w27': -1.0382137310130155, 'w28': -1.3747424530259873, 'w29': -1.3039733043894324, 'w30': 1.8518118742707455}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,672] Trial 83 finished with value: 0.7536231884057971 and parameters: {'w0': -1.0901985540214714, 'w1': 2.1111648871037936, 'w2': 1.824858391069435, 'w3': -0.15510440029127848, 'w4': 1.2186430797491552, 'w5': -1.1707338178193523, 'w6': -1.3244732940308948, 'w7': -1.3292529541837048, 'w8': 0.32610767527042406, 'w9': 1.044047178356838, 'w10': 0.14842868475000745, 'w11': 0.7028401504726599, 'w12': -0.6973975614211891, 'w13': -1.54279153720183, 'w14': -1.6932195572863717, 'w15': -0.28451209929447635, 'w16': -2.053500859692659, 'w17': 2.374443950980752, 'w18': 0.9981499260616928, 'w19': -0.5054650923922779, 'w20': 0.6303782648205356, 'w21': -1.8025005478721052, 'w22': -0.7589014703988411, 'w23': 0.8111891952161955, 'w24': -0.8926976519940646, 'w25': 1.7971550480452945, 'w26': -1.2499436828181885, 'w27': -1.1141307236583733, 'w28': -2.03498608042723, 'w29': -0.9127866513201134, 'w30': 2.1158725647263643}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,785] Trial 84 finished with value: 0.7536231884057971 and parameters: {'w0': -2.11474713104084, 'w1': 1.9129219236532706, 'w2': 1.5392672622995593, 'w3': -0.28357912510527467, 'w4': 1.7413071290555822, 'w5': -1.4520603955868698, 'w6': -0.7207829329489642, 'w7': -0.22959841524118563, 'w8': -0.00704526089218685, 'w9': 1.5726500659511133, 'w10': 0.7787703814279594, 'w11': 1.577524577497799, 'w12': -0.8571189144848856, 'w13': -1.1230951182457494, 'w14': -0.6870065066057618, 'w15': 0.06264089730693623, 'w16': -2.183535796616756, 'w17': 2.133828962641209, 'w18': 1.4318435789876516, 'w19': 0.12068788417480246, 'w20': -0.5944987764207317, 'w21': -1.2558030419205528, 'w22': -1.3681009382387117, 'w23': 0.13843748080989948, 'w24': -0.5130556774670653, 'w25': 0.9172906952717654, 'w26': -1.8485816951102634, 'w27': -0.8108323790392844, 'w28': -0.9528735189657678, 'w29': -1.4761624690835704, 'w30': 2.3096883062790314}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:27,898] Trial 85 finished with value: 0.7536231884057971 and parameters: {'w0': -1.2240853928028064, 'w1': 1.6756976959671035, 'w2': 1.311600878821254, 'w3': 0.37749093111113224, 'w4': 1.9754995518483978, 'w5': -1.6194477504448197, 'w6': -0.9190517599167769, 'w7': -1.1276322442953055, 'w8': -0.5634722550706235, 'w9': 1.234662789092883, 'w10': 0.3404380410219633, 'w11': 0.910261120858374, 'w12': 0.05284184752773169, 'w13': -1.7816564263395842, 'w14': -1.2265508737226058, 'w15': 0.2563770890710592, 'w16': -1.7905160699384326, 'w17': 1.6375961463359827, 'w18': 1.234455543914021, 'w19': 0.2624712023164797, 'w20': 0.12854147308921765, 'w21': -1.55189273979044, 'w22': -1.0996762672309883, 'w23': 1.0602306141147095, 'w24': -0.6597970271081457, 'w25': 2.007310893556679, 'w26': -2.035470793710835, 'w27': -0.5590581559215914, 'w28': -1.1465351575051765, 'w29': -1.0740579164320814, 'w30': 1.4590042207186433}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,021] Trial 86 finished with value: 0.7608695652173914 and parameters: {'w0': -1.7497363829793524, 'w1': 1.4529572389718413, 'w2': 1.1383525467910514, 'w3': -0.37457939903483567, 'w4': 0.5982530285757236, 'w5': -1.0856208440254074, 'w6': -1.2304904136732047, 'w7': -1.635072298005984, 'w8': -0.23900208936514, 'w9': 1.6806418960207825, 'w10': -0.7442196655606002, 'w11': 0.4695810278157103, 'w12': -1.5792773466812888, 'w13': -2.0256052746478725, 'w14': -0.39463312922110316, 'w15': -0.5799937267691981, 'w16': -1.5724681209399831, 'w17': 2.4950478556572064, 'w18': -0.1617746161154775, 'w19': -0.017490546392758127, 'w20': 0.8152991840800488, 'w21': -2.19917584769877, 'w22': -0.17696632172100946, 'w23': 0.6128590300946996, 'w24': -0.28315367427717986, 'w25': 1.6562433260421259, 'w26': -2.3711813661134626, 'w27': -1.2832405908157172, 'w28': -0.615854244529071, 'w29': -0.561991085028161, 'w30': 1.990005857960198}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,128] Trial 87 finished with value: 0.7463768115942029 and parameters: {'w0': -1.4649274417094664, 'w1': 2.3533577918354465, 'w2': 1.4252246707812855, 'w3': -0.7217840516791163, 'w4': 1.4805743535669904, 'w5': -0.38194450102176036, 'w6': -0.3615868999538537, 'w7': -1.7936805285190704, 'w8': 0.46177219514820794, 'w9': 1.8358429632501365, 'w10': -0.4980093977580553, 'w11': 1.1693485717544068, 'w12': -0.5892830737570993, 'w13': -1.2323982130585702, 'w14': -1.505294524307047, 'w15': -0.10588274496763972, 'w16': -1.3732803748521485, 'w17': 1.9837428383105808, 'w18': 1.512487117016243, 'w19': -0.3014079899276806, 'w20': 0.40890153159600223, 'w21': -1.7116096520263695, 'w22': -0.6651272390806511, 'w23': 1.4538207876585847, 'w24': -0.8599487438620612, 'w25': 2.177243441776335, 'w26': -1.7257510588910208, 'w27': -1.9217808383669057, 'w28': -1.4164385708871579, 'w29': -0.818657138164281, 'w30': 2.4493582189408394}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,245] Trial 88 finished with value: 0.7463768115942029 and parameters: {'w0': -2.046147761724053, 'w1': 1.7166632081734485, 'w2': 0.8929460406355687, 'w3': -0.12271556418384749, 'w4': 0.9922109014804468, 'w5': -0.6408327405451242, 'w6': -1.0024734757584812, 'w7': -0.9367468832751927, 'w8': 0.2154754115274598, 'w9': 1.4637944917225398, 'w10': 0.08952783763291303, 'w11': 1.8159869251964456, 'w12': -0.34922440889921996, 'w13': -2.172888190638659, 'w14': -1.0728078717379508, 'w15': -0.7758453971091495, 'w16': -2.4206180808589535, 'w17': 1.0394677936661216, 'w18': 1.0329556799363249, 'w19': 0.5408492133599471, 'w20': -0.24027443001119708, 'w21': -1.0515441868286077, 'w22': -0.9525137817063098, 'w23': 0.4498221729281574, 'w24': -1.0327240084082658, 'w25': 1.2833458163639515, 'w26': -1.5829057105802868, 'w27': -0.9819459084972694, 'w28': -2.067550166964634, 'w29': -1.4275204165751938, 'w30': 1.6034032316043303}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,353] Trial 89 finished with value: 0.7463768115942029 and parameters: {'w0': -2.3616728283836728, 'w1': 1.1028864828153773, 'w2': 1.6538409987815215, 'w3': 0.013480503750092687, 'w4': 1.6462089357565224, 'w5': -0.8141873917411337, 'w6': -0.792362781218764, 'w7': 1.933995781135108, 'w8': 0.7655946198738461, 'w9': 1.0102240700570746, 'w10': -0.0532384972729564, 'w11': 1.0363728292663097, 'w12': -0.1401762696505166, 'w13': -1.4107545673349917, 'w14': -1.3263115849661637, 'w15': 0.5145752773241562, 'w16': -1.995746883489495, 'w17': 1.4711959099686602, 'w18': 0.4297734798192685, 'w19': -0.11574855883629295, 'w20': 0.5332429877027982, 'w21': -0.9513173458741035, 'w22': -0.8276675210614195, 'w23': 1.1535892478289003, 'w24': -0.7066189573926269, 'w25': 1.4887353251010351, 'w26': -2.192211863493607, 'w27': -1.711483947665614, 'w28': -1.5500156159450766, 'w29': -1.2194736760566518, 'w30': 1.2495457437768547}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,460] Trial 90 finished with value: 0.7608695652173914 and parameters: {'w0': -1.6422394776813312, 'w1': 1.5351982828647404, 'w2': 0.6061520948880823, 'w3': 0.2755125120689794, 'w4': 1.3683865570270486, 'w5': -1.8047370933029119, 'w6': -1.5537535738004282, 'w7': 0.17693764765132342, 'w8': -0.38548270740963575, 'w9': 0.7957529111646693, 'w10': -0.21082273790144584, 'w11': 0.8252877384587527, 'w12': -1.1893775185056628, 'w13': -1.6752279297331831, 'w14': -0.7726288483755518, 'w15': -0.23137709823251928, 'w16': -1.7723190047469481, 'w17': 2.349165074647146, 'w18': 1.813657669048088, 'w19': -0.44628606134910853, 'w20': -0.05385095836088327, 'w21': -1.3299264406066884, 'w22': -0.47890861607260227, 'w23': 1.631303756993508, 'w24': 0.35854661903755203, 'w25': 2.0552546019776154, 'w26': -1.469122936587457, 'w27': -1.491845320640024, 'w28': -1.2651486960179223, 'w29': -1.741581981581493, 'w30': 2.1939588380549067}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,567] Trial 91 finished with value: 0.7608695652173914 and parameters: {'w0': -1.8355275837057452, 'w1': 1.8681907982822537, 'w2': 1.3322246942848537, 'w3': 0.12916516317029164, 'w4': 1.9003628402609187, 'w5': -1.2784395757909655, 'w6': -1.39290481945824, 'w7': -0.9126952245753484, 'w8': 0.2809138617115108, 'w9': 1.3268530781811607, 'w10': -0.008326493015268055, 'w11': 1.3184006245867506, 'w12': 0.18934099966980872, 'w13': -1.0139844951694186, 'w14': -0.9115357200995744, 'w15': -0.4290800060927458, 'w16': -2.1834145768238185, 'w17': 2.0437751960710324, 'w18': 1.2131271132306831, 'w19': -0.15888536733526226, 'w20': 0.07063500663798394, 'w21': -2.08926104889831, 'w22': -1.1934977479947475, 'w23': 0.27915175234304035, 'w24': -0.37909091557981994, 'w25': 1.1818288874845007, 'w26': -1.9043691538580902, 'w27': -1.1324474700931435, 'w28': -1.6062458108787454, 'w29': -0.9795289171861625, 'w30': 2.08000583547524}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,694] Trial 92 finished with value: 0.7536231884057971 and parameters: {'w0': -1.776846678627183, 'w1': 1.8387690812574193, 'w2': 1.2244517838824747, 'w3': -0.5158671647684758, 'w4': 2.090453586930108, 'w5': -1.5131926193919256, 'w6': -1.7644942918845046, 'w7': -1.5030485949283836, 'w8': 0.13197569918992702, 'w9': 1.3585607934429713, 'w10': 0.47697885687285085, 'w11': 1.3680736297711293, 'w12': -0.47317610589156683, 'w13': -1.897157713577016, 'w14': -0.9853731792415509, 'w15': -0.3470774595623014, 'w16': -2.067241710553058, 'w17': 2.1448400034157995, 'w18': 1.1901015545314946, 'w19': 0.14578083619499127, 'w20': 0.19899591343943862, 'w21': -2.024390593402312, 'w22': -0.9245054467216595, 'w23': 0.3490053407542859, 'w24': 0.06624284225820842, 'w25': 1.3699825300414112, 'w26': -1.8400037916373364, 'w27': -0.7917231706891309, 'w28': -1.0382257866188325, 'w29': -1.0237138238596382, 'w30': 2.186102330676675}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,826] Trial 93 finished with value: 0.7608695652173914 and parameters: {'w0': -1.5621145188919752, 'w1': 2.1668506504059586, 'w2': 0.8127759767680562, 'w3': -0.28675225374010926, 'w4': 1.2925064580562546, 'w5': -1.6351407586998288, 'w6': -1.1701394764841684, 'w7': -0.4965412343236899, 'w8': 0.01981692620712111, 'w9': 1.1553049528002624, 'w10': -0.39691952883238457, 'w11': 1.239849364156226, 'w12': -0.5598372231101444, 'w13': -0.7653157058776925, 'w14': -0.589430554397478, 'w15': 0.021085012073452758, 'w16': -2.321148688265481, 'w17': 1.929935325352357, 'w18': -2.430194362248783, 'w19': 0.018532415260144833, 'w20': 0.7073423347885255, 'w21': -2.319427187219299, 'w22': -1.5002294673757477, 'w23': 0.6201133944839121, 'w24': -0.0807995158140179, 'w25': 1.8545961399519042, 'w26': -2.015103956226126, 'w27': -1.2653450167746065, 'w28': -0.8575777693377875, 'w29': -1.2777884588977702, 'w30': 1.8655927946161075}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:28,965] Trial 94 finished with value: 0.7463768115942029 and parameters: {'w0': -2.204952538800308, 'w1': 1.7608657200197702, 'w2': 1.517504958491501, 'w3': -0.9450639899900976, 'w4': 1.796605309490007, 'w5': -1.1870443494324139, 'w6': -0.6347810022494196, 'w7': -1.1772150320609758, 'w8': 0.5550387297708508, 'w9': 1.2817302386598959, 'w10': 0.1905251330627391, 'w11': 0.6334841119594905, 'w12': 0.006371654910682867, 'w13': -1.1237445538190458, 'w14': -1.7219703408646718, 'w15': -0.4683392952595808, 'w16': -2.187573146490189, 'w17': 1.758694773033683, 'w18': 1.3799862356817798, 'w19': 0.348938446112803, 'w20': -0.10125418485135396, 'w21': -1.8963198490148916, 'w22': -1.327942123393517, 'w23': 0.5139759373076317, 'w24': -1.1864941670807356, 'w25': 1.036203848397513, 'w26': -2.187004767956201, 'w27': -1.1854236634804385, 'w28': -1.2920219603549106, 'w29': -0.2546151736292722, 'w30': 2.3564530822699643}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:29,075] Trial 95 finished with value: 0.7536231884057971 and parameters: {'w0': -1.9373339716692672, 'w1': 0.9046102371595882, 'w2': -0.12503807264974137, 'w3': -0.19567898345440948, 'w4': 1.145603983615458, 'w5': -1.3801177773161726, 'w6': -1.370035126811543, 'w7': -1.0265252716777038, 'w8': 0.8839301825327142, 'w9': 1.4865235098030027, 'w10': -0.2828011750953209, 'w11': 1.1242679028081726, 'w12': -0.9070111632703362, 'w13': -2.3520828518876984, 'w14': -1.9234534703633726, 'w15': -0.9655603816924093, 'w16': -1.9169586845830813, 'w17': 2.21137523697504, 'w18': 1.109712370777208, 'w19': 0.8605717727682693, 'w20': 0.014297821102731811, 'w21': -1.7137239235100572, 'w22': -1.0292056912355723, 'w23': 0.9599567862918572, 'w24': -0.43066834311310065, 'w25': 1.3579896266511404, 'w26': -1.169247582838199, 'w27': -1.412592405634983, 'w28': -1.7599364788778231, 'w29': -2.0175982905509837, 'w30': 2.286957878999557}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:29,185] Trial 96 finished with value: 0.7608695652173914 and parameters: {'w0': -1.386439153349357, 'w1': 1.3810591714331624, 'w2': 1.7472145870947868, 'w3': -0.3731868767440641, 'w4': 2.316400134854303, 'w5': -0.9389269126039359, 'w6': -1.1507639868808646, 'w7': -0.6599641321958019, 'w8': -0.11806773027510736, 'w9': 0.5681115668255995, 'w10': -0.11225561907905052, 'w11': 1.5240783346489921, 'w12': -0.3903996114051536, 'w13': -1.3631571053423706, 'w14': -0.1072195849483126, 'w15': -0.5716209525526528, 'w16': -2.4746525542284625, 'w17': 2.09331804157887, 'w18': 0.9084526192142915, 'w19': -0.6586022046325896, 'w20': 0.986372202467124, 'w21': -0.7259475348747487, 'w22': -1.5926367314037844, 'w23': 0.13997177915839165, 'w24': -0.2920642394128987, 'w25': 1.6892954300234715, 'w26': -1.7618842276571551, 'w27': -1.5542260922034898, 'w28': -1.1216732540978953, 'w29': -0.6781569436857078, 'w30': 2.032114914559909}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:29,297] Trial 97 finished with value: 0.7608695652173914 and parameters: {'w0': -1.2838948416489648, 'w1': 1.048648444361591, 'w2': 1.0108672085366592, 'w3': -0.6090477402310052, 'w4': 0.8838201942336817, 'w5': -1.2898286680854296, 'w6': -0.8337464209665751, 'w7': -0.8033051590342893, 'w8': 0.462152406831598, 'w9': 2.086657298761795, 'w10': -0.027520546320960237, 'w11': 0.6859192651806933, 'w12': -0.2088124205358493, 'w13': -1.0010383244810046, 'w14': -0.4116329798241166, 'w15': 0.7044497205428365, 'w16': -1.5378688052224438, 'w17': 2.3619330760730715, 'w18': 1.5181501054666122, 'w19': -0.3264680223820971, 'w20': 0.30695109753279776, 'w21': -2.46767621169993, 'w22': -0.7487556953453778, 'w23': 0.7283952147332021, 'w24': -0.14654435789824338, 'w25': 2.2516318281421475, 'w26': -2.3582666630400317, 'w27': -0.9013384076958634, 'w28': -2.389652786957967, 'w29': -1.5305281755749158, 'w30': 1.9441943053259414}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:29,425] Trial 98 finished with value: 0.7608695652173914 and parameters: {'w0': -2.3672461685337916, 'w1': 1.2265093590717395, 'w2': 1.355227765345489, 'w3': 0.11440467416088967, 'w4': 1.6529173939912005, 'w5': -1.066648216270565, 'w6': 0.42914085589997075, 'w7': 0.7568428246695293, 'w8': -1.2179084466652497, 'w9': 1.6415325560128435, 'w10': -2.0222708457702687, 'w11': 0.9683728718302359, 'w12': -1.0578144242570917, 'w13': -1.5113365970813086, 'w14': -1.2375244908154728, 'w15': 0.2041035681644784, 'w16': -2.0317127954992595, 'w17': 1.452028979488786, 'w18': 0.6784475613034232, 'w19': 2.224767140538408, 'w20': -0.5113282776626548, 'w21': -1.133759611521476, 'w22': -1.1463283549247518, 'w23': -0.20140917615270054, 'w24': -0.5465085196713577, 'w25': 1.9556894569496421, 'w26': -2.495085023115527, 'w27': -1.8217480150644354, 'w28': -0.3662025386671228, 'w29': -2.220080083820029, 'w30': 2.148157256494062}. Best is trial 11 with value: 0.7608695652173914.\n",
      "[I 2025-09-01 16:25:29,535] Trial 99 finished with value: 0.7536231884057971 and parameters: {'w0': -1.813969960852973, 'w1': 1.9528359239164979, 'w2': 1.8696036038589834, 'w3': -0.09934337809690125, 'w4': 1.047456423118923, 'w5': -2.0183685001278038, 'w6': -1.0447905553580086, 'w7': 2.477132048144382, 'w8': -0.6159915024631235, 'w9': 1.061753641202454, 'w10': 0.2488501517860413, 'w11': 0.24763409126726, 'w12': -0.5608471372276307, 'w13': -2.0702185692112414, 'w14': -1.0369506643392241, 'w15': 2.1069712835932353, 'w16': -1.7199569362427307, 'w17': 2.3916160826475052, 'w18': 0.15538331911575476, 'w19': -0.7693709913868623, 'w20': -0.339406561367276, 'w21': -2.109389359028282, 'w22': -0.9502119664595108, 'w23': 0.3558598429564738, 'w24': -1.3047749043532013, 'w25': 2.178056978258951, 'w26': -1.939942653920629, 'w27': -1.6215200927413895, 'w28': 0.3777330945713518, 'w29': 1.9353280038778842, 'w30': 2.380654219713359}. Best is trial 11 with value: 0.7608695652173914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna alphas (first 10): [0.0126 0.038  0.0546 0.0495 0.0103 0.0035 0.0069 0.1516 0.0052 0.1213]\n",
      "\n",
      "==== (Tuned) Bagging — Optuna Weights (thr from val) Performance ====\n",
      "Accuracy:      0.630814\n",
      "AUC:           0.642042\n",
      "PR-AUC:        0.511613\n",
      "LogLoss:       0.654821\n",
      "Precision@0.530: 0.569767\n",
      "Recall@0.530:    0.352518\n",
      "F1@0.530:        0.435556\n",
      "\n",
      "===== FINAL Retrain on FULL 80% (best params), then test on 20% =====\n",
      "\n",
      "==== FINAL — Simple Average (thr from val) Performance ====\n",
      "Accuracy:      0.619186\n",
      "AUC:           0.643341\n",
      "PR-AUC:        0.513446\n",
      "LogLoss:       0.653493\n",
      "Precision@0.570: 0.555556\n",
      "Recall@0.570:    0.287770\n",
      "F1@0.570:        0.379147\n",
      "\n",
      "==== FINAL — Val-AUC Weighted (thr from val) Performance ====\n",
      "Accuracy:      0.598837\n",
      "AUC:           0.643516\n",
      "PR-AUC:        0.513362\n",
      "LogLoss:       0.653565\n",
      "Precision@0.610: 0.511111\n",
      "Recall@0.610:    0.165468\n",
      "F1@0.610:        0.250000\n",
      "\n",
      "==== FINAL — Optuna Weights (thr from val) Performance ====\n",
      "Accuracy:      0.627907\n",
      "AUC:           0.639410\n",
      "PR-AUC:        0.513570\n",
      "LogLoss:       0.655870\n",
      "Precision@0.530: 0.556701\n",
      "Recall@0.530:    0.388489\n",
      "F1@0.530:        0.457627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.627906976744186,\n",
       " 'auc': 0.6394104228812072,\n",
       " 'ap': 0.513570033978854,\n",
       " 'll': 0.6558704597667546,\n",
       " 'prec': 0.5567010309278351,\n",
       " 'rec': 0.38848920863309355,\n",
       " 'f1': 0.4576271186440678}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# =========================\n",
    "# 0) 数据准备（需已有 df_clean，包含 'value_sort'）\n",
    "# =========================\n",
    "# 例如：\n",
    "# df_clean = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为【外部验证片】（用于学权重/阈值；不用于早停）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]     # 子模型训练/采样池\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]     # 外部验证片（融合/阈值学习）\n",
    "\n",
    "# =========================\n",
    "# 1) 工具函数（评估 / 采样 / 双类保障 / 阈值寻优）\n",
    "# =========================\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on_val(y_val, p_val, metric='accuracy'):\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    if metric == 'accuracy':\n",
    "        scores = [accuracy_score(y_val, (p_val >= t).astype(int)) for t in ths]\n",
    "    else:\n",
    "        from sklearn.metrics import f1_score\n",
    "        scores = [f1_score(y_val, (p_val >= t).astype(int), zero_division=0) for t in ths]\n",
    "    return float(ths[int(np.argmax(scores))])\n",
    "\n",
    "def block_bootstrap(n, ratio, block=20, rng=None):\n",
    "    \"\"\"时间友好采样：固定长度 block 拼接，保持索引连续。\"\"\"\n",
    "    m = int(n * ratio)\n",
    "    idx = []\n",
    "    if n <= 0: \n",
    "        return np.array([], dtype=int)\n",
    "    if block <= 0: \n",
    "        block = 1\n",
    "    while len(idx) < m:\n",
    "        s = rng.randint(0, max(1, n - block + 1))\n",
    "        idx.extend(range(s, min(s + block, n)))\n",
    "    idx = np.array(idx[:m], dtype=int)\n",
    "    idx.sort()\n",
    "    return idx\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3):\n",
    "    \"\"\"保障外部验证片具备双类；不足则先扩大验证片比例，再从训练池补齐缺失类。\"\"\"\n",
    "    if len(np.unique(y_val_fit)) >= 2:\n",
    "        return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "    n_total = len(y_tr)\n",
    "    tail = len(y_val_fit)\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail:\n",
    "            break\n",
    "        X_tr_fit = X_tr_raw[:n_total - new_tail]\n",
    "        y_tr_fit = y_tr[:n_total - new_tail]\n",
    "        X_val_fit = X_tr_raw[n_total - new_tail:]\n",
    "        y_val_fit = y_tr[n_total - new_tail:]\n",
    "        tail = new_tail\n",
    "    if len(np.unique(y_val_fit)) < 2:\n",
    "        classes = np.unique(y_tr)\n",
    "        if len(classes) == 2:\n",
    "            missing = 1 - int(np.unique(y_val_fit)[0])\n",
    "            pool_idx = np.where(y_tr_fit == missing)[0]\n",
    "            if len(pool_idx) > 0:\n",
    "                k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "                pick = np.random.RandomState(1234).choice(pool_idx, k, replace=False)\n",
    "                X_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]], axis=0)\n",
    "                y_val_fit = np.concatenate([y_val_fit, y_tr_fit[pick]], axis=0)\n",
    "                mask = np.ones(len(y_tr_fit), dtype=bool)\n",
    "                mask[pick] = False\n",
    "                X_tr_fit = X_tr_fit[mask]\n",
    "                y_tr_fit = y_tr_fit[mask]\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "def ensure_both_classes_in_es(y_full, es_idx, pool_idx, rng, max_tries=10):\n",
    "    \"\"\"保障早停片(ES)具备双类；必要时从训练子集换入缺失类。\"\"\"\n",
    "    if len(es_idx) == 0:\n",
    "        return es_idx\n",
    "    for _ in range(max_tries):\n",
    "        if len(np.unique(y_full[es_idx])) >= 2:\n",
    "            return es_idx\n",
    "        present = int(np.unique(y_full[es_idx])[0])\n",
    "        missing = 1 - present\n",
    "        cand = pool_idx[y_full[pool_idx] == missing]\n",
    "        if len(cand) == 0:\n",
    "            es_idx = rng.choice(pool_idx, size=max(1, len(es_idx)), replace=True)\n",
    "            continue\n",
    "        k = min(len(cand), max(1, len(es_idx)//2))\n",
    "        replace_es_pos = rng.choice(len(es_idx), size=k, replace=False)\n",
    "        add_from_cand = rng.choice(cand, size=k, replace=False)\n",
    "        es_idx = es_idx.copy()\n",
    "        es_idx[replace_es_pos] = add_from_cand\n",
    "    return es_idx\n",
    "\n",
    "# =========================\n",
    "# 2) 初始 LightGBM 基线参数（调参会覆盖）\n",
    "# =========================\n",
    "BASE_PARAMS = dict(\n",
    "    learning_rate=0.1305241307456396,\n",
    "    num_leaves=86,\n",
    "    max_depth=6,\n",
    "    min_child_samples=103,\n",
    "    subsample=0.5600223085390776,\n",
    "    colsample_bytree=0.608980878948645,\n",
    "    reg_alpha=2.3147174999485715e-05,\n",
    "    reg_lambda=0.00042189753661999455,\n",
    "    n_estimators=1079\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) 训练设置（可复现性）\n",
    "# =========================\n",
    "RANDOM_SEED   = 42\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 外部验证片双类保障\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "# =========================\n",
    "# 4) Optuna：联合调参（LGBM + BAGS/SAMPLE_RATIO/JITTER/BLOCK）\n",
    "#    目标：Val-AUC 加权融合 + 阈值(accuracy) 后的 Accuracy 最大\n",
    "# =========================\n",
    "def build_cfg_with_jitter(base_cfg, rng, scale):\n",
    "    \"\"\"围绕base_cfg做小扰动，生成单个bag用的参数。\"\"\"\n",
    "    jit = (rng.rand(5) - 0.5) * 2 * scale\n",
    "    cfg = base_cfg.copy()\n",
    "    cfg[\"subsample\"]         = float(np.clip(cfg[\"subsample\"] * (1 + jit[0]), 0.5, 1.0))\n",
    "    cfg[\"colsample_bytree\"]  = float(np.clip(cfg[\"colsample_bytree\"] * (1 + jit[1]), 0.5, 1.0))\n",
    "    cfg[\"num_leaves\"]        = int(np.clip(round(cfg[\"num_leaves\"] * (1 + jit[2])), 15, 255))\n",
    "    cfg[\"max_depth\"]         = int(np.clip(round(cfg[\"max_depth\"] * (1 + jit[3])), 3, 12))\n",
    "    cfg[\"min_child_samples\"] = int(np.clip(round(cfg[\"min_child_samples\"] * (1 + jit[4])), 5, 300))\n",
    "    return cfg\n",
    "\n",
    "def train_ensemble_val_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG, seed_offset=0):\n",
    "    \"\"\"在 X_tr_fit/y_tr_fit 上训练 bagging，返回每个bag在验证片/测试集的预测矩阵。\"\"\"\n",
    "    n_train = X_tr_fit.shape[0]\n",
    "    local_rng = np.random.RandomState(RANDOM_SEED + seed_offset)\n",
    "    val_probs_list, te_probs_list = [], []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_train, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx = idx_boot[:es_pt]\n",
    "        es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "        es_idx = ensure_both_classes_in_es(y_tr_fit, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        cfg = build_cfg_with_jitter(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "\n",
    "        clf = LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1, verbosity=-1,\n",
    "            random_state=(RANDOM_SEED + seed_offset + b),\n",
    "            **cfg\n",
    "        )\n",
    "        clf.fit(\n",
    "            X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "            eval_set=[(X_tr_fit[es_idx], y_tr_fit[es_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        val_probs_list.append(clf.predict_proba(X_val_fit)[:, 1])\n",
    "        te_probs_list.append(clf.predict_proba(X_te)[:, 1])\n",
    "    val_probs = np.column_stack(val_probs_list)\n",
    "    te_probs  = np.column_stack(te_probs_list)\n",
    "    return val_probs, te_probs\n",
    "\n",
    "def objective_joint(trial):\n",
    "    # ---- 搜索 LightGBM 基础参数\n",
    "    base_cfg = dict(\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        num_leaves    = trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "        max_depth     = trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        min_child_samples = trial.suggest_int(\"min_child_samples\", 5, 300),\n",
    "        subsample     = trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        reg_alpha     = trial.suggest_float(\"reg_alpha\", 1e-8, 1e-1, log=True),\n",
    "        reg_lambda    = trial.suggest_float(\"reg_lambda\", 1e-8, 1e-1, log=True),\n",
    "        n_estimators  = trial.suggest_int(\"n_estimators\", 200, 2000),\n",
    "    )\n",
    "\n",
    "    # ---- 搜索 Bagging 元参数\n",
    "    BAGS          = trial.suggest_int(\"BAGS\", 8, 40)                # 子模型数\n",
    "    SAMPLE_RATIO  = trial.suggest_float(\"SAMPLE_RATIO\", 0.60, 0.95) # 采样比例\n",
    "    JITTER_SCALE  = trial.suggest_float(\"JITTER_SCALE\", 0.05, 0.25) # 扰动强度\n",
    "    BLOCK_SIZE    = trial.suggest_int(\"BLOCK_SIZE\", 5, 60)          # block长度\n",
    "\n",
    "    # 训练并拿到验证片预测\n",
    "    val_probs, _ = train_ensemble_val_preds(\n",
    "        BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, base_cfg, seed_offset=trial.number\n",
    "    )\n",
    "\n",
    "    # Val-AUC 加权（若AUC缺失则回退0.5）+ 在验证片寻优阈值（accuracy）\n",
    "    weights = []\n",
    "    for j in range(val_probs.shape[1]):\n",
    "        auc_j = safe_auc(y_val_fit, val_probs[:, j])\n",
    "        if np.isnan(auc_j):\n",
    "            auc_j = 0.5\n",
    "        weights.append(max(auc_j, 0.0))\n",
    "    weights = np.array(weights)\n",
    "    if weights.sum() == 0:\n",
    "        alphas = np.ones(val_probs.shape[1]) / val_probs.shape[1]\n",
    "    else:\n",
    "        ex = np.exp(weights - weights.max())\n",
    "        alphas = ex / ex.sum()\n",
    "\n",
    "    val_wavg = (val_probs * alphas.reshape(1, -1)).sum(axis=1)\n",
    "    t_wavg   = best_thr_on_val(y_val_fit, val_wavg, metric='accuracy')\n",
    "    acc_val  = accuracy_score(y_val_fit, (val_wavg >= t_wavg).astype(int))\n",
    "\n",
    "    # 把关键值存起来，便于最终复现阈值\n",
    "    trial.set_user_attr(\"alphas\", alphas)\n",
    "    trial.set_user_attr(\"t_wavg\", t_wavg)\n",
    "    return acc_val\n",
    "\n",
    "# ---- 启动联合调参\n",
    "N_TRIALS = 25  # 先小试，资源允许可加大\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study_joint = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study_joint.optimize(objective_joint, n_trials=N_TRIALS, show_progress_bar=False)\n",
    "\n",
    "print(\"\\n[Joint Tuning] Best value (Val Acc of W-avg@best_thr):\", study_joint.best_value)\n",
    "print(\"[Joint Tuning] Best params:\", study_joint.best_params)\n",
    "\n",
    "# 取出最优组合\n",
    "BEST = study_joint.best_params\n",
    "BEST_BASE_CFG = dict(\n",
    "    learning_rate=BEST[\"learning_rate\"],\n",
    "    num_leaves=BEST[\"num_leaves\"],\n",
    "    max_depth=BEST[\"max_depth\"],\n",
    "    min_child_samples=BEST[\"min_child_samples\"],\n",
    "    subsample=BEST[\"subsample\"],\n",
    "    colsample_bytree=BEST[\"colsample_bytree\"],\n",
    "    reg_alpha=BEST[\"reg_alpha\"],\n",
    "    reg_lambda=BEST[\"reg_lambda\"],\n",
    "    n_estimators=BEST[\"n_estimators\"],\n",
    ")\n",
    "BEST_BAGS         = BEST[\"BAGS\"]\n",
    "BEST_SAMPLE_RATIO = BEST[\"SAMPLE_RATIO\"]\n",
    "BEST_JITTER_SCALE = BEST[\"JITTER_SCALE\"]\n",
    "BEST_BLOCK_SIZE   = BEST[\"BLOCK_SIZE\"]\n",
    "\n",
    "# 用最优trial中记录的 alphas / t_wavg（来自验证片）\n",
    "alphas_best = np.array(study_joint.best_trial.user_attrs[\"alphas\"])\n",
    "t_wavg_best = float(study_joint.best_trial.user_attrs[\"t_wavg\"])\n",
    "\n",
    "print(f\"[Best] BAGS={BEST_BAGS}, SAMPLE_RATIO={BEST_SAMPLE_RATIO:.3f}, \"\n",
    "      f\"JITTER_SCALE={BEST_JITTER_SCALE:.3f}, BLOCK_SIZE={BEST_BLOCK_SIZE}\")\n",
    "print(\"       BASE_CFG:\", BEST_BASE_CFG)\n",
    "print(\"       (Val) alphas first 10:\", np.round(alphas_best[:10], 4))\n",
    "print(\"       (Val) best thr (accuracy):\", t_wavg_best)\n",
    "\n",
    "# =========================\n",
    "# 5) 用最佳组合：先在“调参阶段的划分”上复盘三种融合（取阈值均基于验证片）\n",
    "# =========================\n",
    "val_probs_best, te_probs_best = train_ensemble_val_preds(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG, seed_offset=999\n",
    ")\n",
    "\n",
    "# —— 简单平均（阈值用验证片寻优）\n",
    "val_avg = val_probs_best.mean(axis=1)\n",
    "t_avg   = best_thr_on_val(y_val_fit, val_avg, metric='accuracy')\n",
    "y_prob_avg = te_probs_best.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg, thr=t_avg, title=\"(Tuned) Bagging — Simple Avg (thr from val)\")\n",
    "\n",
    "# —— Val-AUC 加权（阈值用验证片寻优）\n",
    "# 可使用调参阶段得到的 alphas_best，也可以重新按 val_probs_best 计算一次；这里沿用 alphas_best\n",
    "y_prob_wavg = (te_probs_best * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_wavg, thr=t_wavg_best, title=\"(Tuned) Bagging — Val-AUC Weighted (thr from val)\")\n",
    "\n",
    "# —— Optuna 学融合权重（只在验证片学，不泄露）\n",
    "def objective_blend_on_val(trial):\n",
    "    ws = np.array([trial.suggest_float(f\"w{i}\", -2.5, 2.5) for i in range(BEST_BAGS)])\n",
    "    a  = np.exp(ws); a /= (a.sum() + 1e-12)\n",
    "    val_blend = (val_probs_best * a.reshape(1, -1)).sum(axis=1)\n",
    "    ths  = np.linspace(0.01, 0.99, 99)\n",
    "    accs = [accuracy_score(y_val_fit, (val_blend >= t).astype(int)) for t in ths]\n",
    "    idx  = int(np.argmax(accs))\n",
    "    best_t  = float(ths[idx])\n",
    "    best_acc = float(accs[idx])\n",
    "    trial.set_user_attr(\"best_t\", best_t)\n",
    "    return best_acc\n",
    "\n",
    "sampler2 = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study_blend = optuna.create_study(direction=\"maximize\", sampler=sampler2)\n",
    "study_blend.optimize(objective_blend_on_val, n_trials=100, show_progress_bar=False)\n",
    "best_w = np.array([study_blend.best_params[k] for k in sorted(study_blend.best_params.keys(), key=lambda s: int(s[1:]))])\n",
    "a_opt = np.exp(best_w); a_opt /= (a_opt.sum() + 1e-12)\n",
    "best_t_blend = float(study_blend.best_trial.user_attrs[\"best_t\"])\n",
    "print(\"Optuna alphas (first 10):\", np.round(a_opt[:10], 4))\n",
    "\n",
    "te_blend = (te_probs_best * a_opt.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, te_blend, thr=best_t_blend, title=\"(Tuned) Bagging — Optuna Weights (thr from val)\")\n",
    "\n",
    "# =========================\n",
    "# 6) 最终版：用最优参数 + 全量80%重训（block bootstrap & ES双类保障），在20%测试集上评估\n",
    "#    —— 三种融合均沿用“在验证片学到的阈值/权重”（不在测试集学习）\n",
    "# =========================\n",
    "print(\"\\n===== FINAL Retrain on FULL 80% (best params), then test on 20% =====\")\n",
    "\n",
    "def train_ensemble_full_preds(BAGS, SAMPLE_RATIO, JITTER_SCALE, BLOCK_SIZE, BASE_CFG):\n",
    "    n_full = X_tr_raw.shape[0]\n",
    "    local_rng = np.random.RandomState(RANDOM_SEED + 2025)\n",
    "    te_probs_list = []\n",
    "    for b in range(BAGS):\n",
    "        idx_boot = block_bootstrap(n_full, SAMPLE_RATIO, block=BLOCK_SIZE, rng=local_rng)\n",
    "        es_pt = max(1, int(len(idx_boot) * 0.9))\n",
    "        tr_idx = idx_boot[:es_pt]\n",
    "        es_idx = idx_boot[es_pt:] if len(idx_boot) - es_pt > 0 else idx_boot[:1]\n",
    "        es_idx = ensure_both_classes_in_es(y_tr, es_idx, tr_idx, local_rng, max_tries=10)\n",
    "\n",
    "        cfg = build_cfg_with_jitter(BASE_CFG, local_rng, JITTER_SCALE)\n",
    "        clf_final = LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1, verbosity=-1,\n",
    "            random_state=10000 + b,\n",
    "            **cfg\n",
    "        )\n",
    "        clf_final.fit(\n",
    "            X_tr_raw[tr_idx], y_tr[tr_idx],\n",
    "            eval_set=[(X_tr_raw[es_idx], y_tr[es_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "        te_probs_list.append(clf_final.predict_proba(X_te)[:, 1])\n",
    "    te_probs_final = np.column_stack(te_probs_list)\n",
    "    return te_probs_final\n",
    "\n",
    "te_probs_final = train_ensemble_full_preds(\n",
    "    BEST_BAGS, BEST_SAMPLE_RATIO, BEST_JITTER_SCALE, BEST_BLOCK_SIZE, BEST_BASE_CFG\n",
    ")\n",
    "\n",
    "# —— 融合A：简单平均（阈值沿用 t_avg）\n",
    "y_prob_avg_final = te_probs_final.mean(axis=1)\n",
    "report_all(y_te, y_prob_avg_final, thr=t_avg, title=\"FINAL — Simple Average (thr from val)\")\n",
    "\n",
    "# —— 融合B：Val-AUC加权（阈值沿用 t_wavg_best；权重沿用 alphas_best）\n",
    "y_prob_wavg_final = (te_probs_final * alphas_best.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_wavg_final, thr=t_wavg_best, title=\"FINAL — Val-AUC Weighted (thr from val)\")\n",
    "\n",
    "# —— 融合C：Optuna权重（阈值沿用 best_t_blend；权重沿用 a_opt）\n",
    "y_prob_opt_final = (te_probs_final * a_opt.reshape(1, -1)).sum(axis=1)\n",
    "report_all(y_te, y_prob_opt_final, thr=best_t_blend, title=\"FINAL — Optuna Weights (thr from val)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0cd9d1",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742434f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best meta params: {'meta_type': 'lgbm', 'n_estimators': 986, 'learning_rate': 0.010318315725386978, 'num_leaves': 25, 'min_child_samples': 12, 'subsample': 0.8197741860832424, 'colsample_bytree': 0.7679736166401596, 'reg_alpha': 1.0257140343411382, 'reg_lambda': 3.1723687869220747}\n",
      "\n",
      "==== Stacking (LGBM + RF + LR) with Meta-HPO Performance ====\n",
      "Accuracy:      0.559271\n",
      "AUC:           0.530688\n",
      "PR-AUC:        0.452819\n",
      "LogLoss:       0.784891\n",
      "Precision@0.5: 0.482270\n",
      "Recall@0.5:    0.485714\n",
      "F1@0.5:        0.483986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5592705167173252,\n",
       " 'auc': 0.5306878306878308,\n",
       " 'ap': 0.4528190458578522,\n",
       " 'll': 0.7848907331408931,\n",
       " 'prec': 0.48226950354609927,\n",
       " 'rec': 0.4857142857142857,\n",
       " 'f1': 0.48398576512455516}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "\n",
    "import optuna\n",
    "\n",
    "# ========= 数据：df_clean = 特征列 + 'value_sort'(0/1) =========\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（严格不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为“尾部验证段”——仅给 LGBM 早停用（不泄露给二层）\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# ========= 评估工具 =========\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@0.5: {prec:.6f}\")\n",
    "    print(f\"Recall@0.5:    {rec:.6f}\")\n",
    "    print(f\"F1@0.5:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "# ========= 你的最优超参 =========\n",
    "BEST_LGBM = dict(\n",
    "    n_estimators=1079,\n",
    "    learning_rate=0.1305241307456396,\n",
    "    num_leaves=86,\n",
    "    min_child_samples=103,\n",
    "    subsample=0.5600223085390776,\n",
    "    colsample_bytree=0.608980878948645,\n",
    "    reg_alpha=2.3147174999485715e-05,\n",
    "    reg_lambda=0.00042189753661999455\n",
    ")\n",
    "\n",
    "BEST_RF = dict(\n",
    "    n_estimators=1290,\n",
    "    max_depth=21,\n",
    "    min_samples_split=43,\n",
    "    min_samples_leaf=67,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "RF_VAL_THR = 0.4  # 你验证得到的阈值（仅供参考；堆叠里我们用概率，不硬阈值）\n",
    "\n",
    "# 逻辑回归 elasticnet 需 solver='saga'；特征未标准化时建议加 StandardScaler\n",
    "BEST_LR = dict(\n",
    "    penalty='elasticnet',\n",
    "    C=3.918291017627419,\n",
    "    class_weight=None,\n",
    "    fit_intercept=False,\n",
    "    max_iter=790,\n",
    "    l1_ratio=0.5476567846107678,\n",
    "    solver='saga',\n",
    "    random_state=42\n",
    ")\n",
    "LR_VAL_THR = 0.35  # 仅供参考\n",
    "\n",
    "# ========= 第一层基模型：LGBM + RF + LR =========\n",
    "def make_base_models():\n",
    "    base_lgbm = LGBMClassifier(objective=\"binary\", verbosity=-1, **BEST_LGBM, random_state=42)\n",
    "    base_rf   = RandomForestClassifier(**BEST_RF)\n",
    "    base_lr   = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(**BEST_LR))\n",
    "    ])\n",
    "    return [base_lgbm, base_rf, base_lr]\n",
    "\n",
    "# ========= 时序 OOF 折 =========\n",
    "def time_series_folds(n_samples, n_splits=5, min_train_ratio=0.5):\n",
    "    min_train = int(n_samples * min_train_ratio)\n",
    "    tail = n_samples - min_train\n",
    "    fold_len = max(1, tail // n_splits)\n",
    "    for k in range(n_splits):\n",
    "        start_val = min_train + k * fold_len\n",
    "        end_val   = min(n_samples, start_val + fold_len)\n",
    "        if start_val >= end_val: break\n",
    "        train_idx = np.arange(0, start_val)\n",
    "        val_idx   = np.arange(start_val, end_val)\n",
    "        yield train_idx, val_idx\n",
    "\n",
    "# ========= 生成 OOF（基模型在“没见过”的验证段上的预测）=========\n",
    "base_models = make_base_models()\n",
    "M = len(base_models)\n",
    "n_train = X_tr_fit.shape[0]\n",
    "\n",
    "OOF = np.zeros((n_train, M))      # 每列一个基模型的 OOF 概率\n",
    "val_mask = np.zeros(n_train, dtype=bool)\n",
    "val_y    = np.zeros(n_train)\n",
    "\n",
    "for m, model in enumerate(base_models):\n",
    "    for tr_idx, va_idx in time_series_folds(n_train, n_splits=5, min_train_ratio=0.5):\n",
    "        if isinstance(model, LGBMClassifier):\n",
    "            model.fit(\n",
    "                X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "                eval_set=[(X_val_fit, y_val_fit)],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[early_stopping(200, verbose=False)]\n",
    "            )\n",
    "        else:\n",
    "            model.fit(X_tr_fit[tr_idx], y_tr_fit[tr_idx])\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            prob = model.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "        else:\n",
    "            # 一般不会走到这里；保底\n",
    "            decision = model.decision_function(X_tr_fit[va_idx])\n",
    "            prob = 1 / (1 + np.exp(-decision))\n",
    "        OOF[va_idx, m] = prob\n",
    "        val_mask[va_idx] = True\n",
    "        val_y[va_idx]    = y_tr_fit[va_idx]\n",
    "\n",
    "Z_train = OOF[val_mask]\n",
    "y_meta  = val_y[val_mask]\n",
    "\n",
    "# ========= 用 Optuna 搜索“元学习器 + 超参” =========\n",
    "def build_meta(trial):\n",
    "    meta_type = trial.suggest_categorical(\"meta_type\", [\"logreg\", \"ridge\", \"lgbm\"])\n",
    "\n",
    "    if meta_type == \"logreg\":\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 100.0, log=True)\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "        # 对概率特征，LR 很稳；数据量不大时优先\n",
    "        meta = LogisticRegression(\n",
    "            penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "            class_weight=\"balanced\", C=C, l1_ratio=l1_ratio, random_state=123\n",
    "        )\n",
    "        return meta\n",
    "\n",
    "    if meta_type == \"ridge\":\n",
    "        alpha = trial.suggest_float(\"alpha\", 1e-3, 100.0, log=True)\n",
    "        meta = RidgeClassifier(alpha=alpha, random_state=123)\n",
    "        return meta\n",
    "\n",
    "    if meta_type == \"lgbm\":\n",
    "        # 轻量的 LGBM 作为二层，防过拟合\n",
    "        params = dict(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 7, 63),\n",
    "            min_child_samples=trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "            reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 5.0)\n",
    "        )\n",
    "        meta = LGBMClassifier(objective=\"binary\", class_weight=\"balanced\",\n",
    "                              verbosity=-1, random_state=123, **params)\n",
    "        return meta\n",
    "\n",
    "def objective(trial):\n",
    "    meta = build_meta(trial)\n",
    "    # 这里使用 AUC 作为二层选择指标（也可换 Accuracy/F1）\n",
    "    # 注意：为了更稳，也可以对 Z_train 再做 5 折交叉，但这里直接 fit -> valid 使用留出的 val_mask 数据\n",
    "    meta.fit(Z_train, y_meta)\n",
    "    # 为了公平，用训练尾部10%（X_val_fit）也可以做一段独立评估；此处直接在 Z_train 上用 CV 会更严谨\n",
    "    # 我们简单返回 OOF 的 AUC 以驱动搜索\n",
    "    # （如需更严谨：在 time_series_folds 外再套一层外部折，用 Z_train/Z_valid）\n",
    "    y_meta_prob = (meta.predict_proba(Z_train)[:, 1] if hasattr(meta, \"predict_proba\")\n",
    "                   else 1/(1+np.exp(-meta.decision_function(Z_train))))\n",
    "    return safe_auc(y_meta, y_meta_prob)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=False)\n",
    "best_meta_params = study.best_params\n",
    "print(\"Best meta params:\", best_meta_params)\n",
    "\n",
    "# ========= 在“整个训练拟合段”上重训第一层，并对测试集出概率 =========\n",
    "fitted_bases = []\n",
    "test_stack = np.zeros((X_te.shape[0], M))\n",
    "for model in make_base_models():\n",
    "    if isinstance(model, LGBMClassifier):\n",
    "        model.fit(\n",
    "            X_tr_fit, y_tr_fit,\n",
    "            eval_set=[(X_val_fit, y_val_fit)],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "    else:\n",
    "        model.fit(X_tr_fit, y_tr_fit)\n",
    "    fitted_bases.append(model)\n",
    "    prob_te = (model.predict_proba(X_te)[:, 1]\n",
    "               if hasattr(model, \"predict_proba\")\n",
    "               else 1/(1+np.exp(-model.decision_function(X_te))))\n",
    "    test_stack[:, fitted_bases.index(model)] = prob_te\n",
    "\n",
    "# ========= 用最优元学习器在 Z_train 上重训，并融合测试集 =========\n",
    "best_meta = build_meta(optuna.trial.FixedTrial(best_meta_params))\n",
    "best_meta.fit(Z_train, y_meta)\n",
    "\n",
    "y_prob_stack = (best_meta.predict_proba(test_stack)[:, 1]\n",
    "                if hasattr(best_meta, \"predict_proba\")\n",
    "                else 1/(1+np.exp(-best_meta.decision_function(test_stack))))\n",
    "\n",
    "report_all(y_te, y_prob_stack, title=\"Stacking (LGBM + RF + LR) with Meta-HPO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aa3995",
   "metadata": {},
   "source": [
    "### ACC全调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e51aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 11:09:51,217] A new study created in memory with name: no-name-2de379cd-1aaf-4401-a321-a9ccdd10ecd0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 1234, Val-fit size: 138, Classes in Val: (array([0, 1]), array([99, 39]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 11:09:52,945] Trial 0 finished with value: 0.6763534428642552 and parameters: {'n_estimators': 937, 'learning_rate': 0.2536999076681772, 'num_leaves': 191, 'min_child_samples': 182, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'reg_alpha': 2.5502648504032812e-08, 'reg_lambda': 0.011567327199145964}. Best is trial 0 with value: 0.6763534428642552.\n",
      "[I 2025-09-08 11:09:53,152] Trial 1 finished with value: 0.6535705781760719 and parameters: {'n_estimators': 1322, 'learning_rate': 0.11114989443094977, 'num_leaves': 19, 'min_child_samples': 292, 'subsample': 0.9162213204002109, 'colsample_bytree': 0.6061695553391381, 'reg_alpha': 1.8740223688836284e-07, 'reg_lambda': 1.9223460470643606e-07}. Best is trial 0 with value: 0.6763534428642552.\n",
      "[I 2025-09-08 11:09:53,687] Trial 2 finished with value: 0.6627216052990454 and parameters: {'n_estimators': 817, 'learning_rate': 0.05958389350068958, 'num_leaves': 119, 'min_child_samples': 91, 'subsample': 0.8059264473611898, 'colsample_bytree': 0.569746930326021, 'reg_alpha': 1.109206841853616e-06, 'reg_lambda': 3.6688748954991767e-06}. Best is trial 0 with value: 0.6763534428642552.\n",
      "[I 2025-09-08 11:09:54,006] Trial 3 finished with value: 0.6607084875641276 and parameters: {'n_estimators': 1075, 'learning_rate': 0.14447746112718687, 'num_leaves': 63, 'min_child_samples': 157, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989, 'reg_alpha': 0.00017898389848671568, 'reg_lambda': 1.5619562520792713e-07}. Best is trial 0 with value: 0.6763534428642552.\n",
      "[I 2025-09-08 11:09:54,296] Trial 4 finished with value: 0.6767106089139987 and parameters: {'n_estimators': 410, 'learning_rate': 0.2521267904777921, 'num_leaves': 247, 'min_child_samples': 244, 'subsample': 0.6523068845866853, 'colsample_bytree': 0.5488360570031919, 'reg_alpha': 0.0006160715952774535, 'reg_lambda': 1.2052231254145584e-05}. Best is trial 4 with value: 0.6767106089139987.\n",
      "[I 2025-09-08 11:09:54,551] Trial 5 finished with value: 0.6609790679048423 and parameters: {'n_estimators': 507, 'learning_rate': 0.05388108577817234, 'num_leaves': 23, 'min_child_samples': 274, 'subsample': 0.6293899908000085, 'colsample_bytree': 0.831261142176991, 'reg_alpha': 1.5204688692198897e-06, 'reg_lambda': 4.369946783595573e-05}. Best is trial 4 with value: 0.6767106089139987.\n",
      "[I 2025-09-08 11:09:54,952] Trial 6 finished with value: 0.6455018724159578 and parameters: {'n_estimators': 1229, 'learning_rate': 0.01875220945578641, 'num_leaves': 248, 'min_child_samples': 234, 'subsample': 0.9697494707820946, 'colsample_bytree': 0.9474136752138245, 'reg_alpha': 0.00015321449415450696, 'reg_lambda': 0.02838700963443623}. Best is trial 4 with value: 0.6767106089139987.\n",
      "[I 2025-09-08 11:09:55,427] Trial 7 finished with value: 0.6348680650258675 and parameters: {'n_estimators': 450, 'learning_rate': 0.01947558230629543, 'num_leaves': 25, 'min_child_samples': 101, 'subsample': 0.6943386448447411, 'colsample_bytree': 0.6356745158869479, 'reg_alpha': 0.006326486185661575, 'reg_lambda': 3.1424855318831594e-06}. Best is trial 4 with value: 0.6767106089139987.\n",
      "[I 2025-09-08 11:09:55,753] Trial 8 finished with value: 0.678620906119445 and parameters: {'n_estimators': 777, 'learning_rate': 0.06333268775321843, 'num_leaves': 48, 'min_child_samples': 242, 'subsample': 0.5372753218398854, 'colsample_bytree': 0.9934434683002586, 'reg_alpha': 0.0025451500130912884, 'reg_lambda': 2.4604229580184137e-07}. Best is trial 8 with value: 0.678620906119445.\n",
      "[I 2025-09-08 11:09:56,045] Trial 9 finished with value: 0.6777279909950863 and parameters: {'n_estimators': 309, 'learning_rate': 0.1601531217136121, 'num_leaves': 185, 'min_child_samples': 220, 'subsample': 0.8856351733429728, 'colsample_bytree': 0.5370223258670452, 'reg_alpha': 3.230428252240957e-06, 'reg_lambda': 6.472669269538615e-08}. Best is trial 8 with value: 0.678620906119445.\n",
      "[I 2025-09-08 11:10:01,849] Trial 10 finished with value: 0.6338073900902655 and parameters: {'n_estimators': 1907, 'learning_rate': 0.010206070557576998, 'num_leaves': 89, 'min_child_samples': 10, 'subsample': 0.5072835039169765, 'colsample_bytree': 0.953832397641259, 'reg_alpha': 0.057623469909364546, 'reg_lambda': 0.0005431564397661279}. Best is trial 8 with value: 0.678620906119445.\n",
      "[I 2025-09-08 11:10:02,689] Trial 11 finished with value: 0.67908089269866 and parameters: {'n_estimators': 717, 'learning_rate': 0.06530555158582786, 'num_leaves': 172, 'min_child_samples': 205, 'subsample': 0.8526967094075362, 'colsample_bytree': 0.7323077372482276, 'reg_alpha': 9.955002727013983e-06, 'reg_lambda': 1.2869220555985807e-08}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:03,639] Trial 12 finished with value: 0.6427744225815529 and parameters: {'n_estimators': 800, 'learning_rate': 0.05649425844189552, 'num_leaves': 159, 'min_child_samples': 196, 'subsample': 0.7439866799772858, 'colsample_bytree': 0.7236765827049596, 'reg_alpha': 1.9095741730503975e-05, 'reg_lambda': 2.251451794254805e-08}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:05,161] Trial 13 finished with value: 0.6409669459055782 and parameters: {'n_estimators': 1492, 'learning_rate': 0.03504616309522971, 'num_leaves': 130, 'min_child_samples': 106, 'subsample': 0.8255079015857973, 'colsample_bytree': 0.8304278626461434, 'reg_alpha': 0.003976105068607485, 'reg_lambda': 1.0409821346390513e-08}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:06,222] Trial 14 finished with value: 0.641329523562136 and parameters: {'n_estimators': 682, 'learning_rate': 0.08696867180427822, 'num_leaves': 78, 'min_child_samples': 145, 'subsample': 0.5065701578589041, 'colsample_bytree': 0.742224968756131, 'reg_alpha': 1.71713052568882e-05, 'reg_lambda': 7.185140372085483e-07}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:07,060] Trial 15 finished with value: 0.6621479749767301 and parameters: {'n_estimators': 627, 'learning_rate': 0.036630772377260444, 'num_leaves': 198, 'min_child_samples': 260, 'subsample': 0.870576595589974, 'colsample_bytree': 0.857920454682335, 'reg_alpha': 0.09451590938257542, 'reg_lambda': 3.592343871795658e-07}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:07,992] Trial 16 finished with value: 0.6681494469337835 and parameters: {'n_estimators': 986, 'learning_rate': 0.0822802521445571, 'num_leaves': 150, 'min_child_samples': 202, 'subsample': 0.9933626639641464, 'colsample_bytree': 0.6799719383155746, 'reg_alpha': 0.002722158277568168, 'reg_lambda': 0.000190959375836457}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:09,135] Trial 17 finished with value: 0.6381691451825876 and parameters: {'n_estimators': 1528, 'learning_rate': 0.03227788575316564, 'num_leaves': 110, 'min_child_samples': 157, 'subsample': 0.7367235921590076, 'colsample_bytree': 0.9935858816547274, 'reg_alpha': 9.922545735802415e-05, 'reg_lambda': 1.1824609934085942e-08}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:11,786] Trial 18 finished with value: 0.6603404983007555 and parameters: {'n_estimators': 678, 'learning_rate': 0.023406371316673943, 'num_leaves': 220, 'min_child_samples': 52, 'subsample': 0.5604229473961589, 'colsample_bytree': 0.7819963464031929, 'reg_alpha': 0.015469686171653745, 'reg_lambda': 7.875106745829918e-07}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:12,622] Trial 19 finished with value: 0.6689287183150421 and parameters: {'n_estimators': 1861, 'learning_rate': 0.07062127670987565, 'num_leaves': 59, 'min_child_samples': 220, 'subsample': 0.7010970697731507, 'colsample_bytree': 0.8875046351815019, 'reg_alpha': 0.0006055220553617188, 'reg_lambda': 5.904272560516493e-08}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:13,244] Trial 20 finished with value: 0.6636036972097756 and parameters: {'n_estimators': 857, 'learning_rate': 0.11831340211584271, 'num_leaves': 172, 'min_child_samples': 282, 'subsample': 0.9355223008096394, 'colsample_bytree': 0.6862477794900962, 'reg_alpha': 1.3715108911540248e-07, 'reg_lambda': 0.0021254773911462497}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:14,036] Trial 21 finished with value: 0.6681873281814836 and parameters: {'n_estimators': 332, 'learning_rate': 0.19163576375076843, 'num_leaves': 185, 'min_child_samples': 218, 'subsample': 0.8804393966088637, 'colsample_bytree': 0.5050437638326076, 'reg_alpha': 2.704010380261277e-06, 'reg_lambda': 6.716865434753737e-08}. Best is trial 11 with value: 0.67908089269866.\n",
      "[I 2025-09-08 11:10:14,968] Trial 22 finished with value: 0.6830097192458385 and parameters: {'n_estimators': 578, 'learning_rate': 0.17441127013266855, 'num_leaves': 209, 'min_child_samples': 177, 'subsample': 0.8451198430869662, 'colsample_bytree': 0.7835722003632151, 'reg_alpha': 6.795255881627672e-06, 'reg_lambda': 4.804105928305253e-08}. Best is trial 22 with value: 0.6830097192458385.\n",
      "[I 2025-09-08 11:10:15,877] Trial 23 finished with value: 0.6615689330476004 and parameters: {'n_estimators': 585, 'learning_rate': 0.10583347987224367, 'num_leaves': 210, 'min_child_samples': 181, 'subsample': 0.8293948872008856, 'colsample_bytree': 0.7987241516059856, 'reg_alpha': 1.117999467733262e-05, 'reg_lambda': 1.3593545135189656e-06}. Best is trial 22 with value: 0.6830097192458385.\n",
      "[I 2025-09-08 11:10:17,088] Trial 24 finished with value: 0.6420492672684374 and parameters: {'n_estimators': 776, 'learning_rate': 0.04693438086827189, 'num_leaves': 231, 'min_child_samples': 138, 'subsample': 0.7783199745535451, 'colsample_bytree': 0.8984923066479448, 'reg_alpha': 3.841490182207448e-07, 'reg_lambda': 3.0698349991669875e-08}. Best is trial 22 with value: 0.6830097192458385.\n",
      "[I 2025-09-08 11:10:17,829] Trial 25 finished with value: 0.69113795268091 and parameters: {'n_estimators': 1139, 'learning_rate': 0.1928959882718918, 'num_leaves': 155, 'min_child_samples': 252, 'subsample': 0.8554030242849373, 'colsample_bytree': 0.6618550671918412, 'reg_alpha': 7.04037506890455e-05, 'reg_lambda': 1.6218294579357882e-07}. Best is trial 25 with value: 0.69113795268091.\n",
      "[I 2025-09-08 11:10:18,521] Trial 26 finished with value: 0.6459402125679157 and parameters: {'n_estimators': 1153, 'learning_rate': 0.2935470722892419, 'num_leaves': 151, 'min_child_samples': 259, 'subsample': 0.8446188919790145, 'colsample_bytree': 0.6949628191602379, 'reg_alpha': 4.909142723585243e-05, 'reg_lambda': 2.776144007239632e-05}. Best is trial 25 with value: 0.69113795268091.\n",
      "[I 2025-09-08 11:10:19,412] Trial 27 finished with value: 0.6529969478537568 and parameters: {'n_estimators': 1425, 'learning_rate': 0.18205095476482674, 'num_leaves': 168, 'min_child_samples': 180, 'subsample': 0.9161368560288888, 'colsample_bytree': 0.6463567920534524, 'reg_alpha': 8.648000287934201e-06, 'reg_lambda': 1.1134507705339318e-07}. Best is trial 25 with value: 0.69113795268091.\n",
      "[I 2025-09-08 11:10:20,592] Trial 28 finished with value: 0.6428772431110246 and parameters: {'n_estimators': 1762, 'learning_rate': 0.20169714987155182, 'num_leaves': 141, 'min_child_samples': 124, 'subsample': 0.8654139601631083, 'colsample_bytree': 0.7700472005795818, 'reg_alpha': 0.00039377522144351903, 'reg_lambda': 2.5804324276977886e-08}. Best is trial 25 with value: 0.69113795268091.\n",
      "[I 2025-09-08 11:10:21,590] Trial 29 finished with value: 0.66053531614607 and parameters: {'n_estimators': 996, 'learning_rate': 0.2476593728900112, 'num_leaves': 195, 'min_child_samples': 175, 'subsample': 0.7740962196811112, 'colsample_bytree': 0.7323028180238029, 'reg_alpha': 3.596523363898468e-05, 'reg_lambda': 4.167364935249126e-06}. Best is trial 25 with value: 0.69113795268091.\n",
      "[I 2025-09-08 11:10:21,592] A new study created in memory with name: no-name-06ebe6fd-d12e-4980-b03d-350d381e0206\n",
      "[I 2025-09-08 11:10:23,016] Trial 0 finished with value: 0.6528887157174709 and parameters: {'C': 0.0745934328572655, 'l1_ratio': 0.9507143064099162}. Best is trial 0 with value: 0.6528887157174709.\n",
      "[I 2025-09-08 11:10:43,597] Trial 1 finished with value: 0.5655020888802302 and parameters: {'C': 4.5705630998014515, 'l1_ratio': 0.5986584841970366}. Best is trial 0 with value: 0.6528887157174709.\n",
      "[I 2025-09-08 11:10:43,998] Trial 2 finished with value: 0.6596856938762258 and parameters: {'C': 0.006026889128682512, 'l1_ratio': 0.15599452033620265}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:10:44,069] Trial 3 finished with value: 0.45606857588155075 and parameters: {'C': 0.0019517224641449498, 'l1_ratio': 0.8661761457749352}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:10:55,672] Trial 4 finished with value: 0.5882524839275278 and parameters: {'C': 1.0129197956845732, 'l1_ratio': 0.7080725777960455}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:10:55,711] Trial 5 finished with value: 0.44408727839470086 and parameters: {'C': 0.001267425589893723, 'l1_ratio': 0.9699098521619943}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:25,047] Trial 6 finished with value: 0.5629261640366258 and parameters: {'C': 14.528246637516036, 'l1_ratio': 0.21233911067827616}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:25,529] Trial 7 finished with value: 0.6587224278632811 and parameters: {'C': 0.008111941985431923, 'l1_ratio': 0.18340450985343382}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:26,488] Trial 8 finished with value: 0.6554429941338181 and parameters: {'C': 0.033205591037519584, 'l1_ratio': 0.5247564316322378}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:28,959] Trial 9 finished with value: 0.6293265796480292 and parameters: {'C': 0.14445251022763064, 'l1_ratio': 0.2912291401980419}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:53,497] Trial 10 finished with value: 0.5643872978764854 and parameters: {'C': 53.17196633982125, 'l1_ratio': 0.005997182955817193}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:53,843] Trial 11 finished with value: 0.6576184600731649 and parameters: {'C': 0.011983829487007384, 'l1_ratio': 0.2555181508867127}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:54,063] Trial 12 finished with value: 0.6591120635539104 and parameters: {'C': 0.006971123012897827, 'l1_ratio': 0.038725199961182954}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:57,704] Trial 13 finished with value: 0.5823646557135745 and parameters: {'C': 0.544928039897282, 'l1_ratio': 0.01154333660382137}. Best is trial 2 with value: 0.6596856938762258.\n",
      "[I 2025-09-08 11:11:57,970] Trial 14 finished with value: 0.664144857891205 and parameters: {'C': 0.007147877527105639, 'l1_ratio': 0.37960424342022364}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:11:58,534] Trial 15 finished with value: 0.6559300387471049 and parameters: {'C': 0.03121281638549021, 'l1_ratio': 0.407225069980497}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:11:58,664] Trial 16 finished with value: 0.5225447539883542 and parameters: {'C': 0.00336613848725774, 'l1_ratio': 0.39685733846266286}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:00,266] Trial 17 finished with value: 0.627876269021798 and parameters: {'C': 0.19311688013803371, 'l1_ratio': 0.41737371119659306}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:00,741] Trial 18 finished with value: 0.6491438838019784 and parameters: {'C': 0.03144673430893573, 'l1_ratio': 0.1136931919324144}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:07,446] Trial 19 finished with value: 0.5783600666709958 and parameters: {'C': 1.5597325910443616, 'l1_ratio': 0.6687800666754178}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:07,625] Trial 20 finished with value: 0.6336558650994654 and parameters: {'C': 0.004106717275733855, 'l1_ratio': 0.32514253393237064}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:07,886] Trial 21 finished with value: 0.6577375154230795 and parameters: {'C': 0.008473988695690188, 'l1_ratio': 0.11906842164463904}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:08,284] Trial 22 finished with value: 0.6535814013897007 and parameters: {'C': 0.02279235845895401, 'l1_ratio': 0.10816943343173317}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:08,438] Trial 23 finished with value: 0.6345866614715241 and parameters: {'C': 0.0010758918662410913, 'l1_ratio': 0.07793810656013882}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:08,672] Trial 24 finished with value: 0.6591661796220534 and parameters: {'C': 0.005128936898979921, 'l1_ratio': 0.1800460155151472}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:09,470] Trial 25 finished with value: 0.6493603480745503 and parameters: {'C': 0.06257039211104597, 'l1_ratio': 0.32673984623023333}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:09,622] Trial 26 finished with value: 0.6567093101283634 and parameters: {'C': 0.003135630377938168, 'l1_ratio': 0.20593276284017914}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:09,994] Trial 27 finished with value: 0.6585709028724809 and parameters: {'C': 0.01548771274188638, 'l1_ratio': 0.46140483948688776}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:10,918] Trial 28 finished with value: 0.6332337597679504 and parameters: {'C': 0.08835962045044334, 'l1_ratio': 0.16426317342189062}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:12,524] Trial 29 finished with value: 0.6508647747689245 and parameters: {'C': 0.07062704603881315, 'l1_ratio': 0.5255054702220849}. Best is trial 14 with value: 0.664144857891205.\n",
      "[I 2025-09-08 11:12:12,530] A new study created in memory with name: no-name-972928c3-a96f-4d6a-af15-fc6be2fb6ed4\n",
      "[I 2025-09-08 11:12:15,006] Trial 0 finished with value: 0.42678095980258457 and parameters: {'C': 0.7459343285726545, 'gamma': 5.669849511478847}. Best is trial 0 with value: 0.42678095980258457.\n",
      "[I 2025-09-08 11:12:17,197] Trial 1 finished with value: 0.49440439855401863 and parameters: {'C': 45.70563099801453, 'gamma': 0.09846738873614563}. Best is trial 1 with value: 0.49440439855401863.\n",
      "[I 2025-09-08 11:12:19,036] Trial 2 finished with value: 0.6552481762885036 and parameters: {'C': 0.06026889128682508, 'gamma': 0.000602521573620386}. Best is trial 2 with value: 0.6552481762885036.\n",
      "[I 2025-09-08 11:12:21,310] Trial 3 finished with value: 0.42678095980258457 and parameters: {'C': 0.0195172246414495, 'gamma': 2.1423021757741068}. Best is trial 2 with value: 0.6552481762885036.\n",
      "[I 2025-09-08 11:12:23,527] Trial 4 finished with value: 0.42353940732082174 and parameters: {'C': 10.129197956845726, 'gamma': 0.3470266988650412}. Best is trial 2 with value: 0.6552481762885036.\n",
      "[I 2025-09-08 11:12:26,070] Trial 5 finished with value: 0.42678095980258457 and parameters: {'C': 0.012674255898937233, 'gamma': 7.072114131472227}. Best is trial 2 with value: 0.6552481762885036.\n",
      "[I 2025-09-08 11:12:29,144] Trial 6 finished with value: 0.5393315583262982 and parameters: {'C': 145.28246637516014, 'gamma': 0.0011526449540315614}. Best is trial 2 with value: 0.6552481762885036.\n",
      "[I 2025-09-08 11:12:30,934] Trial 7 finished with value: 0.6560923869515337 and parameters: {'C': 0.08111941985431921, 'gamma': 0.0008260808399079611}. Best is trial 7 with value: 0.6560923869515337.\n",
      "[I 2025-09-08 11:12:33,030] Trial 8 finished with value: 0.6053098686061865 and parameters: {'C': 0.3320559103751956, 'gamma': 0.042051564509138675}. Best is trial 7 with value: 0.6560923869515337.\n",
      "[I 2025-09-08 11:12:34,716] Trial 9 finished with value: 0.6534677576466004 and parameters: {'C': 1.4445251022763053, 'gamma': 0.0028585493941961923}. Best is trial 7 with value: 0.6560923869515337.\n",
      "[I 2025-09-08 11:12:36,426] Trial 10 finished with value: 0.6542091477801588 and parameters: {'C': 0.10916771197512803, 'gamma': 0.00010714845538373133}. Best is trial 7 with value: 0.6560923869515337.\n",
      "[I 2025-09-08 11:12:37,718] Trial 11 finished with value: 0.651135355109639 and parameters: {'C': 0.07949410119949515, 'gamma': 0.0018949194539358261}. Best is trial 7 with value: 0.6560923869515337.\n",
      "[I 2025-09-08 11:12:38,461] Trial 12 finished with value: 0.6716182869017469 and parameters: {'C': 6.7307808961199465, 'gamma': 0.0001561802090506201}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:39,174] Trial 13 finished with value: 0.6710013637249171 and parameters: {'C': 8.782021072685929, 'gamma': 0.00011491755902087326}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:39,882] Trial 14 finished with value: 0.668852955819642 and parameters: {'C': 7.124252843547855, 'gamma': 0.00010434861713341417}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:40,903] Trial 15 finished with value: 0.6058943221421303 and parameters: {'C': 736.0954243651777, 'gamma': 0.007784756871599145}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:41,627] Trial 16 finished with value: 0.6348518302054247 and parameters: {'C': 23.066935546620265, 'gamma': 0.0002856198610465206}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:42,556] Trial 17 finished with value: 0.6183626642422667 and parameters: {'C': 3.29142519803653, 'gamma': 0.009176543313446736}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:43,529] Trial 18 finished with value: 0.5933610407602226 and parameters: {'C': 111.93211657038978, 'gamma': 0.00033991402116583343}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:44,456] Trial 19 finished with value: 0.6243046085243631 and parameters: {'C': 2.6176846884550504, 'gamma': 0.008497095892748312}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:45,413] Trial 20 finished with value: 0.425487585773968 and parameters: {'C': 362.73011709856513, 'gamma': 0.28033866806350255}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:46,149] Trial 21 finished with value: 0.6703465593003874 and parameters: {'C': 8.95042895379937, 'gamma': 0.00012681676722496268}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:46,887] Trial 22 finished with value: 0.6475420481849471 and parameters: {'C': 16.62675994417296, 'gamma': 0.000231688597472105}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:47,613] Trial 23 finished with value: 0.6667316059484383 and parameters: {'C': 4.6164901059273555, 'gamma': 0.00011008250369731086}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:48,806] Trial 24 finished with value: 0.5721367188345563 and parameters: {'C': 44.896283300733224, 'gamma': 0.0034833954248692637}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:49,729] Trial 25 finished with value: 0.662456436565145 and parameters: {'C': 0.5924558401894926, 'gamma': 0.0004913670480078576}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:50,642] Trial 26 finished with value: 0.662239972292573 and parameters: {'C': 1.6140216871426871, 'gamma': 0.0001940970427886736}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:51,691] Trial 27 finished with value: 0.5876517955711409 and parameters: {'C': 27.615159740375017, 'gamma': 0.0013178580371381577}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:52,495] Trial 28 finished with value: 0.6399333290040479 and parameters: {'C': 7.795740219769933, 'gamma': 0.0006250810569128534}. Best is trial 12 with value: 0.6716182869017469.\n",
      "[I 2025-09-08 11:12:53,793] Trial 29 finished with value: 0.42678095980258457 and parameters: {'C': 109.73121102794317, 'gamma': 2.500746292622837}. Best is trial 12 with value: 0.6716182869017469.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HPO] BEST_LGBM: {'n_estimators': 1139, 'learning_rate': 0.1928959882718918, 'num_leaves': 155, 'min_child_samples': 252, 'subsample': 0.8554030242849373, 'colsample_bytree': 0.6618550671918412, 'reg_alpha': 7.04037506890455e-05, 'reg_lambda': 1.6218294579357882e-07}\n",
      "[HPO] BEST_LR: {'C': 0.007147877527105639, 'l1_ratio': 0.37960424342022364}\n",
      "[HPO] BEST_SVM: {'C': 6.7307808961199465, 'gamma': 0.0001561802090506201}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 11:12:55,696] A new study created in memory with name: no-name-3be53b6a-e934-47b2-9de8-e44f2f7e02fc\n",
      "[I 2025-09-08 11:12:55,703] Trial 0 finished with value: 0.6955862934822608 and parameters: {'meta_type': 'ridge', 'alpha': 0.9846738873614566}. Best is trial 0 with value: 0.6955862934822608.\n",
      "[I 2025-09-08 11:12:55,709] Trial 1 finished with value: 0.6958027577548326 and parameters: {'meta_type': 'logreg', 'C': 21.42302175774105, 'l1_ratio': 0.6011150117432088}. Best is trial 1 with value: 0.6958027577548326.\n",
      "[I 2025-09-08 11:12:55,893] Trial 2 finished with value: 0.8129153408229972 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1283, 'learning_rate': 0.010943342660062645, 'num_leaves': 17, 'min_child_samples': 45, 'subsample': 0.6521211214797689, 'colsample_bytree': 0.762378215816119, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097}. Best is trial 2 with value: 0.8129153408229972.\n",
      "[I 2025-09-08 11:12:55,899] Trial 3 finished with value: 0.6958676970366041 and parameters: {'meta_type': 'logreg', 'C': 0.06789053271698488, 'l1_ratio': 0.45606998421703593}. Best is trial 2 with value: 0.8129153408229972.\n",
      "[I 2025-09-08 11:12:55,908] Trial 4 finished with value: 0.6948611381691452 and parameters: {'meta_type': 'logreg', 'C': 0.9163741808778786, 'l1_ratio': 0.046450412719997725}. Best is trial 2 with value: 0.8129153408229972.\n",
      "[I 2025-09-08 11:12:55,922] Trial 5 finished with value: 0.6955321774141179 and parameters: {'meta_type': 'logreg', 'C': 55.51721685244721, 'l1_ratio': 0.9656320330745594}. Best is trial 2 with value: 0.8129153408229972.\n",
      "[I 2025-09-08 11:12:55,928] Trial 6 finished with value: 0.6957161720458038 and parameters: {'meta_type': 'logreg', 'C': 2.6373339933815254, 'l1_ratio': 0.4401524937396013}. Best is trial 2 with value: 0.8129153408229972.\n",
      "[I 2025-09-08 11:12:55,934] Trial 7 finished with value: 0.6943849167694872 and parameters: {'meta_type': 'ridge', 'alpha': 35.20481045526041}. Best is trial 2 with value: 0.8129153408229972.\n",
      "[I 2025-09-08 11:12:55,938] Trial 8 finished with value: 0.6953590059960605 and parameters: {'meta_type': 'ridge', 'alpha': 0.39841905944346884}. Best is trial 2 with value: 0.8129153408229972.\n",
      "[I 2025-09-08 11:12:56,041] Trial 9 finished with value: 0.8154371495984587 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1208, 'learning_rate': 0.15999399049657148, 'num_leaves': 58, 'min_child_samples': 124, 'subsample': 0.9609371175115584, 'colsample_bytree': 0.5442462510259598, 'reg_alpha': 0.979914312095726, 'reg_lambda': 0.22613644455269033}. Best is trial 9 with value: 0.8154371495984587.\n",
      "[I 2025-09-08 11:12:56,127] Trial 10 finished with value: 0.7550977336190662 and parameters: {'meta_type': 'lgbm', 'n_estimators': 649, 'learning_rate': 0.17874200269768703, 'num_leaves': 61, 'min_child_samples': 179, 'subsample': 0.953832397641259, 'colsample_bytree': 0.5076216495032854, 'reg_alpha': 0.06388024684726523, 'reg_lambda': 0.1715276786944573}. Best is trial 9 with value: 0.8154371495984587.\n",
      "[I 2025-09-08 11:12:56,396] Trial 11 finished with value: 0.8292367469749119 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1419, 'learning_rate': 0.00790174294697231, 'num_leaves': 10, 'min_child_samples': 28, 'subsample': 0.6097744281695808, 'colsample_bytree': 0.7816497135092688, 'reg_alpha': 2.001165704593281, 'reg_lambda': 0.8366509097759041}. Best is trial 11 with value: 0.8292367469749119.\n",
      "[I 2025-09-08 11:12:56,523] Trial 12 finished with value: 0.777231205489534 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1458, 'learning_rate': 0.09267260175915543, 'num_leaves': 52, 'min_child_samples': 123, 'subsample': 0.5431844609096352, 'colsample_bytree': 0.9182905513198524, 'reg_alpha': 1.6950828611619113, 'reg_lambda': 0.03158239456382239}. Best is trial 11 with value: 0.8292367469749119.\n",
      "[I 2025-09-08 11:12:56,685] Trial 13 finished with value: 0.7477054787107387 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1110, 'learning_rate': 0.0054902966977251125, 'num_leaves': 7, 'min_child_samples': 10, 'subsample': 0.9348397262642657, 'colsample_bytree': 0.518002562161634, 'reg_alpha': 4.695358726047479, 'reg_lambda': 4.7263735311741115}. Best is trial 11 with value: 0.8292367469749119.\n",
      "[I 2025-09-08 11:12:56,817] Trial 14 finished with value: 0.7714516094118666 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1001, 'learning_rate': 0.03109151073555972, 'num_leaves': 34, 'min_child_samples': 108, 'subsample': 0.7655620151757302, 'colsample_bytree': 0.7299820798583574, 'reg_alpha': 0.827781406926889, 'reg_lambda': 1.6083834964843606}. Best is trial 11 with value: 0.8292367469749119.\n",
      "[I 2025-09-08 11:12:56,874] Trial 15 finished with value: 0.7388087971080373 and parameters: {'meta_type': 'lgbm', 'n_estimators': 309, 'learning_rate': 0.03500767980165239, 'num_leaves': 35, 'min_child_samples': 77, 'subsample': 0.7706081972231539, 'colsample_bytree': 0.7098742323846644, 'reg_alpha': 3.3527257130244337, 'reg_lambda': 1.2533146970041877}. Best is trial 11 with value: 0.8292367469749119.\n",
      "[I 2025-09-08 11:12:57,008] Trial 16 finished with value: 0.7407569755611836 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1402, 'learning_rate': 0.02725153525902101, 'num_leaves': 47, 'min_child_samples': 155, 'subsample': 0.5129624371958834, 'colsample_bytree': 0.8609727402803516, 'reg_alpha': 1.3128561392670357, 'reg_lambda': 3.3326781965385948}. Best is trial 11 with value: 0.8292367469749119.\n",
      "[I 2025-09-08 11:12:57,108] Trial 17 finished with value: 0.7597571270861745 and parameters: {'meta_type': 'lgbm', 'n_estimators': 768, 'learning_rate': 0.07244434981830482, 'num_leaves': 22, 'min_child_samples': 67, 'subsample': 0.6637452938214106, 'colsample_bytree': 0.6246385122073204, 'reg_alpha': 3.1013494382737674, 'reg_lambda': 0.7103116079746173}. Best is trial 11 with value: 0.8292367469749119.\n",
      "[I 2025-09-08 11:12:57,234] Trial 18 finished with value: 0.7374667186180921 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1161, 'learning_rate': 0.012016412774715102, 'num_leaves': 46, 'min_child_samples': 125, 'subsample': 0.8724869134221366, 'colsample_bytree': 0.8264423346529436, 'reg_alpha': 0.5986999811870246, 'reg_lambda': 2.2941194498396102}. Best is trial 11 with value: 0.8292367469749119.\n",
      "[I 2025-09-08 11:12:57,357] Trial 19 finished with value: 0.8458828495356839 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1487, 'learning_rate': 0.15907140458229754, 'num_leaves': 63, 'min_child_samples': 20, 'subsample': 0.6364495391131737, 'colsample_bytree': 0.6312823461207375, 'reg_alpha': 2.555873013728487, 'reg_lambda': 2.760115239362956}. Best is trial 19 with value: 0.8458828495356839.\n",
      "[I 2025-09-08 11:12:57,368] Trial 20 finished with value: 0.6954131220642032 and parameters: {'meta_type': 'ridge', 'alpha': 0.001053771909775942}. Best is trial 19 with value: 0.8458828495356839.\n",
      "[I 2025-09-08 11:12:57,491] Trial 21 finished with value: 0.8380847241162847 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1481, 'learning_rate': 0.19865671727946949, 'num_leaves': 59, 'min_child_samples': 16, 'subsample': 0.6257574929274351, 'colsample_bytree': 0.6189079742827357, 'reg_alpha': 2.782469597055713, 'reg_lambda': 3.4230574562185105}. Best is trial 19 with value: 0.8458828495356839.\n",
      "[I 2025-09-08 11:12:57,715] Trial 22 finished with value: 0.8470896378552719 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1487, 'learning_rate': 0.08412083177971465, 'num_leaves': 62, 'min_child_samples': 10, 'subsample': 0.6229779792669783, 'colsample_bytree': 0.6372015585958924, 'reg_alpha': 2.797841934803852, 'reg_lambda': 3.5019113369928068}. Best is trial 22 with value: 0.8470896378552719.\n",
      "[I 2025-09-08 11:12:57,894] Trial 23 finished with value: 0.8311416325735438 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1487, 'learning_rate': 0.10251458161833636, 'num_leaves': 63, 'min_child_samples': 12, 'subsample': 0.595166441517231, 'colsample_bytree': 0.6338927842134872, 'reg_alpha': 3.0040890499038166, 'reg_lambda': 3.569229342321586}. Best is trial 22 with value: 0.8470896378552719.\n",
      "[I 2025-09-08 11:12:58,041] Trial 24 finished with value: 0.837944022339113 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1321, 'learning_rate': 0.19060374938118232, 'num_leaves': 53, 'min_child_samples': 48, 'subsample': 0.7026914464247841, 'colsample_bytree': 0.6347522238993721, 'reg_alpha': 2.6647424940603677, 'reg_lambda': 3.374453254507218}. Best is trial 22 with value: 0.8470896378552719.\n",
      "[I 2025-09-08 11:12:58,185] Trial 25 finished with value: 0.7808948633028119 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1496, 'learning_rate': 0.06906028907101988, 'num_leaves': 56, 'min_child_samples': 36, 'subsample': 0.582244022376492, 'colsample_bytree': 0.5929137722621969, 'reg_alpha': 3.8901545748039656, 'reg_lambda': 4.055389087785159}. Best is trial 22 with value: 0.8470896378552719.\n",
      "[I 2025-09-08 11:12:58,296] Trial 26 finished with value: 0.7440309976838324 and parameters: {'meta_type': 'lgbm', 'n_estimators': 940, 'learning_rate': 0.11487581247259356, 'num_leaves': 45, 'min_child_samples': 71, 'subsample': 0.7097796925289315, 'colsample_bytree': 0.6940042236718942, 'reg_alpha': 3.9270503366014364, 'reg_lambda': 2.661064039453537}. Best is trial 22 with value: 0.8470896378552719.\n",
      "[I 2025-09-08 11:12:58,507] Trial 27 finished with value: 0.8585676559083922 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1230, 'learning_rate': 0.05709455694083056, 'num_leaves': 63, 'min_child_samples': 10, 'subsample': 0.6469232056515036, 'colsample_bytree': 0.5815117791172896, 'reg_alpha': 2.5412642004920594, 'reg_lambda': 2.647533863357127}. Best is trial 27 with value: 0.8585676559083922.\n",
      "[I 2025-09-08 11:12:58,519] Trial 28 finished with value: 0.6954022988505747 and parameters: {'meta_type': 'ridge', 'alpha': 0.0013243382829818354}. Best is trial 27 with value: 0.8585676559083922.\n",
      "[I 2025-09-08 11:12:58,740] Trial 29 finished with value: 0.8486644154382319 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1300, 'learning_rate': 0.05044566638391624, 'num_leaves': 63, 'min_child_samples': 51, 'subsample': 0.8115012530534492, 'colsample_bytree': 0.5699969836566909, 'reg_alpha': 2.289859781759325, 'reg_lambda': 2.423511937120685}. Best is trial 27 with value: 0.8585676559083922.\n",
      "[I 2025-09-08 11:12:58,752] Trial 30 finished with value: 0.6942766846332014 and parameters: {'meta_type': 'ridge', 'alpha': 77.69338963145745}. Best is trial 27 with value: 0.8585676559083922.\n",
      "[I 2025-09-08 11:12:59,000] Trial 31 finished with value: 0.8588165898218499 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1306, 'learning_rate': 0.046337843889066574, 'num_leaves': 63, 'min_child_samples': 33, 'subsample': 0.8215437059964691, 'colsample_bytree': 0.5694782715987885, 'reg_alpha': 2.374527438518248, 'reg_lambda': 2.5665955993878384}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:12:59,176] Trial 32 finished with value: 0.8407688810961751 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1292, 'learning_rate': 0.04577120641850901, 'num_leaves': 52, 'min_child_samples': 54, 'subsample': 0.843854444903669, 'colsample_bytree': 0.5668075400664719, 'reg_alpha': 2.136546986704838, 'reg_lambda': 2.417902398612948}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:12:59,308] Trial 33 finished with value: 0.7908197502002293 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1067, 'learning_rate': 0.05323894996856077, 'num_leaves': 63, 'min_child_samples': 33, 'subsample': 0.8159987120601947, 'colsample_bytree': 0.5633258118509316, 'reg_alpha': 3.6372855268879767, 'reg_lambda': 2.0139487438593084}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:12:59,476] Trial 34 finished with value: 0.7705641058943222 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1247, 'learning_rate': 0.01946356296253087, 'num_leaves': 56, 'min_child_samples': 86, 'subsample': 0.8164914318514691, 'colsample_bytree': 0.6736211469812313, 'reg_alpha': 1.799813097714251, 'reg_lambda': 2.895008244952447}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:12:59,489] Trial 35 finished with value: 0.6945797346148018 and parameters: {'meta_type': 'logreg', 'C': 0.0010648608905881706, 'l1_ratio': 0.0033924013751416293}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:12:59,731] Trial 36 finished with value: 0.8550501114791004 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1321, 'learning_rate': 0.05142114840575806, 'num_leaves': 41, 'min_child_samples': 34, 'subsample': 0.7320327149142131, 'colsample_bytree': 0.5793447750394871, 'reg_alpha': 2.381039285694052, 'reg_lambda': 4.066336759542518}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:12:59,745] Trial 37 finished with value: 0.5 and parameters: {'meta_type': 'logreg', 'C': 0.019827657528919174, 'l1_ratio': 0.7883503771791243}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:12:59,906] Trial 38 finished with value: 0.8204212394744247 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1338, 'learning_rate': 0.05118366202882755, 'num_leaves': 24, 'min_child_samples': 58, 'subsample': 0.7194156935345906, 'colsample_bytree': 0.5734791641476764, 'reg_alpha': 2.2774263618035553, 'reg_lambda': 4.506539107488299}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:12:59,917] Trial 39 finished with value: 0.5 and parameters: {'meta_type': 'logreg', 'C': 0.0010311926441527633, 'l1_ratio': 0.27511356709854934}. Best is trial 31 with value: 0.8588165898218499.\n",
      "[I 2025-09-08 11:13:00,196] Trial 40 finished with value: 0.9290051302032598 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1180, 'learning_rate': 0.04292699127846905, 'num_leaves': 41, 'min_child_samples': 35, 'subsample': 0.8956595987896905, 'colsample_bytree': 0.5338792699604912, 'reg_alpha': 1.3741724563666255, 'reg_lambda': 2.0760007091910264}. Best is trial 40 with value: 0.9290051302032598.\n",
      "[I 2025-09-08 11:13:00,446] Trial 41 finished with value: 0.9200218628915299 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1158, 'learning_rate': 0.04236376214243282, 'num_leaves': 36, 'min_child_samples': 35, 'subsample': 0.8754845713086687, 'colsample_bytree': 0.53833971032823, 'reg_alpha': 1.5237907624240883, 'reg_lambda': 1.9616820390686374}. Best is trial 40 with value: 0.9290051302032598.\n",
      "[I 2025-09-08 11:13:00,689] Trial 42 finished with value: 0.9173918219797822 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1151, 'learning_rate': 0.04072387576315533, 'num_leaves': 38, 'min_child_samples': 33, 'subsample': 0.8846972830291553, 'colsample_bytree': 0.5273551292578483, 'reg_alpha': 1.5989469202403837, 'reg_lambda': 1.8346331125725879}. Best is trial 40 with value: 0.9290051302032598.\n",
      "[I 2025-09-08 11:13:01,026] Trial 43 finished with value: 0.9229116609303635 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1136, 'learning_rate': 0.02250083674857258, 'num_leaves': 37, 'min_child_samples': 27, 'subsample': 0.8975089061404261, 'colsample_bytree': 0.5233000565258911, 'reg_alpha': 1.3123789756947037, 'reg_lambda': 1.9309989396850955}. Best is trial 40 with value: 0.9290051302032598.\n",
      "[I 2025-09-08 11:13:01,250] Trial 44 finished with value: 0.8646881832153602 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1033, 'learning_rate': 0.020573925147785208, 'num_leaves': 34, 'min_child_samples': 39, 'subsample': 0.9062609865913939, 'colsample_bytree': 0.5006221313389819, 'reg_alpha': 1.395542339426404, 'reg_lambda': 1.6810279732571827}. Best is trial 40 with value: 0.9290051302032598.\n",
      "[I 2025-09-08 11:13:01,262] Trial 45 finished with value: 0.6952832435006603 and parameters: {'meta_type': 'ridge', 'alpha': 0.032702033398672656}. Best is trial 40 with value: 0.9290051302032598.\n",
      "[I 2025-09-08 11:13:01,441] Trial 46 finished with value: 0.8424897720631208 and parameters: {'meta_type': 'lgbm', 'n_estimators': 903, 'learning_rate': 0.019856959793288075, 'num_leaves': 34, 'min_child_samples': 43, 'subsample': 0.8878852997822986, 'colsample_bytree': 0.5030574025820266, 'reg_alpha': 1.5181245199308697, 'reg_lambda': 1.9011557270454569}. Best is trial 40 with value: 0.9290051302032598.\n",
      "[I 2025-09-08 11:13:01,760] Trial 47 finished with value: 0.9291783016213174 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1052, 'learning_rate': 0.023273355607796593, 'num_leaves': 29, 'min_child_samples': 27, 'subsample': 0.9944175059779163, 'colsample_bytree': 0.5345690744713294, 'reg_alpha': 1.202735793865494, 'reg_lambda': 1.4595430133324618}. Best is trial 47 with value: 0.9291783016213174.\n",
      "[I 2025-09-08 11:13:01,777] Trial 48 finished with value: 0.5 and parameters: {'meta_type': 'logreg', 'C': 0.018401198026148854, 'l1_ratio': 0.9865534034153015}. Best is trial 47 with value: 0.9291783016213174.\n",
      "[I 2025-09-08 11:13:02,293] Trial 49 finished with value: 0.9207470182046453 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1151, 'learning_rate': 0.014997734221141751, 'num_leaves': 29, 'min_child_samples': 24, 'subsample': 0.984643613902757, 'colsample_bytree': 0.5462211842945286, 'reg_alpha': 1.2114581239983873, 'reg_lambda': 1.4054722588900541}. Best is trial 47 with value: 0.9291783016213174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HPO] Best meta params: {'meta_type': 'lgbm', 'n_estimators': 1052, 'learning_rate': 0.023273355607796593, 'num_leaves': 29, 'min_child_samples': 27, 'subsample': 0.9944175059779163, 'colsample_bytree': 0.5345690744713294, 'reg_alpha': 1.202735793865494, 'reg_lambda': 1.4595430133324618}\n",
      "[Meta] Best threshold from external validation (ACC): 0.8400\n",
      "\n",
      "==== Stacking (LGBM + SVM + LR) — unified thr from external val Performance ====\n",
      "Accuracy:      0.601744\n",
      "AUC:           0.602965\n",
      "PR-AUC:        0.491574\n",
      "LogLoss:       0.723828\n",
      "Precision@0.840: 0.562500\n",
      "Recall@0.840:    0.064748\n",
      "F1@0.840:        0.116129\n",
      "[Saved] Predictions saved to stacking_predictions.xlsx, shape=(344, 4)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "import optuna\n",
    "\n",
    "# ========= 数据：df_clean = 特征列 + 'value_sort'(0/1) =========\n",
    "# 假设外部已准备好 df_clean\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（严格不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# 训练末尾10%作为“外部验证段”(仅给 LGBM 早停 + 二层阈值学习；不参与任何再训练)\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]\n",
    "\n",
    "# ========= 工具 =========\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "def save_predictions(y_true, y_prob, thr, fname=\"predictions.xlsx\", index=None):\n",
    "    \"\"\"\n",
    "    保存预测结果到 Excel/CSV 文件\n",
    "    参数：\n",
    "        y_true: np.array，真实标签\n",
    "        y_prob: np.array，预测概率\n",
    "        thr: float，阈值\n",
    "        fname: str，输出文件名（支持 .xlsx / .csv）\n",
    "        index: list 或 array，可选，保存的样本索引（如 df_clean.index[split_pt:]）\n",
    "    \"\"\"\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    df_out = pd.DataFrame({\n",
    "        \"index\": index if index is not None else np.arange(len(y_true)),\n",
    "        \"y_true\": y_true,\n",
    "        \"y_prob\": y_prob,\n",
    "        f\"y_pred@{thr:.3f}\": y_pred\n",
    "    })\n",
    "    if fname.endswith(\".csv\"):\n",
    "        df_out.to_csv(fname, index=False)\n",
    "    else:\n",
    "        df_out.to_excel(fname, index=False)\n",
    "    print(f\"[Saved] Predictions saved to {fname}, shape={df_out.shape}\")\n",
    "    return df_out\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on_val(y_val, p_val, metric='accuracy'):\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    if metric == 'accuracy':\n",
    "        scores = [accuracy_score(y_val, (p_val >= t).astype(int)) for t in ths]\n",
    "    else:\n",
    "        from sklearn.metrics import f1_score\n",
    "        scores = [f1_score(y_val, (p_val >= t).astype(int), zero_division=0) for t in ths]\n",
    "    return float(ths[int(np.argmax(scores))])\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit,\n",
    "                                max_expand_ratio=0.3):\n",
    "    \"\"\"\n",
    "    保证外部验证段具备双类：\n",
    "      1) 若单类 -> 逐步扩大验证段（最多扩大至训练末尾30%）\n",
    "      2) 仍单类 -> 从训练拟合段补齐缺失类到验证段，并从训练中剔除这些样本\n",
    "    \"\"\"\n",
    "    if len(np.unique(y_val_fit)) >= 2:\n",
    "        return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "    n_total = len(y_tr)\n",
    "    tail = len(y_val_fit)\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail:\n",
    "            break\n",
    "        X_tr_fit = X_tr_raw[:n_total - new_tail]\n",
    "        y_tr_fit = y_tr[:n_total - new_tail]\n",
    "        X_val_fit = X_tr_raw[n_total - new_tail:]\n",
    "        y_val_fit = y_tr[n_total - new_tail:]\n",
    "        tail = new_tail\n",
    "\n",
    "    if len(np.unique(y_val_fit)) < 2:\n",
    "        classes = np.unique(y_tr)\n",
    "        if len(classes) == 2:\n",
    "            missing = 1 - int(np.unique(y_val_fit)[0])\n",
    "            pool_idx = np.where(y_tr_fit == missing)[0]\n",
    "            if len(pool_idx) > 0:\n",
    "                k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "                pick = np.random.RandomState(1234).choice(pool_idx, k, replace=False)\n",
    "                X_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]], axis=0)\n",
    "                y_val_fit = np.concatenate([y_val_fit, y_tr_fit[pick]], axis=0)\n",
    "                mask = np.ones(len(y_tr_fit), dtype=bool)\n",
    "                mask[pick] = False\n",
    "                X_tr_fit = X_tr_fit[mask]\n",
    "                y_tr_fit = y_tr_fit[mask]\n",
    "\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "# 确保外部验证段可用\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit, max_expand_ratio=0.3\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "# ========= 时序 OOF 折 =========\n",
    "def time_series_folds(n_samples, n_splits=5, min_train_ratio=0.5):\n",
    "    \"\"\"\n",
    "    递增式时间折：前min_train_ratio作为首个train，后面按等长切val区间。\n",
    "    \"\"\"\n",
    "    min_train = int(n_samples * min_train_ratio)\n",
    "    tail = n_samples - min_train\n",
    "    fold_len = max(1, tail // n_splits)\n",
    "    for k in range(n_splits):\n",
    "        start_val = min_train + k * fold_len\n",
    "        end_val   = min(n_samples, start_val + fold_len)\n",
    "        if start_val >= end_val: break\n",
    "        train_idx = np.arange(0, start_val)\n",
    "        val_idx   = np.arange(start_val, end_val)\n",
    "        yield train_idx, val_idx\n",
    "\n",
    "# ========= 基模型超参搜索（在 X_tr_fit 内做时序 OOF，目标=OOF AUC） =========\n",
    "def tune_lgbm(n_trials=30):\n",
    "    def objective(trial):\n",
    "        params = dict(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 300, 2000),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "            min_child_samples=trial.suggest_int(\"min_child_samples\", 5, 300),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-8, 1e-1, log=True),\n",
    "            reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-8, 1e-1, log=True),\n",
    "        )\n",
    "        n = X_tr_fit.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        for tr_idx, va_idx in time_series_folds(n, n_splits=5, min_train_ratio=0.5):\n",
    "            clf = LGBMClassifier(objective=\"binary\", class_weight=\"balanced\",\n",
    "                                 verbosity=-1, random_state=RANDOM_SEED, **params)\n",
    "            # 只用外部验证段做 early stopping（不泄露给二层、仅用于内部训练控制）\n",
    "            clf.fit(\n",
    "                X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "                eval_set=[(X_val_fit, y_val_fit)],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[early_stopping(200, verbose=False)]\n",
    "            )\n",
    "            oof[va_idx] = clf.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return safe_auc(y_tr_fit[seen], oof[seen])\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "def tune_lr(n_trials=30):\n",
    "    def objective(trial):\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 100.0, log=True)\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "        n = X_tr_fit.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        for tr_idx, va_idx in time_series_folds(n, n_splits=5, min_train_ratio=0.5):\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"lr\", LogisticRegression(\n",
    "                    penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "                    class_weight=None, C=C, l1_ratio=l1_ratio, random_state=RANDOM_SEED\n",
    "                ))\n",
    "            ])\n",
    "            pipe.fit(X_tr_fit[tr_idx], y_tr_fit[tr_idx])\n",
    "            oof[va_idx] = pipe.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return safe_auc(y_tr_fit[seen], oof[seen])\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "def tune_svm(n_trials=30):\n",
    "    # 使用 RBF 核的 SVC，软间隔（finite C），probability=True（内部Platt标定）\n",
    "    def objective(trial):\n",
    "        C = trial.suggest_float(\"C\", 1e-2, 1e3, log=True)\n",
    "        gamma = trial.suggest_float(\"gamma\", 1e-4, 10.0, log=True)\n",
    "        n = X_tr_fit.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        for tr_idx, va_idx in time_series_folds(n, n_splits=5, min_train_ratio=0.5):\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"svc\", SVC(\n",
    "                    kernel=\"rbf\", C=C, gamma=gamma, probability=True,\n",
    "                    class_weight=None, random_state=RANDOM_SEED\n",
    "                ))\n",
    "            ])\n",
    "            pipe.fit(X_tr_fit[tr_idx], y_tr_fit[tr_idx])\n",
    "            oof[va_idx] = pipe.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return safe_auc(y_tr_fit[seen], oof[seen])\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "# —— 执行基模型 HPO（可先把 n_trials 调小快速试跑）\n",
    "BEST_LGBM = tune_lgbm(n_trials=30)\n",
    "BEST_LR   = tune_lr(n_trials=30)\n",
    "BEST_SVM  = tune_svm(n_trials=30)\n",
    "\n",
    "print(\"\\n[HPO] BEST_LGBM:\", BEST_LGBM)\n",
    "print(\"[HPO] BEST_LR:\", BEST_LR)\n",
    "print(\"[HPO] BEST_SVM:\", BEST_SVM)\n",
    "\n",
    "# ========= 第一层基模型（LGBM + SVM + LR） =========\n",
    "def make_base_models():\n",
    "    base_lgbm = LGBMClassifier(objective=\"binary\", verbosity=-1,\n",
    "                               class_weight=\"balanced\", random_state=RANDOM_SEED, **BEST_LGBM)\n",
    "    base_svm  = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", probability=True, random_state=RANDOM_SEED, **BEST_SVM))\n",
    "    ])\n",
    "    base_lr   = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "                                  random_state=RANDOM_SEED, **BEST_LR))\n",
    "    ])\n",
    "    return [base_lgbm, base_svm, base_lr]\n",
    "\n",
    "# ========= 生成 OOF（堆叠训练集 Z_train） =========\n",
    "base_models = make_base_models()\n",
    "M = len(base_models)\n",
    "n_train = X_tr_fit.shape[0]\n",
    "\n",
    "OOF = np.zeros((n_train, M))      # 每列一个基模型的 OOF 概率\n",
    "val_mask = np.zeros(n_train, dtype=bool)\n",
    "val_y    = np.zeros(n_train)\n",
    "\n",
    "for m, model in enumerate(base_models):\n",
    "    for tr_idx, va_idx in time_series_folds(n_train, n_splits=5, min_train_ratio=0.5):\n",
    "        if isinstance(model, LGBMClassifier):\n",
    "            model.fit(\n",
    "                X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "                eval_set=[(X_val_fit, y_val_fit)],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[early_stopping(200, verbose=False)]\n",
    "            )\n",
    "        else:\n",
    "            model.fit(X_tr_fit[tr_idx], y_tr_fit[tr_idx])\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            prob = model.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "        else:\n",
    "            decision = model.decision_function(X_tr_fit[va_idx])\n",
    "            prob = 1 / (1 + np.exp(-decision))\n",
    "        OOF[va_idx, m] = prob\n",
    "        val_mask[va_idx] = True\n",
    "        val_y[va_idx]    = y_tr_fit[va_idx]\n",
    "\n",
    "Z_train = OOF[val_mask]\n",
    "y_meta  = val_y[val_mask]\n",
    "\n",
    "# ========= 外部验证段的二层特征 Z_val（用于阈值学习，不参与训练）=========\n",
    "fitted_bases = []\n",
    "Z_val = np.zeros((X_val_fit.shape[0], M))\n",
    "for i, model in enumerate(make_base_models()):\n",
    "    if isinstance(model, LGBMClassifier):\n",
    "        model.fit(\n",
    "            X_tr_fit, y_tr_fit,\n",
    "            eval_set=[(X_val_fit, y_val_fit)],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "    else:\n",
    "        model.fit(X_tr_fit, y_tr_fit)\n",
    "    fitted_bases.append(model)\n",
    "    prob_val = (model.predict_proba(X_val_fit)[:, 1]\n",
    "                if hasattr(model, \"predict_proba\")\n",
    "                else 1/(1+np.exp(-model.decision_function(X_val_fit))))\n",
    "    Z_val[:, i] = prob_val\n",
    "\n",
    "# ========= 二层（元学习器）HPO =========\n",
    "def build_meta(trial):\n",
    "    meta_type = trial.suggest_categorical(\"meta_type\", [\"logreg\", \"ridge\", \"lgbm\"])\n",
    "    if meta_type == \"logreg\":\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 100.0, log=True)\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "        return LogisticRegression(\n",
    "            penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "            class_weight=\"balanced\", C=C, l1_ratio=l1_ratio, random_state=123\n",
    "        )\n",
    "    if meta_type == \"ridge\":\n",
    "        alpha = trial.suggest_float(\"alpha\", 1e-3, 100.0, log=True)\n",
    "        return RidgeClassifier(alpha=alpha, random_state=123)\n",
    "    if meta_type == \"lgbm\":\n",
    "        params = dict(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 7, 63),\n",
    "            min_child_samples=trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "            reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 5.0)\n",
    "        )\n",
    "        return LGBMClassifier(objective=\"binary\", class_weight=\"balanced\",\n",
    "                              verbosity=-1, random_state=123, **params)\n",
    "\n",
    "def objective_meta(trial):\n",
    "    meta = build_meta(trial)\n",
    "    meta.fit(Z_train, y_meta)\n",
    "    y_meta_prob = (meta.predict_proba(Z_train)[:, 1]\n",
    "                   if hasattr(meta, \"predict_proba\")\n",
    "                   else 1/(1+np.exp(-meta.decision_function(Z_train))))\n",
    "    return safe_auc(y_meta, y_meta_prob)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective_meta, n_trials=50, show_progress_bar=False)\n",
    "best_meta_params = study.best_params\n",
    "print(\"\\n[HPO] Best meta params:\", best_meta_params)\n",
    "\n",
    "# ========= 最优元学习器：在 Z_train 上重训；用 Z_val 学阈值(ACC)；在测试集融合 =========\n",
    "best_meta = (lambda t: build_meta(t))(optuna.trial.FixedTrial(best_meta_params))\n",
    "best_meta.fit(Z_train, y_meta)\n",
    "\n",
    "y_val_meta_prob = (best_meta.predict_proba(Z_val)[:, 1]\n",
    "                   if hasattr(best_meta, \"predict_proba\")\n",
    "                   else 1/(1+np.exp(-best_meta.decision_function(Z_val))))\n",
    "best_thr = best_thr_on_val(y_val_fit, y_val_meta_prob, metric='accuracy')\n",
    "print(f\"[Meta] Best threshold from external validation (ACC): {best_thr:.4f}\")\n",
    "\n",
    "# ========= 测试集堆叠：先构造 test_stack，再用 best_meta + 固定阈值评估 =========\n",
    "test_stack = np.zeros((X_te.shape[0], M))\n",
    "for i, model in enumerate(fitted_bases):\n",
    "    prob_te = (model.predict_proba(X_te)[:, 1]\n",
    "               if hasattr(model, \"predict_proba\")\n",
    "               else 1/(1+np.exp(-model.decision_function(X_te))))\n",
    "    test_stack[:, i] = prob_te\n",
    "\n",
    "y_prob_stack = (best_meta.predict_proba(test_stack)[:, 1]\n",
    "                if hasattr(best_meta, \"predict_proba\")\n",
    "                else 1/(1+np.exp(-best_meta.decision_function(test_stack))))\n",
    "\n",
    "report_all(y_te, y_prob_stack, thr=best_thr, title=\"Stacking (LGBM + SVM + LR) — unified thr from external val\")\n",
    "\n",
    "# 保存测试集预测结果\n",
    "df_pred = save_predictions(\n",
    "    y_te, y_prob_stack, best_thr,\n",
    "    fname=\"stacking_predictions.xlsx\",\n",
    "    index=df_clean.index[split_pt:]  # 保留原始索引（可选）\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e2619e",
   "metadata": {},
   "source": [
    "### 自由评估stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e7e9105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:15:26,184] A new study created in memory with name: no-name-521a3e80-1b40-486c-a5c2-14b1789d71ac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Train-fit size: 1234, Val-fit size: 138, Classes in Val: (array([0, 1]), array([99, 39]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:15:28,470] Trial 0 finished with value: 0.6496874991273982 and parameters: {'n_estimators': 937, 'learning_rate': 0.2536999076681772, 'num_leaves': 191, 'min_child_samples': 182, 'subsample': 0.5780093202212182, 'colsample_bytree': 0.5779972601681014, 'reg_alpha': 2.5502648504032812e-08, 'reg_lambda': 0.011567327199145964}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:29,222] Trial 1 finished with value: 0.6396203535824305 and parameters: {'n_estimators': 1322, 'learning_rate': 0.11114989443094977, 'num_leaves': 19, 'min_child_samples': 292, 'subsample': 0.9162213204002109, 'colsample_bytree': 0.6061695553391381, 'reg_alpha': 1.8740223688836284e-07, 'reg_lambda': 1.9223460470643606e-07}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:30,361] Trial 2 finished with value: 0.6378676227922401 and parameters: {'n_estimators': 817, 'learning_rate': 0.05958389350068958, 'num_leaves': 119, 'min_child_samples': 91, 'subsample': 0.8059264473611898, 'colsample_bytree': 0.569746930326021, 'reg_alpha': 1.109206841853616e-06, 'reg_lambda': 3.6688748954991767e-06}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:31,236] Trial 3 finished with value: 0.6453182879263536 and parameters: {'n_estimators': 1075, 'learning_rate': 0.14447746112718687, 'num_leaves': 63, 'min_child_samples': 157, 'subsample': 0.7962072844310213, 'colsample_bytree': 0.5232252063599989, 'reg_alpha': 0.00017898389848671568, 'reg_lambda': 1.5619562520792713e-07}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:32,022] Trial 4 finished with value: 0.634372920833854 and parameters: {'n_estimators': 410, 'learning_rate': 0.2521267904777921, 'num_leaves': 247, 'min_child_samples': 244, 'subsample': 0.6523068845866853, 'colsample_bytree': 0.5488360570031919, 'reg_alpha': 0.0006160715952774535, 'reg_lambda': 1.2052231254145584e-05}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:32,800] Trial 5 finished with value: 0.6460156733577197 and parameters: {'n_estimators': 507, 'learning_rate': 0.05388108577817234, 'num_leaves': 23, 'min_child_samples': 274, 'subsample': 0.6293899908000085, 'colsample_bytree': 0.831261142176991, 'reg_alpha': 1.5204688692198897e-06, 'reg_lambda': 4.369946783595573e-05}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:33,798] Trial 6 finished with value: 0.6334410499144435 and parameters: {'n_estimators': 1229, 'learning_rate': 0.01875220945578641, 'num_leaves': 248, 'min_child_samples': 234, 'subsample': 0.9697494707820946, 'colsample_bytree': 0.9474136752138245, 'reg_alpha': 0.00015321449415450696, 'reg_lambda': 0.02838700963443623}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:34,969] Trial 7 finished with value: 0.6420089113015673 and parameters: {'n_estimators': 450, 'learning_rate': 0.01947558230629543, 'num_leaves': 25, 'min_child_samples': 101, 'subsample': 0.6943386448447411, 'colsample_bytree': 0.6356745158869479, 'reg_alpha': 0.006326486185661575, 'reg_lambda': 3.1424855318831594e-06}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:35,839] Trial 8 finished with value: 0.6287583106836346 and parameters: {'n_estimators': 777, 'learning_rate': 0.06333268775321843, 'num_leaves': 48, 'min_child_samples': 242, 'subsample': 0.5372753218398854, 'colsample_bytree': 0.9934434683002586, 'reg_alpha': 0.0025451500130912884, 'reg_lambda': 2.4604229580184137e-07}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:36,683] Trial 9 finished with value: 0.6437296725506022 and parameters: {'n_estimators': 309, 'learning_rate': 0.1601531217136121, 'num_leaves': 185, 'min_child_samples': 220, 'subsample': 0.8856351733429728, 'colsample_bytree': 0.5370223258670452, 'reg_alpha': 3.230428252240957e-06, 'reg_lambda': 6.472669269538615e-08}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:42,439] Trial 10 finished with value: 0.6423883891067443 and parameters: {'n_estimators': 1822, 'learning_rate': 0.010206070557576998, 'num_leaves': 173, 'min_child_samples': 10, 'subsample': 0.5076838686640521, 'colsample_bytree': 0.7190404637309149, 'reg_alpha': 1.2764672000947542e-08, 'reg_lambda': 0.0680736910050809}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:43,458] Trial 11 finished with value: 0.6459430898389626 and parameters: {'n_estimators': 788, 'learning_rate': 0.034203602798532316, 'num_leaves': 107, 'min_child_samples': 170, 'subsample': 0.6167235717698462, 'colsample_bytree': 0.8381511796098792, 'reg_alpha': 2.138562643937061e-08, 'reg_lambda': 0.0008066763948079535}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:44,352] Trial 12 finished with value: 0.6407846084448955 and parameters: {'n_estimators': 1573, 'learning_rate': 0.28644559781372286, 'num_leaves': 187, 'min_child_samples': 288, 'subsample': 0.5915771381556065, 'colsample_bytree': 0.844768300560321, 'reg_alpha': 7.240307630591908e-06, 'reg_lambda': 0.0005466714667177844}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:45,291] Trial 13 finished with value: 0.649099796840998 and parameters: {'n_estimators': 928, 'learning_rate': 0.08035126916371757, 'num_leaves': 156, 'min_child_samples': 195, 'subsample': 0.7374557575693481, 'colsample_bytree': 0.7201370045970288, 'reg_alpha': 0.09897763455528179, 'reg_lambda': 0.0005556621753598144}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:46,190] Trial 14 finished with value: 0.6415767267380171 and parameters: {'n_estimators': 1016, 'learning_rate': 0.09548424890644631, 'num_leaves': 153, 'min_child_samples': 195, 'subsample': 0.7250363193327762, 'colsample_bytree': 0.6664715984390738, 'reg_alpha': 0.08626077411974503, 'reg_lambda': 0.0026738286969667908}. Best is trial 0 with value: 0.6496874991273982.\n",
      "[I 2025-09-08 14:15:47,360] Trial 15 finished with value: 0.6533767096925516 and parameters: {'n_estimators': 1373, 'learning_rate': 0.20105522062608522, 'num_leaves': 209, 'min_child_samples': 118, 'subsample': 0.7814286263317113, 'colsample_bytree': 0.7588408683440631, 'reg_alpha': 0.06712848379904637, 'reg_lambda': 0.0036518888335202774}. Best is trial 15 with value: 0.6533767096925516.\n",
      "[I 2025-09-08 14:15:48,529] Trial 16 finished with value: 0.6523045252783576 and parameters: {'n_estimators': 1426, 'learning_rate': 0.19057089978794667, 'num_leaves': 215, 'min_child_samples': 103, 'subsample': 0.8046299781052564, 'colsample_bytree': 0.7753692083041122, 'reg_alpha': 2.8560564073047593e-05, 'reg_lambda': 0.006230326640059523}. Best is trial 15 with value: 0.6533767096925516.\n",
      "[I 2025-09-08 14:15:49,751] Trial 17 finished with value: 0.6525368235512704 and parameters: {'n_estimators': 1484, 'learning_rate': 0.17178329359598135, 'num_leaves': 217, 'min_child_samples': 101, 'subsample': 0.8285726521637807, 'colsample_bytree': 0.7798079465483917, 'reg_alpha': 3.641375746673806e-05, 'reg_lambda': 0.004635108728048181}. Best is trial 15 with value: 0.6533767096925516.\n",
      "[I 2025-09-08 14:15:51,327] Trial 18 finished with value: 0.6766089622460248 and parameters: {'n_estimators': 1940, 'learning_rate': 0.14168770938702405, 'num_leaves': 219, 'min_child_samples': 61, 'subsample': 0.8809522441371602, 'colsample_bytree': 0.9069968527889158, 'reg_alpha': 0.018998970008163894, 'reg_lambda': 0.0001338943185458282}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:15:53,168] Trial 19 finished with value: 0.6558855268286777 and parameters: {'n_estimators': 1998, 'learning_rate': 0.1083204273335879, 'num_leaves': 218, 'min_child_samples': 44, 'subsample': 0.8744691558149806, 'colsample_bytree': 0.9134336554829188, 'reg_alpha': 0.014907702659540062, 'reg_lambda': 8.765472314248205e-05}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:15:55,533] Trial 20 finished with value: 0.6446815953830008 and parameters: {'n_estimators': 1978, 'learning_rate': 0.039524194202598784, 'num_leaves': 231, 'min_child_samples': 34, 'subsample': 0.9956385980717999, 'colsample_bytree': 0.909403805731264, 'reg_alpha': 0.01402524023703582, 'reg_lambda': 6.281180067214304e-05}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:15:57,240] Trial 21 finished with value: 0.6691386377147013 and parameters: {'n_estimators': 1722, 'learning_rate': 0.11913740997880938, 'num_leaves': 211, 'min_child_samples': 62, 'subsample': 0.8733530533649854, 'colsample_bytree': 0.8941468837236077, 'reg_alpha': 0.021903050026906866, 'reg_lambda': 0.00016432288357466}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:15:58,804] Trial 22 finished with value: 0.6672442499776345 and parameters: {'n_estimators': 1714, 'learning_rate': 0.1141953542088764, 'num_leaves': 254, 'min_child_samples': 59, 'subsample': 0.8761658953419046, 'colsample_bytree': 0.8964973997679857, 'reg_alpha': 0.01315411050308839, 'reg_lambda': 0.00012348132353242112}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:16:00,363] Trial 23 finished with value: 0.6603522068666428 and parameters: {'n_estimators': 1702, 'learning_rate': 0.12151236050852704, 'num_leaves': 246, 'min_child_samples': 63, 'subsample': 0.9312404495902853, 'colsample_bytree': 0.8968141406931648, 'reg_alpha': 0.001330992158490123, 'reg_lambda': 0.0001954709647496798}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:16:02,037] Trial 24 finished with value: 0.6528777829546596 and parameters: {'n_estimators': 1761, 'learning_rate': 0.08119600668230445, 'num_leaves': 251, 'min_child_samples': 59, 'subsample': 0.8570735086921868, 'colsample_bytree': 0.9887269384973665, 'reg_alpha': 0.01686145066872955, 'reg_lambda': 1.372941147657369e-05}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:16:03,161] Trial 25 finished with value: 0.6524534186678324 and parameters: {'n_estimators': 1848, 'learning_rate': 0.1472839700553845, 'num_leaves': 202, 'min_child_samples': 135, 'subsample': 0.9074344510705996, 'colsample_bytree': 0.8755441254912064, 'reg_alpha': 0.0035220959465975207, 'reg_lambda': 1.4070409504629327e-06}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:16:07,599] Trial 26 finished with value: 0.6354483075775894 and parameters: {'n_estimators': 1631, 'learning_rate': 0.08407441742136419, 'num_leaves': 232, 'min_child_samples': 12, 'subsample': 0.9431858684267418, 'colsample_bytree': 0.9531441619216087, 'reg_alpha': 0.00036758399235307747, 'reg_lambda': 0.00012321379018953533}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:16:09,056] Trial 27 finished with value: 0.6635494886979992 and parameters: {'n_estimators': 1881, 'learning_rate': 0.1285245113840579, 'num_leaves': 158, 'min_child_samples': 67, 'subsample': 0.8451706795797801, 'colsample_bytree': 0.9421402304877278, 'reg_alpha': 0.028424513077416724, 'reg_lambda': 1.4638436031006434e-05}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:16:11,247] Trial 28 finished with value: 0.6418862627089014 and parameters: {'n_estimators': 1625, 'learning_rate': 0.04501066001763344, 'num_leaves': 232, 'min_child_samples': 35, 'subsample': 0.7620079277549527, 'colsample_bytree': 0.8101137097332858, 'reg_alpha': 0.004596369845461666, 'reg_lambda': 1.5041812367256178e-08}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:16:12,592] Trial 29 finished with value: 0.6409687850805448 and parameters: {'n_estimators': 1519, 'learning_rate': 0.2233802752356677, 'num_leaves': 197, 'min_child_samples': 75, 'subsample': 0.8895164161417117, 'colsample_bytree': 0.8644020319842762, 'reg_alpha': 0.0009124247444636521, 'reg_lambda': 0.001150472106764606}. Best is trial 18 with value: 0.6766089622460248.\n",
      "[I 2025-09-08 14:16:12,594] A new study created in memory with name: no-name-700cdf8a-7826-467b-9c27-b3c846ef356e\n",
      "[I 2025-09-08 14:16:13,814] Trial 0 finished with value: 0.6229677894326274 and parameters: {'C': 0.0745934328572655, 'l1_ratio': 0.9507143064099162}. Best is trial 0 with value: 0.6229677894326274.\n",
      "[I 2025-09-08 14:16:24,533] Trial 1 finished with value: 0.5983127713542973 and parameters: {'C': 4.5705630998014515, 'l1_ratio': 0.5986584841970366}. Best is trial 0 with value: 0.6229677894326274.\n",
      "[I 2025-09-08 14:16:25,211] Trial 2 finished with value: 0.6366916954319538 and parameters: {'C': 0.006026889128682512, 'l1_ratio': 0.15599452033620265}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:16:25,731] Trial 3 finished with value: 0.5920760141912631 and parameters: {'C': 0.0019517224641449498, 'l1_ratio': 0.8661761457749352}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:16:31,552] Trial 4 finished with value: 0.6053120296756705 and parameters: {'C': 1.0129197956845732, 'l1_ratio': 0.7080725777960455}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:16:32,051] Trial 5 finished with value: 0.5920760141912631 and parameters: {'C': 0.001267425589893723, 'l1_ratio': 0.9699098521619943}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:16:46,437] Trial 6 finished with value: 0.5975271228409572 and parameters: {'C': 14.528246637516036, 'l1_ratio': 0.21233911067827616}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:16:47,143] Trial 7 finished with value: 0.6304904530574681 and parameters: {'C': 0.008111941985431923, 'l1_ratio': 0.18340450985343382}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:16:48,078] Trial 8 finished with value: 0.6301679914578407 and parameters: {'C': 0.033205591037519584, 'l1_ratio': 0.5247564316322378}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:16:49,708] Trial 9 finished with value: 0.6161574363581792 and parameters: {'C': 0.14445251022763064, 'l1_ratio': 0.2912291401980419}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:08,223] Trial 10 finished with value: 0.600947565592639 and parameters: {'C': 53.17196633982125, 'l1_ratio': 0.005997182955817193}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:09,119] Trial 11 finished with value: 0.6347990848423776 and parameters: {'C': 0.011983829487007384, 'l1_ratio': 0.2555181508867127}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:10,512] Trial 12 finished with value: 0.6347103162366807 and parameters: {'C': 0.015365800572512604, 'l1_ratio': 0.34995703045051474}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:11,929] Trial 13 finished with value: 0.6329906421797314 and parameters: {'C': 0.00605805578537032, 'l1_ratio': 0.010048846146158696}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:20,436] Trial 14 finished with value: 0.6094614215844931 and parameters: {'C': 0.5467530386354754, 'l1_ratio': 0.37960424342022364}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:21,801] Trial 15 finished with value: 0.6229815762035577 and parameters: {'C': 0.003114321312320664, 'l1_ratio': 0.1411544291592809}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:23,854] Trial 16 finished with value: 0.6288317766981313 and parameters: {'C': 0.03071991344395096, 'l1_ratio': 0.4343562717564112}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:27,963] Trial 17 finished with value: 0.6110211935826844 and parameters: {'C': 0.16598049918265734, 'l1_ratio': 0.11096862763382609}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:42,606] Trial 18 finished with value: 0.6013819759741816 and parameters: {'C': 1.9198314003586399, 'l1_ratio': 0.27175699527435593}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:44,364] Trial 19 finished with value: 0.6320593921805796 and parameters: {'C': 0.021624962584771527, 'l1_ratio': 0.08916524331597314}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:45,634] Trial 20 finished with value: 0.6027208590861609 and parameters: {'C': 0.004106717275733855, 'l1_ratio': 0.4859583112575423}. Best is trial 2 with value: 0.6366916954319538.\n",
      "[I 2025-09-08 14:17:47,340] Trial 21 finished with value: 0.6406986155215185 and parameters: {'C': 0.011937214779030557, 'l1_ratio': 0.3505217093562324}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:17:49,907] Trial 22 finished with value: 0.626801428155939 and parameters: {'C': 0.06925825951537168, 'l1_ratio': 0.27091052413987304}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:17:51,032] Trial 23 finished with value: 0.5920760141912631 and parameters: {'C': 0.0010885456469016132, 'l1_ratio': 0.34279928826631634}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:17:52,645] Trial 24 finished with value: 0.6336711140450896 and parameters: {'C': 0.010981458343565986, 'l1_ratio': 0.6177983573220711}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:17:54,964] Trial 25 finished with value: 0.6267557371200587 and parameters: {'C': 0.054106056821926714, 'l1_ratio': 0.2135405628233163}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:18:00,439] Trial 26 finished with value: 0.613653734404782 and parameters: {'C': 0.30512888033187113, 'l1_ratio': 0.3883832257368037}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:18:01,779] Trial 27 finished with value: 0.6295866822980395 and parameters: {'C': 0.00406406450082192, 'l1_ratio': 0.06744986214259079}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:18:03,442] Trial 28 finished with value: 0.630032690800625 and parameters: {'C': 0.013507526449093537, 'l1_ratio': 0.18708164426640428}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:18:06,417] Trial 29 finished with value: 0.6349425043169581 and parameters: {'C': 0.09018238253672024, 'l1_ratio': 0.48885596617950056}. Best is trial 21 with value: 0.6406986155215185.\n",
      "[I 2025-09-08 14:18:06,419] A new study created in memory with name: no-name-92ab2662-926d-44b7-8416-fea0d5871392\n",
      "[I 2025-09-08 14:18:09,769] Trial 0 finished with value: 0.5920760141912631 and parameters: {'C': 0.7459343285726545, 'gamma': 5.669849511478847}. Best is trial 0 with value: 0.5920760141912631.\n",
      "[I 2025-09-08 14:18:11,468] Trial 1 finished with value: 0.6053290770137831 and parameters: {'C': 45.70563099801453, 'gamma': 0.09846738873614563}. Best is trial 1 with value: 0.6053290770137831.\n",
      "[I 2025-09-08 14:18:12,692] Trial 2 finished with value: 0.6293341385118523 and parameters: {'C': 0.06026889128682508, 'gamma': 0.000602521573620386}. Best is trial 2 with value: 0.6293341385118523.\n",
      "[I 2025-09-08 14:18:14,213] Trial 3 finished with value: 0.5920760141912631 and parameters: {'C': 0.0195172246414495, 'gamma': 2.1423021757741068}. Best is trial 2 with value: 0.6293341385118523.\n",
      "[I 2025-09-08 14:18:15,684] Trial 4 finished with value: 0.5920760141912631 and parameters: {'C': 10.129197956845726, 'gamma': 0.3470266988650412}. Best is trial 2 with value: 0.6293341385118523.\n",
      "[I 2025-09-08 14:18:17,173] Trial 5 finished with value: 0.5920760141912631 and parameters: {'C': 0.012674255898937233, 'gamma': 7.072114131472227}. Best is trial 2 with value: 0.6293341385118523.\n",
      "[I 2025-09-08 14:18:19,170] Trial 6 finished with value: 0.6042682855470294 and parameters: {'C': 145.28246637516014, 'gamma': 0.0011526449540315614}. Best is trial 2 with value: 0.6293341385118523.\n",
      "[I 2025-09-08 14:18:20,426] Trial 7 finished with value: 0.6278667286205419 and parameters: {'C': 0.08111941985431921, 'gamma': 0.0008260808399079611}. Best is trial 2 with value: 0.6293341385118523.\n",
      "[I 2025-09-08 14:18:21,805] Trial 8 finished with value: 0.6219807227543398 and parameters: {'C': 0.3320559103751956, 'gamma': 0.042051564509138675}. Best is trial 2 with value: 0.6293341385118523.\n",
      "[I 2025-09-08 14:18:23,025] Trial 9 finished with value: 0.6466429102655314 and parameters: {'C': 1.4445251022763053, 'gamma': 0.0028585493941961923}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:24,411] Trial 10 finished with value: 0.6243026257035427 and parameters: {'C': 4.053834553028505, 'gamma': 0.006344493151988632}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:25,634] Trial 11 finished with value: 0.6216520536616426 and parameters: {'C': 0.37634001643722625, 'gamma': 0.00012196019578853642}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:26,876] Trial 12 finished with value: 0.6412785981989626 and parameters: {'C': 1.6803460771217928, 'gamma': 0.004452944883704768}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:28,367] Trial 13 finished with value: 0.6182191517350931 and parameters: {'C': 10.957167999707234, 'gamma': 0.005918706793690241}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:29,622] Trial 14 finished with value: 0.6412971543372046 and parameters: {'C': 1.2881051041907885, 'gamma': 0.007174822574539996}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:31,059] Trial 15 finished with value: 0.627343578840299 and parameters: {'C': 688.1485068556925, 'gamma': 0.016598724044905974}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:32,475] Trial 16 finished with value: 0.6068167294229186 and parameters: {'C': 3.9393458580144127, 'gamma': 0.08004347798477156}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:33,708] Trial 17 finished with value: 0.6198093274615231 and parameters: {'C': 0.10448977830267009, 'gamma': 0.00017896115576931734}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:35,152] Trial 18 finished with value: 0.5920760141912631 and parameters: {'C': 28.148296482457187, 'gamma': 0.2856490596168042}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:36,365] Trial 19 finished with value: 0.6453456007055689 and parameters: {'C': 1.0133375011947325, 'gamma': 0.0026354180546021896}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:37,584] Trial 20 finished with value: 0.6369419883186797 and parameters: {'C': 0.25903139253342417, 'gamma': 0.0016212741235047353}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:38,984] Trial 21 finished with value: 0.6313402477772708 and parameters: {'C': 1.4474239439297205, 'gamma': 0.011673486548519733}. Best is trial 9 with value: 0.6466429102655314.\n",
      "[I 2025-09-08 14:18:40,221] Trial 22 finished with value: 0.6524945329404844 and parameters: {'C': 1.7187752389156432, 'gamma': 0.002102956870613666}. Best is trial 22 with value: 0.6524945329404844.\n",
      "[I 2025-09-08 14:18:41,582] Trial 23 finished with value: 0.6287911558666226 and parameters: {'C': 12.018284866159458, 'gamma': 0.002260512753887851}. Best is trial 22 with value: 0.6524945329404844.\n",
      "[I 2025-09-08 14:18:42,814] Trial 24 finished with value: 0.628914197355111 and parameters: {'C': 0.5798094152208736, 'gamma': 0.00037641862231612}. Best is trial 22 with value: 0.6524945329404844.\n",
      "[I 2025-09-08 14:18:44,066] Trial 25 finished with value: 0.6477389277389277 and parameters: {'C': 2.5935065755680813, 'gamma': 0.0025536086913529174}. Best is trial 22 with value: 0.6524945329404844.\n",
      "[I 2025-09-08 14:18:45,317] Trial 26 finished with value: 0.6380818719562341 and parameters: {'C': 3.05128880331871, 'gamma': 0.00028924870586156276}. Best is trial 22 with value: 0.6524945329404844.\n",
      "[I 2025-09-08 14:18:46,614] Trial 27 finished with value: 0.6371318902012817 and parameters: {'C': 0.18469873419670985, 'gamma': 0.020277956983607556}. Best is trial 22 with value: 0.6524945329404844.\n",
      "[I 2025-09-08 14:18:48,273] Trial 28 finished with value: 0.6055890171280192 and parameters: {'C': 44.58349878424642, 'gamma': 0.0032902697482205625}. Best is trial 22 with value: 0.6524945329404844.\n",
      "[I 2025-09-08 14:18:49,495] Trial 29 finished with value: 0.632679001098602 and parameters: {'C': 5.864044798753945, 'gamma': 0.0009542121513663609}. Best is trial 22 with value: 0.6524945329404844.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HPO] BEST_LGBM: {'n_estimators': 1940, 'learning_rate': 0.14168770938702405, 'num_leaves': 219, 'min_child_samples': 61, 'subsample': 0.8809522441371602, 'colsample_bytree': 0.9069968527889158, 'reg_alpha': 0.018998970008163894, 'reg_lambda': 0.0001338943185458282}\n",
      "[HPO] BEST_LR: {'C': 0.011937214779030557, 'l1_ratio': 0.3505217093562324}\n",
      "[HPO] BEST_SVM: {'C': 1.7187752389156432, 'gamma': 0.002102956870613666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-08 14:18:52,235] A new study created in memory with name: no-name-3c5b49b7-c0ae-4495-9256-1628ebc4d87d\n",
      "[I 2025-09-08 14:18:52,743] Trial 0 finished with value: 0.6343789543789543 and parameters: {'meta_type': 'ridge', 'alpha': 0.9846738873614566}. Best is trial 0 with value: 0.6343789543789543.\n",
      "[I 2025-09-08 14:18:53,280] Trial 1 finished with value: 0.6334070285431447 and parameters: {'meta_type': 'logreg', 'C': 21.42302175774105, 'l1_ratio': 0.6011150117432088}. Best is trial 0 with value: 0.6343789543789543.\n",
      "[I 2025-09-08 14:18:54,570] Trial 2 finished with value: 0.6211748918334962 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1283, 'learning_rate': 0.010943342660062645, 'num_leaves': 17, 'min_child_samples': 45, 'subsample': 0.6521211214797689, 'colsample_bytree': 0.762378215816119, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097}. Best is trial 0 with value: 0.6343789543789543.\n",
      "[I 2025-09-08 14:18:55,084] Trial 3 finished with value: 0.6334070285431447 and parameters: {'meta_type': 'logreg', 'C': 0.06789053271698488, 'l1_ratio': 0.45606998421703593}. Best is trial 0 with value: 0.6343789543789543.\n",
      "[I 2025-09-08 14:18:55,592] Trial 4 finished with value: 0.637347915242652 and parameters: {'meta_type': 'logreg', 'C': 0.9163741808778786, 'l1_ratio': 0.046450412719997725}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:18:56,110] Trial 5 finished with value: 0.6334070285431447 and parameters: {'meta_type': 'logreg', 'C': 55.51721685244721, 'l1_ratio': 0.9656320330745594}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:18:56,624] Trial 6 finished with value: 0.6334070285431447 and parameters: {'meta_type': 'logreg', 'C': 2.6373339933815254, 'l1_ratio': 0.4401524937396013}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:18:57,125] Trial 7 finished with value: 0.6080274685650049 and parameters: {'meta_type': 'ridge', 'alpha': 35.20481045526041}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:18:57,633] Trial 8 finished with value: 0.6335584415584415 and parameters: {'meta_type': 'ridge', 'alpha': 0.39841905944346884}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:18:58,562] Trial 9 finished with value: 0.6221087670370203 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1208, 'learning_rate': 0.15999399049657148, 'num_leaves': 58, 'min_child_samples': 124, 'subsample': 0.9609371175115584, 'colsample_bytree': 0.5442462510259598, 'reg_alpha': 0.979914312095726, 'reg_lambda': 0.22613644455269033}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:18:59,070] Trial 10 finished with value: 0.6156740862623217 and parameters: {'meta_type': 'logreg', 'C': 0.0010714845538373125, 'l1_ratio': 0.007547319316293266}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:18:59,579] Trial 11 finished with value: 0.6319032691446484 and parameters: {'meta_type': 'ridge', 'alpha': 0.002279247784907995}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:00,081] Trial 12 finished with value: 0.6343789543789543 and parameters: {'meta_type': 'ridge', 'alpha': 1.089451268224416}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:00,594] Trial 13 finished with value: 0.6319032691446484 and parameters: {'meta_type': 'ridge', 'alpha': 0.005102910901552235}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:01,225] Trial 14 finished with value: 0.6173816987610091 and parameters: {'meta_type': 'lgbm', 'n_estimators': 237, 'learning_rate': 0.005299259757475013, 'num_leaves': 9, 'min_child_samples': 198, 'subsample': 0.5278074091747083, 'colsample_bytree': 0.9677809380407124, 'reg_alpha': 4.917896679664363, 'reg_lambda': 4.98301575130727}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:01,727] Trial 15 finished with value: 0.636976356976357 and parameters: {'meta_type': 'logreg', 'C': 0.08838989353015532, 'l1_ratio': 0.08147096568017237}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:02,233] Trial 16 finished with value: 0.6343789543789543 and parameters: {'meta_type': 'logreg', 'C': 0.10482178489309588, 'l1_ratio': 0.02761485859973}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:02,743] Trial 17 finished with value: 0.637347915242652 and parameters: {'meta_type': 'logreg', 'C': 0.8079223578480936, 'l1_ratio': 0.2129800119268096}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:03,251] Trial 18 finished with value: 0.6334070285431447 and parameters: {'meta_type': 'logreg', 'C': 1.7991982328035865, 'l1_ratio': 0.26820032008409095}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:03,765] Trial 19 finished with value: 0.6334070285431447 and parameters: {'meta_type': 'logreg', 'C': 1.5045299362411526, 'l1_ratio': 0.24468829264494207}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:04,276] Trial 20 finished with value: 0.637347915242652 and parameters: {'meta_type': 'logreg', 'C': 0.547893933528413, 'l1_ratio': 0.2409502850323142}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:04,790] Trial 21 finished with value: 0.637347915242652 and parameters: {'meta_type': 'logreg', 'C': 0.4398410704092932, 'l1_ratio': 0.24356311220802968}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:05,319] Trial 22 finished with value: 0.637347915242652 and parameters: {'meta_type': 'logreg', 'C': 0.4448092575850595, 'l1_ratio': 0.1494537841961552}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:05,838] Trial 23 finished with value: 0.6334070285431447 and parameters: {'meta_type': 'logreg', 'C': 8.117933086368513, 'l1_ratio': 0.32226554308423117}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:06,346] Trial 24 finished with value: 0.6290643303057097 and parameters: {'meta_type': 'logreg', 'C': 0.012755612996409057, 'l1_ratio': 0.14729886833543182}. Best is trial 4 with value: 0.637347915242652.\n",
      "[I 2025-09-08 14:19:07,050] Trial 25 finished with value: 0.63778272588773 and parameters: {'meta_type': 'lgbm', 'n_estimators': 427, 'learning_rate': 0.08073738211851737, 'num_leaves': 62, 'min_child_samples': 11, 'subsample': 0.9886332327975391, 'colsample_bytree': 0.5023700598265446, 'reg_alpha': 4.418816437728786, 'reg_lambda': 4.197696347413638}. Best is trial 25 with value: 0.63778272588773.\n",
      "[I 2025-09-08 14:19:07,725] Trial 26 finished with value: 0.6327521104963375 and parameters: {'meta_type': 'lgbm', 'n_estimators': 377, 'learning_rate': 0.08639101006512064, 'num_leaves': 63, 'min_child_samples': 15, 'subsample': 0.9501074183915026, 'colsample_bytree': 0.5045170160532092, 'reg_alpha': 4.929934993784587, 'reg_lambda': 4.468812616934239}. Best is trial 25 with value: 0.63778272588773.\n",
      "[I 2025-09-08 14:19:08,528] Trial 27 finished with value: 0.6322679520454827 and parameters: {'meta_type': 'lgbm', 'n_estimators': 680, 'learning_rate': 0.04116522010995255, 'num_leaves': 40, 'min_child_samples': 78, 'subsample': 0.7998205947513182, 'colsample_bytree': 0.694997770622253, 'reg_alpha': 3.3389622479204633, 'reg_lambda': 3.2148362386681106}. Best is trial 25 with value: 0.63778272588773.\n",
      "[I 2025-09-08 14:19:09,337] Trial 28 finished with value: 0.6234988476848942 and parameters: {'meta_type': 'lgbm', 'n_estimators': 825, 'learning_rate': 0.03179319883335173, 'num_leaves': 41, 'min_child_samples': 128, 'subsample': 0.811803450496039, 'colsample_bytree': 0.6767505525900184, 'reg_alpha': 3.140140180035988, 'reg_lambda': 3.2300791585554673}. Best is trial 25 with value: 0.63778272588773.\n",
      "[I 2025-09-08 14:19:10,688] Trial 29 finished with value: 0.5528237652633496 and parameters: {'meta_type': 'lgbm', 'n_estimators': 594, 'learning_rate': 0.19731183802133903, 'num_leaves': 50, 'min_child_samples': 17, 'subsample': 0.9843175507085435, 'colsample_bytree': 0.8959186944460145, 'reg_alpha': 0.1579545992765503, 'reg_lambda': 3.754930067770263}. Best is trial 25 with value: 0.63778272588773.\n",
      "[I 2025-09-08 14:19:11,462] Trial 30 finished with value: 0.6298385425080592 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1037, 'learning_rate': 0.06867058492123489, 'num_leaves': 26, 'min_child_samples': 79, 'subsample': 0.689780051203376, 'colsample_bytree': 0.598108336598088, 'reg_alpha': 3.949388459655978, 'reg_lambda': 1.8381849197074729}. Best is trial 25 with value: 0.63778272588773.\n",
      "[I 2025-09-08 14:19:11,964] Trial 31 finished with value: 0.6374406419885228 and parameters: {'meta_type': 'logreg', 'C': 0.6408632021684102, 'l1_ratio': 0.7187395332922486}. Best is trial 25 with value: 0.63778272588773.\n",
      "[I 2025-09-08 14:19:12,473] Trial 32 finished with value: 0.6334070285431447 and parameters: {'meta_type': 'logreg', 'C': 4.100515658716197, 'l1_ratio': 0.7106031142111567}. Best is trial 25 with value: 0.63778272588773.\n",
      "[I 2025-09-08 14:19:12,977] Trial 33 finished with value: 0.6595645542113291 and parameters: {'meta_type': 'logreg', 'C': 0.020522176205286135, 'l1_ratio': 0.9069801597901574}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:13,494] Trial 34 finished with value: 0.5520565533576139 and parameters: {'meta_type': 'logreg', 'C': 0.011178362990199694, 'l1_ratio': 0.8959892536697537}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:14,476] Trial 35 finished with value: 0.6389417989417989 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1497, 'learning_rate': 0.016407828266022658, 'num_leaves': 50, 'min_child_samples': 179, 'subsample': 0.8664389573368141, 'colsample_bytree': 0.8073127098016666, 'reg_alpha': 2.051984933566552, 'reg_lambda': 2.3982544128209335}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:15,380] Trial 36 finished with value: 0.6220149033942137 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1445, 'learning_rate': 0.01576280723241601, 'num_leaves': 52, 'min_child_samples': 193, 'subsample': 0.8781104340289815, 'colsample_bytree': 0.8228836880893486, 'reg_alpha': 2.1739778277864086, 'reg_lambda': 2.312435772069017}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:16,126] Trial 37 finished with value: 0.6267490565494195 and parameters: {'meta_type': 'lgbm', 'n_estimators': 551, 'learning_rate': 0.016890837426187036, 'num_leaves': 52, 'min_child_samples': 153, 'subsample': 0.89123382832531, 'colsample_bytree': 0.834151881551296, 'reg_alpha': 1.4910943705382285, 'reg_lambda': 0.7831832838822188}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:16,966] Trial 38 finished with value: 0.6298259796263426 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1067, 'learning_rate': 0.06572362166439863, 'num_leaves': 62, 'min_child_samples': 160, 'subsample': 0.8835641546573688, 'colsample_bytree': 0.6372905860647262, 'reg_alpha': 3.8910487531338394, 'reg_lambda': 2.787588257864037}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:18,108] Trial 39 finished with value: 0.6288401253918496 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1470, 'learning_rate': 0.019604438728957767, 'num_leaves': 45, 'min_child_samples': 85, 'subsample': 0.799138948340479, 'colsample_bytree': 0.7548968240519163, 'reg_alpha': 2.7887552117225622, 'reg_lambda': 3.966725571093984}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:19,134] Trial 40 finished with value: 0.625795751467644 and parameters: {'meta_type': 'lgbm', 'n_estimators': 812, 'learning_rate': 0.007332028062488592, 'num_leaves': 30, 'min_child_samples': 49, 'subsample': 0.9963063242639438, 'colsample_bytree': 0.8489349668038233, 'reg_alpha': 1.4252244034892638, 'reg_lambda': 2.2471624783934105}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:19,667] Trial 41 finished with value: 0.6553493968046823 and parameters: {'meta_type': 'logreg', 'C': 0.018186385723816145, 'l1_ratio': 0.7892563109861638}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:20,184] Trial 42 finished with value: 0.5962106445839901 and parameters: {'meta_type': 'logreg', 'C': 0.012208329551044516, 'l1_ratio': 0.8100950826915841}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:20,711] Trial 43 finished with value: 0.5432125254796999 and parameters: {'meta_type': 'logreg', 'C': 0.0028085513761170566, 'l1_ratio': 0.7579244668461373}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:21,215] Trial 44 finished with value: 0.6157596465185725 and parameters: {'meta_type': 'ridge', 'alpha': 24.659397597537637}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:21,896] Trial 45 finished with value: 0.6352060965854069 and parameters: {'meta_type': 'lgbm', 'n_estimators': 369, 'learning_rate': 0.11870521392893524, 'num_leaves': 56, 'min_child_samples': 161, 'subsample': 0.8938599128507625, 'colsample_bytree': 0.9926384781508923, 'reg_alpha': 4.2202034278127964, 'reg_lambda': 1.5119655970166517}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:22,415] Trial 46 finished with value: 0.6470288373542069 and parameters: {'meta_type': 'logreg', 'C': 0.020059492407160102, 'l1_ratio': 0.6536895006476033}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:22,920] Trial 47 finished with value: 0.6319032691446484 and parameters: {'meta_type': 'ridge', 'alpha': 0.03584978390544449}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:23,833] Trial 48 finished with value: 0.6171239391390779 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1016, 'learning_rate': 0.043138036405141474, 'num_leaves': 46, 'min_child_samples': 108, 'subsample': 0.7428832145911555, 'colsample_bytree': 0.5834070818560985, 'reg_alpha': 2.5050266310199194, 'reg_lambda': 3.7597074594820055}. Best is trial 33 with value: 0.6595645542113291.\n",
      "[I 2025-09-08 14:19:24,336] Trial 49 finished with value: 0.6394949494949494 and parameters: {'meta_type': 'logreg', 'C': 0.02990692158338161, 'l1_ratio': 0.5991818894481659}. Best is trial 33 with value: 0.6595645542113291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HPO] Best meta params: {'meta_type': 'logreg', 'C': 0.020522176205286135, 'l1_ratio': 0.9069801597901574}\n",
      "[Meta] Best threshold from external validation (F1): 0.4900\n",
      "\n",
      "==== Stacking (LGBM + SVM + LR) — threshold from external val (F1) Performance ====\n",
      "Accuracy:      0.601744\n",
      "AUC:           0.626671\n",
      "PR-AUC:        0.495331\n",
      "LogLoss:       0.676211\n",
      "Precision@0.490: 0.505495\n",
      "Recall@0.490:    0.661871\n",
      "F1@0.490:        0.573209\n",
      "\n",
      "[Notes]\n",
      "- HPO_METRIC = f1 （用于基模型与二层模型的超参搜索目标，可在顶部切换 'auc'/'f1'/'accuracy'/'precision'/'recall'）\n",
      "- 外部验证段阈值学习使用 EXT_THR_METRIC = f1 （'f1'/'accuracy'/'precision'/'recall'）\n",
      "- 全流程严格时序；测试集只在最后一步评估；外部验证段不参与OOF/HPO，避免软泄露。\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Stacking (LGBM + SVM + LR) with time-series OOF, no soft leakage, and switchable HPO metric.\n",
    "Author: Tony + ChatGPT\n",
    "\n",
    "What you can switch:\n",
    "- HPO_METRIC: \"auc\" | \"f1\" | \"accuracy\" | \"precision\" | \"recall\"\n",
    "  (controls both base-model HPO and meta-model HPO objectives)\n",
    "- EXT_THR_METRIC: \"f1\" | \"accuracy\" | \"precision\" | \"recall\"\n",
    "  (controls how we pick the production threshold on the external val)\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from lightgbm import LGBMClassifier, early_stopping\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# ========= 必填：准备 df_clean =========\n",
    "# df_clean = 你的特征DataFrame（列：<feature...> + 'value_sort'）\n",
    "# 例如：\n",
    "# df_clean = pd.read_csv(\"your_data.csv\", parse_dates=[\"date\"], index_col=\"date\").sort_index()\n",
    "# assert \"value_sort\" in df_clean.columns\n",
    "\n",
    "# --------- 这里给一个占位检测，帮助避免忘记注入 df_clean ---------\n",
    "try:\n",
    "    df_clean\n",
    "except NameError as _:\n",
    "    raise RuntimeError(\"请事先在当前解释器中定义 df_clean（含列 'value_sort'）。\")\n",
    "\n",
    "# ========= 全局配置 =========\n",
    "RANDOM_SEED    = 42\n",
    "HPO_METRIC     = \"f1\"         # \"auc\" | \"f1\" | \"accuracy\" | \"precision\" | \"recall\"\n",
    "EXT_THR_METRIC = \"f1\"         # \"f1\" | \"accuracy\" | \"precision\" | \"recall\"\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# ========= 切分：前80%训练，后20%测试；训练末尾10%为外部验证段 =========\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr_raw, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te,     y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "val_tail_ratio = 0.1\n",
    "val_start = max(1, int(len(y_tr) * (1 - val_tail_ratio)))\n",
    "X_tr_fit,  y_tr_fit  = X_tr_raw[:val_start], y_tr[:val_start]   # 用于OOF/HPO/基模型训练\n",
    "X_val_fit, y_val_fit = X_tr_raw[val_start:], y_tr[val_start:]   # 外部验证段（仅阈值学习 & 堆叠验证）\n",
    "\n",
    "# ========= 实用函数 =========\n",
    "def safe_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on_vec(y, p, metric='accuracy'):\n",
    "    \"\"\"在给定 metric 下（accuracy/f1/precision/recall）网格搜阈值并返回最优阈值。\"\"\"\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    metric = metric.lower()\n",
    "    scores = []\n",
    "    for t in ths:\n",
    "        pred = (p >= t).astype(int)\n",
    "        if metric == 'accuracy':\n",
    "            s = accuracy_score(y, pred)\n",
    "        elif metric == 'f1':\n",
    "            s = f1_score(y, pred, zero_division=0)\n",
    "        elif metric == 'precision':\n",
    "            s = precision_score(y, pred, zero_division=0)\n",
    "        elif metric == 'recall':\n",
    "            s = recall_score(y, pred, zero_division=0)\n",
    "        else:\n",
    "            raise ValueError(\"metric must be one of {'accuracy','f1','precision','recall'}\")\n",
    "        scores.append(s)\n",
    "    return float(ths[int(np.argmax(scores))])\n",
    "\n",
    "def ensure_both_classes_for_val(X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit,\n",
    "                                max_expand_ratio=0.3):\n",
    "    \"\"\"确保外部验证段具有双类（必要时扩大或从训练拟合段补齐一些样本）。\"\"\"\n",
    "    if len(np.unique(y_val_fit)) >= 2:\n",
    "        return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "    n_total = len(y_tr)\n",
    "    tail = len(y_val_fit)\n",
    "    # 扩尾法（最多扩到训练的max_expand_ratio）\n",
    "    while len(np.unique(y_val_fit)) < 2 and (tail / n_total) < max_expand_ratio:\n",
    "        new_tail = int(min(n_total * (tail / n_total + 0.05), n_total * max_expand_ratio))\n",
    "        if new_tail <= tail:\n",
    "            break\n",
    "        X_tr_fit = X_tr_raw[:n_total - new_tail]\n",
    "        y_tr_fit = y_tr[:n_total - new_tail]\n",
    "        X_val_fit = X_tr_raw[n_total - new_tail:]\n",
    "        y_val_fit = y_tr[n_total - new_tail:]\n",
    "        tail = new_tail\n",
    "\n",
    "    # 仍单类则从训练拟合段补齐\n",
    "    if len(np.unique(y_val_fit)) < 2:\n",
    "        miss = 1 - int(np.unique(y_val_fit)[0])\n",
    "        pool_idx = np.where(y_tr_fit == miss)[0]\n",
    "        if len(pool_idx) > 0:\n",
    "            rng = np.random.RandomState(1234)\n",
    "            k = min(len(pool_idx), max(1, len(y_val_fit)//2))\n",
    "            pick = rng.choice(pool_idx, size=k, replace=False)\n",
    "            X_val_fit = np.concatenate([X_val_fit, X_tr_fit[pick]], axis=0)\n",
    "            y_val_fit = np.concatenate([y_val_fit, y_tr_fit[pick]], axis=0)\n",
    "            mask = np.ones(len(y_tr_fit), dtype=bool)\n",
    "            mask[pick] = False\n",
    "            X_tr_fit = X_tr_fit[mask]\n",
    "            y_tr_fit = y_tr_fit[mask]\n",
    "    return X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    "\n",
    "X_tr_fit, y_tr_fit, X_val_fit, y_val_fit = ensure_both_classes_for_val(\n",
    "    X_tr_raw, y_tr, X_tr_fit, y_tr_fit, X_val_fit, y_val_fit\n",
    ")\n",
    "print(f\"[Info] Train-fit size: {len(y_tr_fit)}, Val-fit size: {len(y_val_fit)}, \"\n",
    "      f\"Classes in Val: {np.unique(y_val_fit, return_counts=True)}\")\n",
    "\n",
    "def time_series_folds(n_samples, n_splits=5, min_train_ratio=0.5):\n",
    "    \"\"\"递增式时间折：前min_train_ratio作为首个train，后面按等长切val区间。\"\"\"\n",
    "    min_train = int(n_samples * min_train_ratio)\n",
    "    tail = n_samples - min_train\n",
    "    fold_len = max(1, tail // n_splits)\n",
    "    for k in range(n_splits):\n",
    "        start_val = min_train + k * fold_len\n",
    "        end_val   = min(n_samples, start_val + fold_len)\n",
    "        if start_val >= end_val: break\n",
    "        train_idx = np.arange(0, start_val)\n",
    "        val_idx   = np.arange(start_val, end_val)\n",
    "        yield train_idx, val_idx\n",
    "\n",
    "# ========= 按指标计算“折外OOF分数”（支持 AUC/F1/Accuracy/Precision/Recall） =========\n",
    "def fold_metric_score(y_val, p_val, metric: str):\n",
    "    \"\"\"按指定指标计算单折验证段分数；AUC直接算，阈值类指标先扫阈值再打分。\"\"\"\n",
    "    metric = metric.lower()\n",
    "    if metric == \"auc\":\n",
    "        return safe_auc(y_val, p_val), None\n",
    "    elif metric in {\"f1\", \"accuracy\", \"precision\", \"recall\"}:\n",
    "        thr = best_thr_on_vec(y_val, p_val, metric=metric)\n",
    "        pred = (p_val >= thr).astype(int)\n",
    "        if metric == \"accuracy\":\n",
    "            score = accuracy_score(y_val, pred)\n",
    "        elif metric == \"f1\":\n",
    "            score = f1_score(y_val, pred, zero_division=0)\n",
    "        elif metric == \"precision\":\n",
    "            score = precision_score(y_val, pred, zero_division=0)\n",
    "        else:  # \"recall\"\n",
    "            score = recall_score(y_val, pred, zero_division=0)\n",
    "        return float(score), float(thr)\n",
    "    else:\n",
    "        raise ValueError(\"HPO_METRIC must be one of {'auc','f1','accuracy','precision','recall'}\")\n",
    "\n",
    "def aggregate_oof_metric(y, p, folds, metric: str):\n",
    "    \"\"\"对每个折的验证段独立找阈值（若需要），再按验证样本量加权平均分数。\"\"\"\n",
    "    scores, weights, thrs = [], [], []\n",
    "    for _, va_idx in folds:\n",
    "        score, thr = fold_metric_score(y[va_idx], p[va_idx], metric)\n",
    "        scores.append(score); weights.append(len(va_idx)); thrs.append(thr)\n",
    "    scores = np.array(scores); weights = np.array(weights)\n",
    "    wavg = np.sum(scores * weights) / np.sum(weights)\n",
    "    return float(wavg)\n",
    "\n",
    "# ========= 基模型 HPO（在 X_tr_fit 内做时序 OOF；目标=OOF metric） =========\n",
    "def tune_lgbm(n_trials=30):\n",
    "    def objective(trial):\n",
    "        params = dict(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 300, 2000),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "            min_child_samples=trial.suggest_int(\"min_child_samples\", 5, 300),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-8, 1e-1, log=True),\n",
    "            reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-8, 1e-1, log=True),\n",
    "        )\n",
    "        n = X_tr_fit.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        fold_list = list(time_series_folds(n, n_splits=5, min_train_ratio=0.5))\n",
    "        for tr_idx, va_idx in fold_list:\n",
    "            clf = LGBMClassifier(objective=\"binary\", class_weight=\"balanced\",\n",
    "                                 verbosity=-1, random_state=RANDOM_SEED, **params)\n",
    "            # 重要：折内早停，用折内 val（不再使用外部验证段）\n",
    "            clf.fit(\n",
    "                X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "                eval_set=[(X_tr_fit[va_idx], y_tr_fit[va_idx])],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[early_stopping(200, verbose=False)]\n",
    "            )\n",
    "            oof[va_idx] = clf.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return aggregate_oof_metric(y_tr_fit, oof, fold_list, HPO_METRIC)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "def tune_lr(n_trials=30):\n",
    "    def objective(trial):\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 100.0, log=True)\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "        n = X_tr_fit.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        fold_list = list(time_series_folds(n, n_splits=5, min_train_ratio=0.5))\n",
    "        for tr_idx, va_idx in fold_list:\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"lr\", LogisticRegression(\n",
    "                    penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "                    class_weight=None, C=C, l1_ratio=l1_ratio, random_state=RANDOM_SEED\n",
    "                ))\n",
    "            ])\n",
    "            pipe.fit(X_tr_fit[tr_idx], y_tr_fit[tr_idx])\n",
    "            oof[va_idx] = pipe.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return aggregate_oof_metric(y_tr_fit, oof, fold_list, HPO_METRIC)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "def tune_svm(n_trials=30):\n",
    "    def objective(trial):\n",
    "        C = trial.suggest_float(\"C\", 1e-2, 1e3, log=True)\n",
    "        gamma = trial.suggest_float(\"gamma\", 1e-4, 10.0, log=True)\n",
    "        n = X_tr_fit.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        fold_list = list(time_series_folds(n, n_splits=5, min_train_ratio=0.5))\n",
    "        for tr_idx, va_idx in fold_list:\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"svc\", SVC(\n",
    "                    kernel=\"rbf\", C=C, gamma=gamma, probability=True,\n",
    "                    class_weight=None, random_state=RANDOM_SEED\n",
    "                ))\n",
    "            ])\n",
    "            pipe.fit(X_tr_fit[tr_idx], y_tr_fit[tr_idx])\n",
    "            oof[va_idx] = pipe.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return aggregate_oof_metric(y_tr_fit, oof, fold_list, HPO_METRIC)\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "# —— 执行基模型 HPO（可先把 n_trials 调小快速试跑）——\n",
    "BEST_LGBM = tune_lgbm(n_trials=30)\n",
    "BEST_LR   = tune_lr(n_trials=30)\n",
    "BEST_SVM  = tune_svm(n_trials=30)\n",
    "\n",
    "print(\"\\n[HPO] BEST_LGBM:\", BEST_LGBM)\n",
    "print(\"[HPO] BEST_LR:\", BEST_LR)\n",
    "print(\"[HPO] BEST_SVM:\", BEST_SVM)\n",
    "\n",
    "# ========= 第一层基模型（LGBM + SVM + LR） =========\n",
    "def make_base_models():\n",
    "    base_lgbm = LGBMClassifier(objective=\"binary\", verbosity=-1,\n",
    "                               class_weight=\"balanced\", random_state=RANDOM_SEED, **BEST_LGBM)\n",
    "    base_svm  = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", probability=True, random_state=RANDOM_SEED, **BEST_SVM))\n",
    "    ])\n",
    "    base_lr   = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "                                  random_state=RANDOM_SEED, **BEST_LR))\n",
    "    ])\n",
    "    return [base_lgbm, base_svm, base_lr]\n",
    "\n",
    "# ========= 生成 OOF（堆叠训练集 Z_train），折内早停仅用折内val =========\n",
    "base_models_for_oof = make_base_models()\n",
    "M = len(base_models_for_oof)\n",
    "n_train = X_tr_fit.shape[0]\n",
    "OOF = np.zeros((n_train, M))\n",
    "val_mask = np.zeros(n_train, dtype=bool)\n",
    "val_y    = np.zeros(n_train)\n",
    "fold_list_main = list(time_series_folds(n_train, n_splits=5, min_train_ratio=0.5))\n",
    "\n",
    "for m, model0 in enumerate(base_models_for_oof):\n",
    "    for tr_idx, va_idx in fold_list_main:\n",
    "        model = deepcopy(model0)  # 每折独立实例化，避免状态残留\n",
    "        if isinstance(model, LGBMClassifier):\n",
    "            model.fit(\n",
    "                X_tr_fit[tr_idx], y_tr_fit[tr_idx],\n",
    "                eval_set=[(X_tr_fit[va_idx], y_tr_fit[va_idx])],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[early_stopping(200, verbose=False)]\n",
    "            )\n",
    "        else:\n",
    "            model.fit(X_tr_fit[tr_idx], y_tr_fit[tr_idx])\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            prob = model.predict_proba(X_tr_fit[va_idx])[:, 1]\n",
    "        else:\n",
    "            decision = model.decision_function(X_tr_fit[va_idx])\n",
    "            prob = 1 / (1 + np.exp(-decision))\n",
    "        OOF[va_idx, m] = prob\n",
    "        val_mask[va_idx] = True\n",
    "        val_y[va_idx]    = y_tr_fit[va_idx]\n",
    "\n",
    "Z_train = OOF[val_mask]\n",
    "y_meta  = val_y[val_mask]\n",
    "\n",
    "# ========= 外部验证段：训练好的基模型（用全部 X_tr_fit 拟合一次），产生 Z_val =========\n",
    "fitted_bases = []\n",
    "Z_val = np.zeros((X_val_fit.shape[0], M))\n",
    "for i, model in enumerate(make_base_models()):\n",
    "    if isinstance(model, LGBMClassifier):\n",
    "        # 这里可以使用外部验证段做早停（仅控制拟合轮次，不影响OOF/HPO）\n",
    "        model.fit(\n",
    "            X_tr_fit, y_tr_fit,\n",
    "            eval_set=[(X_val_fit, y_val_fit)],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[early_stopping(200, verbose=False)]\n",
    "        )\n",
    "    else:\n",
    "        model.fit(X_tr_fit, y_tr_fit)\n",
    "    fitted_bases.append(model)\n",
    "    prob_val = (model.predict_proba(X_val_fit)[:, 1]\n",
    "                if hasattr(model, \"predict_proba\")\n",
    "                else 1/(1+np.exp(-model.decision_function(X_val_fit))))\n",
    "    Z_val[:, i] = prob_val\n",
    "\n",
    "# ========= 二层（元学习器）HPO：同样按 HPO_METRIC 做时序OOF =========\n",
    "def build_meta(trial):\n",
    "    meta_type = trial.suggest_categorical(\"meta_type\", [\"logreg\", \"ridge\", \"lgbm\"])\n",
    "    if meta_type == \"logreg\":\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 100.0, log=True)\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "        return Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"lr\", LogisticRegression(\n",
    "                penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "                class_weight=\"balanced\", C=C, l1_ratio=l1_ratio, random_state=123\n",
    "            ))\n",
    "        ])\n",
    "    if meta_type == \"ridge\":\n",
    "        alpha = trial.suggest_float(\"alpha\", 1e-3, 100.0, log=True)\n",
    "        # RidgeClassifier 没有概率，二层更推荐LogReg/LGBM；这里仍支持（用决策函数过sigmoid）\n",
    "        return RidgeClassifier(alpha=alpha, random_state=123)\n",
    "    if meta_type == \"lgbm\":\n",
    "        params = dict(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 7, 63),\n",
    "            min_child_samples=trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "            reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 5.0)\n",
    "        )\n",
    "        return LGBMClassifier(objective=\"binary\", class_weight=\"balanced\",\n",
    "                              verbosity=-1, random_state=123, **params)\n",
    "\n",
    "def objective_meta(trial):\n",
    "    n = Z_train.shape[0]\n",
    "    oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "    folds = list(time_series_folds(n, n_splits=5, min_train_ratio=0.6))\n",
    "    for tr_idx, va_idx in folds:\n",
    "        meta = build_meta(trial)\n",
    "        Xtr, Xva = Z_train[tr_idx], Z_train[va_idx]\n",
    "        ytr, yva = y_meta[tr_idx], y_meta[va_idx]\n",
    "        if isinstance(meta, RidgeClassifier):\n",
    "            meta.fit(Xtr, ytr)\n",
    "            prob = 1/(1+np.exp(-meta.decision_function(Xva)))\n",
    "        else:\n",
    "            meta.fit(Xtr, ytr)\n",
    "            prob = (meta.predict_proba(Xva)[:,1]\n",
    "                    if hasattr(meta, \"predict_proba\")\n",
    "                    else 1/(1+np.exp(-meta.decision_function(Xva))))\n",
    "        oof[va_idx] = prob; seen[va_idx] = True\n",
    "    return aggregate_oof_metric(y_meta, oof, folds, HPO_METRIC)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective_meta, n_trials=50, show_progress_bar=False)\n",
    "best_meta_params = study.best_params\n",
    "print(\"\\n[HPO] Best meta params:\", best_meta_params)\n",
    "\n",
    "# ========= 训练最优二层；在外部验证段上学阈值（按 EXT_THR_METRIC） =========\n",
    "def instantiate_meta_from_params(params):\n",
    "    # 复用 build_meta 的配置空间\n",
    "    trial = optuna.trial.FixedTrial(params)\n",
    "    return build_meta(trial)\n",
    "\n",
    "best_meta = instantiate_meta_from_params(best_meta_params)\n",
    "best_meta.fit(Z_train, y_meta)\n",
    "\n",
    "y_val_meta_prob = (best_meta.predict_proba(Z_val)[:, 1]\n",
    "                   if hasattr(best_meta, \"predict_proba\")\n",
    "                   else 1/(1+np.exp(-best_meta.decision_function(Z_val))))\n",
    "best_thr = best_thr_on_vec(y_val_fit, y_val_meta_prob, metric=EXT_THR_METRIC)\n",
    "print(f\"[Meta] Best threshold from external validation ({EXT_THR_METRIC.upper()}): {best_thr:.4f}\")\n",
    "\n",
    "# ========= 测试集融合：先堆叠 test，再用 best_meta + 固定阈值评估 =========\n",
    "test_stack = np.zeros((X_te.shape[0], M))\n",
    "for i, model in enumerate(fitted_bases):\n",
    "    prob_te = (model.predict_proba(X_te)[:, 1]\n",
    "               if hasattr(model, \"predict_proba\")\n",
    "               else 1/(1+np.exp(-model.decision_function(X_te))))\n",
    "    test_stack[:, i] = prob_te\n",
    "\n",
    "y_prob_stack = (best_meta.predict_proba(test_stack)[:, 1]\n",
    "                if hasattr(best_meta, \"predict_proba\")\n",
    "                else 1/(1+np.exp(-best_meta.decision_function(test_stack))))\n",
    "\n",
    "report_all(\n",
    "    y_te, y_prob_stack, thr=best_thr,\n",
    "    title=f\"Stacking (LGBM + SVM + LR) — threshold from external val ({EXT_THR_METRIC.upper()})\"\n",
    ")\n",
    "\n",
    "print(\"\\n[Notes]\")\n",
    "print(f\"- HPO_METRIC = {HPO_METRIC} （用于基模型与二层模型的超参搜索目标，可在顶部切换 'auc'/'f1'/'accuracy'/'precision'/'recall'）\")\n",
    "print(f\"- 外部验证段阈值学习使用 EXT_THR_METRIC = {EXT_THR_METRIC} （'f1'/'accuracy'/'precision'/'recall'）\")\n",
    "print(\"- 全流程严格时序；测试集只在最后一步评估；外部验证段不参与OOF/HPO，避免软泄露。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0974ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Export] Saved test predictions to: stack_test_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ========= 导出测试集预测结果到 Excel =========\n",
    "# 测试集对应的原索引（例如时间索引）\n",
    "test_index = df_clean.index[split_pt:]\n",
    "\n",
    "# 根据学到的阈值生成离散预测\n",
    "y_pred_stack = (y_prob_stack >= best_thr).astype(int)\n",
    "\n",
    "# 组装为 DataFrame（按你的要求四列）\n",
    "df_out = pd.DataFrame({\n",
    "    \"index\": test_index,\n",
    "    \"y_true\": 1 -y_te.astype(int),\n",
    "    \"y_prob\": y_prob_stack.astype(float),\n",
    "    \"y_pred\": 1 - y_pred_stack.astype(int),\n",
    "})\n",
    "\n",
    "# 写入 Excel（不额外保存行索引）\n",
    "out_path = \"stack_test_results.xlsx\"\n",
    "df_out.to_excel(out_path, index=False)\n",
    "print(f\"\\n[Export] Saved test predictions to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3bfb8",
   "metadata": {},
   "source": [
    "### 面向测试集调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 14:32:48,598] A new study created in memory with name: no-name-4b734a82-65be-4b35-869e-e2df91ebbb31\n",
      "[I 2025-09-01 14:32:50,070] Trial 0 finished with value: 0.6585879490950021 and parameters: {'n_estimators': 937, 'learning_rate': 0.2536999076681772, 'num_leaves': 191, 'max_depth': 8, 'min_child_samples': 51, 'subsample': 0.5779972601681014, 'colsample_bytree': 0.5290418060840998, 'reg_alpha': 0.011567327199145964, 'reg_lambda': 0.00016136341713591298}. Best is trial 0 with value: 0.6585879490950021.\n",
      "[I 2025-09-01 14:32:54,869] Trial 1 finished with value: 0.6633171758981901 and parameters: {'n_estimators': 1504, 'learning_rate': 0.010725209743171996, 'num_leaves': 248, 'max_depth': 11, 'min_child_samples': 67, 'subsample': 0.5909124836035503, 'colsample_bytree': 0.5917022549267169, 'reg_alpha': 1.348018029089077e-06, 'reg_lambda': 4.712973756110775e-05}. Best is trial 1 with value: 0.6633171758981901.\n",
      "[I 2025-09-01 14:32:56,924] Trial 2 finished with value: 0.655955557976145 and parameters: {'n_estimators': 1034, 'learning_rate': 0.02692655251486473, 'num_leaves': 162, 'max_depth': 4, 'min_child_samples': 91, 'subsample': 0.6831809216468459, 'colsample_bytree': 0.728034992108518, 'reg_alpha': 0.003134958021096905, 'reg_lambda': 2.498713568466942e-07}. Best is trial 1 with value: 0.6633171758981901.\n",
      "[I 2025-09-01 14:33:05,875] Trial 3 finished with value: 0.6607120164115969 and parameters: {'n_estimators': 1174, 'learning_rate': 0.07500118950416987, 'num_leaves': 26, 'max_depth': 9, 'min_child_samples': 55, 'subsample': 0.5325257964926398, 'colsample_bytree': 0.9744427686266666, 'reg_alpha': 0.05746775499181854, 'reg_lambda': 0.004558074684027324}. Best is trial 1 with value: 0.6633171758981901.\n",
      "[I 2025-09-01 14:33:15,331] Trial 4 finished with value: 0.6712052720440063 and parameters: {'n_estimators': 818, 'learning_rate': 0.013940346079873234, 'num_leaves': 179, 'max_depth': 7, 'min_child_samples': 41, 'subsample': 0.7475884550556351, 'colsample_bytree': 0.5171942605576092, 'reg_alpha': 0.023186906702901938, 'reg_lambda': 6.478282331897318e-07}. Best is trial 4 with value: 0.6712052720440063.\n",
      "[I 2025-09-01 14:33:30,926] Trial 5 finished with value: 0.659295971533867 and parameters: {'n_estimators': 1426, 'learning_rate': 0.028869220380495747, 'num_leaves': 140, 'max_depth': 8, 'min_child_samples': 59, 'subsample': 0.9847923138822793, 'colsample_bytree': 0.8875664116805573, 'reg_alpha': 0.037713131110779854, 'reg_lambda': 0.018356566544355055}. Best is trial 4 with value: 0.6712052720440063.\n",
      "[I 2025-09-01 14:33:40,642] Trial 6 finished with value: 0.656636348782746 and parameters: {'n_estimators': 1317, 'learning_rate': 0.22999586428143728, 'num_leaves': 36, 'max_depth': 4, 'min_child_samples': 18, 'subsample': 0.6626651653816322, 'colsample_bytree': 0.6943386448447411, 'reg_alpha': 7.933105363733006e-07, 'reg_lambda': 0.006326486185661575}. Best is trial 4 with value: 0.6712052720440063.\n",
      "[I 2025-09-01 14:33:43,169] Trial 7 finished with value: 0.6573352940108563 and parameters: {'n_estimators': 906, 'learning_rate': 0.026000059117302653, 'num_leaves': 145, 'max_depth': 4, 'min_child_samples': 242, 'subsample': 0.5372753218398854, 'colsample_bytree': 0.9934434683002586, 'reg_alpha': 0.0025451500130912884, 'reg_lambda': 2.4604229580184137e-07}. Best is trial 4 with value: 0.6712052720440063.\n",
      "[I 2025-09-01 14:33:44,084] Trial 8 finished with value: 0.6407239983297932 and parameters: {'n_estimators': 309, 'learning_rate': 0.1601531217136121, 'num_leaves': 185, 'max_depth': 10, 'min_child_samples': 233, 'subsample': 0.5370223258670452, 'colsample_bytree': 0.6792328642721364, 'reg_alpha': 6.472669269538615e-08, 'reg_lambda': 0.011008394410181295}. Best is trial 4 with value: 0.6712052720440063.\n",
      "[I 2025-09-01 14:33:49,657] Trial 9 finished with value: 0.652760379790498 and parameters: {'n_estimators': 1360, 'learning_rate': 0.030816017044468066, 'num_leaves': 30, 'max_depth': 6, 'min_child_samples': 101, 'subsample': 0.864803089169032, 'colsample_bytree': 0.8187787356776066, 'reg_alpha': 0.016236379661338295, 'reg_lambda': 2.0207122587167337e-05}. Best is trial 4 with value: 0.6712052720440063.\n",
      "[I 2025-09-01 14:33:52,644] Trial 10 finished with value: 0.6608663289944265 and parameters: {'n_estimators': 1907, 'learning_rate': 0.010206070557576998, 'num_leaves': 89, 'max_depth': 6, 'min_child_samples': 163, 'subsample': 0.8036901462240623, 'colsample_bytree': 0.5075634079566923, 'reg_alpha': 0.0001972129985951013, 'reg_lambda': 2.146579851025732e-08}. Best is trial 4 with value: 0.6712052720440063.\n",
      "[I 2025-09-01 14:33:53,693] Trial 11 finished with value: 0.6773051576711507 and parameters: {'n_estimators': 513, 'learning_rate': 0.010555894926322258, 'num_leaves': 242, 'max_depth': 12, 'min_child_samples': 140, 'subsample': 0.6760277706246425, 'colsample_bytree': 0.5997477096084406, 'reg_alpha': 9.767561163926882e-06, 'reg_lambda': 1.5885164622243413e-05}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:33:54,688] Trial 12 finished with value: 0.6765245175462484 and parameters: {'n_estimators': 524, 'learning_rate': 0.016324514507051233, 'num_leaves': 244, 'max_depth': 12, 'min_child_samples': 167, 'subsample': 0.7480206560848571, 'colsample_bytree': 0.6178606265353371, 'reg_alpha': 4.357042179639525e-05, 'reg_lambda': 2.338988433239291e-06}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:33:55,524] Trial 13 finished with value: 0.6764337454387016 and parameters: {'n_estimators': 442, 'learning_rate': 0.017026154117980523, 'num_leaves': 254, 'max_depth': 12, 'min_child_samples': 168, 'subsample': 0.7013091609538729, 'colsample_bytree': 0.62077746649017, 'reg_alpha': 3.0171559278838854e-05, 'reg_lambda': 2.0510509750420737e-06}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:33:56,178] Trial 14 finished with value: 0.6597770637038651 and parameters: {'n_estimators': 649, 'learning_rate': 0.05412598241868387, 'num_leaves': 220, 'max_depth': 12, 'min_child_samples': 299, 'subsample': 0.8383174003650329, 'colsample_bytree': 0.6230067264563669, 'reg_alpha': 2.437077907695549e-05, 'reg_lambda': 5.220332299303262e-06}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:33:57,521] Trial 15 finished with value: 0.6673656118947769 and parameters: {'n_estimators': 562, 'learning_rate': 0.019293369292093035, 'num_leaves': 217, 'max_depth': 10, 'min_child_samples': 129, 'subsample': 0.7643984493790572, 'colsample_bytree': 0.7859309796575296, 'reg_alpha': 1.9338445918815573e-06, 'reg_lambda': 0.00045901574758297215}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:33:58,421] Trial 16 finished with value: 0.64605232104279 and parameters: {'n_estimators': 690, 'learning_rate': 0.04636458067332012, 'num_leaves': 89, 'max_depth': 11, 'min_child_samples': 200, 'subsample': 0.9298249375977756, 'colsample_bytree': 0.5846107311632509, 'reg_alpha': 0.00029109418423311866, 'reg_lambda': 1.2366719225667896e-08}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:33:59,196] Trial 17 finished with value: 0.6613292667429154 and parameters: {'n_estimators': 312, 'learning_rate': 0.0793423791839793, 'num_leaves': 226, 'max_depth': 12, 'min_child_samples': 129, 'subsample': 0.6445217592035919, 'colsample_bytree': 0.6601698676289585, 'reg_alpha': 1.795286200247655e-08, 'reg_lambda': 0.0004996418082651761}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:34:01,498] Trial 18 finished with value: 0.65128987164824 and parameters: {'n_estimators': 1787, 'learning_rate': 0.014805330729616196, 'num_leaves': 105, 'max_depth': 10, 'min_child_samples': 197, 'subsample': 0.736061287588024, 'colsample_bytree': 0.5706770169804495, 'reg_alpha': 7.552061634331524e-06, 'reg_lambda': 8.00491902635637e-06}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:34:02,680] Trial 19 finished with value: 0.6685365720821306 and parameters: {'n_estimators': 535, 'learning_rate': 0.020573151099978502, 'num_leaves': 203, 'max_depth': 11, 'min_child_samples': 136, 'subsample': 0.61495172443368, 'colsample_bytree': 0.7491025122658858, 'reg_alpha': 0.00019813493479356554, 'reg_lambda': 7.967246295126507e-08}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:34:03,942] Trial 20 finished with value: 0.6482671604669318 and parameters: {'n_estimators': 769, 'learning_rate': 0.037247584077775044, 'num_leaves': 232, 'max_depth': 9, 'min_child_samples': 192, 'subsample': 0.9005419643298582, 'colsample_bytree': 0.8490483200027008, 'reg_alpha': 0.0007356021780399486, 'reg_lambda': 0.09055230200461421}. Best is trial 11 with value: 0.6773051576711507.\n",
      "[I 2025-09-01 14:34:04,795] Trial 21 finished with value: 0.6782491875896375 and parameters: {'n_estimators': 477, 'learning_rate': 0.016986681854303406, 'num_leaves': 236, 'max_depth': 12, 'min_child_samples': 165, 'subsample': 0.6965101889428231, 'colsample_bytree': 0.629959468368531, 'reg_alpha': 2.983987972895709e-05, 'reg_lambda': 1.8458599124132515e-06}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:06,015] Trial 22 finished with value: 0.6750630866147449 and parameters: {'n_estimators': 456, 'learning_rate': 0.013599459876442017, 'num_leaves': 255, 'max_depth': 12, 'min_child_samples': 101, 'subsample': 0.7962645359951741, 'colsample_bytree': 0.6372818009011647, 'reg_alpha': 6.669507698466873e-06, 'reg_lambda': 1.526252909977575e-06}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:06,574] Trial 23 finished with value: 0.6712052720440064 and parameters: {'n_estimators': 430, 'learning_rate': 0.010984385520609161, 'num_leaves': 208, 'max_depth': 11, 'min_child_samples': 228, 'subsample': 0.7121543628480164, 'colsample_bytree': 0.5588210086708917, 'reg_alpha': 7.338639738298274e-05, 'reg_lambda': 3.480365275578131e-05}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:07,851] Trial 24 finished with value: 0.6602763102953725 and parameters: {'n_estimators': 658, 'learning_rate': 0.02028437211834526, 'num_leaves': 234, 'max_depth': 12, 'min_child_samples': 148, 'subsample': 0.6252098121189111, 'colsample_bytree': 0.7065388942237791, 'reg_alpha': 3.0727333876831644e-07, 'reg_lambda': 3.2009929930028573e-06}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:09,458] Trial 25 finished with value: 0.6677377775357188 and parameters: {'n_estimators': 1035, 'learning_rate': 0.013169850656638497, 'num_leaves': 169, 'max_depth': 10, 'min_child_samples': 175, 'subsample': 0.7661070727433523, 'colsample_bytree': 0.6463567920534524, 'reg_alpha': 8.648000287934201e-06, 'reg_lambda': 7.766783151827254e-07}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:10,059] Trial 26 finished with value: 0.6688905833015631 and parameters: {'n_estimators': 575, 'learning_rate': 0.02132006050645245, 'num_leaves': 239, 'max_depth': 11, 'min_child_samples': 279, 'subsample': 0.6698229838256848, 'colsample_bytree': 0.6035548202781365, 'reg_alpha': 6.735257466651036e-05, 'reg_lambda': 1.1886864262355133e-05}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:11,888] Trial 27 finished with value: 0.6543852005155855 and parameters: {'n_estimators': 839, 'learning_rate': 0.10222688324868048, 'num_leaves': 205, 'max_depth': 9, 'min_child_samples': 115, 'subsample': 0.7183426573542904, 'colsample_bytree': 0.5392661283932232, 'reg_alpha': 3.818268530970089e-06, 'reg_lambda': 9.83322034921762e-05}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:12,498] Trial 28 finished with value: 0.6560826389267106 and parameters: {'n_estimators': 376, 'learning_rate': 0.034385556340785106, 'num_leaves': 114, 'max_depth': 3, 'min_child_samples': 216, 'subsample': 0.7909470980479408, 'colsample_bytree': 0.7215514614076001, 'reg_alpha': 1.693142118224869e-05, 'reg_lambda': 4.347916616283758e-08}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:13,867] Trial 29 finished with value: 0.6654140115825209 and parameters: {'n_estimators': 750, 'learning_rate': 0.016340374608086107, 'num_leaves': 190, 'max_depth': 12, 'min_child_samples': 150, 'subsample': 0.5726220110067168, 'colsample_bytree': 0.5447178937156802, 'reg_alpha': 2.4000418254035197e-07, 'reg_lambda': 0.00015910658461283986}. Best is trial 21 with value: 0.6782491875896375.\n",
      "[I 2025-09-01 14:34:13,868] A new study created in memory with name: no-name-230235d9-4b72-42c5-b6f3-420106b7cdf7\n",
      "[I 2025-09-01 14:34:15,035] Trial 0 finished with value: 0.6451082911243033 and parameters: {'C': 0.0745934328572655, 'l1_ratio': 0.9507143064099162}. Best is trial 0 with value: 0.6451082911243033.\n",
      "[I 2025-09-01 14:34:38,823] Trial 1 finished with value: 0.5865875133888858 and parameters: {'C': 4.5705630998014515, 'l1_ratio': 0.5986584841970366}. Best is trial 0 with value: 0.6451082911243033.\n",
      "[I 2025-09-01 14:34:39,289] Trial 2 finished with value: 0.6628270065174373 and parameters: {'C': 0.006026889128682512, 'l1_ratio': 0.15599452033620265}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:34:39,363] Trial 3 finished with value: 0.5049743114935643 and parameters: {'C': 0.0019517224641449498, 'l1_ratio': 0.8661761457749352}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:34:49,649] Trial 4 finished with value: 0.6050142512208849 and parameters: {'C': 1.0129197956845732, 'l1_ratio': 0.7080725777960455}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:34:49,688] Trial 5 finished with value: 0.5049743114935643 and parameters: {'C': 0.001267425589893723, 'l1_ratio': 0.9699098521619943}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:06,535] Trial 6 finished with value: 0.582339378755696 and parameters: {'C': 14.528246637516036, 'l1_ratio': 0.21233911067827616}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:06,879] Trial 7 finished with value: 0.6614563476934807 and parameters: {'C': 0.008111941985431923, 'l1_ratio': 0.18340450985343382}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:07,664] Trial 8 finished with value: 0.6505092315233376 and parameters: {'C': 0.033205591037519584, 'l1_ratio': 0.5247564316322378}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:09,292] Trial 9 finished with value: 0.6244939455004266 and parameters: {'C': 0.14445251022763064, 'l1_ratio': 0.2912291401980419}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:34,149] Trial 10 finished with value: 0.5808507161919285 and parameters: {'C': 53.17196633982125, 'l1_ratio': 0.005997182955817193}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:34,881] Trial 11 finished with value: 0.6604487772997113 and parameters: {'C': 0.011983829487007384, 'l1_ratio': 0.2555181508867127}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:35,376] Trial 12 finished with value: 0.6491839587531544 and parameters: {'C': 0.006971123012897827, 'l1_ratio': 0.038725199961182954}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:43,996] Trial 13 finished with value: 0.6081458889312492 and parameters: {'C': 0.544928039897282, 'l1_ratio': 0.3924528921026325}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:44,504] Trial 14 finished with value: 0.655955557976145 and parameters: {'C': 0.007561198162730505, 'l1_ratio': 0.1255529720465407}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:45,712] Trial 15 finished with value: 0.6514895702848429 and parameters: {'C': 0.02533989267880574, 'l1_ratio': 0.407225069980497}. Best is trial 2 with value: 0.6628270065174373.\n",
      "[I 2025-09-01 14:35:46,055] Trial 16 finished with value: 0.6685184176606213 and parameters: {'C': 0.00336613848725774, 'l1_ratio': 0.14405154622530358}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:35:46,225] Trial 17 finished with value: 0.5328231940889203 and parameters: {'C': 0.002400220468000353, 'l1_ratio': 0.36909361820990294}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:35:49,910] Trial 18 finished with value: 0.61449085924877 and parameters: {'C': 0.1628251948592309, 'l1_ratio': 0.10754868704932502}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:35:49,981] Trial 19 finished with value: 0.4987564221266089 and parameters: {'C': 0.0010996893674165798, 'l1_ratio': 0.678948064898575}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:05,634] Trial 20 finished with value: 0.592215384056787 and parameters: {'C': 1.8408389745834335, 'l1_ratio': 0.32176717760026485}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:05,898] Trial 21 finished with value: 0.6677922408002469 and parameters: {'C': 0.0050194151469280775, 'l1_ratio': 0.19627506050221602}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:06,089] Trial 22 finished with value: 0.665976798649311 and parameters: {'C': 0.003495786544047756, 'l1_ratio': 0.11652629063915484}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:06,652] Trial 23 finished with value: 0.6364304776428298 and parameters: {'C': 0.030817264852033247, 'l1_ratio': 0.07108833264425789}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:06,796] Trial 24 finished with value: 0.5468202530726358 and parameters: {'C': 0.0034835065433695142, 'l1_ratio': 0.47969584949267774}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:07,285] Trial 25 finished with value: 0.6482943920991958 and parameters: {'C': 0.018466550431704476, 'l1_ratio': 0.2327767753201073}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:08,253] Trial 26 finished with value: 0.625755677795327 and parameters: {'C': 0.06960620000603192, 'l1_ratio': 0.08780100138860267}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:08,426] Trial 27 finished with value: 0.6666485122451572 and parameters: {'C': 0.0024796336953268063, 'l1_ratio': 0.15953089830684697}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:08,622] Trial 28 finished with value: 0.6427028302743132 and parameters: {'C': 0.003485384961451231, 'l1_ratio': 0.303446300888558}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:09,772] Trial 29 finished with value: 0.6183849826625275 and parameters: {'C': 0.06948299705908421, 'l1_ratio': 0.0028219025209752224}. Best is trial 16 with value: 0.6685184176606213.\n",
      "[I 2025-09-01 14:36:09,773] A new study created in memory with name: no-name-26cb5eaf-2df4-4af9-9015-1fd5c58965d0\n",
      "[I 2025-09-01 14:36:11,221] Trial 0 finished with value: 0.5273587132146034 and parameters: {'C': 0.7459343285726545, 'gamma': 5.669849511478847}. Best is trial 0 with value: 0.5273587132146034.\n",
      "[I 2025-09-01 14:36:12,576] Trial 1 finished with value: 0.5568233393242924 and parameters: {'C': 45.70563099801453, 'gamma': 0.09846738873614563}. Best is trial 1 with value: 0.5568233393242924.\n",
      "[I 2025-09-01 14:36:13,536] Trial 2 finished with value: 0.6633353303196994 and parameters: {'C': 0.06026889128682508, 'gamma': 0.000602521573620386}. Best is trial 2 with value: 0.6633353303196994.\n",
      "[I 2025-09-01 14:36:14,828] Trial 3 finished with value: 0.5273587132146034 and parameters: {'C': 0.0195172246414495, 'gamma': 2.1423021757741068}. Best is trial 2 with value: 0.6633353303196994.\n",
      "[I 2025-09-01 14:36:16,070] Trial 4 finished with value: 0.5298821778044043 and parameters: {'C': 10.129197956845726, 'gamma': 0.3470266988650412}. Best is trial 2 with value: 0.6633353303196994.\n",
      "[I 2025-09-01 14:36:17,298] Trial 5 finished with value: 0.5273587132146034 and parameters: {'C': 0.012674255898937233, 'gamma': 7.072114131472227}. Best is trial 2 with value: 0.6633353303196994.\n",
      "[I 2025-09-01 14:36:19,349] Trial 6 finished with value: 0.57429697002705 and parameters: {'C': 145.28246637516014, 'gamma': 0.0011526449540315614}. Best is trial 2 with value: 0.6633353303196994.\n",
      "[I 2025-09-01 14:36:20,329] Trial 7 finished with value: 0.6678240110378884 and parameters: {'C': 0.08111941985431921, 'gamma': 0.0008260808399079611}. Best is trial 7 with value: 0.6678240110378884.\n",
      "[I 2025-09-01 14:36:21,517] Trial 8 finished with value: 0.6052366428843745 and parameters: {'C': 0.3320559103751956, 'gamma': 0.042051564509138675}. Best is trial 7 with value: 0.6678240110378884.\n",
      "[I 2025-09-01 14:36:22,476] Trial 9 finished with value: 0.6709511101428753 and parameters: {'C': 1.4445251022763053, 'gamma': 0.0028585493941961923}. Best is trial 9 with value: 0.6709511101428753.\n",
      "[I 2025-09-01 14:36:23,645] Trial 10 finished with value: 0.6386543942777263 and parameters: {'C': 4.053834553028505, 'gamma': 0.006344493151988632}. Best is trial 9 with value: 0.6709511101428753.\n",
      "[I 2025-09-01 14:36:24,641] Trial 11 finished with value: 0.64803115298731 and parameters: {'C': 0.3968021095121739, 'gamma': 0.00012196019578853642}. Best is trial 9 with value: 0.6709511101428753.\n",
      "[I 2025-09-01 14:36:25,607] Trial 12 finished with value: 0.6623640687689487 and parameters: {'C': 0.16700125058925383, 'gamma': 0.004848332613939981}. Best is trial 9 with value: 0.6709511101428753.\n",
      "[I 2025-09-01 14:36:26,607] Trial 13 finished with value: 0.6577074596517981 and parameters: {'C': 2.191795846392853, 'gamma': 0.004234479062789693}. Best is trial 9 with value: 0.6709511101428753.\n",
      "[I 2025-09-01 14:36:28,128] Trial 14 finished with value: 0.5977797142494055 and parameters: {'C': 543.0119434848286, 'gamma': 0.00011474362129890263}. Best is trial 9 with value: 0.6709511101428753.\n",
      "[I 2025-09-01 14:36:29,112] Trial 15 finished with value: 0.6699889258028793 and parameters: {'C': 0.07102715975388059, 'gamma': 0.0010467691057016403}. Best is trial 9 with value: 0.6709511101428753.\n",
      "[I 2025-09-01 14:36:30,352] Trial 16 finished with value: 0.6296815714467259 and parameters: {'C': 17.721392005157938, 'gamma': 0.014851877511086235}. Best is trial 9 with value: 0.6709511101428753.\n",
      "[I 2025-09-01 14:36:31,275] Trial 17 finished with value: 0.6776727847067153 and parameters: {'C': 1.1377936958968322, 'gamma': 0.0015861085846054562}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:32,547] Trial 18 finished with value: 0.5308625165659095 and parameters: {'C': 1.4983109873380083, 'gamma': 0.3088642425783607}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:33,507] Trial 19 finished with value: 0.6556015467567127 and parameters: {'C': 8.113077078966386, 'gamma': 0.0003934947257226475}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:34,748] Trial 20 finished with value: 0.6244939455004266 and parameters: {'C': 29.59838423188361, 'gamma': 0.02117255372771633}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:35,727] Trial 21 finished with value: 0.6634533340595101 and parameters: {'C': 0.0391902861580148, 'gamma': 0.0020021172215098286}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:36,723] Trial 22 finished with value: 0.6539131855563423 and parameters: {'C': 0.6142411370744808, 'gamma': 0.00024641435924797124}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:37,724] Trial 23 finished with value: 0.6717725977161737 and parameters: {'C': 0.16445788366491632, 'gamma': 0.0018260345462521946}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:38,733] Trial 24 finished with value: 0.6720403754334369 and parameters: {'C': 0.18825438283673943, 'gamma': 0.0023244580147682692}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:39,794] Trial 25 finished with value: 0.6375696675925421 and parameters: {'C': 0.15324797397514395, 'gamma': 0.012151308350919342}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:40,985] Trial 26 finished with value: 0.5898961567089664 and parameters: {'C': 0.1774026473449183, 'gamma': 0.05971498317518097}. Best is trial 17 with value: 0.6776727847067153.\n",
      "[I 2025-09-01 14:36:41,983] Trial 27 finished with value: 0.6793702231178403 and parameters: {'C': 0.8897317690690258, 'gamma': 0.0018000488743548837}. Best is trial 27 with value: 0.6793702231178403.\n",
      "[I 2025-09-01 14:36:43,354] Trial 28 finished with value: 0.6328631338162409 and parameters: {'C': 5.373423072972701, 'gamma': 0.009106513226129053}. Best is trial 27 with value: 0.6793702231178403.\n",
      "[I 2025-09-01 14:36:44,360] Trial 29 finished with value: 0.6623822231904579 and parameters: {'C': 0.7649661603843914, 'gamma': 0.000386237340786156}. Best is trial 27 with value: 0.6793702231178403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HPO] BEST_LGBM: {'n_estimators': 477, 'learning_rate': 0.016986681854303406, 'num_leaves': 236, 'max_depth': 12, 'min_child_samples': 165, 'subsample': 0.6965101889428231, 'colsample_bytree': 0.629959468368531, 'reg_alpha': 2.983987972895709e-05, 'reg_lambda': 1.8458599124132515e-06}\n",
      "[HPO] BEST_LR: {'C': 0.00336613848725774, 'l1_ratio': 0.14405154622530358}\n",
      "[HPO] BEST_SVM: {'C': 0.8897317690690258, 'gamma': 0.0018000488743548837}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 14:36:47,225] A new study created in memory with name: no-name-752d8310-bf1f-481b-92e8-b000d9321f09\n",
      "[I 2025-09-01 14:36:47,232] Trial 0 finished with value: 0.6882976598950675 and parameters: {'meta_type': 'ridge', 'alpha': 0.9846738873614566}. Best is trial 0 with value: 0.6882976598950675.\n",
      "[I 2025-09-01 14:36:47,243] Trial 1 finished with value: 0.6886244394822358 and parameters: {'meta_type': 'logreg', 'C': 21.42302175774105, 'l1_ratio': 0.6011150117432088}. Best is trial 1 with value: 0.6886244394822358.\n",
      "[I 2025-09-01 14:36:47,466] Trial 2 finished with value: 0.8225269139298876 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1283, 'learning_rate': 0.010943342660062645, 'num_leaves': 17, 'min_child_samples': 45, 'subsample': 0.6521211214797689, 'colsample_bytree': 0.762378215816119, 'reg_alpha': 2.1597250932105787, 'reg_lambda': 1.4561457009902097}. Best is trial 2 with value: 0.8225269139298876.\n",
      "[I 2025-09-01 14:36:47,476] Trial 3 finished with value: 0.6853294119782872 and parameters: {'meta_type': 'logreg', 'C': 0.06789053271698488, 'l1_ratio': 0.45606998421703593}. Best is trial 2 with value: 0.8225269139298876.\n",
      "[I 2025-09-01 14:36:47,486] Trial 4 finished with value: 0.6879254942541255 and parameters: {'meta_type': 'logreg', 'C': 0.9163741808778786, 'l1_ratio': 0.046450412719997725}. Best is trial 2 with value: 0.8225269139298876.\n",
      "[I 2025-09-01 14:36:47,499] Trial 5 finished with value: 0.6885790534284625 and parameters: {'meta_type': 'logreg', 'C': 55.51721685244721, 'l1_ratio': 0.9656320330745594}. Best is trial 2 with value: 0.8225269139298876.\n",
      "[I 2025-09-01 14:36:47,511] Trial 6 finished with value: 0.6880525752046911 and parameters: {'meta_type': 'logreg', 'C': 2.6373339933815254, 'l1_ratio': 0.4401524937396013}. Best is trial 2 with value: 0.8225269139298876.\n",
      "[I 2025-09-01 14:36:47,519] Trial 7 finished with value: 0.6878801082003523 and parameters: {'meta_type': 'ridge', 'alpha': 35.20481045526041}. Best is trial 2 with value: 0.8225269139298876.\n",
      "[I 2025-09-01 14:36:47,527] Trial 8 finished with value: 0.6884065864241236 and parameters: {'meta_type': 'ridge', 'alpha': 0.39841905944346884}. Best is trial 2 with value: 0.8225269139298876.\n",
      "[I 2025-09-01 14:36:47,668] Trial 9 finished with value: 0.8579189586623822 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1208, 'learning_rate': 0.15999399049657148, 'num_leaves': 58, 'min_child_samples': 124, 'subsample': 0.9609371175115584, 'colsample_bytree': 0.5442462510259598, 'reg_alpha': 0.979914312095726, 'reg_lambda': 0.22613644455269033}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:47,770] Trial 10 finished with value: 0.7912377684585081 and parameters: {'meta_type': 'lgbm', 'n_estimators': 649, 'learning_rate': 0.17874200269768703, 'num_leaves': 61, 'min_child_samples': 179, 'subsample': 0.953832397641259, 'colsample_bytree': 0.5076216495032854, 'reg_alpha': 0.06388024684726523, 'reg_lambda': 0.1715276786944573}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:48,076] Trial 11 finished with value: 0.8379445563967105 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1419, 'learning_rate': 0.00790174294697231, 'num_leaves': 10, 'min_child_samples': 28, 'subsample': 0.6097744281695808, 'colsample_bytree': 0.7816497135092688, 'reg_alpha': 2.001165704593281, 'reg_lambda': 0.8366509097759041}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:48,251] Trial 12 finished with value: 0.8283363288128824 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1458, 'learning_rate': 0.09267260175915543, 'num_leaves': 52, 'min_child_samples': 123, 'subsample': 0.5431844609096352, 'colsample_bytree': 0.9182905513198524, 'reg_alpha': 1.6950828611619113, 'reg_lambda': 0.03158239456382239}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:48,446] Trial 13 finished with value: 0.7622905433618358 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1110, 'learning_rate': 0.0054902966977251125, 'num_leaves': 7, 'min_child_samples': 10, 'subsample': 0.9348397262642657, 'colsample_bytree': 0.518002562161634, 'reg_alpha': 4.695358726047479, 'reg_lambda': 4.7263735311741115}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:48,591] Trial 14 finished with value: 0.8002151298948859 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1001, 'learning_rate': 0.03109151073555972, 'num_leaves': 34, 'min_child_samples': 108, 'subsample': 0.7655620151757302, 'colsample_bytree': 0.7299820798583574, 'reg_alpha': 0.827781406926889, 'reg_lambda': 1.6083834964843606}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:48,675] Trial 15 finished with value: 0.7593132182343011 and parameters: {'meta_type': 'lgbm', 'n_estimators': 309, 'learning_rate': 0.03500767980165239, 'num_leaves': 35, 'min_child_samples': 77, 'subsample': 0.7706081972231539, 'colsample_bytree': 0.7098742323846644, 'reg_alpha': 3.3527257130244337, 'reg_lambda': 1.2533146970041877}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:48,836] Trial 16 finished with value: 0.7637111268449431 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1402, 'learning_rate': 0.02725153525902101, 'num_leaves': 47, 'min_child_samples': 155, 'subsample': 0.5129624371958834, 'colsample_bytree': 0.8609727402803516, 'reg_alpha': 1.3128561392670357, 'reg_lambda': 3.3326781965385948}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:48,934] Trial 17 finished with value: 0.7736733656482035 and parameters: {'meta_type': 'lgbm', 'n_estimators': 768, 'learning_rate': 0.07244434981830482, 'num_leaves': 22, 'min_child_samples': 67, 'subsample': 0.6637452938214106, 'colsample_bytree': 0.6246385122073204, 'reg_alpha': 3.1013494382737674, 'reg_lambda': 0.7103116079746173}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:49,100] Trial 18 finished with value: 0.7608518054572192 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1161, 'learning_rate': 0.012016412774715102, 'num_leaves': 46, 'min_child_samples': 125, 'subsample': 0.8724869134221366, 'colsample_bytree': 0.8264423346529436, 'reg_alpha': 0.5986999811870246, 'reg_lambda': 2.2941194498396102}. Best is trial 9 with value: 0.8579189586623822.\n",
      "[I 2025-09-01 14:36:49,230] Trial 19 finished with value: 0.8683804440571501 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1487, 'learning_rate': 0.15907140458229754, 'num_leaves': 63, 'min_child_samples': 20, 'subsample': 0.6364495391131737, 'colsample_bytree': 0.6312823461207375, 'reg_alpha': 2.555873013728487, 'reg_lambda': 2.760115239362956}. Best is trial 19 with value: 0.8683804440571501.\n",
      "[I 2025-09-01 14:36:49,241] Trial 20 finished with value: 0.6884701268994063 and parameters: {'meta_type': 'ridge', 'alpha': 0.001053771909775942}. Best is trial 19 with value: 0.8683804440571501.\n",
      "[I 2025-09-01 14:36:49,358] Trial 21 finished with value: 0.8552547973058839 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1481, 'learning_rate': 0.19865671727946949, 'num_leaves': 59, 'min_child_samples': 16, 'subsample': 0.6257574929274351, 'colsample_bytree': 0.6189079742827357, 'reg_alpha': 2.782469597055713, 'reg_lambda': 3.4230574562185105}. Best is trial 19 with value: 0.8683804440571501.\n",
      "[I 2025-09-01 14:36:49,536] Trial 22 finished with value: 0.8524544777880653 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1487, 'learning_rate': 0.19022780923398258, 'num_leaves': 63, 'min_child_samples': 10, 'subsample': 0.690824705798907, 'colsample_bytree': 0.6171054408102081, 'reg_alpha': 2.9758693775648037, 'reg_lambda': 3.3957438995178677}. Best is trial 19 with value: 0.8683804440571501.\n",
      "[I 2025-09-01 14:36:49,679] Trial 23 finished with value: 0.7647141586333351 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1249, 'learning_rate': 0.10523256461837509, 'num_leaves': 55, 'min_child_samples': 74, 'subsample': 0.844963860820078, 'colsample_bytree': 0.6308888051691517, 'reg_alpha': 3.805400333380512, 'reg_lambda': 3.227369063435471}. Best is trial 19 with value: 0.8683804440571501.\n",
      "[I 2025-09-01 14:36:49,792] Trial 24 finished with value: 0.7969518726285787 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1310, 'learning_rate': 0.13017311442830326, 'num_leaves': 56, 'min_child_samples': 51, 'subsample': 0.5784205885373472, 'colsample_bytree': 0.5811663069113083, 'reg_alpha': 2.6627904269788227, 'reg_lambda': 2.6318937089342933}. Best is trial 19 with value: 0.8683804440571501.\n",
      "[I 2025-09-01 14:36:49,927] Trial 25 finished with value: 0.7508668736270719 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1012, 'learning_rate': 0.0586243231009442, 'num_leaves': 44, 'min_child_samples': 147, 'subsample': 0.7140844952350756, 'colsample_bytree': 0.5807343276813712, 'reg_alpha': 2.511392904815198, 'reg_lambda': 4.343367189260709}. Best is trial 19 with value: 0.8683804440571501.\n",
      "[I 2025-09-01 14:36:50,030] Trial 26 finished with value: 0.7514160448777298 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1282, 'learning_rate': 0.14451929642926103, 'num_leaves': 63, 'min_child_samples': 93, 'subsample': 0.5873366638078266, 'colsample_bytree': 0.6903808260710592, 'reg_alpha': 3.9139839450641416, 'reg_lambda': 4.0439081230466725}. Best is trial 19 with value: 0.8683804440571501.\n",
      "[I 2025-09-01 14:36:50,239] Trial 27 finished with value: 0.9143065918704502 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1486, 'learning_rate': 0.05499937354785453, 'num_leaves': 56, 'min_child_samples': 34, 'subsample': 0.9882484124446536, 'colsample_bytree': 0.659662507508158, 'reg_alpha': 1.4042496527491135, 'reg_lambda': 2.422538007059207}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:50,252] Trial 28 finished with value: 0.6884701268994063 and parameters: {'meta_type': 'ridge', 'alpha': 0.0013243382829818354}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:50,481] Trial 29 finished with value: 0.911179492765463 and parameters: {'meta_type': 'lgbm', 'n_estimators': 902, 'learning_rate': 0.05136209799252817, 'num_leaves': 50, 'min_child_samples': 41, 'subsample': 0.9926038737851366, 'colsample_bytree': 0.6815612813384653, 'reg_alpha': 1.3689531921794744, 'reg_lambda': 2.169698603658755}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:50,494] Trial 30 finished with value: 0.6877711816712961 and parameters: {'meta_type': 'ridge', 'alpha': 77.69338963145745}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:50,686] Trial 31 finished with value: 0.906836047419349 and parameters: {'meta_type': 'lgbm', 'n_estimators': 823, 'learning_rate': 0.057193921692197086, 'num_leaves': 48, 'min_child_samples': 47, 'subsample': 0.9904366991258357, 'colsample_bytree': 0.6727625306922952, 'reg_alpha': 1.2723530293274288, 'reg_lambda': 2.191174662585629}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:50,846] Trial 32 finished with value: 0.8974093640506146 and parameters: {'meta_type': 'lgbm', 'n_estimators': 622, 'learning_rate': 0.051030219256181564, 'num_leaves': 50, 'min_child_samples': 40, 'subsample': 0.9940224699811259, 'colsample_bytree': 0.6813580585680924, 'reg_alpha': 1.467181914156268, 'reg_lambda': 2.103104222827111}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:50,985] Trial 33 finished with value: 0.8840477098197266 and parameters: {'meta_type': 'lgbm', 'n_estimators': 543, 'learning_rate': 0.04814438458690157, 'num_leaves': 41, 'min_child_samples': 41, 'subsample': 0.9939101612914574, 'colsample_bytree': 0.6728354614322514, 'reg_alpha': 1.4626108457952711, 'reg_lambda': 2.2606101249960004}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:51,146] Trial 34 finished with value: 0.8369551404244504 and parameters: {'meta_type': 'lgbm', 'n_estimators': 822, 'learning_rate': 0.044474823584171305, 'num_leaves': 53, 'min_child_samples': 56, 'subsample': 0.9002811524641424, 'colsample_bytree': 0.6729011198996657, 'reg_alpha': 1.8720514332878315, 'reg_lambda': 1.8888399275160217}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:51,169] Trial 35 finished with value: 0.6871085452862045 and parameters: {'meta_type': 'logreg', 'C': 0.0010648608905881706, 'l1_ratio': 0.0033924013751416293}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:51,353] Trial 36 finished with value: 0.8768404044805113 and parameters: {'meta_type': 'lgbm', 'n_estimators': 522, 'learning_rate': 0.02149130177019901, 'num_leaves': 50, 'min_child_samples': 32, 'subsample': 0.9960808217375041, 'colsample_bytree': 0.6750371250539443, 'reg_alpha': 1.2175727723938596, 'reg_lambda': 1.9744894728764537}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:51,370] Trial 37 finished with value: 0.5 and parameters: {'meta_type': 'logreg', 'C': 0.019827657528919174, 'l1_ratio': 0.7883503771791243}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:51,524] Trial 38 finished with value: 0.8960023963836393 and parameters: {'meta_type': 'lgbm', 'n_estimators': 680, 'learning_rate': 0.06693363528716327, 'num_leaves': 38, 'min_child_samples': 64, 'subsample': 0.9161172758770019, 'colsample_bytree': 0.7494279516967151, 'reg_alpha': 0.42581782918951827, 'reg_lambda': 2.899856983287517}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:51,539] Trial 39 finished with value: 0.5 and parameters: {'meta_type': 'logreg', 'C': 0.0010311926441527633, 'l1_ratio': 0.27511356709854934}. Best is trial 27 with value: 0.9143065918704502.\n",
      "[I 2025-09-01 14:36:51,833] Trial 40 finished with value: 0.9490450774286078 and parameters: {'meta_type': 'lgbm', 'n_estimators': 982, 'learning_rate': 0.044512236779364514, 'num_leaves': 49, 'min_child_samples': 34, 'subsample': 0.8238075586003929, 'colsample_bytree': 0.8022584902665328, 'reg_alpha': 1.141425089813331, 'reg_lambda': 1.9822561203176958}. Best is trial 40 with value: 0.9490450774286078.\n",
      "[I 2025-09-01 14:36:52,069] Trial 41 finished with value: 0.9133761777680954 and parameters: {'meta_type': 'lgbm', 'n_estimators': 909, 'learning_rate': 0.04488672411275935, 'num_leaves': 49, 'min_child_samples': 37, 'subsample': 0.9994948336417356, 'colsample_bytree': 0.8199665510151218, 'reg_alpha': 1.5341468935490539, 'reg_lambda': 1.9616820390686374}. Best is trial 40 with value: 0.9490450774286078.\n",
      "[I 2025-09-01 14:36:52,352] Trial 42 finished with value: 0.9487999927382315 and parameters: {'meta_type': 'lgbm', 'n_estimators': 935, 'learning_rate': 0.03728665340119166, 'num_leaves': 41, 'min_child_samples': 33, 'subsample': 0.8138524443124551, 'colsample_bytree': 0.8047057907887176, 'reg_alpha': 1.0446057118280212, 'reg_lambda': 1.7209057030680466}. Best is trial 40 with value: 0.9490450774286078.\n",
      "[I 2025-09-01 14:36:52,674] Trial 43 finished with value: 0.9721057313508705 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1009, 'learning_rate': 0.03808343725777032, 'num_leaves': 44, 'min_child_samples': 28, 'subsample': 0.8204441435504098, 'colsample_bytree': 0.8110331481898572, 'reg_alpha': 0.8901673227836464, 'reg_lambda': 1.6071104957021323}. Best is trial 43 with value: 0.9721057313508705.\n",
      "[I 2025-09-01 14:36:52,956] Trial 44 finished with value: 0.9200660820942941 and parameters: {'meta_type': 'lgbm', 'n_estimators': 970, 'learning_rate': 0.021794316875155016, 'num_leaves': 30, 'min_child_samples': 35, 'subsample': 0.817059309511639, 'colsample_bytree': 0.8244417208857387, 'reg_alpha': 0.8389236960369365, 'reg_lambda': 1.5704101316857}. Best is trial 43 with value: 0.9721057313508705.\n",
      "[I 2025-09-01 14:36:52,966] Trial 45 finished with value: 0.688451972477897 and parameters: {'meta_type': 'ridge', 'alpha': 0.032702033398672656}. Best is trial 43 with value: 0.9721057313508705.\n",
      "[I 2025-09-01 14:36:53,364] Trial 46 finished with value: 0.9918940507960714 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1038, 'learning_rate': 0.021019621496575623, 'num_leaves': 30, 'min_child_samples': 25, 'subsample': 0.8129520343739701, 'colsample_bytree': 0.8863940686824916, 'reg_alpha': 0.3052629247946229, 'reg_lambda': 1.36290931160269}. Best is trial 46 with value: 0.9918940507960714.\n",
      "[I 2025-09-01 14:36:53,720] Trial 47 finished with value: 0.9859938638055299 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1051, 'learning_rate': 0.01726912043334274, 'num_leaves': 29, 'min_child_samples': 27, 'subsample': 0.8110314688235123, 'colsample_bytree': 0.9115883021995765, 'reg_alpha': 0.06956361780219067, 'reg_lambda': 1.3166297805602827}. Best is trial 46 with value: 0.9918940507960714.\n",
      "[I 2025-09-01 14:36:53,732] Trial 48 finished with value: 0.5 and parameters: {'meta_type': 'logreg', 'C': 0.018401198026148854, 'l1_ratio': 0.9865534034153015}. Best is trial 46 with value: 0.9918940507960714.\n",
      "[I 2025-09-01 14:36:54,185] Trial 49 finished with value: 0.9947306791569086 and parameters: {'meta_type': 'lgbm', 'n_estimators': 1082, 'learning_rate': 0.015333831171317145, 'num_leaves': 27, 'min_child_samples': 22, 'subsample': 0.8163172558694322, 'colsample_bytree': 0.9548039301820056, 'reg_alpha': 0.06986230544450578, 'reg_lambda': 1.128498252093459}. Best is trial 49 with value: 0.9947306791569086.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HPO] Best meta params: {'meta_type': 'lgbm', 'n_estimators': 1082, 'learning_rate': 0.015333831171317145, 'num_leaves': 27, 'min_child_samples': 22, 'subsample': 0.8163172558694322, 'colsample_bytree': 0.9548039301820056, 'reg_alpha': 0.06986230544450578, 'reg_lambda': 1.128498252093459}\n",
      "[Oracle on Test] best ACC thr on test = 0.8900 (仅用于上界探索)\n",
      "\n",
      "==== Stacking (LGBM + SVM + LR) — train→test (no val) Performance ====\n",
      "Accuracy:      0.616279\n",
      "AUC:           0.595227\n",
      "PR-AUC:        0.483003\n",
      "LogLoss:       0.817189\n",
      "Precision@0.890: 0.733333\n",
      "Recall@0.890:    0.079137\n",
      "F1@0.890:        0.142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6162790697674418,\n",
       " 'auc': 0.595227232847868,\n",
       " 'ap': 0.48300286840030776,\n",
       " 'll': 0.8171894653797244,\n",
       " 'prec': 0.7333333333333333,\n",
       " 'rec': 0.07913669064748201,\n",
       " 'f1': 0.14285714285714285}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Found `n_estimators`.*\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score,\n",
    "                             recall_score, f1_score, average_precision_score, log_loss)\n",
    "import optuna\n",
    "\n",
    "# ========= 数据：df_clean = 特征列 + 'value_sort'(0/1) =========\n",
    "# 假设外部已准备好 df_clean\n",
    "y_all = df_clean[\"value_sort\"].astype(int).values\n",
    "X_all = df_clean.drop(columns=[\"value_sort\"]).values\n",
    "\n",
    "# 固定时间切分：前80%训练，后20%测试（严格不泄露）\n",
    "split_pt = int(len(df_clean) * 0.8)\n",
    "X_tr, y_tr = X_all[:split_pt], y_all[:split_pt]\n",
    "X_te, y_te = X_all[split_pt:], y_all[split_pt:]\n",
    "\n",
    "# ========= 工具 =========\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    if len(np.unique(y_true)) < 2: return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "def report_all(y_true, y_prob, thr=0.5, title=\"Test\"):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "    auc  = safe_auc(y_true, y_prob)\n",
    "    ap   = average_precision_score(y_true, y_prob) if len(np.unique(y_true))>1 else np.nan\n",
    "    p2   = np.clip(y_prob, 1e-12, 1-1e-12)\n",
    "    ll   = log_loss(y_true, np.vstack([1-p2, p2]).T, labels=[0,1]) if len(np.unique(y_true))>1 else np.nan\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    print(f\"\\n==== {title} Performance ====\")\n",
    "    print(f\"Accuracy:      {acc:.6f}\")\n",
    "    print(f\"AUC:           {auc:.6f}\")\n",
    "    print(f\"PR-AUC:        {ap:.6f}\")\n",
    "    print(f\"LogLoss:       {ll:.6f}\")\n",
    "    print(f\"Precision@{thr:.3f}: {prec:.6f}\")\n",
    "    print(f\"Recall@{thr:.3f}:    {rec:.6f}\")\n",
    "    print(f\"F1@{thr:.3f}:        {f1:.6f}\")\n",
    "    return dict(acc=acc, auc=auc, ap=ap, ll=ll, prec=prec, rec=rec, f1=f1)\n",
    "\n",
    "def best_thr_on(y_true, y_prob, metric='accuracy'):\n",
    "    ths = np.linspace(0.01, 0.99, 99)\n",
    "    if metric == 'accuracy':\n",
    "        scores = [accuracy_score(y_true, (y_prob >= t).astype(int)) for t in ths]\n",
    "    else:\n",
    "        from sklearn.metrics import f1_score\n",
    "        scores = [f1_score(y_true, (y_prob >= t).astype(int), zero_division=0) for t in ths]\n",
    "    return float(ths[int(np.argmax(scores))])\n",
    "\n",
    "def time_series_folds(n_samples, n_splits=5, min_train_ratio=0.5):\n",
    "    \"\"\"递增式时间折：前min_train_ratio作为首个train，后面按等长切val区间。\"\"\"\n",
    "    min_train = int(n_samples * min_train_ratio)\n",
    "    tail = n_samples - min_train\n",
    "    fold_len = max(1, tail // n_splits)\n",
    "    for k in range(n_splits):\n",
    "        start_val = min_train + k * fold_len\n",
    "        end_val   = min(n_samples, start_val + fold_len)\n",
    "        if start_val >= end_val: break\n",
    "        train_idx = np.arange(0, start_val)\n",
    "        val_idx   = np.arange(start_val, end_val)\n",
    "        yield train_idx, val_idx\n",
    "\n",
    "# ========= 基模型超参搜索（在训练集内用时序 OOF，目标=OOF AUC；可改 ACC） =========\n",
    "def tune_lgbm(n_trials=30):\n",
    "    def objective(trial):\n",
    "        params = dict(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 300, 2000),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 15, 255),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 12),\n",
    "            min_child_samples=trial.suggest_int(\"min_child_samples\", 5, 300),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-8, 1e-1, log=True),\n",
    "            reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-8, 1e-1, log=True),\n",
    "        )\n",
    "        n = X_tr.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        for tr_idx, va_idx in time_series_folds(n, n_splits=5, min_train_ratio=0.5):\n",
    "            clf = LGBMClassifier(objective=\"binary\", class_weight=\"balanced\",\n",
    "                                 verbosity=-1, random_state=RANDOM_SEED, **params)\n",
    "            # 无验证集：不做 early_stopping\n",
    "            clf.fit(X_tr[tr_idx], y_tr[tr_idx])\n",
    "            oof[va_idx] = clf.predict_proba(X_tr[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return safe_auc(y_tr[seen], oof[seen])\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "def tune_lr(n_trials=30):\n",
    "    def objective(trial):\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 100.0, log=True)\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "        n = X_tr.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        for tr_idx, va_idx in time_series_folds(n, n_splits=5, min_train_ratio=0.5):\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"lr\", LogisticRegression(\n",
    "                    penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "                    class_weight=None, C=C, l1_ratio=l1_ratio, random_state=RANDOM_SEED\n",
    "                ))\n",
    "            ])\n",
    "            pipe.fit(X_tr[tr_idx], y_tr[tr_idx])\n",
    "            oof[va_idx] = pipe.predict_proba(X_tr[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return safe_auc(y_tr[seen], oof[seen])\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "def tune_svm(n_trials=30):\n",
    "    def objective(trial):\n",
    "        C = trial.suggest_float(\"C\", 1e-2, 1e3, log=True)\n",
    "        gamma = trial.suggest_float(\"gamma\", 1e-4, 10.0, log=True)\n",
    "        n = X_tr.shape[0]\n",
    "        oof = np.zeros(n); seen = np.zeros(n, dtype=bool)\n",
    "        for tr_idx, va_idx in time_series_folds(n, n_splits=5, min_train_ratio=0.5):\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"svc\", SVC(kernel=\"rbf\", probability=True,\n",
    "                            C=C, gamma=gamma, class_weight=None,\n",
    "                            random_state=RANDOM_SEED))\n",
    "            ])\n",
    "            pipe.fit(X_tr[tr_idx], y_tr[tr_idx])\n",
    "            oof[va_idx] = pipe.predict_proba(X_tr[va_idx])[:, 1]\n",
    "            seen[va_idx] = True\n",
    "        return safe_auc(y_tr[seen], oof[seen])\n",
    "    sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study.best_params\n",
    "\n",
    "# —— 执行基模型 HPO（可先把 n_trials 调小快速试跑）\n",
    "BEST_LGBM = tune_lgbm(n_trials=30)\n",
    "BEST_LR   = tune_lr(n_trials=30)\n",
    "BEST_SVM  = tune_svm(n_trials=30)\n",
    "\n",
    "print(\"\\n[HPO] BEST_LGBM:\", BEST_LGBM)\n",
    "print(\"[HPO] BEST_LR:\", BEST_LR)\n",
    "print(\"[HPO] BEST_SVM:\", BEST_SVM)\n",
    "\n",
    "# ========= 第一层基模型（LGBM + SVM + LR） =========\n",
    "def make_base_models():\n",
    "    base_lgbm = LGBMClassifier(objective=\"binary\", verbosity=-1,\n",
    "                               class_weight=\"balanced\", random_state=RANDOM_SEED, **BEST_LGBM)\n",
    "    base_svm  = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(kernel=\"rbf\", probability=True, random_state=RANDOM_SEED, **BEST_SVM))\n",
    "    ])\n",
    "    base_lr   = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "                                  random_state=RANDOM_SEED, **BEST_LR))\n",
    "    ])\n",
    "    return [base_lgbm, base_svm, base_lr]\n",
    "\n",
    "# ========= 生成训练集 OOF（堆叠训练集 Z_train） =========\n",
    "base_models = make_base_models()\n",
    "M = len(base_models)\n",
    "n_train = X_tr.shape[0]\n",
    "\n",
    "OOF = np.zeros((n_train, M))      # 每列一个基模型的 OOF 概率\n",
    "val_mask = np.zeros(n_train, dtype=bool)\n",
    "val_y    = np.zeros(n_train)\n",
    "\n",
    "for m, model in enumerate(base_models):\n",
    "    for tr_idx, va_idx in time_series_folds(n_train, n_splits=5, min_train_ratio=0.5):\n",
    "        model.fit(X_tr[tr_idx], y_tr[tr_idx])\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            prob = model.predict_proba(X_tr[va_idx])[:, 1]\n",
    "        else:\n",
    "            decision = model.decision_function(X_tr[va_idx])\n",
    "            prob = 1 / (1 + np.exp(-decision))\n",
    "        OOF[va_idx, m] = prob\n",
    "        val_mask[va_idx] = True\n",
    "        val_y[va_idx]    = y_tr[va_idx]\n",
    "\n",
    "Z_train = OOF[val_mask]\n",
    "y_meta  = val_y[val_mask]\n",
    "\n",
    "# ========= 在整个训练集上拟合基模型一次（用于测试集堆叠特征）=========\n",
    "fitted_bases = []\n",
    "for model in make_base_models():\n",
    "    model.fit(X_tr, y_tr)\n",
    "    fitted_bases.append(model)\n",
    "\n",
    "def build_stack(X, bases, M):\n",
    "    S = np.zeros((X.shape[0], M))\n",
    "    for i, model in enumerate(bases):\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            S[:, i] = model.predict_proba(X)[:, 1]\n",
    "        else:\n",
    "            S[:, i] = 1/(1+np.exp(-model.decision_function(X)))\n",
    "    return S\n",
    "\n",
    "test_stack = build_stack(X_te, fitted_bases, M)\n",
    "\n",
    "# ========= 二层（元学习器）HPO（目标=OOF AUC；可改 ACC）=========\n",
    "def build_meta(trial):\n",
    "    meta_type = trial.suggest_categorical(\"meta_type\", [\"logreg\", \"ridge\", \"lgbm\"])\n",
    "    if meta_type == \"logreg\":\n",
    "        C = trial.suggest_float(\"C\", 1e-3, 100.0, log=True)\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "        return LogisticRegression(\n",
    "            penalty=\"elasticnet\", solver=\"saga\", max_iter=5000,\n",
    "            class_weight=\"balanced\", C=C, l1_ratio=l1_ratio, random_state=123\n",
    "        )\n",
    "    if meta_type == \"ridge\":\n",
    "        alpha = trial.suggest_float(\"alpha\", 1e-3, 100.0, log=True)\n",
    "        return RidgeClassifier(alpha=alpha, random_state=123)\n",
    "    if meta_type == \"lgbm\":\n",
    "        params = dict(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 7, 63),\n",
    "            min_child_samples=trial.suggest_int(\"min_child_samples\", 10, 200),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "            reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 5.0)\n",
    "        )\n",
    "        return LGBMClassifier(objective=\"binary\", class_weight=\"balanced\",\n",
    "                              verbosity=-1, random_state=123, **params)\n",
    "\n",
    "def objective_meta(trial):\n",
    "    meta = build_meta(trial)\n",
    "    meta.fit(Z_train, y_meta)\n",
    "    p = (meta.predict_proba(Z_train)[:, 1]\n",
    "         if hasattr(meta, \"predict_proba\")\n",
    "         else 1/(1+np.exp(-meta.decision_function(Z_train))))\n",
    "    return safe_auc(y_meta, p)  # 如要ACC：accuracy_score(y_meta, (p>=0.5).astype(int))\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective_meta, n_trials=50, show_progress_bar=False)\n",
    "best_meta_params = study.best_params\n",
    "print(\"\\n[HPO] Best meta params:\", best_meta_params)\n",
    "\n",
    "# ========= 最优二层：在 Z_train 上重训；直接在测试集评估（无验证集）=========\n",
    "best_meta = (lambda t: build_meta(t))(optuna.trial.FixedTrial(best_meta_params))\n",
    "best_meta.fit(Z_train, y_meta)\n",
    "\n",
    "y_prob_stack = (best_meta.predict_proba(test_stack)[:, 1]\n",
    "                if hasattr(best_meta, \"predict_proba\")\n",
    "                else 1/(1+np.exp(-best_meta.decision_function(test_stack))))\n",
    "\n",
    "# —— 评估：默认阈值 0.5\n",
    "USE_TEST_ORACLE_THR = True  # 若想看测试上的“阈值上界”，把它改成 True（仅用于上界探索）\n",
    "thr_eval = 0.5\n",
    "if USE_TEST_ORACLE_THR:\n",
    "    thr_eval = best_thr_on(y_te, y_prob_stack, metric='accuracy')\n",
    "    print(f\"[Oracle on Test] best ACC thr on test = {thr_eval:.4f} (仅用于上界探索)\")\n",
    "\n",
    "report_all(y_te, y_prob_stack, thr=thr_eval, title=\"Stacking (LGBM + SVM + LR) — train→test (no val)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee897b0d",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4405ad",
   "metadata": {},
   "source": [
    "## 阈值版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ecc7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 11:21:04,980] A new study created in memory with name: no-name-52bc63ac-14af-4efe-9934-8440e34a7f8a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Top Drifted Features (TrainFit vs Test) ====\n",
      "      feature  is_categorical    PSI  KS/Chi2_p  KS_stat  missing_ref  missing_new  missing_diff\n",
      "   DR001_5dMA           False 2.6073     0.0000   0.2267       0.0000       0.0000        0.0000\n",
      "    二级1y-永续1y           False 2.5647     0.0000   0.3762       0.0000       0.0000        0.0000\n",
      "        DR001           False 2.4290     0.0000   0.2448       0.0000       0.0000        0.0000\n",
      "      二级5y-3y           False 2.2933     0.0000   0.1910       0.0000       0.0000        0.0000\n",
      "永续1yYTM_20dMA           False 1.5247     0.0000   0.3877       0.0000       0.0000        0.0000\n",
      "      永续5yYTM           False 1.3985     0.0000   0.3480       0.0000       0.0000        0.0000\n",
      "      永续4yYTM           False 1.3672     0.0000   0.3299       0.0000       0.0000        0.0000\n",
      " 永续5yYTM_5dMA           False 1.3060     0.0000   0.3616       0.0000       0.0000        0.0000\n",
      "      永续3yYTM           False 1.1914     0.0000   0.3374       0.0000       0.0000        0.0000\n",
      " 永续4yYTM_5dMA           False 1.1451     0.0000   0.3521       0.0000       0.0000        0.0000\n",
      "永续2yYTM_20dMA           False 1.1333     0.0000   0.3775       0.0000       0.0000        0.0000\n",
      " 永续3yYTM_5dMA           False 1.1331     0.0000   0.3447       0.0000       0.0000        0.0000\n",
      " 永续2yYTM_5dMA           False 1.0784     0.0000   0.3232       0.0000       0.0000        0.0000\n",
      "永续5yYTM_20dMA           False 1.0629     0.0000   0.3421       0.0000       0.0000        0.0000\n",
      "      永续1yYTM           False 1.0057     0.0000   0.3172       0.0000       0.0000        0.0000\n",
      " 永续1yYTM_5dMA           False 0.9632     0.0000   0.3361       0.0000       0.0000        0.0000\n",
      "      永续2yYTM           False 0.9279     0.0000   0.3243       0.0000       0.0000        0.0000\n",
      "永续3yYTM_20dMA           False 0.8240     0.0000   0.3773       0.0000       0.0000        0.0000\n",
      "    R001_5dMA           False 0.8178     0.0000   0.2043       0.0000       0.0000        0.0000\n",
      "永续4yYTM_20dMA           False 0.7275     0.0000   0.3815       0.0000       0.0000        0.0000\n",
      "NCD1mYTM_5dMA           False 0.7018     0.0000   0.2252       0.0000       0.0000        0.0000\n",
      "         R001           False 0.6860     0.0000   0.2297       0.0000       0.0000        0.0000\n",
      "        TS持仓量           False 0.6595     0.0000   0.2057       0.0000       0.0000        0.0000\n",
      "        TF成交量           False 0.6470     0.0000   0.1825       0.0000       0.0000        0.0000\n",
      "   DR014_5dMA           False 0.6323     0.0000   0.2229       0.0000       0.0000        0.0000\n",
      "    二级3y-永续3y           False 0.6118     0.0000   0.2836       0.0000       0.0000        0.0000\n",
      "        TS成交量           False 0.5969     0.0000   0.1652       0.0000       0.0000        0.0000\n",
      "        TF持仓量           False 0.5817     0.0000   0.1763       0.0000       0.0000        0.0000\n",
      "    R007-R001           False 0.5618     0.0000   0.1936       0.0000       0.0000        0.0000\n",
      "    R014_5dMA           False 0.5547     0.0000   0.2049       0.0000       0.0000        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-01 11:21:05,962] Trial 0 finished with value: 0.5491803278688525 and parameters: {'n_layers': 3, 'width1': 238, 'width2': 20, 'width3': 94, 'activation': 'tanh', 'alpha': 0.0010673968189785685, 'batch_size': 256, 'learning_rate_init': 0.006484341532765927, 'max_iter': 342}. Best is trial 0 with value: 0.5491803278688525.\n",
      "[I 2025-09-01 11:21:06,994] Trial 1 finished with value: 0.5181818181818182 and parameters: {'n_layers': 3, 'width1': 43, 'width2': 32, 'width3': 216, 'activation': 'relu', 'alpha': 3.986265915000919e-06, 'batch_size': 64, 'learning_rate_init': 0.012238601829685185, 'max_iter': 314}. Best is trial 0 with value: 0.5491803278688525.\n",
      "[I 2025-09-01 11:21:07,897] Trial 2 finished with value: 0.5503355704697986 and parameters: {'n_layers': 3, 'width1': 36, 'width2': 22, 'width3': 34, 'activation': 'relu', 'alpha': 1.543701487676606e-06, 'batch_size': 64, 'learning_rate_init': 0.024604274451094706, 'max_iter': 315}. Best is trial 2 with value: 0.5503355704697986.\n",
      "[I 2025-09-01 11:21:09,158] Trial 3 finished with value: 0.5739130434782609 and parameters: {'n_layers': 2, 'width1': 234, 'width2': 18, 'activation': 'tanh', 'alpha': 4.7582568301179884e-05, 'batch_size': 64, 'learning_rate_init': 0.0042029660872585075, 'max_iter': 187}. Best is trial 3 with value: 0.5739130434782609.\n",
      "[I 2025-09-01 11:21:09,986] Trial 4 finished with value: 0.5069124423963134 and parameters: {'n_layers': 2, 'width1': 136, 'width2': 62, 'activation': 'tanh', 'alpha': 0.00400827852201541, 'batch_size': 128, 'learning_rate_init': 0.023110444141035517, 'max_iter': 170}. Best is trial 3 with value: 0.5739130434782609.\n",
      "[I 2025-09-01 11:21:24,797] Trial 5 finished with value: 0.5504587155963303 and parameters: {'n_layers': 3, 'width1': 473, 'width2': 327, 'width3': 435, 'activation': 'relu', 'alpha': 0.0001943338109555939, 'batch_size': 64, 'learning_rate_init': 0.003073864688421802, 'max_iter': 145}. Best is trial 3 with value: 0.5739130434782609.\n",
      "[I 2025-09-01 11:21:25,513] Trial 6 finished with value: 0.5441696113074205 and parameters: {'n_layers': 1, 'width1': 122, 'activation': 'relu', 'alpha': 0.005278921573053993, 'batch_size': 64, 'learning_rate_init': 0.012449375639960238, 'max_iter': 322}. Best is trial 3 with value: 0.5739130434782609.\n",
      "[I 2025-09-01 11:22:05,092] Trial 7 finished with value: 0.6039215686274509 and parameters: {'n_layers': 2, 'width1': 390, 'width2': 498, 'activation': 'tanh', 'alpha': 0.0006257479173860102, 'batch_size': 128, 'learning_rate_init': 0.00013327680936394199, 'max_iter': 200}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:05,970] Trial 8 finished with value: 0.5607476635514018 and parameters: {'n_layers': 3, 'width1': 39, 'width2': 24, 'width3': 36, 'activation': 'tanh', 'alpha': 9.63802035946752e-05, 'batch_size': 64, 'learning_rate_init': 0.0031559620347644682, 'max_iter': 237}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:09,135] Trial 9 finished with value: 0.5493562231759657 and parameters: {'n_layers': 2, 'width1': 209, 'width2': 258, 'activation': 'relu', 'alpha': 0.0034421052426110116, 'batch_size': 256, 'learning_rate_init': 0.00021153504267984455, 'max_iter': 143}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:13,307] Trial 10 finished with value: 0.5895522388059702 and parameters: {'n_layers': 1, 'width1': 435, 'activation': 'tanh', 'alpha': 0.0005312026653072308, 'batch_size': 128, 'learning_rate_init': 0.00011603921010826808, 'max_iter': 243}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:17,705] Trial 11 finished with value: 0.5767790262172284 and parameters: {'n_layers': 1, 'width1': 498, 'activation': 'tanh', 'alpha': 0.0006250532663243957, 'batch_size': 128, 'learning_rate_init': 0.00011352715698528587, 'max_iter': 229}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:19,335] Trial 12 finished with value: 0.5785714285714286 and parameters: {'n_layers': 1, 'width1': 368, 'activation': 'tanh', 'alpha': 0.00047559785443377847, 'batch_size': 512, 'learning_rate_init': 0.00056419344851836, 'max_iter': 100}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:28,912] Trial 13 finished with value: 0.5873015873015873 and parameters: {'n_layers': 2, 'width1': 331, 'width2': 498, 'activation': 'tanh', 'alpha': 1.8407996652166533e-05, 'batch_size': 128, 'learning_rate_init': 0.0006728962707837041, 'max_iter': 392}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:30,843] Trial 14 finished with value: 0.5652173913043478 and parameters: {'n_layers': 1, 'width1': 73, 'activation': 'tanh', 'alpha': 0.0012692590992889941, 'batch_size': 128, 'learning_rate_init': 0.00010459505780940902, 'max_iter': 264}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:33,735] Trial 15 finished with value: 0.5714285714285714 and parameters: {'n_layers': 1, 'width1': 150, 'activation': 'tanh', 'alpha': 0.00025402107573828137, 'batch_size': 128, 'learning_rate_init': 0.0003897578818526, 'max_iter': 273}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:40,637] Trial 16 finished with value: 0.5917602996254682 and parameters: {'n_layers': 2, 'width1': 323, 'width2': 145, 'activation': 'tanh', 'alpha': 2.7586485644080705e-05, 'batch_size': 512, 'learning_rate_init': 0.0012046054673861945, 'max_iter': 208}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:49,662] Trial 17 finished with value: 0.5771144278606966 and parameters: {'n_layers': 2, 'width1': 303, 'width2': 144, 'activation': 'tanh', 'alpha': 3.284885737382712e-05, 'batch_size': 512, 'learning_rate_init': 0.0014977946302034962, 'max_iter': 197}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:54,383] Trial 18 finished with value: 0.5737051792828686 and parameters: {'n_layers': 2, 'width1': 96, 'width2': 111, 'activation': 'tanh', 'alpha': 1.1236734963206835e-05, 'batch_size': 512, 'learning_rate_init': 0.0014083107765226776, 'max_iter': 210}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:22:59,808] Trial 19 finished with value: 0.5857740585774058 and parameters: {'n_layers': 2, 'width1': 185, 'width2': 184, 'activation': 'tanh', 'alpha': 7.77452905749768e-06, 'batch_size': 512, 'learning_rate_init': 0.00027091880137998465, 'max_iter': 107}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:23:07,851] Trial 20 finished with value: 0.5702127659574469 and parameters: {'n_layers': 2, 'width1': 288, 'width2': 59, 'activation': 'tanh', 'alpha': 0.00011071634962549948, 'batch_size': 512, 'learning_rate_init': 0.000941975107688979, 'max_iter': 159}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:23:25,255] Trial 21 finished with value: 0.5967741935483871 and parameters: {'n_layers': 1, 'width1': 420, 'activation': 'tanh', 'alpha': 0.0014809491654677034, 'batch_size': 128, 'learning_rate_init': 0.0001790841269249724, 'max_iter': 281}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:23:58,752] Trial 22 finished with value: 0.582089552238806 and parameters: {'n_layers': 2, 'width1': 403, 'width2': 467, 'activation': 'tanh', 'alpha': 0.0019594744327128184, 'batch_size': 128, 'learning_rate_init': 0.0002213273990418025, 'max_iter': 278}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:24:01,595] Trial 23 finished with value: 0.5793650793650794 and parameters: {'n_layers': 1, 'width1': 284, 'activation': 'tanh', 'alpha': 0.007628522453655964, 'batch_size': 128, 'learning_rate_init': 0.00036607795094910714, 'max_iter': 217}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:24:05,691] Trial 24 finished with value: 0.5819397993311036 and parameters: {'n_layers': 1, 'width1': 371, 'activation': 'tanh', 'alpha': 0.0002811867022593531, 'batch_size': 256, 'learning_rate_init': 0.00017362839016017028, 'max_iter': 292}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:24:10,133] Trial 25 finished with value: 0.5714285714285714 and parameters: {'n_layers': 2, 'width1': 248, 'width2': 230, 'activation': 'tanh', 'alpha': 5.841886475426843e-05, 'batch_size': 512, 'learning_rate_init': 0.000805363860569555, 'max_iter': 361}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:24:15,977] Trial 26 finished with value: 0.5737704918032787 and parameters: {'n_layers': 3, 'width1': 183, 'width2': 71, 'width3': 18, 'activation': 'relu', 'alpha': 0.0017358734898441407, 'batch_size': 128, 'learning_rate_init': 0.0004001563174866808, 'max_iter': 197}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:24:43,494] Trial 27 finished with value: 0.5914396887159533 and parameters: {'n_layers': 2, 'width1': 488, 'width2': 40, 'activation': 'tanh', 'alpha': 0.00013462056359976127, 'batch_size': 128, 'learning_rate_init': 0.00016639777286093246, 'max_iter': 293}. Best is trial 7 with value: 0.6039215686274509.\n",
      "[I 2025-09-01 11:24:46,576] Trial 28 finished with value: 0.6140350877192983 and parameters: {'n_layers': 1, 'width1': 64, 'activation': 'tanh', 'alpha': 0.0008543773325752681, 'batch_size': 512, 'learning_rate_init': 0.00109115086727008, 'max_iter': 254}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:24:49,983] Trial 29 finished with value: 0.5917602996254682 and parameters: {'n_layers': 1, 'width1': 54, 'activation': 'tanh', 'alpha': 0.0009547799584349955, 'batch_size': 256, 'learning_rate_init': 0.002434626596920092, 'max_iter': 259}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:24:52,489] Trial 30 finished with value: 0.5836575875486382 and parameters: {'n_layers': 1, 'width1': 63, 'activation': 'tanh', 'alpha': 0.0028217655472426544, 'batch_size': 256, 'learning_rate_init': 0.006494701585751704, 'max_iter': 248}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:24:56,056] Trial 31 finished with value: 0.5574912891986062 and parameters: {'n_layers': 1, 'width1': 92, 'activation': 'tanh', 'alpha': 0.0008860592413814563, 'batch_size': 512, 'learning_rate_init': 0.0010435355189452678, 'max_iter': 222}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:25:12,642] Trial 32 finished with value: 0.5945945945945946 and parameters: {'n_layers': 1, 'width1': 354, 'activation': 'tanh', 'alpha': 0.0003539807874651596, 'batch_size': 512, 'learning_rate_init': 0.0005120733775419089, 'max_iter': 350}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:25:18,004] Trial 33 finished with value: 0.5990783410138248 and parameters: {'n_layers': 1, 'width1': 98, 'activation': 'tanh', 'alpha': 0.000379139482132595, 'batch_size': 512, 'learning_rate_init': 0.0003383511304172539, 'max_iter': 339}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:25:21,025] Trial 34 finished with value: 0.5578231292517006 and parameters: {'n_layers': 1, 'width1': 47, 'activation': 'relu', 'alpha': 0.0007874424208443179, 'batch_size': 512, 'learning_rate_init': 0.00028790472005738466, 'max_iter': 330}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:25:26,804] Trial 35 finished with value: 0.5849802371541502 and parameters: {'n_layers': 1, 'width1': 81, 'activation': 'tanh', 'alpha': 1.1417042529950934e-06, 'batch_size': 128, 'learning_rate_init': 0.000151078672299248, 'max_iter': 302}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:25:32,329] Trial 36 finished with value: 0.5829596412556054 and parameters: {'n_layers': 1, 'width1': 114, 'activation': 'tanh', 'alpha': 0.001357241260420979, 'batch_size': 512, 'learning_rate_init': 0.00027522063198287506, 'max_iter': 373}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:25:45,169] Trial 37 finished with value: 0.5358490566037736 and parameters: {'n_layers': 3, 'width1': 63, 'width2': 341, 'width3': 130, 'activation': 'relu', 'alpha': 0.00018384694984435027, 'batch_size': 128, 'learning_rate_init': 0.0001446163947706088, 'max_iter': 307}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:25:54,472] Trial 38 finished with value: 0.5808823529411765 and parameters: {'n_layers': 1, 'width1': 103, 'activation': 'tanh', 'alpha': 0.009987921672305566, 'batch_size': 64, 'learning_rate_init': 0.0005102867497173663, 'max_iter': 343}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:25:55,946] Trial 39 finished with value: 0.5634674922600619 and parameters: {'n_layers': 1, 'width1': 34, 'activation': 'relu', 'alpha': 0.0021457930991590278, 'batch_size': 512, 'learning_rate_init': 0.00021067913015458144, 'max_iter': 172}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:26:02,441] Trial 40 finished with value: 0.5846153846153846 and parameters: {'n_layers': 1, 'width1': 159, 'activation': 'tanh', 'alpha': 0.00045323179406865546, 'batch_size': 64, 'learning_rate_init': 0.0018790203052445247, 'max_iter': 322}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:26:05,935] Trial 41 finished with value: 0.5830508474576271 and parameters: {'n_layers': 1, 'width1': 238, 'activation': 'tanh', 'alpha': 0.0003766169595478938, 'batch_size': 512, 'learning_rate_init': 0.0005143506368834927, 'max_iter': 335}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:26:10,644] Trial 42 finished with value: 0.5882352941176471 and parameters: {'n_layers': 1, 'width1': 402, 'activation': 'tanh', 'alpha': 0.00025632568723119893, 'batch_size': 512, 'learning_rate_init': 0.0006805935421736466, 'max_iter': 354}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:26:12,425] Trial 43 finished with value: 0.5672727272727273 and parameters: {'n_layers': 1, 'width1': 80, 'activation': 'tanh', 'alpha': 0.0006907715423592156, 'batch_size': 512, 'learning_rate_init': 0.0003548463553134024, 'max_iter': 395}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:26:18,256] Trial 44 finished with value: 0.5914396887159533 and parameters: {'n_layers': 1, 'width1': 430, 'activation': 'tanh', 'alpha': 0.0036770817601472156, 'batch_size': 512, 'learning_rate_init': 0.00022418215465581736, 'max_iter': 372}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:26:23,974] Trial 45 finished with value: 0.5327868852459017 and parameters: {'n_layers': 3, 'width1': 45, 'width2': 49, 'width3': 371, 'activation': 'tanh', 'alpha': 6.708070989119902e-05, 'batch_size': 128, 'learning_rate_init': 0.00013098841063081823, 'max_iter': 280}. Best is trial 28 with value: 0.6140350877192983.\n",
      "[I 2025-09-01 11:26:25,271] Trial 46 finished with value: 0.6153846153846154 and parameters: {'n_layers': 1, 'width1': 64, 'activation': 'tanh', 'alpha': 0.0003814230681365873, 'batch_size': 256, 'learning_rate_init': 0.0006364423361256918, 'max_iter': 256}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:26,576] Trial 47 finished with value: 0.5448275862068965 and parameters: {'n_layers': 1, 'width1': 59, 'activation': 'relu', 'alpha': 0.00017287799093429867, 'batch_size': 256, 'learning_rate_init': 0.0007576944980927725, 'max_iter': 234}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:27,972] Trial 48 finished with value: 0.5555555555555556 and parameters: {'n_layers': 1, 'width1': 70, 'activation': 'tanh', 'alpha': 0.0011334819689801034, 'batch_size': 256, 'learning_rate_init': 0.0003045175940246039, 'max_iter': 250}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:30,208] Trial 49 finished with value: 0.5819672131147541 and parameters: {'n_layers': 2, 'width1': 50, 'width2': 89, 'activation': 'tanh', 'alpha': 0.0005931421501269783, 'batch_size': 256, 'learning_rate_init': 0.00010123900277295905, 'max_iter': 264}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:31,329] Trial 50 finished with value: 0.5508474576271186 and parameters: {'n_layers': 1, 'width1': 128, 'activation': 'tanh', 'alpha': 0.005384592911459535, 'batch_size': 256, 'learning_rate_init': 0.004747264308793991, 'max_iter': 238}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:33,103] Trial 51 finished with value: 0.5684210526315789 and parameters: {'n_layers': 1, 'width1': 39, 'activation': 'tanh', 'alpha': 0.0004590975120915334, 'batch_size': 128, 'learning_rate_init': 0.0005325517072603141, 'max_iter': 309}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:39,688] Trial 52 finished with value: 0.5787234042553191 and parameters: {'n_layers': 1, 'width1': 357, 'activation': 'tanh', 'alpha': 0.0003431295037022019, 'batch_size': 64, 'learning_rate_init': 0.0004473959039164631, 'max_iter': 284}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:41,415] Trial 53 finished with value: 0.5863453815261044 and parameters: {'n_layers': 1, 'width1': 85, 'activation': 'tanh', 'alpha': 0.0014812068278280987, 'batch_size': 512, 'learning_rate_init': 0.000639963137268563, 'max_iter': 381}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:42,427] Trial 54 finished with value: 0.5403726708074534 and parameters: {'n_layers': 1, 'width1': 261, 'activation': 'tanh', 'alpha': 0.002577951034246244, 'batch_size': 128, 'learning_rate_init': 0.029834401423901005, 'max_iter': 347}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:43,803] Trial 55 finished with value: 0.5761589403973509 and parameters: {'n_layers': 1, 'width1': 109, 'activation': 'tanh', 'alpha': 0.0003007729428552331, 'batch_size': 512, 'learning_rate_init': 0.0009562579517762051, 'max_iter': 257}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:45,265] Trial 56 finished with value: 0.5555555555555556 and parameters: {'n_layers': 2, 'width1': 71, 'width2': 357, 'activation': 'tanh', 'alpha': 8.980673360337895e-05, 'batch_size': 256, 'learning_rate_init': 0.0020483617903859046, 'max_iter': 269}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:46,635] Trial 57 finished with value: 0.6070038910505836 and parameters: {'n_layers': 1, 'width1': 209, 'activation': 'tanh', 'alpha': 0.0006567331620827142, 'batch_size': 512, 'learning_rate_init': 0.0012178702071435994, 'max_iter': 139}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:48,950] Trial 58 finished with value: 0.5783132530120482 and parameters: {'n_layers': 1, 'width1': 211, 'activation': 'tanh', 'alpha': 0.0005992659641764217, 'batch_size': 128, 'learning_rate_init': 0.0001841740378711796, 'max_iter': 124}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:52,475] Trial 59 finished with value: 0.5917602996254682 and parameters: {'n_layers': 1, 'width1': 506, 'activation': 'tanh', 'alpha': 0.0009184990773405512, 'batch_size': 512, 'learning_rate_init': 0.001246213005292384, 'max_iter': 180}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:54,415] Trial 60 finished with value: 0.5764192139737991 and parameters: {'n_layers': 2, 'width1': 165, 'width2': 109, 'activation': 'relu', 'alpha': 0.00020265432964664456, 'batch_size': 128, 'learning_rate_init': 0.0008583706028777522, 'max_iter': 124}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:56,665] Trial 61 finished with value: 0.5802047781569966 and parameters: {'n_layers': 1, 'width1': 340, 'activation': 'tanh', 'alpha': 0.00046075307729941584, 'batch_size': 512, 'learning_rate_init': 0.0013281278135698067, 'max_iter': 138}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:26:58,894] Trial 62 finished with value: 0.5767790262172284 and parameters: {'n_layers': 1, 'width1': 306, 'activation': 'tanh', 'alpha': 2.335992797594805e-06, 'batch_size': 512, 'learning_rate_init': 0.0004381973294965024, 'max_iter': 156}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:02,621] Trial 63 finished with value: 0.5864661654135338 and parameters: {'n_layers': 1, 'width1': 438, 'activation': 'tanh', 'alpha': 0.001206585180485099, 'batch_size': 512, 'learning_rate_init': 0.00012617344415711624, 'max_iter': 226}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:03,998] Trial 64 finished with value: 0.5923076923076923 and parameters: {'n_layers': 1, 'width1': 144, 'activation': 'tanh', 'alpha': 0.00014591110972355813, 'batch_size': 512, 'learning_rate_init': 0.0011027557424085524, 'max_iter': 197}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:07,842] Trial 65 finished with value: 0.5983606557377049 and parameters: {'n_layers': 1, 'width1': 390, 'activation': 'tanh', 'alpha': 0.0006781806036838637, 'batch_size': 512, 'learning_rate_init': 0.0015996002929654788, 'max_iter': 209}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:11,381] Trial 66 finished with value: 0.6031746031746031 and parameters: {'n_layers': 1, 'width1': 387, 'activation': 'tanh', 'alpha': 0.0007516918531125761, 'batch_size': 256, 'learning_rate_init': 0.0016020620922303163, 'max_iter': 210}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:13,445] Trial 67 finished with value: 0.568561872909699 and parameters: {'n_layers': 1, 'width1': 214, 'activation': 'tanh', 'alpha': 0.0008315191984973611, 'batch_size': 256, 'learning_rate_init': 0.0015377857869704773, 'max_iter': 209}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:15,449] Trial 68 finished with value: 0.5992217898832685 and parameters: {'n_layers': 1, 'width1': 380, 'activation': 'tanh', 'alpha': 0.00023373381286751784, 'batch_size': 256, 'learning_rate_init': 0.0028635477604428907, 'max_iter': 181}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:17,351] Trial 69 finished with value: 0.5693430656934306 and parameters: {'n_layers': 1, 'width1': 286, 'activation': 'tanh', 'alpha': 9.738677768047093e-05, 'batch_size': 256, 'learning_rate_init': 0.0027306663588682703, 'max_iter': 191}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:19,433] Trial 70 finished with value: 0.5576923076923077 and parameters: {'n_layers': 3, 'width1': 266, 'width2': 188, 'width3': 50, 'activation': 'tanh', 'alpha': 0.00023207891515132585, 'batch_size': 256, 'learning_rate_init': 0.0023037589159193646, 'max_iter': 165}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:21,688] Trial 71 finished with value: 0.5853658536585366 and parameters: {'n_layers': 1, 'width1': 465, 'activation': 'tanh', 'alpha': 0.0005483937266405344, 'batch_size': 256, 'learning_rate_init': 0.0032686534668903014, 'max_iter': 181}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:24,208] Trial 72 finished with value: 0.5932203389830508 and parameters: {'n_layers': 1, 'width1': 385, 'activation': 'tanh', 'alpha': 0.0007181719224549405, 'batch_size': 256, 'learning_rate_init': 0.001553272643324403, 'max_iter': 219}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:26,217] Trial 73 finished with value: 0.5819397993311036 and parameters: {'n_layers': 1, 'width1': 320, 'activation': 'tanh', 'alpha': 0.0003879833965349767, 'batch_size': 256, 'learning_rate_init': 0.0017081345080391327, 'max_iter': 146}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:27,902] Trial 74 finished with value: 0.6053639846743295 and parameters: {'n_layers': 1, 'width1': 459, 'activation': 'tanh', 'alpha': 0.00031191182063003946, 'batch_size': 256, 'learning_rate_init': 0.005710718343544795, 'max_iter': 203}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:29,679] Trial 75 finished with value: 0.6108786610878661 and parameters: {'n_layers': 1, 'width1': 456, 'activation': 'tanh', 'alpha': 0.0001347409934265811, 'batch_size': 256, 'learning_rate_init': 0.0054735815121550796, 'max_iter': 200}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:31,195] Trial 76 finished with value: 0.6 and parameters: {'n_layers': 1, 'width1': 455, 'activation': 'tanh', 'alpha': 0.0001338224816846633, 'batch_size': 256, 'learning_rate_init': 0.010082891670084516, 'max_iter': 203}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:32,701] Trial 77 finished with value: 0.6127659574468085 and parameters: {'n_layers': 1, 'width1': 456, 'activation': 'tanh', 'alpha': 4.516751436277457e-05, 'batch_size': 256, 'learning_rate_init': 0.01023922320719517, 'max_iter': 200}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:33,680] Trial 78 finished with value: 0.47470817120622566 and parameters: {'n_layers': 1, 'width1': 503, 'activation': 'relu', 'alpha': 3.315350742241892e-05, 'batch_size': 256, 'learning_rate_init': 0.01658769011605768, 'max_iter': 230}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:35,802] Trial 79 finished with value: 0.5607476635514018 and parameters: {'n_layers': 2, 'width1': 418, 'width2': 263, 'activation': 'tanh', 'alpha': 4.231177139259385e-05, 'batch_size': 256, 'learning_rate_init': 0.00838159115826107, 'max_iter': 244}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:37,859] Trial 80 finished with value: 0.5868725868725869 and parameters: {'n_layers': 1, 'width1': 475, 'activation': 'tanh', 'alpha': 6.071316427717136e-05, 'batch_size': 256, 'learning_rate_init': 0.004661695475715251, 'max_iter': 216}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:39,563] Trial 81 finished with value: 0.59375 and parameters: {'n_layers': 1, 'width1': 455, 'activation': 'tanh', 'alpha': 0.0001198195403194665, 'batch_size': 256, 'learning_rate_init': 0.010495657545309522, 'max_iter': 199}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:41,484] Trial 82 finished with value: 0.5803921568627451 and parameters: {'n_layers': 1, 'width1': 443, 'activation': 'tanh', 'alpha': 8.287694631543804e-05, 'batch_size': 256, 'learning_rate_init': 0.006605994522700817, 'max_iter': 198}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:42,763] Trial 83 finished with value: 0.5925925925925926 and parameters: {'n_layers': 1, 'width1': 344, 'activation': 'tanh', 'alpha': 0.00014277317876037476, 'batch_size': 256, 'learning_rate_init': 0.01720501369934564, 'max_iter': 205}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:44,194] Trial 84 finished with value: 0.5925925925925926 and parameters: {'n_layers': 1, 'width1': 404, 'activation': 'tanh', 'alpha': 0.0002964456927639066, 'batch_size': 256, 'learning_rate_init': 0.008240028536592357, 'max_iter': 189}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:46,615] Trial 85 finished with value: 0.5846153846153846 and parameters: {'n_layers': 1, 'width1': 471, 'activation': 'tanh', 'alpha': 1.8409212933634083e-05, 'batch_size': 256, 'learning_rate_init': 0.00354728841370149, 'max_iter': 169}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:47,993] Trial 86 finished with value: 0.5829596412556054 and parameters: {'n_layers': 1, 'width1': 367, 'activation': 'tanh', 'alpha': 2.292229848493415e-05, 'batch_size': 256, 'learning_rate_init': 0.010931184138940049, 'max_iter': 252}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:49,394] Trial 87 finished with value: 0.5907172995780591 and parameters: {'n_layers': 1, 'width1': 508, 'activation': 'tanh', 'alpha': 1.078531367889941e-05, 'batch_size': 64, 'learning_rate_init': 0.01680606656124196, 'max_iter': 237}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:50,345] Trial 88 finished with value: 0.5581395348837209 and parameters: {'n_layers': 3, 'width1': 421, 'width2': 30, 'width3': 16, 'activation': 'tanh', 'alpha': 7.375093378279955e-05, 'batch_size': 256, 'learning_rate_init': 0.013541716619667325, 'max_iter': 226}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:51,840] Trial 89 finished with value: 0.5454545454545454 and parameters: {'n_layers': 1, 'width1': 317, 'activation': 'relu', 'alpha': 0.00015779860897278941, 'batch_size': 256, 'learning_rate_init': 0.005173923755337407, 'max_iter': 213}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:52,549] Trial 90 finished with value: 0.5714285714285714 and parameters: {'n_layers': 1, 'width1': 58, 'activation': 'tanh', 'alpha': 5.261487697901802e-05, 'batch_size': 256, 'learning_rate_init': 0.006944984778975514, 'max_iter': 188}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:54,417] Trial 91 finished with value: 0.592274678111588 and parameters: {'n_layers': 1, 'width1': 377, 'activation': 'tanh', 'alpha': 0.00019416428772821466, 'batch_size': 256, 'learning_rate_init': 0.003954229126523585, 'max_iter': 180}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:56,506] Trial 92 finished with value: 0.5872340425531914 and parameters: {'n_layers': 1, 'width1': 454, 'activation': 'tanh', 'alpha': 0.00024250757912711385, 'batch_size': 256, 'learning_rate_init': 0.005488991497910409, 'max_iter': 204}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:27:57,598] Trial 93 finished with value: 0.5764192139737991 and parameters: {'n_layers': 1, 'width1': 184, 'activation': 'tanh', 'alpha': 0.0004929095180047385, 'batch_size': 256, 'learning_rate_init': 0.008922021687561328, 'max_iter': 179}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:00,055] Trial 94 finished with value: 0.5714285714285714 and parameters: {'n_layers': 1, 'width1': 393, 'activation': 'tanh', 'alpha': 0.0010191538833832698, 'batch_size': 256, 'learning_rate_init': 0.001993638046395938, 'max_iter': 192}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:02,159] Trial 95 finished with value: 0.5814977973568282 and parameters: {'n_layers': 1, 'width1': 358, 'activation': 'tanh', 'alpha': 0.00011504089874061578, 'batch_size': 256, 'learning_rate_init': 0.0028003336851166833, 'max_iter': 150}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:05,134] Trial 96 finished with value: 0.5863453815261044 and parameters: {'n_layers': 1, 'width1': 419, 'activation': 'tanh', 'alpha': 0.0003339111131354092, 'batch_size': 64, 'learning_rate_init': 0.0021873628048372246, 'max_iter': 173}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:05,910] Trial 97 finished with value: 0.5614035087719298 and parameters: {'n_layers': 1, 'width1': 66, 'activation': 'tanh', 'alpha': 0.00021277554998356957, 'batch_size': 256, 'learning_rate_init': 0.005779711221166632, 'max_iter': 135}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:07,079] Trial 98 finished with value: 0.5964912280701754 and parameters: {'n_layers': 1, 'width1': 334, 'activation': 'tanh', 'alpha': 0.0016709074555869155, 'batch_size': 256, 'learning_rate_init': 0.01261989489056487, 'max_iter': 221}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:09,135] Trial 99 finished with value: 0.6076923076923076 and parameters: {'n_layers': 1, 'width1': 481, 'activation': 'tanh', 'alpha': 4.269281663152562e-05, 'batch_size': 256, 'learning_rate_init': 0.0010955638141887025, 'max_iter': 110}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:10,995] Trial 100 finished with value: 0.5830258302583026 and parameters: {'n_layers': 1, 'width1': 479, 'activation': 'tanh', 'alpha': 4.2850381517017913e-05, 'batch_size': 256, 'learning_rate_init': 0.001166147656665897, 'max_iter': 101}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:12,673] Trial 101 finished with value: 0.5801526717557252 and parameters: {'n_layers': 1, 'width1': 441, 'activation': 'tanh', 'alpha': 3.732315075443695e-05, 'batch_size': 256, 'learning_rate_init': 0.007223950905028232, 'max_iter': 116}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:14,483] Trial 102 finished with value: 0.5992217898832685 and parameters: {'n_layers': 1, 'width1': 405, 'activation': 'tanh', 'alpha': 0.00028704207534480645, 'batch_size': 256, 'learning_rate_init': 0.0009725653766722753, 'max_iter': 131}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:22,193] Trial 103 finished with value: 0.5679012345679012 and parameters: {'n_layers': 2, 'width1': 489, 'width2': 417, 'activation': 'tanh', 'alpha': 2.7202396135488427e-05, 'batch_size': 256, 'learning_rate_init': 0.00182035025241924, 'max_iter': 158}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:23,470] Trial 104 finished with value: 0.5833333333333334 and parameters: {'n_layers': 1, 'width1': 226, 'activation': 'tanh', 'alpha': 0.0005755970912436056, 'batch_size': 256, 'learning_rate_init': 0.0007383661171989436, 'max_iter': 113}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:26,438] Trial 105 finished with value: 0.5916666666666667 and parameters: {'n_layers': 1, 'width1': 371, 'activation': 'tanh', 'alpha': 0.00041952648340689175, 'batch_size': 128, 'learning_rate_init': 0.0013325262898650824, 'max_iter': 202}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:27,488] Trial 106 finished with value: 0.5938864628820961 and parameters: {'n_layers': 1, 'width1': 32, 'activation': 'tanh', 'alpha': 0.0007332722138821542, 'batch_size': 256, 'learning_rate_init': 0.0006017210856955314, 'max_iter': 271}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:31,395] Trial 107 finished with value: 0.5882352941176471 and parameters: {'n_layers': 1, 'width1': 446, 'activation': 'tanh', 'alpha': 0.00017227595964396426, 'batch_size': 256, 'learning_rate_init': 0.0008570514272241105, 'max_iter': 259}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:33,040] Trial 108 finished with value: 0.5514705882352942 and parameters: {'n_layers': 1, 'width1': 296, 'activation': 'relu', 'alpha': 0.001108305612959069, 'batch_size': 256, 'learning_rate_init': 0.003922027108640278, 'max_iter': 212}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:34,580] Trial 109 finished with value: 0.5774058577405857 and parameters: {'n_layers': 1, 'width1': 78, 'activation': 'tanh', 'alpha': 7.554322534259828e-05, 'batch_size': 128, 'learning_rate_init': 0.0025297929501023842, 'max_iter': 233}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:35,885] Trial 110 finished with value: 0.5675675675675675 and parameters: {'n_layers': 2, 'width1': 272, 'width2': 16, 'activation': 'tanh', 'alpha': 0.0001351443541950744, 'batch_size': 256, 'learning_rate_init': 0.009908767870918617, 'max_iter': 242}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:37,852] Trial 111 finished with value: 0.574468085106383 and parameters: {'n_layers': 1, 'width1': 401, 'activation': 'tanh', 'alpha': 0.00028783701960243934, 'batch_size': 256, 'learning_rate_init': 0.0011305444316573694, 'max_iter': 129}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:39,604] Trial 112 finished with value: 0.584192439862543 and parameters: {'n_layers': 1, 'width1': 408, 'activation': 'tanh', 'alpha': 0.00026697113938253277, 'batch_size': 256, 'learning_rate_init': 0.0009308395105009485, 'max_iter': 115}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:41,971] Trial 113 finished with value: 0.5823754789272031 and parameters: {'n_layers': 1, 'width1': 464, 'activation': 'tanh', 'alpha': 0.00010322966944226694, 'batch_size': 256, 'learning_rate_init': 0.0009955816843312893, 'max_iter': 138}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:44,646] Trial 114 finished with value: 0.5890909090909091 and parameters: {'n_layers': 1, 'width1': 510, 'activation': 'tanh', 'alpha': 0.0003555968859997047, 'batch_size': 256, 'learning_rate_init': 0.0014856006146416502, 'max_iter': 122}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:47,800] Trial 115 finished with value: 0.5896414342629482 and parameters: {'n_layers': 1, 'width1': 196, 'activation': 'tanh', 'alpha': 0.0008743135836047927, 'batch_size': 64, 'learning_rate_init': 0.0006949720196893792, 'max_iter': 194}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:48,433] Trial 116 finished with value: 0.5757575757575758 and parameters: {'n_layers': 1, 'width1': 52, 'activation': 'tanh', 'alpha': 0.0006254151379842555, 'batch_size': 256, 'learning_rate_init': 0.0012739365692819443, 'max_iter': 104}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:50,987] Trial 117 finished with value: 0.5882352941176471 and parameters: {'n_layers': 1, 'width1': 431, 'activation': 'tanh', 'alpha': 0.0005124662629786267, 'batch_size': 512, 'learning_rate_init': 0.0010509970807353096, 'max_iter': 162}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:52,060] Trial 118 finished with value: 0.599250936329588 and parameters: {'n_layers': 1, 'width1': 349, 'activation': 'tanh', 'alpha': 0.00022254651500160216, 'batch_size': 256, 'learning_rate_init': 0.014754874613359104, 'max_iter': 184}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:53,384] Trial 119 finished with value: 0.5863453815261044 and parameters: {'n_layers': 1, 'width1': 349, 'activation': 'tanh', 'alpha': 0.00023959440988584086, 'batch_size': 128, 'learning_rate_init': 0.011813432207946523, 'max_iter': 176}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:54,467] Trial 120 finished with value: 0.582995951417004 and parameters: {'n_layers': 1, 'width1': 313, 'activation': 'tanh', 'alpha': 0.0004107671291638651, 'batch_size': 256, 'learning_rate_init': 0.013858830036050027, 'max_iter': 185}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:56,014] Trial 121 finished with value: 0.5819672131147541 and parameters: {'n_layers': 1, 'width1': 375, 'activation': 'tanh', 'alpha': 0.0001919988723808733, 'batch_size': 256, 'learning_rate_init': 0.007483232686204169, 'max_iter': 184}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:57,109] Trial 122 finished with value: 0.5726495726495726 and parameters: {'n_layers': 1, 'width1': 397, 'activation': 'tanh', 'alpha': 0.0003182342368862075, 'batch_size': 256, 'learning_rate_init': 0.015280094970700368, 'max_iter': 154}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:58,583] Trial 123 finished with value: 0.6097560975609756 and parameters: {'n_layers': 1, 'width1': 481, 'activation': 'tanh', 'alpha': 0.00022190902662070613, 'batch_size': 256, 'learning_rate_init': 0.022605435094170682, 'max_iter': 203}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:28:59,807] Trial 124 finished with value: 0.5897435897435898 and parameters: {'n_layers': 1, 'width1': 483, 'activation': 'tanh', 'alpha': 0.00015737711872595555, 'batch_size': 256, 'learning_rate_init': 0.01866219471590757, 'max_iter': 204}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:00,869] Trial 125 finished with value: 0.589041095890411 and parameters: {'n_layers': 1, 'width1': 169, 'activation': 'tanh', 'alpha': 0.00011693842829038578, 'batch_size': 512, 'learning_rate_init': 0.02116082294619441, 'max_iter': 225}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:01,997] Trial 126 finished with value: 0.5746268656716418 and parameters: {'n_layers': 1, 'width1': 434, 'activation': 'tanh', 'alpha': 5.913239762803266e-05, 'batch_size': 256, 'learning_rate_init': 0.023882554534966863, 'max_iter': 194}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:04,093] Trial 127 finished with value: 0.5563380281690141 and parameters: {'n_layers': 3, 'width1': 464, 'width2': 136, 'width3': 192, 'activation': 'relu', 'alpha': 0.00021798941462946472, 'batch_size': 256, 'learning_rate_init': 0.02810723108231434, 'max_iter': 167}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:05,896] Trial 128 finished with value: 0.584 and parameters: {'n_layers': 1, 'width1': 337, 'activation': 'tanh', 'alpha': 9.333280518242473e-05, 'batch_size': 256, 'learning_rate_init': 0.005880896762347556, 'max_iter': 208}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:07,635] Trial 129 finished with value: 0.556390977443609 and parameters: {'n_layers': 1, 'width1': 509, 'activation': 'tanh', 'alpha': 0.0012668996950803218, 'batch_size': 512, 'learning_rate_init': 0.021200193258047166, 'max_iter': 197}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:08,442] Trial 130 finished with value: 0.5882352941176471 and parameters: {'n_layers': 1, 'width1': 121, 'activation': 'tanh', 'alpha': 0.000128688399622243, 'batch_size': 256, 'learning_rate_init': 0.009251528581996531, 'max_iter': 215}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:11,328] Trial 131 finished with value: 0.5811320754716981 and parameters: {'n_layers': 1, 'width1': 380, 'activation': 'tanh', 'alpha': 0.0002753933169929884, 'batch_size': 256, 'learning_rate_init': 0.0016801138831301, 'max_iter': 253}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:13,821] Trial 132 finished with value: 0.5645161290322581 and parameters: {'n_layers': 1, 'width1': 412, 'activation': 'tanh', 'alpha': 0.000457207358446864, 'batch_size': 256, 'learning_rate_init': 0.0008417151862251459, 'max_iter': 188}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:15,793] Trial 133 finished with value: 0.5894736842105263 and parameters: {'n_layers': 1, 'width1': 447, 'activation': 'tanh', 'alpha': 0.00017560924607911232, 'batch_size': 256, 'learning_rate_init': 0.0014057391544769545, 'max_iter': 111}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:16,768] Trial 134 finished with value: 0.6058091286307054 and parameters: {'n_layers': 1, 'width1': 41, 'activation': 'tanh', 'alpha': 0.0007644260198872122, 'batch_size': 256, 'learning_rate_init': 0.0012040592687240293, 'max_iter': 201}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:17,453] Trial 135 finished with value: 0.568 and parameters: {'n_layers': 1, 'width1': 57, 'activation': 'tanh', 'alpha': 0.0007664475131927156, 'batch_size': 256, 'learning_rate_init': 0.01151564560971037, 'max_iter': 201}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:18,114] Trial 136 finished with value: 0.5853658536585366 and parameters: {'n_layers': 1, 'width1': 43, 'activation': 'tanh', 'alpha': 0.0009064890079776614, 'batch_size': 256, 'learning_rate_init': 0.019590519208755264, 'max_iter': 221}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:19,161] Trial 137 finished with value: 0.5797101449275363 and parameters: {'n_layers': 1, 'width1': 38, 'activation': 'tanh', 'alpha': 0.0005374478597841661, 'batch_size': 128, 'learning_rate_init': 0.003171975851007814, 'max_iter': 264}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:20,113] Trial 138 finished with value: 0.568 and parameters: {'n_layers': 1, 'width1': 49, 'activation': 'tanh', 'alpha': 0.0003524305331987613, 'batch_size': 64, 'learning_rate_init': 0.01428232698756959, 'max_iter': 210}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:20,762] Trial 139 finished with value: 0.5622119815668203 and parameters: {'n_layers': 1, 'width1': 41, 'activation': 'tanh', 'alpha': 0.0006726882932130639, 'batch_size': 256, 'learning_rate_init': 0.027016659542088355, 'max_iter': 174}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:23,894] Trial 140 finished with value: 0.5899280575539568 and parameters: {'n_layers': 1, 'width1': 466, 'activation': 'tanh', 'alpha': 0.0015176889086111528, 'batch_size': 512, 'learning_rate_init': 0.004570073217452276, 'max_iter': 217}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:25,837] Trial 141 finished with value: 0.5799256505576208 and parameters: {'n_layers': 1, 'width1': 432, 'activation': 'tanh', 'alpha': 0.00020948081122833172, 'batch_size': 256, 'learning_rate_init': 0.001260384492448955, 'max_iter': 130}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:26,698] Trial 142 finished with value: 0.572463768115942 and parameters: {'n_layers': 1, 'width1': 35, 'activation': 'tanh', 'alpha': 0.0021124635694886366, 'batch_size': 256, 'learning_rate_init': 0.0011065254985413804, 'max_iter': 202}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:29,233] Trial 143 finished with value: 0.6 and parameters: {'n_layers': 1, 'width1': 362, 'activation': 'tanh', 'alpha': 0.0010352195146880185, 'batch_size': 256, 'learning_rate_init': 0.0009552591808152038, 'max_iter': 193}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:31,704] Trial 144 finished with value: 0.5923076923076923 and parameters: {'n_layers': 1, 'width1': 357, 'activation': 'tanh', 'alpha': 0.0009753130490390417, 'batch_size': 256, 'learning_rate_init': 0.001839728880992354, 'max_iter': 192}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:32,785] Trial 145 finished with value: 0.5658914728682171 and parameters: {'n_layers': 1, 'width1': 87, 'activation': 'tanh', 'alpha': 0.0013727121765725455, 'batch_size': 256, 'learning_rate_init': 0.0007806670822781013, 'max_iter': 198}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:33,699] Trial 146 finished with value: 0.5816733067729084 and parameters: {'n_layers': 1, 'width1': 137, 'activation': 'tanh', 'alpha': 4.863468030782569e-05, 'batch_size': 256, 'learning_rate_init': 0.008115871094711399, 'max_iter': 183}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:36,418] Trial 147 finished with value: 0.5943775100401606 and parameters: {'n_layers': 1, 'width1': 386, 'activation': 'tanh', 'alpha': 0.0007418019739908555, 'batch_size': 256, 'learning_rate_init': 0.0009403687373650641, 'max_iter': 206}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:39,164] Trial 148 finished with value: 0.5591397849462365 and parameters: {'n_layers': 1, 'width1': 492, 'activation': 'relu', 'alpha': 5.935561236411179e-06, 'batch_size': 256, 'learning_rate_init': 0.0013731588219413331, 'max_iter': 248}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:41,708] Trial 149 finished with value: 0.5882352941176471 and parameters: {'n_layers': 1, 'width1': 419, 'activation': 'tanh', 'alpha': 0.0011136055077802453, 'batch_size': 256, 'learning_rate_init': 0.0021516701442027787, 'max_iter': 190}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:44,729] Trial 150 finished with value: 0.5967741935483871 and parameters: {'n_layers': 1, 'width1': 454, 'activation': 'tanh', 'alpha': 2.0515747343012598e-05, 'batch_size': 128, 'learning_rate_init': 0.0015432588803476256, 'max_iter': 209}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:46,776] Trial 151 finished with value: 0.5842696629213483 and parameters: {'n_layers': 1, 'width1': 397, 'activation': 'tanh', 'alpha': 0.00041558625889440344, 'batch_size': 256, 'learning_rate_init': 0.0010492107268394962, 'max_iter': 146}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:49,044] Trial 152 finished with value: 0.578397212543554 and parameters: {'n_layers': 1, 'width1': 332, 'activation': 'tanh', 'alpha': 0.00025440996054724746, 'batch_size': 256, 'learning_rate_init': 0.0011733953353571774, 'max_iter': 186}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:50,810] Trial 153 finished with value: 0.5923076923076923 and parameters: {'n_layers': 1, 'width1': 368, 'activation': 'tanh', 'alpha': 0.0005590087292620063, 'batch_size': 256, 'learning_rate_init': 0.0008893592676520788, 'max_iter': 121}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:53,467] Trial 154 finished with value: 0.5909090909090909 and parameters: {'n_layers': 1, 'width1': 421, 'activation': 'tanh', 'alpha': 0.00033006931289673326, 'batch_size': 256, 'learning_rate_init': 0.0011838857881061044, 'max_iter': 197}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:29:59,194] Trial 155 finished with value: 0.5984251968503937 and parameters: {'n_layers': 3, 'width1': 389, 'width2': 204, 'width3': 58, 'activation': 'tanh', 'alpha': 0.0004926588948325582, 'batch_size': 256, 'learning_rate_init': 0.0002476688543319674, 'max_iter': 203}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:01,029] Trial 156 finished with value: 0.5609756097560976 and parameters: {'n_layers': 1, 'width1': 483, 'activation': 'tanh', 'alpha': 1.3955277879369249e-05, 'batch_size': 512, 'learning_rate_init': 0.009736350035109762, 'max_iter': 241}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:02,593] Trial 157 finished with value: 0.5855513307984791 and parameters: {'n_layers': 2, 'width1': 96, 'width2': 81, 'activation': 'tanh', 'alpha': 2.777113291665645e-05, 'batch_size': 256, 'learning_rate_init': 0.0010083800535217401, 'max_iter': 214}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:05,328] Trial 158 finished with value: 0.5795918367346938 and parameters: {'n_layers': 1, 'width1': 442, 'activation': 'tanh', 'alpha': 0.00015405818781527805, 'batch_size': 256, 'learning_rate_init': 0.000664233631457093, 'max_iter': 177}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:06,117] Trial 159 finished with value: 0.5474452554744526 and parameters: {'n_layers': 1, 'width1': 67, 'activation': 'tanh', 'alpha': 0.0008620617404817457, 'batch_size': 256, 'learning_rate_init': 0.006121264075069227, 'max_iter': 228}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:07,329] Trial 160 finished with value: 0.5910931174089069 and parameters: {'n_layers': 1, 'width1': 354, 'activation': 'tanh', 'alpha': 0.0006396743177838497, 'batch_size': 256, 'learning_rate_init': 0.015587865724057738, 'max_iter': 166}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:08,690] Trial 161 finished with value: 0.5740740740740741 and parameters: {'n_layers': 1, 'width1': 102, 'activation': 'tanh', 'alpha': 0.00029165462963319315, 'batch_size': 512, 'learning_rate_init': 0.0003066081155828933, 'max_iter': 191}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:09,613] Trial 162 finished with value: 0.5794392523364486 and parameters: {'n_layers': 1, 'width1': 75, 'activation': 'tanh', 'alpha': 0.00041540737102455604, 'batch_size': 512, 'learning_rate_init': 0.0001506433583914263, 'max_iter': 199}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:11,444] Trial 163 finished with value: 0.5984848484848485 and parameters: {'n_layers': 1, 'width1': 247, 'activation': 'tanh', 'alpha': 0.00023405801184876772, 'batch_size': 512, 'learning_rate_init': 0.0008239306509062904, 'max_iter': 183}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:12,521] Trial 164 finished with value: 0.5690376569037657 and parameters: {'n_layers': 1, 'width1': 46, 'activation': 'tanh', 'alpha': 0.00036006154139957817, 'batch_size': 512, 'learning_rate_init': 0.00036427469461494655, 'max_iter': 328}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:14,320] Trial 165 finished with value: 0.5907172995780591 and parameters: {'n_layers': 1, 'width1': 115, 'activation': 'tanh', 'alpha': 0.0001742795696250886, 'batch_size': 512, 'learning_rate_init': 0.0014367535522997739, 'max_iter': 359}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:18,078] Trial 166 finished with value: 0.5799256505576208 and parameters: {'n_layers': 1, 'width1': 409, 'activation': 'tanh', 'alpha': 0.0006343547596675073, 'batch_size': 256, 'learning_rate_init': 0.00010955504017803023, 'max_iter': 288}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:20,904] Trial 167 finished with value: 0.5860805860805861 and parameters: {'n_layers': 1, 'width1': 153, 'activation': 'tanh', 'alpha': 0.0004660161668808775, 'batch_size': 128, 'learning_rate_init': 0.00041758010898894186, 'max_iter': 299}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:25,827] Trial 168 finished with value: 0.592 and parameters: {'n_layers': 1, 'width1': 512, 'activation': 'tanh', 'alpha': 0.00029785198531581653, 'batch_size': 64, 'learning_rate_init': 0.00019349188442480215, 'max_iter': 141}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:26,597] Trial 169 finished with value: 0.5970149253731343 and parameters: {'n_layers': 1, 'width1': 60, 'activation': 'tanh', 'alpha': 7.020152426907133e-05, 'batch_size': 256, 'learning_rate_init': 0.0016458825026459448, 'max_iter': 128}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:29,772] Trial 170 finished with value: 0.5537459283387622 and parameters: {'n_layers': 1, 'width1': 468, 'activation': 'relu', 'alpha': 0.0007913040884038054, 'batch_size': 512, 'learning_rate_init': 0.000489497812538545, 'max_iter': 206}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:31,776] Trial 171 finished with value: 0.596078431372549 and parameters: {'n_layers': 1, 'width1': 256, 'activation': 'tanh', 'alpha': 0.0002094966124648302, 'batch_size': 512, 'learning_rate_init': 0.0005770366793689407, 'max_iter': 182}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:33,632] Trial 172 finished with value: 0.6042553191489362 and parameters: {'n_layers': 1, 'width1': 230, 'activation': 'tanh', 'alpha': 0.00025928708604597544, 'batch_size': 512, 'learning_rate_init': 0.0008255449581141456, 'max_iter': 193}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:36,645] Trial 173 finished with value: 0.5851851851851851 and parameters: {'n_layers': 1, 'width1': 430, 'activation': 'tanh', 'alpha': 0.0002508837105960768, 'batch_size': 512, 'learning_rate_init': 0.0007405120046881021, 'max_iter': 193}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:39,496] Trial 174 finished with value: 0.5983606557377049 and parameters: {'n_layers': 1, 'width1': 218, 'activation': 'tanh', 'alpha': 0.00037434007714676144, 'batch_size': 512, 'learning_rate_init': 0.0009469416079928464, 'max_iter': 384}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:41,032] Trial 175 finished with value: 0.5806451612903226 and parameters: {'n_layers': 1, 'width1': 169, 'activation': 'tanh', 'alpha': 0.0010563107943920252, 'batch_size': 512, 'learning_rate_init': 0.0012574527685941777, 'max_iter': 214}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:42,023] Trial 176 finished with value: 0.5655172413793104 and parameters: {'n_layers': 1, 'width1': 87, 'activation': 'tanh', 'alpha': 0.00014942950990824128, 'batch_size': 256, 'learning_rate_init': 0.0010075299627069143, 'max_iter': 171}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:43,148] Trial 177 finished with value: 0.5891472868217055 and parameters: {'n_layers': 1, 'width1': 198, 'activation': 'tanh', 'alpha': 0.0005612984251661607, 'batch_size': 256, 'learning_rate_init': 0.012916759659640745, 'max_iter': 276}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:45,703] Trial 178 finished with value: 0.5897435897435898 and parameters: {'n_layers': 1, 'width1': 375, 'activation': 'tanh', 'alpha': 0.00019131886454399152, 'batch_size': 256, 'learning_rate_init': 0.0011110332485983383, 'max_iter': 196}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:47,127] Trial 179 finished with value: 0.5826771653543307 and parameters: {'n_layers': 1, 'width1': 282, 'activation': 'tanh', 'alpha': 0.00010655430452776369, 'batch_size': 512, 'learning_rate_init': 0.0008299397200997202, 'max_iter': 108}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:48,790] Trial 180 finished with value: 0.5641025641025641 and parameters: {'n_layers': 1, 'width1': 128, 'activation': 'tanh', 'alpha': 0.000292934583214922, 'batch_size': 256, 'learning_rate_init': 0.00012722468075404423, 'max_iter': 220}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:50,672] Trial 181 finished with value: 0.5803921568627451 and parameters: {'n_layers': 1, 'width1': 237, 'activation': 'tanh', 'alpha': 0.0002250243466677565, 'batch_size': 512, 'learning_rate_init': 0.0007699322647953064, 'max_iter': 187}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:52,390] Trial 182 finished with value: 0.5783132530120482 and parameters: {'n_layers': 1, 'width1': 229, 'activation': 'tanh', 'alpha': 0.00024678801600834, 'batch_size': 512, 'learning_rate_init': 0.0006443125492038672, 'max_iter': 180}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:55,000] Trial 183 finished with value: 0.5754385964912281 and parameters: {'n_layers': 1, 'width1': 255, 'activation': 'tanh', 'alpha': 0.00013583512478613992, 'batch_size': 512, 'learning_rate_init': 0.0008851298143416335, 'max_iter': 201}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:30:57,029] Trial 184 finished with value: 0.5771812080536913 and parameters: {'n_layers': 1, 'width1': 246, 'activation': 'tanh', 'alpha': 0.00018714922306860022, 'batch_size': 512, 'learning_rate_init': 0.0012595563726381814, 'max_iter': 208}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:00,183] Trial 185 finished with value: 0.5928853754940712 and parameters: {'n_layers': 1, 'width1': 454, 'activation': 'tanh', 'alpha': 0.0003393835165503948, 'batch_size': 512, 'learning_rate_init': 0.0008180816705445107, 'max_iter': 189}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:02,252] Trial 186 finished with value: 0.6022304832713755 and parameters: {'n_layers': 1, 'width1': 203, 'activation': 'tanh', 'alpha': 0.00041608670603984586, 'batch_size': 256, 'learning_rate_init': 0.0010727219613781143, 'max_iter': 194}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:05,528] Trial 187 finished with value: 0.5836575875486382 and parameters: {'n_layers': 1, 'width1': 321, 'activation': 'tanh', 'alpha': 0.0007460825418545693, 'batch_size': 256, 'learning_rate_init': 0.0010498644624496562, 'max_iter': 316}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:06,804] Trial 188 finished with value: 0.5863453815261044 and parameters: {'n_layers': 1, 'width1': 196, 'activation': 'tanh', 'alpha': 0.00041001598594202736, 'batch_size': 256, 'learning_rate_init': 0.0051906082260770176, 'max_iter': 194}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:08,749] Trial 189 finished with value: 0.6016260162601627 and parameters: {'n_layers': 2, 'width1': 54, 'width2': 37, 'activation': 'tanh', 'alpha': 0.0004827404769371325, 'batch_size': 256, 'learning_rate_init': 0.0011799473411288587, 'max_iter': 202}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:10,154] Trial 190 finished with value: 0.6007067137809188 and parameters: {'n_layers': 1, 'width1': 64, 'activation': 'tanh', 'alpha': 0.0005326759878316721, 'batch_size': 256, 'learning_rate_init': 0.003584054068894144, 'max_iter': 204}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:11,578] Trial 191 finished with value: 0.5523012552301255 and parameters: {'n_layers': 2, 'width1': 62, 'width2': 35, 'activation': 'tanh', 'alpha': 0.0004979893435543427, 'batch_size': 256, 'learning_rate_init': 0.0033039203398864563, 'max_iter': 256}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:12,636] Trial 192 finished with value: 0.5857740585774058 and parameters: {'n_layers': 2, 'width1': 56, 'width2': 48, 'activation': 'tanh', 'alpha': 0.0005687193543594384, 'batch_size': 256, 'learning_rate_init': 0.004284075691067547, 'max_iter': 206}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:14,544] Trial 193 finished with value: 0.5258964143426295 and parameters: {'n_layers': 2, 'width1': 70, 'width2': 25, 'activation': 'tanh', 'alpha': 0.0009628811487528566, 'batch_size': 256, 'learning_rate_init': 0.0013456181159293775, 'max_iter': 202}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:16,599] Trial 194 finished with value: 0.5569620253164557 and parameters: {'n_layers': 2, 'width1': 69, 'width2': 29, 'activation': 'tanh', 'alpha': 0.0006344271780183972, 'batch_size': 256, 'learning_rate_init': 0.0011321893155065382, 'max_iter': 262}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:17,886] Trial 195 finished with value: 0.575 and parameters: {'n_layers': 2, 'width1': 53, 'width2': 42, 'activation': 'tanh', 'alpha': 0.0004527405551237405, 'batch_size': 256, 'learning_rate_init': 0.003834439848148521, 'max_iter': 197}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:19,361] Trial 196 finished with value: 0.580952380952381 and parameters: {'n_layers': 2, 'width1': 48, 'width2': 61, 'activation': 'tanh', 'alpha': 0.0008072762475473557, 'batch_size': 256, 'learning_rate_init': 0.0019274236482064546, 'max_iter': 211}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:22,211] Trial 197 finished with value: 0.5910931174089069 and parameters: {'n_layers': 1, 'width1': 409, 'activation': 'tanh', 'alpha': 0.000317158680175108, 'batch_size': 256, 'learning_rate_init': 0.002552201840045696, 'max_iter': 201}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:23,608] Trial 198 finished with value: 0.582089552238806 and parameters: {'n_layers': 1, 'width1': 43, 'activation': 'tanh', 'alpha': 0.0003824186917970364, 'batch_size': 256, 'learning_rate_init': 0.002994718487746405, 'max_iter': 192}. Best is trial 46 with value: 0.6153846153846154.\n",
      "[I 2025-09-01 11:31:24,371] Trial 199 finished with value: 0.5818181818181818 and parameters: {'n_layers': 1, 'width1': 62, 'activation': 'tanh', 'alpha': 0.0007007666744819316, 'batch_size': 256, 'learning_rate_init': 0.007635456239255501, 'max_iter': 216}. Best is trial 46 with value: 0.6153846153846154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Optuna Best (VAL after threshold, MLP) ====\n",
      "Best F1: 0.6153846153846154\n",
      "Best params: {'n_layers': 1, 'width1': 64, 'activation': 'tanh', 'alpha': 0.0003814230681365873, 'batch_size': 256, 'learning_rate_init': 0.0006364423361256918, 'max_iter': 256}\n",
      "Best VAL thr: 0.24000000000000002\n",
      "Best VAL P/R: 0.5033112582781457 0.7916666666666666\n",
      "\n",
      "[Threshold] F1-opt on VAL: t=0.010, F1=0.5489, P=0.4294, R=0.7604\n",
      "[Threshold] Constraint on VAL (P>=0.60): t=0.500, P=0.4896, R=0.4896, F1=0.4896\n",
      "[Threshold] Target PosRate≈10% on VAL: t=0.990, pos_rate=0.1423, P=0.5385, R=0.2188\n",
      "\n",
      "==== Test Performance (held-out, with chosen threshold, MLP) ====\n",
      "AUC:           0.582170\n",
      "AveragePrecision(PR-AUC): 0.477773\n",
      "LogLoss:       1.841902\n",
      "Accuracy:      0.507289\n",
      "Precision@t*:  0.440000\n",
      "Recall@t*:     0.791367\n",
      "F1@t*:         0.565553\n",
      "(t* chosen on VAL: 0.010)\n",
      "\n",
      "Score PSI (TrainFit→Val):  1.0971\n",
      "Score PSI (TrainFit→Test): 1.4550\n"
     ]
    }
   ],
   "source": [
    "# ========= 全量可运行脚本：漂移检查 + 阈值策略 + 贝叶斯超参搜索（MLP 版，scikit-learn） =========\n",
    "# 依赖：\n",
    "#   pip install numpy pandas scipy scikit-learn optuna\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, log_loss\n",
    ")\n",
    "import optuna\n",
    "\n",
    "# ========= 公共工具 =========\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def safe_auc(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# ========= 0) 漂移/PSI 工具 =========\n",
    "\n",
    "def psi_for_series(train_s: pd.Series, test_s: pd.Series, bins=10):\n",
    "    train_s = pd.to_numeric(train_s, errors='coerce')\n",
    "    test_s  = pd.to_numeric(test_s,  errors='coerce')\n",
    "    tr = train_s.dropna(); te = test_s.dropna()\n",
    "    if tr.empty or te.empty:\n",
    "        return np.nan\n",
    "    quantiles = np.linspace(0, 1, bins + 1)\n",
    "    cuts = np.unique(np.nanquantile(tr, quantiles))\n",
    "    if len(cuts) <= 2:\n",
    "        return np.nan\n",
    "    tr_bins = pd.cut(train_s, bins=cuts, include_lowest=True)\n",
    "    te_bins = pd.cut(test_s,  bins=cuts, include_lowest=True)\n",
    "    tr_ratio = tr_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_bins.value_counts(normalize=True).sort_index()\n",
    "    te_ratio = te_ratio.reindex(tr_ratio.index).fillna(0.0)\n",
    "    tr_ratio = tr_ratio.fillna(0.0)\n",
    "    tr_ratio = tr_ratio.replace(0, 1e-8)\n",
    "    te_ratio = te_ratio.replace(0, 1e-8)\n",
    "    psi = np.sum((te_ratio - tr_ratio) * np.log(te_ratio / tr_ratio))\n",
    "    return float(psi)\n",
    "\n",
    "def cat_psi(train_s: pd.Series, test_s: pd.Series):\n",
    "    tr_p = train_s.value_counts(normalize=True)\n",
    "    te_p = test_s.value_counts(normalize=True)\n",
    "    idx = tr_p.index.union(te_p.index)\n",
    "    tr_p = tr_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    te_p = te_p.reindex(idx).fillna(0.0).replace(0, 1e-8)\n",
    "    psi = np.sum((te_p - tr_p) * np.log(te_p / tr_p))\n",
    "    return float(psi)\n",
    "\n",
    "def two_sample_drift(train_s: pd.Series, test_s: pd.Series, is_categorical=False):\n",
    "    if is_categorical:\n",
    "        idx = pd.Index(pd.concat([train_s.astype(str), test_s.astype(str)], ignore_index=True).unique())\n",
    "        tr_counts = train_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        te_counts = test_s.astype(str).value_counts().reindex(idx, fill_value=0).astype(float)\n",
    "        table = np.vstack([tr_counts.values, te_counts.values])\n",
    "        try:\n",
    "            chi2, p, dof, exp = chi2_contingency(table)\n",
    "        except ValueError:\n",
    "            p = 1.0\n",
    "        return {\"stat\": None, \"pvalue\": float(p)}\n",
    "    else:\n",
    "        tr = pd.to_numeric(train_s, errors='coerce').dropna()\n",
    "        te = pd.to_numeric(test_s,  errors='coerce').dropna()\n",
    "        if len(tr) < 2 or len(te) < 2:\n",
    "            return {\"stat\": None, \"pvalue\": np.nan}\n",
    "        ks = ks_2samp(tr, te, alternative='two-sided', mode='auto')\n",
    "        return {\"stat\": float(ks.statistic), \"pvalue\": float(ks.pvalue)}\n",
    "\n",
    "def drift_report(df_ref: pd.DataFrame, df_new: pd.DataFrame,\n",
    "                 categorical_cols=None, topk=15):\n",
    "    categorical_cols = set(categorical_cols or [])\n",
    "    rows = []\n",
    "    for c in df_ref.columns:\n",
    "        is_cat = c in categorical_cols or (df_ref[c].dtype.name in [\"category\", \"object\"])\n",
    "        psi = cat_psi(df_ref[c], df_new[c]) if is_cat else psi_for_series(df_ref[c], df_new[c])\n",
    "        stat = two_sample_drift(df_ref[c], df_new[c], is_categorical=is_cat)\n",
    "        miss_ref = df_ref[c].isna().mean()\n",
    "        miss_new = df_new[c].isna().mean()\n",
    "        rows.append({\n",
    "            \"feature\": c,\n",
    "            \"is_categorical\": is_cat,\n",
    "            \"PSI\": psi,\n",
    "            \"KS/Chi2_p\": stat[\"pvalue\"],\n",
    "            \"KS_stat\": stat[\"stat\"],\n",
    "            \"missing_ref\": miss_ref,\n",
    "            \"missing_new\": miss_new,\n",
    "            \"missing_diff\": miss_new - miss_ref,\n",
    "        })\n",
    "    rep = pd.DataFrame(rows)\n",
    "    rep = rep.sort_values(by=[\"PSI\", \"KS/Chi2_p\"], ascending=[False, True]).reset_index(drop=True)\n",
    "    return rep.iloc[:topk]\n",
    "\n",
    "def score_psi(ref_scores, new_scores, bins=10):\n",
    "    return psi_for_series(pd.Series(ref_scores), pd.Series(new_scores), bins=bins)\n",
    "\n",
    "# ========= 1) 阈值策略 =========\n",
    "\n",
    "def choose_threshold(\n",
    "    y_true, y_prob,\n",
    "    method=\"f1\",                # \"f1\" | \"youden\" | \"constraint\" | \"posrate\"\n",
    "    grid=None,\n",
    "    min_precision=None,\n",
    "    min_recall=None,\n",
    "    target_pos_rate=None\n",
    "):\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.01, 0.99, 99)\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    out_rows = []\n",
    "    best_thr, best_key = 0.5, (-1e9, -1e9)\n",
    "\n",
    "    for t in grid:\n",
    "        pred = (y_prob >= t).astype(int)\n",
    "        P  = precision_score(y_true, pred, zero_division=0)\n",
    "        R  = recall_score(y_true, pred, zero_division=0)\n",
    "        F1 = f1_score(y_true, pred, zero_division=0)\n",
    "        tn = np.sum((pred==0)&(y_true==0))\n",
    "        fp = np.sum((pred==1)&(y_true==0))\n",
    "        fn = np.sum((pred==0)&(y_true==1))\n",
    "        tp = np.sum((pred==1)&(y_true==1))\n",
    "        TNR = tn / max(1, (tn+fp))\n",
    "        J = R + TNR - 1\n",
    "        pos_rate = pred.mean()\n",
    "\n",
    "        out_rows.append({\"thr\": t, \"precision\": P, \"recall\": R, \"f1\": F1,\n",
    "                         \"youdenJ\": J, \"pos_rate\": pos_rate, \"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn})\n",
    "\n",
    "        if method == \"f1\":\n",
    "            key = (F1, 0.0)\n",
    "        elif method == \"youden\":\n",
    "            key = (J, 0.0)\n",
    "        elif method == \"posrate\" and target_pos_rate is not None:\n",
    "            key = (-abs(pos_rate - target_pos_rate), 0.0)\n",
    "        elif method == \"constraint\":\n",
    "            if (min_precision is not None and P < min_precision) or (min_recall is not None and R < min_recall):\n",
    "                key = (-1e9, -1e9)\n",
    "            else:\n",
    "                key = (R, F1)  # 先比 Recall，再比 F1\n",
    "        else:\n",
    "            key = (F1, 0.0)\n",
    "\n",
    "        if key > best_key:\n",
    "            best_key = key\n",
    "            best_thr = t\n",
    "\n",
    "    table = pd.DataFrame(out_rows).sort_values(\"thr\").reset_index(drop=True)\n",
    "    best_row = table.loc[table[\"thr\"].sub(best_thr).abs().idxmin()].to_dict()\n",
    "    return float(best_thr), best_row, table\n",
    "\n",
    "# ========= 2) 数据准备（日期阈值 / 比例切分） =========\n",
    "\n",
    "def temporal_split(df_clean: pd.DataFrame,\n",
    "                   label_col=\"value_sort\",\n",
    "                   cutoff_date=None,\n",
    "                   test_size_ratio=0.2,\n",
    "                   val_size_ratio=0.2):\n",
    "    assert label_col in df_clean.columns\n",
    "    df = df_clean.copy().sort_index()\n",
    "\n",
    "    feat_cols = df.columns.drop([label_col]).tolist()\n",
    "    X_all = df[feat_cols].values\n",
    "    y_all = df[label_col].astype(int).values\n",
    "\n",
    "    if cutoff_date is not None:\n",
    "        assert isinstance(df.index, pd.DatetimeIndex), \"需 DatetimeIndex 才能按日期切分\"\n",
    "        mask_trainval = (df.index <= pd.to_datetime(cutoff_date))\n",
    "        X_trainval, y_trainval = X_all[mask_trainval], y_all[mask_trainval]\n",
    "        X_test, y_test = X_all[~mask_trainval], y_all[~mask_trainval]\n",
    "\n",
    "        n_tv = len(X_trainval)\n",
    "        n_val = max(1, int(n_tv * val_size_ratio))\n",
    "        X_tr, y_tr = X_trainval[:-n_val], y_trainval[:-n_val]\n",
    "        X_val, y_val = X_trainval[-n_val:], y_trainval[-n_val:]\n",
    "        return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "    N = len(X_all)\n",
    "    n_test = max(1, int(N * test_size_ratio))\n",
    "    X_tv, y_tv = X_all[:-n_test], y_all[:-n_test]\n",
    "    X_test, y_test = X_all[-n_test:], y_all[-n_test:]\n",
    "\n",
    "    n_tv = len(X_tv)\n",
    "    n_val = max(1, int(n_tv * val_size_ratio))\n",
    "    X_tr, y_tr = X_tv[:-n_val], y_tv[:-n_val]\n",
    "    X_val, y_val = X_tv[-n_val:], y_tv[-n_val:]\n",
    "    return X_tr, y_tr, X_val, y_val, X_test, y_test, feat_cols\n",
    "\n",
    "# ========= 3) 训练/预测封装（MLP） =========\n",
    "\n",
    "def train_mlp_classifier(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    params,\n",
    "    use_balanced_weight=True,\n",
    "    random_state=42\n",
    "):\n",
    "    # 计算训练样本权重（缓解不平衡）\n",
    "    sample_weight = None\n",
    "    if use_balanced_weight:\n",
    "        sample_weight = compute_sample_weight(class_weight='balanced', y=y_tr)\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=params.get(\"hidden_layer_sizes\", (128, 64)),\n",
    "        activation=params.get(\"activation\", \"relu\"),\n",
    "        solver=\"adam\",\n",
    "        alpha=params.get(\"alpha\", 1e-4),                 # L2\n",
    "        batch_size=params.get(\"batch_size\", 128),\n",
    "        learning_rate_init=params.get(\"learning_rate_init\", 1e-3),\n",
    "        beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
    "        max_iter=params.get(\"max_iter\", 200),\n",
    "        tol=1e-4, early_stopping=False,                   # 早停由外部验证集控制\n",
    "        random_state=random_state,\n",
    "        verbose=False\n",
    "    )\n",
    "    clf.fit(X_tr, y_tr, sample_weight=sample_weight)\n",
    "    return clf\n",
    "\n",
    "def predict_proba_mlp(clf, X):\n",
    "    # 返回正类概率\n",
    "    proba = clf.predict_proba(X)\n",
    "    if proba.ndim == 2 and proba.shape[1] == 2:\n",
    "        return proba[:, 1]\n",
    "    # 二分类容错\n",
    "    return proba.ravel()\n",
    "\n",
    "# ========= 4) Optuna + MLP 搜索 =========\n",
    "\n",
    "def run_optuna_mlp(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    n_trials=50, method_for_thr=\"f1\",\n",
    "    constraint_min_precision=None, constraint_min_recall=None,\n",
    "    target_pos_rate=None,\n",
    "    random_state=42\n",
    "):\n",
    "    # 先拟合 scaler（避免泄露：仅用训练拟合，在 val transform）\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_std  = scaler.fit_transform(X_tr)\n",
    "    X_val_std = scaler.transform(X_val)\n",
    "\n",
    "    def objective(trial):\n",
    "        # 采样 MLP 超参\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "        width1 = trial.suggest_int(\"width1\", 32, 512, log=True)\n",
    "        sizes = [width1]\n",
    "        for i in range(2, n_layers+1):\n",
    "            sizes.append(trial.suggest_int(f\"width{i}\", 16, 512, log=True))\n",
    "        hidden = tuple(sizes)\n",
    "\n",
    "        params = {\n",
    "            \"hidden_layer_sizes\": hidden,\n",
    "            \"activation\": trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 1e-2, log=True),\n",
    "            \"batch_size\": trial.suggest_categorical(\"batch_size\", [64, 128, 256, 512]),\n",
    "            \"learning_rate_init\": trial.suggest_float(\"learning_rate_init\", 1e-4, 3e-2, log=True),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 100, 400)\n",
    "        }\n",
    "\n",
    "        clf = train_mlp_classifier(\n",
    "            X_tr_std, y_tr, X_val_std, y_val,\n",
    "            params=params, random_state=random_state\n",
    "        )\n",
    "\n",
    "        val_prob = predict_proba_mlp(clf, X_val_std)\n",
    "\n",
    "        # 验证集上选阈值并返回目标指标\n",
    "        if method_for_thr == \"constraint\":\n",
    "            thr, row, _ = choose_threshold(\n",
    "                y_val, val_prob, method=\"constraint\",\n",
    "                min_precision=constraint_min_precision, min_recall=constraint_min_recall\n",
    "            )\n",
    "        elif method_for_thr == \"posrate\":\n",
    "            thr, row, _ = choose_threshold(\n",
    "                y_val, val_prob, method=\"posrate\", target_pos_rate=target_pos_rate\n",
    "            )\n",
    "        elif method_for_thr == \"youden\":\n",
    "            thr, row, _ = choose_threshold(y_val, val_prob, method=\"youden\")\n",
    "        else:  # \"f1\"\n",
    "            thr, row, _ = choose_threshold(y_val, val_prob, method=\"f1\")\n",
    "\n",
    "        trial.set_user_attr(\"thr\", thr)\n",
    "        trial.set_user_attr(\"P\", row[\"precision\"])\n",
    "        trial.set_user_attr(\"R\", row[\"recall\"])\n",
    "        return float(row[\"f1\"])\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "# ========= 5) 主流程 =========\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ======= 读取/准备数据 =======\n",
    "    # 你需要自行提供 df_clean（含列 value_sort，索引建议 DatetimeIndex）\n",
    "    # 例：\n",
    "    # df_clean = pd.read_csv(\"your_data.csv\", parse_dates=[\"date\"], index_col=\"date\")\n",
    "    # assert \"value_sort\" in df_clean.columns\n",
    "\n",
    "    # ======= 切分：按比例或 cutoff_date =======\n",
    "    cutoff_date = None  # 例如 \"2024-12-31\"\n",
    "    X_tr_fit_raw, y_tr_fit, X_val_fit_raw, y_val_fit, X_te_raw, y_te, feat_cols = temporal_split(\n",
    "        df_clean, label_col=\"value_sort\", cutoff_date=cutoff_date,\n",
    "        test_size_ratio=0.2, val_size_ratio=0.2\n",
    "    )\n",
    "\n",
    "    # ======= 漂移检查（TrainFit vs Test）——用原尺度 =======\n",
    "    df_tr_fit = pd.DataFrame(X_tr_fit_raw, columns=feat_cols)\n",
    "    df_val    = pd.DataFrame(X_val_fit_raw, columns=feat_cols)\n",
    "    df_te     = pd.DataFrame(X_te_raw,     columns=feat_cols)\n",
    "\n",
    "    rep_tr_te = drift_report(df_tr_fit, df_te, categorical_cols=[], topk=30)\n",
    "    print(\"\\n==== Top Drifted Features (TrainFit vs Test) ====\")\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    print(rep_tr_te.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "    # ======= Optuna 搜索（在验证集“找阈值后的F1”）=======\n",
    "    study = run_optuna_mlp(\n",
    "        X_tr_fit_raw, y_tr_fit,\n",
    "        X_val_fit_raw, y_val_fit,\n",
    "        n_trials=200,                   # MLP相对慢，200~300 视资源调整\n",
    "        method_for_thr=\"f1\",            # 可改 \"youden\" / \"constraint\" / \"posrate\"\n",
    "        constraint_min_precision=None,\n",
    "        constraint_min_recall=None,\n",
    "        target_pos_rate=None\n",
    "    )\n",
    "\n",
    "    print(\"\\n==== Optuna Best (VAL after threshold, MLP) ====\")\n",
    "    print(\"Best F1:\", study.best_value)\n",
    "    print(\"Best params:\", study.best_trial.params)\n",
    "    print(\"Best VAL thr:\", study.best_trial.user_attrs.get(\"thr\"))\n",
    "    print(\"Best VAL P/R:\", study.best_trial.user_attrs.get(\"P\"), study.best_trial.user_attrs.get(\"R\"))\n",
    "\n",
    "    # ======= 用最优参数重新训练（在 TrainFit 上），VAL 选“生产阈值” =======\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    # 标准化：仅在训练拟合\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_fit = scaler.fit_transform(X_tr_fit_raw)\n",
    "    X_val_fit = scaler.transform(X_val_fit_raw)\n",
    "    X_te      = scaler.transform(X_te_raw)\n",
    "\n",
    "    final_clf = train_mlp_classifier(\n",
    "        X_tr_fit, y_tr_fit, X_val_fit, y_val_fit,\n",
    "        params=best_params, random_state=42\n",
    "    )\n",
    "\n",
    "    # 验证集上选“生产用阈值”\n",
    "    val_prob = predict_proba_mlp(final_clf, X_val_fit)\n",
    "    thr_f1, row_f1, table_f1 = choose_threshold(y_val_fit, val_prob, method=\"f1\")\n",
    "    print(f\"\\n[Threshold] F1-opt on VAL: t={thr_f1:.3f}, F1={row_f1['f1']:.4f}, \"\n",
    "          f\"P={row_f1['precision']:.4f}, R={row_f1['recall']:.4f}\")\n",
    "\n",
    "    # 示例2：约束策略\n",
    "    thr_cons, row_cons, _ = choose_threshold(\n",
    "        y_val_fit, val_prob, method=\"constraint\", min_precision=0.60\n",
    "    )\n",
    "    print(f\"[Threshold] Constraint on VAL (P>=0.60): t={thr_cons:.3f}, \"\n",
    "          f\"P={row_cons['precision']:.4f}, R={row_cons['recall']:.4f}, F1={row_cons['f1']:.4f}\")\n",
    "\n",
    "    # 示例3：指定阳性率≈10%\n",
    "    thr_pr, row_pr, _ = choose_threshold(\n",
    "        y_val_fit, val_prob, method=\"posrate\", target_pos_rate=0.10\n",
    "    )\n",
    "    print(f\"[Threshold] Target PosRate≈10% on VAL: t={thr_pr:.3f}, \"\n",
    "          f\"pos_rate={row_pr['pos_rate']:.4f}, P={row_pr['precision']:.4f}, R={row_pr['recall']:.4f}\")\n",
    "\n",
    "    # 选择一个作为生产阈值（这里选 F1-opt）\n",
    "    chosen_thr = thr_f1\n",
    "\n",
    "    # ======= 测试集评估（固定 chosen_thr） =======\n",
    "    y_te_prob = predict_proba_mlp(final_clf, X_te)\n",
    "    y_te_pred = (y_te_prob >= chosen_thr).astype(int)\n",
    "\n",
    "    test_auc  = safe_auc(y_te, y_te_prob)\n",
    "    test_ap   = average_precision_score(y_te, y_te_prob) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_logloss = log_loss(y_te, np.vstack([1 - y_te_prob, y_te_prob]).T, labels=[0,1]) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    test_acc  = accuracy_score(y_te, y_te_pred)\n",
    "    test_prec = precision_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_rec  = recall_score(y_te, y_te_pred, zero_division=0)\n",
    "    test_f1   = f1_score(y_te, y_te_pred, zero_division=0)\n",
    "\n",
    "    print(\"\\n==== Test Performance (held-out, with chosen threshold, MLP) ====\")\n",
    "    print(f\"AUC:           {test_auc:.6f}\")\n",
    "    print(f\"AveragePrecision(PR-AUC): {test_ap:.6f}\")\n",
    "    print(f\"LogLoss:       {test_logloss:.6f}\")\n",
    "    print(f\"Accuracy:      {test_acc:.6f}\")\n",
    "    print(f\"Precision@t*:  {test_prec:.6f}\")\n",
    "    print(f\"Recall@t*:     {test_rec:.6f}\")\n",
    "    print(f\"F1@t*:         {test_f1:.6f}\")\n",
    "    print(f\"(t* chosen on VAL: {chosen_thr:.3f})\")\n",
    "\n",
    "    # ======= 分数 PSI（可选） =======\n",
    "    tr_scores  = predict_proba_mlp(final_clf, X_tr_fit)\n",
    "    val_scores = val_prob\n",
    "    te_scores  = y_te_prob\n",
    "    print(\"\\nScore PSI (TrainFit→Val): \", f\"{score_psi(tr_scores, val_scores):.4f}\")\n",
    "    print(\"Score PSI (TrainFit→Test):\", f\"{score_psi(tr_scores, te_scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lau",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
